// $ANTLR 3.5.2 org/apache/hadoop/hive/ql/parse/HiveParser.g 2019-11-19 07:53:49

package org.apache.hadoop.hive.ql.parse;

import java.util.Arrays;
import java.util.Collection;
import java.util.HashMap;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hive.conf.HiveConf;


import org.antlr.runtime.*;
import java.util.Stack;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;

import org.antlr.runtime.tree.*;


/**
   Licensed to the Apache Software Foundation (ASF) under one or more 
   contributor license agreements.  See the NOTICE file distributed with 
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with 
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
*/
@SuppressWarnings("all")
public class HiveParser extends Parser {
	public static final String[] tokenNames = new String[] {
		"<invalid>", "<EOR>", "<DOWN>", "<UP>", "AMPERSAND", "BITWISEOR", "BITWISEXOR", 
		"ByteLengthLiteral", "COLON", "COMMA", "CONCATENATE", "CharSetLiteral", 
		"CharSetName", "DIV", "DIVIDE", "DOLLAR", "DOT", "Digit", "EQUAL", "EQUAL_NS", 
		"Exponent", "GREATERTHAN", "GREATERTHANOREQUALTO", "HexDigit", "Identifier", 
		"IntegralLiteral", "KW_ABORT", "KW_ACTIVATE", "KW_ACTIVE", "KW_ADD", "KW_ADMIN", 
		"KW_AFTER", "KW_ALL", "KW_ALLOC_FRACTION", "KW_ALTER", "KW_ANALYZE", "KW_AND", 
		"KW_ANY", "KW_APPLICATION", "KW_ARCHIVE", "KW_ARRAY", "KW_AS", "KW_ASC", 
		"KW_AUTHORIZATION", "KW_AUTOCOMMIT", "KW_BEFORE", "KW_BETWEEN", "KW_BIGINT", 
		"KW_BINARY", "KW_BOOLEAN", "KW_BOTH", "KW_BUCKET", "KW_BUCKETS", "KW_BY", 
		"KW_CACHE", "KW_CASCADE", "KW_CASE", "KW_CAST", "KW_CBO", "KW_CHANGE", 
		"KW_CHAR", "KW_CHECK", "KW_CLUSTER", "KW_CLUSTERED", "KW_CLUSTERSTATUS", 
		"KW_COLLECTION", "KW_COLUMN", "KW_COLUMNS", "KW_COMMENT", "KW_COMMIT", 
		"KW_COMPACT", "KW_COMPACTIONS", "KW_COMPUTE", "KW_CONCATENATE", "KW_CONF", 
		"KW_CONSTRAINT", "KW_CONTINUE", "KW_COST", "KW_CREATE", "KW_CROSS", "KW_CUBE", 
		"KW_CURRENT", "KW_CURRENT_DATE", "KW_CURRENT_TIMESTAMP", "KW_CURSOR", 
		"KW_DATA", "KW_DATABASE", "KW_DATABASES", "KW_DATE", "KW_DATETIME", "KW_DAY", 
		"KW_DBPROPERTIES", "KW_DEBUG", "KW_DECIMAL", "KW_DEFAULT", "KW_DEFERRED", 
		"KW_DEFINED", "KW_DELETE", "KW_DELIMITED", "KW_DEPENDENCY", "KW_DESC", 
		"KW_DESCRIBE", "KW_DETAIL", "KW_DIRECTORIES", "KW_DIRECTORY", "KW_DISABLE", 
		"KW_DISTINCT", "KW_DISTRIBUTE", "KW_DISTRIBUTED", "KW_DO", "KW_DOUBLE", 
		"KW_DOW", "KW_DROP", "KW_DUMP", "KW_ELEM_TYPE", "KW_ELSE", "KW_ENABLE", 
		"KW_END", "KW_ENFORCED", "KW_ESCAPED", "KW_EXCEPT", "KW_EXCHANGE", "KW_EXCLUSIVE", 
		"KW_EXISTS", "KW_EXPLAIN", "KW_EXPORT", "KW_EXPRESSION", "KW_EXTENDED", 
		"KW_EXTERNAL", "KW_EXTRACT", "KW_FALSE", "KW_FETCH", "KW_FIELDS", "KW_FILE", 
		"KW_FILEFORMAT", "KW_FIRST", "KW_FLOAT", "KW_FLOOR", "KW_FOLLOWING", "KW_FOR", 
		"KW_FORCE", "KW_FOREIGN", "KW_FORMAT", "KW_FORMATTED", "KW_FROM", "KW_FULL", 
		"KW_FUNCTION", "KW_FUNCTIONS", "KW_GRANT", "KW_GROUP", "KW_GROUPING", 
		"KW_HAVING", "KW_HOUR", "KW_IDXPROPERTIES", "KW_IF", "KW_IMPORT", "KW_IN", 
		"KW_INDEX", "KW_INDEXES", "KW_INNER", "KW_INPATH", "KW_INPUTDRIVER", "KW_INPUTFORMAT", 
		"KW_INSERT", "KW_INT", "KW_INTERSECT", "KW_INTERVAL", "KW_INTO", "KW_IS", 
		"KW_ISOLATION", "KW_ITEMS", "KW_JAR", "KW_JOIN", "KW_JOINCOST", "KW_KEY", 
		"KW_KEYS", "KW_KEY_TYPE", "KW_KILL", "KW_LAST", "KW_LATERAL", "KW_LEFT", 
		"KW_LESS", "KW_LEVEL", "KW_LIKE", "KW_LIMIT", "KW_LINES", "KW_LOAD", "KW_LOCAL", 
		"KW_LOCATION", "KW_LOCK", "KW_LOCKS", "KW_LOGICAL", "KW_LONG", "KW_MACRO", 
		"KW_MANAGEMENT", "KW_MAP", "KW_MAPJOIN", "KW_MAPPING", "KW_MATCHED", "KW_MATERIALIZED", 
		"KW_MERGE", "KW_METADATA", "KW_MINUS", "KW_MINUTE", "KW_MONTH", "KW_MORE", 
		"KW_MOVE", "KW_MSCK", "KW_NONE", "KW_NORELY", "KW_NOSCAN", "KW_NOT", "KW_NOVALIDATE", 
		"KW_NULL", "KW_NULLS", "KW_OF", "KW_OFFSET", "KW_ON", "KW_ONLY", "KW_OPERATOR", 
		"KW_OPTION", "KW_OR", "KW_ORDER", "KW_OUT", "KW_OUTER", "KW_OUTPUTDRIVER", 
		"KW_OUTPUTFORMAT", "KW_OVER", "KW_OVERWRITE", "KW_OWNER", "KW_PARTITION", 
		"KW_PARTITIONED", "KW_PARTITIONS", "KW_PATH", "KW_PERCENT", "KW_PLAN", 
		"KW_PLANS", "KW_PLUS", "KW_POOL", "KW_PRECEDING", "KW_PRECISION", "KW_PRESERVE", 
		"KW_PRIMARY", "KW_PRINCIPALS", "KW_PROCEDURE", "KW_PURGE", "KW_QUARTER", 
		"KW_QUERY", "KW_QUERY_PARALLELISM", "KW_RANGE", "KW_READ", "KW_READS", 
		"KW_REBUILD", "KW_RECORDREADER", "KW_RECORDWRITER", "KW_REDUCE", "KW_REFERENCES", 
		"KW_REGEXP", "KW_RELOAD", "KW_RELY", "KW_RENAME", "KW_REOPTIMIZATION", 
		"KW_REPAIR", "KW_REPL", "KW_REPLACE", "KW_REPLICATION", "KW_RESOURCE", 
		"KW_RESTRICT", "KW_REVOKE", "KW_REWRITE", "KW_RIGHT", "KW_RLIKE", "KW_ROLE", 
		"KW_ROLES", "KW_ROLLBACK", "KW_ROLLUP", "KW_ROW", "KW_ROWS", "KW_SCHEDULING_POLICY", 
		"KW_SCHEMA", "KW_SCHEMAS", "KW_SECOND", "KW_SELECT", "KW_SEMI", "KW_SERDE", 
		"KW_SERDEPROPERTIES", "KW_SERVER", "KW_SET", "KW_SETS", "KW_SHARED", "KW_SHOW", 
		"KW_SHOW_DATABASE", "KW_SKEWED", "KW_SMALLINT", "KW_SNAPSHOT", "KW_SORT", 
		"KW_SORTED", "KW_SSL", "KW_START", "KW_STATISTICS", "KW_STATUS", "KW_STORED", 
		"KW_STREAMTABLE", "KW_STRING", "KW_STRUCT", "KW_SUMMARY", "KW_SYNC", "KW_TABLE", 
		"KW_TABLES", "KW_TABLESAMPLE", "KW_TBLPROPERTIES", "KW_TEMPORARY", "KW_TERMINATED", 
		"KW_THEN", "KW_TIME", "KW_TIMESTAMP", "KW_TIMESTAMPLOCALTZ", "KW_TINYINT", 
		"KW_TO", "KW_TOUCH", "KW_TRANSACTION", "KW_TRANSACTIONAL", "KW_TRANSACTIONS", 
		"KW_TRANSFORM", "KW_TRIGGER", "KW_TRUE", "KW_TRUNCATE", "KW_UNARCHIVE", 
		"KW_UNBOUNDED", "KW_UNDO", "KW_UNION", "KW_UNIONTYPE", "KW_UNIQUE", "KW_UNIQUEJOIN", 
		"KW_UNLOCK", "KW_UNMANAGED", "KW_UNSET", "KW_UNSIGNED", "KW_UPDATE", "KW_URI", 
		"KW_USE", "KW_USER", "KW_USING", "KW_UTC", "KW_UTCTIMESTAMP", "KW_VALIDATE", 
		"KW_VALUES", "KW_VALUE_TYPE", "KW_VARCHAR", "KW_VECTORIZATION", "KW_VIEW", 
		"KW_VIEWS", "KW_WAIT", "KW_WEEK", "KW_WHEN", "KW_WHERE", "KW_WHILE", "KW_WINDOW", 
		"KW_WITH", "KW_WORK", "KW_WORKLOAD", "KW_WRITE", "KW_YEAR", "KW_ZONE", 
		"LCURLY", "LESSTHAN", "LESSTHANOREQUALTO", "LINE_COMMENT", "LPAREN", "LSQUARE", 
		"Letter", "MINUS", "MOD", "NOTEQUAL", "Number", "NumberLiteral", "PLUS", 
		"QUERY_HINT", "QUESTION", "QuotedIdentifier", "RCURLY", "RPAREN", "RSQUARE", 
		"RegexComponent", "SEMICOLON", "STAR", "StringLiteral", "TILDE", "WS", 
		"KW_BATCH", "KW_DAYOFWEEK", "KW_HOLD_DDLTIME", "KW_IGNORE", "KW_NO_DROP", 
		"KW_OFFLINE", "KW_PROTECTION", "KW_READONLY", "KW_TIMESTAMPTZ", "TOK_ABORT_TRANSACTIONS", 
		"TOK_ACTIVATE", "TOK_ADD_TRIGGER", "TOK_ADMIN_OPTION_FOR", "TOK_ALIASLIST", 
		"TOK_ALLCOLREF", "TOK_ALLOC_FRACTION", "TOK_ALTERDATABASE_LOCATION", "TOK_ALTERDATABASE_OWNER", 
		"TOK_ALTERDATABASE_PROPERTIES", "TOK_ALTERTABLE", "TOK_ALTERTABLE_ADDCOLS", 
		"TOK_ALTERTABLE_ADDCONSTRAINT", "TOK_ALTERTABLE_ADDPARTS", "TOK_ALTERTABLE_ARCHIVE", 
		"TOK_ALTERTABLE_BUCKETS", "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION", "TOK_ALTERTABLE_CLUSTER_SORT", 
		"TOK_ALTERTABLE_COMPACT", "TOK_ALTERTABLE_DROPCONSTRAINT", "TOK_ALTERTABLE_DROPPARTS", 
		"TOK_ALTERTABLE_DROPPROPERTIES", "TOK_ALTERTABLE_EXCHANGEPARTITION", "TOK_ALTERTABLE_FILEFORMAT", 
		"TOK_ALTERTABLE_LOCATION", "TOK_ALTERTABLE_MERGEFILES", "TOK_ALTERTABLE_OWNER", 
		"TOK_ALTERTABLE_PARTCOLTYPE", "TOK_ALTERTABLE_PROPERTIES", "TOK_ALTERTABLE_RENAME", 
		"TOK_ALTERTABLE_RENAMECOL", "TOK_ALTERTABLE_RENAMEPART", "TOK_ALTERTABLE_REPLACECOLS", 
		"TOK_ALTERTABLE_SERDEPROPERTIES", "TOK_ALTERTABLE_SERIALIZER", "TOK_ALTERTABLE_SKEWED", 
		"TOK_ALTERTABLE_SKEWED_LOCATION", "TOK_ALTERTABLE_TOUCH", "TOK_ALTERTABLE_UNARCHIVE", 
		"TOK_ALTERTABLE_UPDATECOLSTATS", "TOK_ALTERTABLE_UPDATECOLUMNS", "TOK_ALTERTABLE_UPDATESTATS", 
		"TOK_ALTERVIEW", "TOK_ALTERVIEW_ADDPARTS", "TOK_ALTERVIEW_DROPPARTS", 
		"TOK_ALTERVIEW_DROPPROPERTIES", "TOK_ALTERVIEW_PROPERTIES", "TOK_ALTERVIEW_RENAME", 
		"TOK_ALTER_MAPPING", "TOK_ALTER_MATERIALIZED_VIEW", "TOK_ALTER_MATERIALIZED_VIEW_REBUILD", 
		"TOK_ALTER_MATERIALIZED_VIEW_REWRITE", "TOK_ALTER_POOL", "TOK_ALTER_RP", 
		"TOK_ALTER_TRIGGER", "TOK_ANALYZE", "TOK_ARCHIVE", "TOK_BIGINT", "TOK_BINARY", 
		"TOK_BLOCKING", "TOK_BOOLEAN", "TOK_CACHE_METADATA", "TOK_CASCADE", "TOK_CHAR", 
		"TOK_CHARSETLITERAL", "TOK_CHECK_CONSTRAINT", "TOK_CLUSTERBY", "TOK_COLTYPELIST", 
		"TOK_COL_NAME", "TOK_COMMIT", "TOK_CONSTRAINT_NAME", "TOK_CREATEDATABASE", 
		"TOK_CREATEFUNCTION", "TOK_CREATEMACRO", "TOK_CREATEROLE", "TOK_CREATETABLE", 
		"TOK_CREATEVIEW", "TOK_CREATE_MAPPING", "TOK_CREATE_MATERIALIZED_VIEW", 
		"TOK_CREATE_POOL", "TOK_CREATE_RP", "TOK_CREATE_TRIGGER", "TOK_CROSSJOIN", 
		"TOK_CTE", "TOK_CUBE_GROUPBY", "TOK_DATABASECOMMENT", "TOK_DATABASELOCATION", 
		"TOK_DATABASEPROPERTIES", "TOK_DATE", "TOK_DATELITERAL", "TOK_DATETIME", 
		"TOK_DBNAME", "TOK_DBPROPLIST", "TOK_DB_TYPE", "TOK_DECIMAL", "TOK_DEFAULT_POOL", 
		"TOK_DEFAULT_VALUE", "TOK_DELETE", "TOK_DELETE_FROM", "TOK_DESCDATABASE", 
		"TOK_DESCFUNCTION", "TOK_DESCTABLE", "TOK_DESTINATION", "TOK_DETAIL", 
		"TOK_DIR", "TOK_DISABLE", "TOK_DISTRIBUTEBY", "TOK_DOUBLE", "TOK_DROPDATABASE", 
		"TOK_DROPFUNCTION", "TOK_DROPMACRO", "TOK_DROPROLE", "TOK_DROPTABLE", 
		"TOK_DROPVIEW", "TOK_DROP_MAPPING", "TOK_DROP_MATERIALIZED_VIEW", "TOK_DROP_POOL", 
		"TOK_DROP_RP", "TOK_DROP_TRIGGER", "TOK_ENABLE", "TOK_EXCEPTALL", "TOK_EXCEPTDISTINCT", 
		"TOK_EXPLAIN", "TOK_EXPLAIN_SQ_REWRITE", "TOK_EXPLIST", "TOK_EXPORT", 
		"TOK_EXPRESSION", "TOK_FALSE", "TOK_FILE", "TOK_FILEFORMAT_GENERIC", "TOK_FLOAT", 
		"TOK_FORCE", "TOK_FOREIGN_KEY", "TOK_FROM", "TOK_FULLOUTERJOIN", "TOK_FUNCTION", 
		"TOK_FUNCTIONDI", "TOK_FUNCTIONSTAR", "TOK_GRANT", "TOK_GRANT_OPTION_FOR", 
		"TOK_GRANT_ROLE", "TOK_GRANT_WITH_ADMIN_OPTION", "TOK_GRANT_WITH_OPTION", 
		"TOK_GROUP", "TOK_GROUPBY", "TOK_GROUPING_SETS", "TOK_GROUPING_SETS_EXPRESSION", 
		"TOK_HAVING", "TOK_IFEXISTS", "TOK_IFNOTEXISTS", "TOK_IMPORT", "TOK_INPUTFORMAT", 
		"TOK_INSERT", "TOK_INSERT_INTO", "TOK_INT", "TOK_INTERSECTALL", "TOK_INTERSECTDISTINCT", 
		"TOK_INTERVAL_DAY_LITERAL", "TOK_INTERVAL_DAY_TIME", "TOK_INTERVAL_DAY_TIME_LITERAL", 
		"TOK_INTERVAL_HOUR_LITERAL", "TOK_INTERVAL_MINUTE_LITERAL", "TOK_INTERVAL_MONTH_LITERAL", 
		"TOK_INTERVAL_SECOND_LITERAL", "TOK_INTERVAL_YEAR_LITERAL", "TOK_INTERVAL_YEAR_MONTH", 
		"TOK_INTERVAL_YEAR_MONTH_LITERAL", "TOK_ISOLATION_LEVEL", "TOK_ISOLATION_SNAPSHOT", 
		"TOK_JAR", "TOK_JOIN", "TOK_KILL_QUERY", "TOK_LATERAL_VIEW", "TOK_LATERAL_VIEW_OUTER", 
		"TOK_LEFTOUTERJOIN", "TOK_LEFTSEMIJOIN", "TOK_LENGTH", "TOK_LIKERP", "TOK_LIKETABLE", 
		"TOK_LIMIT", "TOK_LIST", "TOK_LOAD", "TOK_LOCKDB", "TOK_LOCKTABLE", "TOK_MAP", 
		"TOK_MATCHED", "TOK_MERGE", "TOK_METADATA", "TOK_MSCK", "TOK_NORELY", 
		"TOK_NOT_CLUSTERED", "TOK_NOT_MATCHED", "TOK_NOT_NULL", "TOK_NOT_SORTED", 
		"TOK_NOVALIDATE", "TOK_NO_DROP", "TOK_NULL", "TOK_NULLS_FIRST", "TOK_NULLS_LAST", 
		"TOK_OFFLINE", "TOK_OFFSET", "TOK_ONLY", "TOK_OPERATOR", "TOK_OP_ADD", 
		"TOK_OP_AND", "TOK_OP_BITAND", "TOK_OP_BITNOT", "TOK_OP_BITOR", "TOK_OP_BITXOR", 
		"TOK_OP_DIV", "TOK_OP_EQ", "TOK_OP_GE", "TOK_OP_GT", "TOK_OP_LE", "TOK_OP_LIKE", 
		"TOK_OP_LT", "TOK_OP_MOD", "TOK_OP_MUL", "TOK_OP_NE", "TOK_OP_NOT", "TOK_OP_OR", 
		"TOK_OP_SUB", "TOK_ORDERBY", "TOK_ORREPLACE", "TOK_PARTITIONINGSPEC", 
		"TOK_PARTITIONLOCATION", "TOK_PARTSPEC", "TOK_PARTVAL", "TOK_PATH", "TOK_PERCENT", 
		"TOK_PRIMARY_KEY", "TOK_PRINCIPAL_NAME", "TOK_PRIVILEGE", "TOK_PRIVILEGE_LIST", 
		"TOK_PRIV_ALL", "TOK_PRIV_ALTER_DATA", "TOK_PRIV_ALTER_METADATA", "TOK_PRIV_CREATE", 
		"TOK_PRIV_DELETE", "TOK_PRIV_DROP", "TOK_PRIV_INSERT", "TOK_PRIV_LOCK", 
		"TOK_PRIV_OBJECT", "TOK_PRIV_OBJECT_COL", "TOK_PRIV_SELECT", "TOK_PRIV_SHOW_DATABASE", 
		"TOK_PTBLFUNCTION", "TOK_QUERY", "TOK_QUERY_PARALLELISM", "TOK_READONLY", 
		"TOK_RECORDREADER", "TOK_RECORDWRITER", "TOK_RELOADFUNCTIONS", "TOK_RELY", 
		"TOK_RENAME", "TOK_REPLACE", "TOK_REPLICATION", "TOK_REPL_CONFIG", "TOK_REPL_CONFIG_LIST", 
		"TOK_REPL_DUMP", "TOK_REPL_LOAD", "TOK_REPL_STATUS", "TOK_REPL_TABLES", 
		"TOK_REPL_TABLES_LIST", "TOK_RESOURCE_ALL", "TOK_RESOURCE_LIST", "TOK_RESOURCE_URI", 
		"TOK_RESTRICT", "TOK_REVOKE", "TOK_REVOKE_ROLE", "TOK_REWRITE_DISABLED", 
		"TOK_REWRITE_ENABLED", "TOK_RIGHTOUTERJOIN", "TOK_ROLE", "TOK_ROLLBACK", 
		"TOK_ROLLUP_GROUPBY", "TOK_ROWCOUNT", "TOK_SCHEDULING_POLICY", "TOK_SELECT", 
		"TOK_SELECTDI", "TOK_SELEXPR", "TOK_SERDE", "TOK_SERDENAME", "TOK_SERDEPROPS", 
		"TOK_SERVER_TYPE", "TOK_SETCOLREF", "TOK_SET_AUTOCOMMIT", "TOK_SET_COLUMNS_CLAUSE", 
		"TOK_SHOWCOLUMNS", "TOK_SHOWCONF", "TOK_SHOWDATABASES", "TOK_SHOWDBLOCKS", 
		"TOK_SHOWFUNCTIONS", "TOK_SHOWLOCKS", "TOK_SHOWMATERIALIZEDVIEWS", "TOK_SHOWPARTITIONS", 
		"TOK_SHOWTABLES", "TOK_SHOWVIEWS", "TOK_SHOW_COMPACTIONS", "TOK_SHOW_CREATEDATABASE", 
		"TOK_SHOW_CREATETABLE", "TOK_SHOW_GRANT", "TOK_SHOW_ROLES", "TOK_SHOW_ROLE_GRANT", 
		"TOK_SHOW_ROLE_PRINCIPALS", "TOK_SHOW_RP", "TOK_SHOW_SET_ROLE", "TOK_SHOW_TABLESTATUS", 
		"TOK_SHOW_TBLPROPERTIES", "TOK_SHOW_TRANSACTIONS", "TOK_SKEWED_LOCATIONS", 
		"TOK_SKEWED_LOCATION_LIST", "TOK_SKEWED_LOCATION_MAP", "TOK_SMALLINT", 
		"TOK_SORTBY", "TOK_START_TRANSACTION", "TOK_STORAGEHANDLER", "TOK_STOREDASDIRS", 
		"TOK_STRING", "TOK_STRINGLITERALSEQUENCE", "TOK_STRUCT", "TOK_SUBQUERY", 
		"TOK_SUBQUERY_EXPR", "TOK_SUBQUERY_OP", "TOK_SUBQUERY_OP_NOTEXISTS", "TOK_SUBQUERY_OP_NOTIN", 
		"TOK_SUMMARY", "TOK_SWITCHDATABASE", "TOK_TAB", "TOK_TABALIAS", "TOK_TABCOL", 
		"TOK_TABCOLLIST", "TOK_TABCOLNAME", "TOK_TABCOLVALUE", "TOK_TABCOLVALUES", 
		"TOK_TABCOLVALUE_PAIR", "TOK_TABLEBUCKETSAMPLE", "TOK_TABLECOMMENT", "TOK_TABLEFILEFORMAT", 
		"TOK_TABLELOCATION", "TOK_TABLEPARTCOLNAMES", "TOK_TABLEPARTCOLS", "TOK_TABLEPROPERTIES", 
		"TOK_TABLEPROPERTY", "TOK_TABLEPROPLIST", "TOK_TABLEROWFORMAT", "TOK_TABLEROWFORMATCOLLITEMS", 
		"TOK_TABLEROWFORMATFIELD", "TOK_TABLEROWFORMATLINES", "TOK_TABLEROWFORMATMAPKEYS", 
		"TOK_TABLEROWFORMATNULL", "TOK_TABLESERIALIZER", "TOK_TABLESKEWED", "TOK_TABLESPLITSAMPLE", 
		"TOK_TABLE_OR_COL", "TOK_TABLE_PARTITION", "TOK_TABLE_TYPE", "TOK_TABNAME", 
		"TOK_TABREF", "TOK_TABSORTCOLNAMEASC", "TOK_TABSORTCOLNAMEDESC", "TOK_TABSRC", 
		"TOK_TABTYPE", "TOK_TEMPORARY", "TOK_TIMESTAMP", "TOK_TIMESTAMPLITERAL", 
		"TOK_TIMESTAMPLOCALTZ", "TOK_TIMESTAMPLOCALTZLITERAL", "TOK_TINYINT", 
		"TOK_TMP_FILE", "TOK_TO", "TOK_TRANSFORM", "TOK_TRIGGER_EXPRESSION", "TOK_TRUE", 
		"TOK_TRUNCATETABLE", "TOK_TXN_ACCESS_MODE", "TOK_TXN_READ_ONLY", "TOK_TXN_READ_WRITE", 
		"TOK_UNIONALL", "TOK_UNIONDISTINCT", "TOK_UNIONTYPE", "TOK_UNIQUE", "TOK_UNIQUEJOIN", 
		"TOK_UNLOCKDB", "TOK_UNLOCKTABLE", "TOK_UNMANAGED", "TOK_UPDATE", "TOK_UPDATE_TABLE", 
		"TOK_URI_TYPE", "TOK_USER", "TOK_USERSCRIPTCOLNAMES", "TOK_USERSCRIPTCOLSCHEMA", 
		"TOK_VALIDATE", "TOK_VARCHAR", "TOK_VIEWCLUSTERCOLS", "TOK_VIEWDISTRIBUTECOLS", 
		"TOK_VIEWPARTCOLS", "TOK_VIEWSORTCOLS", "TOK_WHERE", "TOK_WINDOWDEF", 
		"TOK_WINDOWRANGE", "TOK_WINDOWSPEC", "TOK_WINDOWVALUES"
	};
	public static final int EOF=-1;
	public static final int AMPERSAND=4;
	public static final int BITWISEOR=5;
	public static final int BITWISEXOR=6;
	public static final int ByteLengthLiteral=7;
	public static final int COLON=8;
	public static final int COMMA=9;
	public static final int CONCATENATE=10;
	public static final int CharSetLiteral=11;
	public static final int CharSetName=12;
	public static final int DIV=13;
	public static final int DIVIDE=14;
	public static final int DOLLAR=15;
	public static final int DOT=16;
	public static final int Digit=17;
	public static final int EQUAL=18;
	public static final int EQUAL_NS=19;
	public static final int Exponent=20;
	public static final int GREATERTHAN=21;
	public static final int GREATERTHANOREQUALTO=22;
	public static final int HexDigit=23;
	public static final int Identifier=24;
	public static final int IntegralLiteral=25;
	public static final int KW_ABORT=26;
	public static final int KW_ACTIVATE=27;
	public static final int KW_ACTIVE=28;
	public static final int KW_ADD=29;
	public static final int KW_ADMIN=30;
	public static final int KW_AFTER=31;
	public static final int KW_ALL=32;
	public static final int KW_ALLOC_FRACTION=33;
	public static final int KW_ALTER=34;
	public static final int KW_ANALYZE=35;
	public static final int KW_AND=36;
	public static final int KW_ANY=37;
	public static final int KW_APPLICATION=38;
	public static final int KW_ARCHIVE=39;
	public static final int KW_ARRAY=40;
	public static final int KW_AS=41;
	public static final int KW_ASC=42;
	public static final int KW_AUTHORIZATION=43;
	public static final int KW_AUTOCOMMIT=44;
	public static final int KW_BEFORE=45;
	public static final int KW_BETWEEN=46;
	public static final int KW_BIGINT=47;
	public static final int KW_BINARY=48;
	public static final int KW_BOOLEAN=49;
	public static final int KW_BOTH=50;
	public static final int KW_BUCKET=51;
	public static final int KW_BUCKETS=52;
	public static final int KW_BY=53;
	public static final int KW_CACHE=54;
	public static final int KW_CASCADE=55;
	public static final int KW_CASE=56;
	public static final int KW_CAST=57;
	public static final int KW_CBO=58;
	public static final int KW_CHANGE=59;
	public static final int KW_CHAR=60;
	public static final int KW_CHECK=61;
	public static final int KW_CLUSTER=62;
	public static final int KW_CLUSTERED=63;
	public static final int KW_CLUSTERSTATUS=64;
	public static final int KW_COLLECTION=65;
	public static final int KW_COLUMN=66;
	public static final int KW_COLUMNS=67;
	public static final int KW_COMMENT=68;
	public static final int KW_COMMIT=69;
	public static final int KW_COMPACT=70;
	public static final int KW_COMPACTIONS=71;
	public static final int KW_COMPUTE=72;
	public static final int KW_CONCATENATE=73;
	public static final int KW_CONF=74;
	public static final int KW_CONSTRAINT=75;
	public static final int KW_CONTINUE=76;
	public static final int KW_COST=77;
	public static final int KW_CREATE=78;
	public static final int KW_CROSS=79;
	public static final int KW_CUBE=80;
	public static final int KW_CURRENT=81;
	public static final int KW_CURRENT_DATE=82;
	public static final int KW_CURRENT_TIMESTAMP=83;
	public static final int KW_CURSOR=84;
	public static final int KW_DATA=85;
	public static final int KW_DATABASE=86;
	public static final int KW_DATABASES=87;
	public static final int KW_DATE=88;
	public static final int KW_DATETIME=89;
	public static final int KW_DAY=90;
	public static final int KW_DBPROPERTIES=91;
	public static final int KW_DEBUG=92;
	public static final int KW_DECIMAL=93;
	public static final int KW_DEFAULT=94;
	public static final int KW_DEFERRED=95;
	public static final int KW_DEFINED=96;
	public static final int KW_DELETE=97;
	public static final int KW_DELIMITED=98;
	public static final int KW_DEPENDENCY=99;
	public static final int KW_DESC=100;
	public static final int KW_DESCRIBE=101;
	public static final int KW_DETAIL=102;
	public static final int KW_DIRECTORIES=103;
	public static final int KW_DIRECTORY=104;
	public static final int KW_DISABLE=105;
	public static final int KW_DISTINCT=106;
	public static final int KW_DISTRIBUTE=107;
	public static final int KW_DISTRIBUTED=108;
	public static final int KW_DO=109;
	public static final int KW_DOUBLE=110;
	public static final int KW_DOW=111;
	public static final int KW_DROP=112;
	public static final int KW_DUMP=113;
	public static final int KW_ELEM_TYPE=114;
	public static final int KW_ELSE=115;
	public static final int KW_ENABLE=116;
	public static final int KW_END=117;
	public static final int KW_ENFORCED=118;
	public static final int KW_ESCAPED=119;
	public static final int KW_EXCEPT=120;
	public static final int KW_EXCHANGE=121;
	public static final int KW_EXCLUSIVE=122;
	public static final int KW_EXISTS=123;
	public static final int KW_EXPLAIN=124;
	public static final int KW_EXPORT=125;
	public static final int KW_EXPRESSION=126;
	public static final int KW_EXTENDED=127;
	public static final int KW_EXTERNAL=128;
	public static final int KW_EXTRACT=129;
	public static final int KW_FALSE=130;
	public static final int KW_FETCH=131;
	public static final int KW_FIELDS=132;
	public static final int KW_FILE=133;
	public static final int KW_FILEFORMAT=134;
	public static final int KW_FIRST=135;
	public static final int KW_FLOAT=136;
	public static final int KW_FLOOR=137;
	public static final int KW_FOLLOWING=138;
	public static final int KW_FOR=139;
	public static final int KW_FORCE=140;
	public static final int KW_FOREIGN=141;
	public static final int KW_FORMAT=142;
	public static final int KW_FORMATTED=143;
	public static final int KW_FROM=144;
	public static final int KW_FULL=145;
	public static final int KW_FUNCTION=146;
	public static final int KW_FUNCTIONS=147;
	public static final int KW_GRANT=148;
	public static final int KW_GROUP=149;
	public static final int KW_GROUPING=150;
	public static final int KW_HAVING=151;
	public static final int KW_HOUR=152;
	public static final int KW_IDXPROPERTIES=153;
	public static final int KW_IF=154;
	public static final int KW_IMPORT=155;
	public static final int KW_IN=156;
	public static final int KW_INDEX=157;
	public static final int KW_INDEXES=158;
	public static final int KW_INNER=159;
	public static final int KW_INPATH=160;
	public static final int KW_INPUTDRIVER=161;
	public static final int KW_INPUTFORMAT=162;
	public static final int KW_INSERT=163;
	public static final int KW_INT=164;
	public static final int KW_INTERSECT=165;
	public static final int KW_INTERVAL=166;
	public static final int KW_INTO=167;
	public static final int KW_IS=168;
	public static final int KW_ISOLATION=169;
	public static final int KW_ITEMS=170;
	public static final int KW_JAR=171;
	public static final int KW_JOIN=172;
	public static final int KW_JOINCOST=173;
	public static final int KW_KEY=174;
	public static final int KW_KEYS=175;
	public static final int KW_KEY_TYPE=176;
	public static final int KW_KILL=177;
	public static final int KW_LAST=178;
	public static final int KW_LATERAL=179;
	public static final int KW_LEFT=180;
	public static final int KW_LESS=181;
	public static final int KW_LEVEL=182;
	public static final int KW_LIKE=183;
	public static final int KW_LIMIT=184;
	public static final int KW_LINES=185;
	public static final int KW_LOAD=186;
	public static final int KW_LOCAL=187;
	public static final int KW_LOCATION=188;
	public static final int KW_LOCK=189;
	public static final int KW_LOCKS=190;
	public static final int KW_LOGICAL=191;
	public static final int KW_LONG=192;
	public static final int KW_MACRO=193;
	public static final int KW_MANAGEMENT=194;
	public static final int KW_MAP=195;
	public static final int KW_MAPJOIN=196;
	public static final int KW_MAPPING=197;
	public static final int KW_MATCHED=198;
	public static final int KW_MATERIALIZED=199;
	public static final int KW_MERGE=200;
	public static final int KW_METADATA=201;
	public static final int KW_MINUS=202;
	public static final int KW_MINUTE=203;
	public static final int KW_MONTH=204;
	public static final int KW_MORE=205;
	public static final int KW_MOVE=206;
	public static final int KW_MSCK=207;
	public static final int KW_NONE=208;
	public static final int KW_NORELY=209;
	public static final int KW_NOSCAN=210;
	public static final int KW_NOT=211;
	public static final int KW_NOVALIDATE=212;
	public static final int KW_NULL=213;
	public static final int KW_NULLS=214;
	public static final int KW_OF=215;
	public static final int KW_OFFSET=216;
	public static final int KW_ON=217;
	public static final int KW_ONLY=218;
	public static final int KW_OPERATOR=219;
	public static final int KW_OPTION=220;
	public static final int KW_OR=221;
	public static final int KW_ORDER=222;
	public static final int KW_OUT=223;
	public static final int KW_OUTER=224;
	public static final int KW_OUTPUTDRIVER=225;
	public static final int KW_OUTPUTFORMAT=226;
	public static final int KW_OVER=227;
	public static final int KW_OVERWRITE=228;
	public static final int KW_OWNER=229;
	public static final int KW_PARTITION=230;
	public static final int KW_PARTITIONED=231;
	public static final int KW_PARTITIONS=232;
	public static final int KW_PATH=233;
	public static final int KW_PERCENT=234;
	public static final int KW_PLAN=235;
	public static final int KW_PLANS=236;
	public static final int KW_PLUS=237;
	public static final int KW_POOL=238;
	public static final int KW_PRECEDING=239;
	public static final int KW_PRECISION=240;
	public static final int KW_PRESERVE=241;
	public static final int KW_PRIMARY=242;
	public static final int KW_PRINCIPALS=243;
	public static final int KW_PROCEDURE=244;
	public static final int KW_PURGE=245;
	public static final int KW_QUARTER=246;
	public static final int KW_QUERY=247;
	public static final int KW_QUERY_PARALLELISM=248;
	public static final int KW_RANGE=249;
	public static final int KW_READ=250;
	public static final int KW_READS=251;
	public static final int KW_REBUILD=252;
	public static final int KW_RECORDREADER=253;
	public static final int KW_RECORDWRITER=254;
	public static final int KW_REDUCE=255;
	public static final int KW_REFERENCES=256;
	public static final int KW_REGEXP=257;
	public static final int KW_RELOAD=258;
	public static final int KW_RELY=259;
	public static final int KW_RENAME=260;
	public static final int KW_REOPTIMIZATION=261;
	public static final int KW_REPAIR=262;
	public static final int KW_REPL=263;
	public static final int KW_REPLACE=264;
	public static final int KW_REPLICATION=265;
	public static final int KW_RESOURCE=266;
	public static final int KW_RESTRICT=267;
	public static final int KW_REVOKE=268;
	public static final int KW_REWRITE=269;
	public static final int KW_RIGHT=270;
	public static final int KW_RLIKE=271;
	public static final int KW_ROLE=272;
	public static final int KW_ROLES=273;
	public static final int KW_ROLLBACK=274;
	public static final int KW_ROLLUP=275;
	public static final int KW_ROW=276;
	public static final int KW_ROWS=277;
	public static final int KW_SCHEDULING_POLICY=278;
	public static final int KW_SCHEMA=279;
	public static final int KW_SCHEMAS=280;
	public static final int KW_SECOND=281;
	public static final int KW_SELECT=282;
	public static final int KW_SEMI=283;
	public static final int KW_SERDE=284;
	public static final int KW_SERDEPROPERTIES=285;
	public static final int KW_SERVER=286;
	public static final int KW_SET=287;
	public static final int KW_SETS=288;
	public static final int KW_SHARED=289;
	public static final int KW_SHOW=290;
	public static final int KW_SHOW_DATABASE=291;
	public static final int KW_SKEWED=292;
	public static final int KW_SMALLINT=293;
	public static final int KW_SNAPSHOT=294;
	public static final int KW_SORT=295;
	public static final int KW_SORTED=296;
	public static final int KW_SSL=297;
	public static final int KW_START=298;
	public static final int KW_STATISTICS=299;
	public static final int KW_STATUS=300;
	public static final int KW_STORED=301;
	public static final int KW_STREAMTABLE=302;
	public static final int KW_STRING=303;
	public static final int KW_STRUCT=304;
	public static final int KW_SUMMARY=305;
	public static final int KW_SYNC=306;
	public static final int KW_TABLE=307;
	public static final int KW_TABLES=308;
	public static final int KW_TABLESAMPLE=309;
	public static final int KW_TBLPROPERTIES=310;
	public static final int KW_TEMPORARY=311;
	public static final int KW_TERMINATED=312;
	public static final int KW_THEN=313;
	public static final int KW_TIME=314;
	public static final int KW_TIMESTAMP=315;
	public static final int KW_TIMESTAMPLOCALTZ=316;
	public static final int KW_TINYINT=317;
	public static final int KW_TO=318;
	public static final int KW_TOUCH=319;
	public static final int KW_TRANSACTION=320;
	public static final int KW_TRANSACTIONAL=321;
	public static final int KW_TRANSACTIONS=322;
	public static final int KW_TRANSFORM=323;
	public static final int KW_TRIGGER=324;
	public static final int KW_TRUE=325;
	public static final int KW_TRUNCATE=326;
	public static final int KW_UNARCHIVE=327;
	public static final int KW_UNBOUNDED=328;
	public static final int KW_UNDO=329;
	public static final int KW_UNION=330;
	public static final int KW_UNIONTYPE=331;
	public static final int KW_UNIQUE=332;
	public static final int KW_UNIQUEJOIN=333;
	public static final int KW_UNLOCK=334;
	public static final int KW_UNMANAGED=335;
	public static final int KW_UNSET=336;
	public static final int KW_UNSIGNED=337;
	public static final int KW_UPDATE=338;
	public static final int KW_URI=339;
	public static final int KW_USE=340;
	public static final int KW_USER=341;
	public static final int KW_USING=342;
	public static final int KW_UTC=343;
	public static final int KW_UTCTIMESTAMP=344;
	public static final int KW_VALIDATE=345;
	public static final int KW_VALUES=346;
	public static final int KW_VALUE_TYPE=347;
	public static final int KW_VARCHAR=348;
	public static final int KW_VECTORIZATION=349;
	public static final int KW_VIEW=350;
	public static final int KW_VIEWS=351;
	public static final int KW_WAIT=352;
	public static final int KW_WEEK=353;
	public static final int KW_WHEN=354;
	public static final int KW_WHERE=355;
	public static final int KW_WHILE=356;
	public static final int KW_WINDOW=357;
	public static final int KW_WITH=358;
	public static final int KW_WORK=359;
	public static final int KW_WORKLOAD=360;
	public static final int KW_WRITE=361;
	public static final int KW_YEAR=362;
	public static final int KW_ZONE=363;
	public static final int LCURLY=364;
	public static final int LESSTHAN=365;
	public static final int LESSTHANOREQUALTO=366;
	public static final int LINE_COMMENT=367;
	public static final int LPAREN=368;
	public static final int LSQUARE=369;
	public static final int Letter=370;
	public static final int MINUS=371;
	public static final int MOD=372;
	public static final int NOTEQUAL=373;
	public static final int Number=374;
	public static final int NumberLiteral=375;
	public static final int PLUS=376;
	public static final int QUERY_HINT=377;
	public static final int QUESTION=378;
	public static final int QuotedIdentifier=379;
	public static final int RCURLY=380;
	public static final int RPAREN=381;
	public static final int RSQUARE=382;
	public static final int RegexComponent=383;
	public static final int SEMICOLON=384;
	public static final int STAR=385;
	public static final int StringLiteral=386;
	public static final int TILDE=387;
	public static final int WS=388;
	public static final int KW_BATCH=424;
	public static final int KW_DAYOFWEEK=463;
	public static final int KW_HOLD_DDLTIME=512;
	public static final int KW_IGNORE=516;
	public static final int KW_NO_DROP=564;
	public static final int KW_OFFLINE=568;
	public static final int KW_PROTECTION=594;
	public static final int KW_READONLY=601;
	public static final int KW_TIMESTAMPTZ=661;
	public static final int TOK_ABORT_TRANSACTIONS=721;
	public static final int TOK_ACTIVATE=722;
	public static final int TOK_ADD_TRIGGER=723;
	public static final int TOK_ADMIN_OPTION_FOR=724;
	public static final int TOK_ALIASLIST=725;
	public static final int TOK_ALLCOLREF=726;
	public static final int TOK_ALLOC_FRACTION=727;
	public static final int TOK_ALTERDATABASE_LOCATION=728;
	public static final int TOK_ALTERDATABASE_OWNER=729;
	public static final int TOK_ALTERDATABASE_PROPERTIES=730;
	public static final int TOK_ALTERTABLE=731;
	public static final int TOK_ALTERTABLE_ADDCOLS=732;
	public static final int TOK_ALTERTABLE_ADDCONSTRAINT=733;
	public static final int TOK_ALTERTABLE_ADDPARTS=734;
	public static final int TOK_ALTERTABLE_ARCHIVE=735;
	public static final int TOK_ALTERTABLE_BUCKETS=736;
	public static final int TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION=737;
	public static final int TOK_ALTERTABLE_CLUSTER_SORT=738;
	public static final int TOK_ALTERTABLE_COMPACT=739;
	public static final int TOK_ALTERTABLE_DROPCONSTRAINT=740;
	public static final int TOK_ALTERTABLE_DROPPARTS=741;
	public static final int TOK_ALTERTABLE_DROPPROPERTIES=742;
	public static final int TOK_ALTERTABLE_EXCHANGEPARTITION=743;
	public static final int TOK_ALTERTABLE_FILEFORMAT=744;
	public static final int TOK_ALTERTABLE_LOCATION=745;
	public static final int TOK_ALTERTABLE_MERGEFILES=746;
	public static final int TOK_ALTERTABLE_OWNER=747;
	public static final int TOK_ALTERTABLE_PARTCOLTYPE=748;
	public static final int TOK_ALTERTABLE_PROPERTIES=749;
	public static final int TOK_ALTERTABLE_RENAME=750;
	public static final int TOK_ALTERTABLE_RENAMECOL=751;
	public static final int TOK_ALTERTABLE_RENAMEPART=752;
	public static final int TOK_ALTERTABLE_REPLACECOLS=753;
	public static final int TOK_ALTERTABLE_SERDEPROPERTIES=754;
	public static final int TOK_ALTERTABLE_SERIALIZER=755;
	public static final int TOK_ALTERTABLE_SKEWED=756;
	public static final int TOK_ALTERTABLE_SKEWED_LOCATION=757;
	public static final int TOK_ALTERTABLE_TOUCH=758;
	public static final int TOK_ALTERTABLE_UNARCHIVE=759;
	public static final int TOK_ALTERTABLE_UPDATECOLSTATS=760;
	public static final int TOK_ALTERTABLE_UPDATECOLUMNS=761;
	public static final int TOK_ALTERTABLE_UPDATESTATS=762;
	public static final int TOK_ALTERVIEW=763;
	public static final int TOK_ALTERVIEW_ADDPARTS=764;
	public static final int TOK_ALTERVIEW_DROPPARTS=765;
	public static final int TOK_ALTERVIEW_DROPPROPERTIES=766;
	public static final int TOK_ALTERVIEW_PROPERTIES=767;
	public static final int TOK_ALTERVIEW_RENAME=768;
	public static final int TOK_ALTER_MAPPING=769;
	public static final int TOK_ALTER_MATERIALIZED_VIEW=770;
	public static final int TOK_ALTER_MATERIALIZED_VIEW_REBUILD=771;
	public static final int TOK_ALTER_MATERIALIZED_VIEW_REWRITE=772;
	public static final int TOK_ALTER_POOL=773;
	public static final int TOK_ALTER_RP=774;
	public static final int TOK_ALTER_TRIGGER=775;
	public static final int TOK_ANALYZE=776;
	public static final int TOK_ARCHIVE=777;
	public static final int TOK_BIGINT=778;
	public static final int TOK_BINARY=779;
	public static final int TOK_BLOCKING=780;
	public static final int TOK_BOOLEAN=781;
	public static final int TOK_CACHE_METADATA=782;
	public static final int TOK_CASCADE=783;
	public static final int TOK_CHAR=784;
	public static final int TOK_CHARSETLITERAL=785;
	public static final int TOK_CHECK_CONSTRAINT=786;
	public static final int TOK_CLUSTERBY=787;
	public static final int TOK_COLTYPELIST=788;
	public static final int TOK_COL_NAME=789;
	public static final int TOK_COMMIT=790;
	public static final int TOK_CONSTRAINT_NAME=791;
	public static final int TOK_CREATEDATABASE=792;
	public static final int TOK_CREATEFUNCTION=793;
	public static final int TOK_CREATEMACRO=794;
	public static final int TOK_CREATEROLE=795;
	public static final int TOK_CREATETABLE=796;
	public static final int TOK_CREATEVIEW=797;
	public static final int TOK_CREATE_MAPPING=798;
	public static final int TOK_CREATE_MATERIALIZED_VIEW=799;
	public static final int TOK_CREATE_POOL=800;
	public static final int TOK_CREATE_RP=801;
	public static final int TOK_CREATE_TRIGGER=802;
	public static final int TOK_CROSSJOIN=803;
	public static final int TOK_CTE=804;
	public static final int TOK_CUBE_GROUPBY=805;
	public static final int TOK_DATABASECOMMENT=806;
	public static final int TOK_DATABASELOCATION=807;
	public static final int TOK_DATABASEPROPERTIES=808;
	public static final int TOK_DATE=809;
	public static final int TOK_DATELITERAL=810;
	public static final int TOK_DATETIME=811;
	public static final int TOK_DBNAME=812;
	public static final int TOK_DBPROPLIST=813;
	public static final int TOK_DB_TYPE=814;
	public static final int TOK_DECIMAL=815;
	public static final int TOK_DEFAULT_POOL=816;
	public static final int TOK_DEFAULT_VALUE=817;
	public static final int TOK_DELETE=818;
	public static final int TOK_DELETE_FROM=819;
	public static final int TOK_DESCDATABASE=820;
	public static final int TOK_DESCFUNCTION=821;
	public static final int TOK_DESCTABLE=822;
	public static final int TOK_DESTINATION=823;
	public static final int TOK_DETAIL=824;
	public static final int TOK_DIR=825;
	public static final int TOK_DISABLE=826;
	public static final int TOK_DISTRIBUTEBY=827;
	public static final int TOK_DOUBLE=828;
	public static final int TOK_DROPDATABASE=829;
	public static final int TOK_DROPFUNCTION=830;
	public static final int TOK_DROPMACRO=831;
	public static final int TOK_DROPROLE=832;
	public static final int TOK_DROPTABLE=833;
	public static final int TOK_DROPVIEW=834;
	public static final int TOK_DROP_MAPPING=835;
	public static final int TOK_DROP_MATERIALIZED_VIEW=836;
	public static final int TOK_DROP_POOL=837;
	public static final int TOK_DROP_RP=838;
	public static final int TOK_DROP_TRIGGER=839;
	public static final int TOK_ENABLE=840;
	public static final int TOK_EXCEPTALL=841;
	public static final int TOK_EXCEPTDISTINCT=842;
	public static final int TOK_EXPLAIN=843;
	public static final int TOK_EXPLAIN_SQ_REWRITE=844;
	public static final int TOK_EXPLIST=845;
	public static final int TOK_EXPORT=846;
	public static final int TOK_EXPRESSION=847;
	public static final int TOK_FALSE=848;
	public static final int TOK_FILE=849;
	public static final int TOK_FILEFORMAT_GENERIC=850;
	public static final int TOK_FLOAT=851;
	public static final int TOK_FORCE=852;
	public static final int TOK_FOREIGN_KEY=853;
	public static final int TOK_FROM=854;
	public static final int TOK_FULLOUTERJOIN=855;
	public static final int TOK_FUNCTION=856;
	public static final int TOK_FUNCTIONDI=857;
	public static final int TOK_FUNCTIONSTAR=858;
	public static final int TOK_GRANT=859;
	public static final int TOK_GRANT_OPTION_FOR=860;
	public static final int TOK_GRANT_ROLE=861;
	public static final int TOK_GRANT_WITH_ADMIN_OPTION=862;
	public static final int TOK_GRANT_WITH_OPTION=863;
	public static final int TOK_GROUP=864;
	public static final int TOK_GROUPBY=865;
	public static final int TOK_GROUPING_SETS=866;
	public static final int TOK_GROUPING_SETS_EXPRESSION=867;
	public static final int TOK_HAVING=868;
	public static final int TOK_IFEXISTS=869;
	public static final int TOK_IFNOTEXISTS=870;
	public static final int TOK_IMPORT=871;
	public static final int TOK_INPUTFORMAT=872;
	public static final int TOK_INSERT=873;
	public static final int TOK_INSERT_INTO=874;
	public static final int TOK_INT=875;
	public static final int TOK_INTERSECTALL=876;
	public static final int TOK_INTERSECTDISTINCT=877;
	public static final int TOK_INTERVAL_DAY_LITERAL=878;
	public static final int TOK_INTERVAL_DAY_TIME=879;
	public static final int TOK_INTERVAL_DAY_TIME_LITERAL=880;
	public static final int TOK_INTERVAL_HOUR_LITERAL=881;
	public static final int TOK_INTERVAL_MINUTE_LITERAL=882;
	public static final int TOK_INTERVAL_MONTH_LITERAL=883;
	public static final int TOK_INTERVAL_SECOND_LITERAL=884;
	public static final int TOK_INTERVAL_YEAR_LITERAL=885;
	public static final int TOK_INTERVAL_YEAR_MONTH=886;
	public static final int TOK_INTERVAL_YEAR_MONTH_LITERAL=887;
	public static final int TOK_ISOLATION_LEVEL=888;
	public static final int TOK_ISOLATION_SNAPSHOT=889;
	public static final int TOK_JAR=890;
	public static final int TOK_JOIN=891;
	public static final int TOK_KILL_QUERY=892;
	public static final int TOK_LATERAL_VIEW=893;
	public static final int TOK_LATERAL_VIEW_OUTER=894;
	public static final int TOK_LEFTOUTERJOIN=895;
	public static final int TOK_LEFTSEMIJOIN=896;
	public static final int TOK_LENGTH=897;
	public static final int TOK_LIKERP=898;
	public static final int TOK_LIKETABLE=899;
	public static final int TOK_LIMIT=900;
	public static final int TOK_LIST=901;
	public static final int TOK_LOAD=902;
	public static final int TOK_LOCKDB=903;
	public static final int TOK_LOCKTABLE=904;
	public static final int TOK_MAP=905;
	public static final int TOK_MATCHED=906;
	public static final int TOK_MERGE=907;
	public static final int TOK_METADATA=908;
	public static final int TOK_MSCK=909;
	public static final int TOK_NORELY=910;
	public static final int TOK_NOT_CLUSTERED=911;
	public static final int TOK_NOT_MATCHED=912;
	public static final int TOK_NOT_NULL=913;
	public static final int TOK_NOT_SORTED=914;
	public static final int TOK_NOVALIDATE=915;
	public static final int TOK_NO_DROP=916;
	public static final int TOK_NULL=917;
	public static final int TOK_NULLS_FIRST=918;
	public static final int TOK_NULLS_LAST=919;
	public static final int TOK_OFFLINE=920;
	public static final int TOK_OFFSET=921;
	public static final int TOK_ONLY=922;
	public static final int TOK_OPERATOR=923;
	public static final int TOK_OP_ADD=924;
	public static final int TOK_OP_AND=925;
	public static final int TOK_OP_BITAND=926;
	public static final int TOK_OP_BITNOT=927;
	public static final int TOK_OP_BITOR=928;
	public static final int TOK_OP_BITXOR=929;
	public static final int TOK_OP_DIV=930;
	public static final int TOK_OP_EQ=931;
	public static final int TOK_OP_GE=932;
	public static final int TOK_OP_GT=933;
	public static final int TOK_OP_LE=934;
	public static final int TOK_OP_LIKE=935;
	public static final int TOK_OP_LT=936;
	public static final int TOK_OP_MOD=937;
	public static final int TOK_OP_MUL=938;
	public static final int TOK_OP_NE=939;
	public static final int TOK_OP_NOT=940;
	public static final int TOK_OP_OR=941;
	public static final int TOK_OP_SUB=942;
	public static final int TOK_ORDERBY=943;
	public static final int TOK_ORREPLACE=944;
	public static final int TOK_PARTITIONINGSPEC=945;
	public static final int TOK_PARTITIONLOCATION=946;
	public static final int TOK_PARTSPEC=947;
	public static final int TOK_PARTVAL=948;
	public static final int TOK_PATH=949;
	public static final int TOK_PERCENT=950;
	public static final int TOK_PRIMARY_KEY=951;
	public static final int TOK_PRINCIPAL_NAME=952;
	public static final int TOK_PRIVILEGE=953;
	public static final int TOK_PRIVILEGE_LIST=954;
	public static final int TOK_PRIV_ALL=955;
	public static final int TOK_PRIV_ALTER_DATA=956;
	public static final int TOK_PRIV_ALTER_METADATA=957;
	public static final int TOK_PRIV_CREATE=958;
	public static final int TOK_PRIV_DELETE=959;
	public static final int TOK_PRIV_DROP=960;
	public static final int TOK_PRIV_INSERT=961;
	public static final int TOK_PRIV_LOCK=962;
	public static final int TOK_PRIV_OBJECT=963;
	public static final int TOK_PRIV_OBJECT_COL=964;
	public static final int TOK_PRIV_SELECT=965;
	public static final int TOK_PRIV_SHOW_DATABASE=966;
	public static final int TOK_PTBLFUNCTION=967;
	public static final int TOK_QUERY=968;
	public static final int TOK_QUERY_PARALLELISM=969;
	public static final int TOK_READONLY=970;
	public static final int TOK_RECORDREADER=971;
	public static final int TOK_RECORDWRITER=972;
	public static final int TOK_RELOADFUNCTIONS=973;
	public static final int TOK_RELY=974;
	public static final int TOK_RENAME=975;
	public static final int TOK_REPLACE=976;
	public static final int TOK_REPLICATION=977;
	public static final int TOK_REPL_CONFIG=978;
	public static final int TOK_REPL_CONFIG_LIST=979;
	public static final int TOK_REPL_DUMP=980;
	public static final int TOK_REPL_LOAD=981;
	public static final int TOK_REPL_STATUS=982;
	public static final int TOK_REPL_TABLES=983;
	public static final int TOK_REPL_TABLES_LIST=984;
	public static final int TOK_RESOURCE_ALL=985;
	public static final int TOK_RESOURCE_LIST=986;
	public static final int TOK_RESOURCE_URI=987;
	public static final int TOK_RESTRICT=988;
	public static final int TOK_REVOKE=989;
	public static final int TOK_REVOKE_ROLE=990;
	public static final int TOK_REWRITE_DISABLED=991;
	public static final int TOK_REWRITE_ENABLED=992;
	public static final int TOK_RIGHTOUTERJOIN=993;
	public static final int TOK_ROLE=994;
	public static final int TOK_ROLLBACK=995;
	public static final int TOK_ROLLUP_GROUPBY=996;
	public static final int TOK_ROWCOUNT=997;
	public static final int TOK_SCHEDULING_POLICY=998;
	public static final int TOK_SELECT=999;
	public static final int TOK_SELECTDI=1000;
	public static final int TOK_SELEXPR=1001;
	public static final int TOK_SERDE=1002;
	public static final int TOK_SERDENAME=1003;
	public static final int TOK_SERDEPROPS=1004;
	public static final int TOK_SERVER_TYPE=1005;
	public static final int TOK_SETCOLREF=1006;
	public static final int TOK_SET_AUTOCOMMIT=1007;
	public static final int TOK_SET_COLUMNS_CLAUSE=1008;
	public static final int TOK_SHOWCOLUMNS=1009;
	public static final int TOK_SHOWCONF=1010;
	public static final int TOK_SHOWDATABASES=1011;
	public static final int TOK_SHOWDBLOCKS=1012;
	public static final int TOK_SHOWFUNCTIONS=1013;
	public static final int TOK_SHOWLOCKS=1014;
	public static final int TOK_SHOWMATERIALIZEDVIEWS=1015;
	public static final int TOK_SHOWPARTITIONS=1016;
	public static final int TOK_SHOWTABLES=1017;
	public static final int TOK_SHOWVIEWS=1018;
	public static final int TOK_SHOW_COMPACTIONS=1019;
	public static final int TOK_SHOW_CREATEDATABASE=1020;
	public static final int TOK_SHOW_CREATETABLE=1021;
	public static final int TOK_SHOW_GRANT=1022;
	public static final int TOK_SHOW_ROLES=1023;
	public static final int TOK_SHOW_ROLE_GRANT=1024;
	public static final int TOK_SHOW_ROLE_PRINCIPALS=1025;
	public static final int TOK_SHOW_RP=1026;
	public static final int TOK_SHOW_SET_ROLE=1027;
	public static final int TOK_SHOW_TABLESTATUS=1028;
	public static final int TOK_SHOW_TBLPROPERTIES=1029;
	public static final int TOK_SHOW_TRANSACTIONS=1030;
	public static final int TOK_SKEWED_LOCATIONS=1031;
	public static final int TOK_SKEWED_LOCATION_LIST=1032;
	public static final int TOK_SKEWED_LOCATION_MAP=1033;
	public static final int TOK_SMALLINT=1034;
	public static final int TOK_SORTBY=1035;
	public static final int TOK_START_TRANSACTION=1036;
	public static final int TOK_STORAGEHANDLER=1037;
	public static final int TOK_STOREDASDIRS=1038;
	public static final int TOK_STRING=1039;
	public static final int TOK_STRINGLITERALSEQUENCE=1040;
	public static final int TOK_STRUCT=1041;
	public static final int TOK_SUBQUERY=1042;
	public static final int TOK_SUBQUERY_EXPR=1043;
	public static final int TOK_SUBQUERY_OP=1044;
	public static final int TOK_SUBQUERY_OP_NOTEXISTS=1045;
	public static final int TOK_SUBQUERY_OP_NOTIN=1046;
	public static final int TOK_SUMMARY=1047;
	public static final int TOK_SWITCHDATABASE=1048;
	public static final int TOK_TAB=1049;
	public static final int TOK_TABALIAS=1050;
	public static final int TOK_TABCOL=1051;
	public static final int TOK_TABCOLLIST=1052;
	public static final int TOK_TABCOLNAME=1053;
	public static final int TOK_TABCOLVALUE=1054;
	public static final int TOK_TABCOLVALUES=1055;
	public static final int TOK_TABCOLVALUE_PAIR=1056;
	public static final int TOK_TABLEBUCKETSAMPLE=1057;
	public static final int TOK_TABLECOMMENT=1058;
	public static final int TOK_TABLEFILEFORMAT=1059;
	public static final int TOK_TABLELOCATION=1060;
	public static final int TOK_TABLEPARTCOLNAMES=1061;
	public static final int TOK_TABLEPARTCOLS=1062;
	public static final int TOK_TABLEPROPERTIES=1063;
	public static final int TOK_TABLEPROPERTY=1064;
	public static final int TOK_TABLEPROPLIST=1065;
	public static final int TOK_TABLEROWFORMAT=1066;
	public static final int TOK_TABLEROWFORMATCOLLITEMS=1067;
	public static final int TOK_TABLEROWFORMATFIELD=1068;
	public static final int TOK_TABLEROWFORMATLINES=1069;
	public static final int TOK_TABLEROWFORMATMAPKEYS=1070;
	public static final int TOK_TABLEROWFORMATNULL=1071;
	public static final int TOK_TABLESERIALIZER=1072;
	public static final int TOK_TABLESKEWED=1073;
	public static final int TOK_TABLESPLITSAMPLE=1074;
	public static final int TOK_TABLE_OR_COL=1075;
	public static final int TOK_TABLE_PARTITION=1076;
	public static final int TOK_TABLE_TYPE=1077;
	public static final int TOK_TABNAME=1078;
	public static final int TOK_TABREF=1079;
	public static final int TOK_TABSORTCOLNAMEASC=1080;
	public static final int TOK_TABSORTCOLNAMEDESC=1081;
	public static final int TOK_TABSRC=1082;
	public static final int TOK_TABTYPE=1083;
	public static final int TOK_TEMPORARY=1084;
	public static final int TOK_TIMESTAMP=1085;
	public static final int TOK_TIMESTAMPLITERAL=1086;
	public static final int TOK_TIMESTAMPLOCALTZ=1087;
	public static final int TOK_TIMESTAMPLOCALTZLITERAL=1088;
	public static final int TOK_TINYINT=1089;
	public static final int TOK_TMP_FILE=1090;
	public static final int TOK_TO=1091;
	public static final int TOK_TRANSFORM=1092;
	public static final int TOK_TRIGGER_EXPRESSION=1093;
	public static final int TOK_TRUE=1094;
	public static final int TOK_TRUNCATETABLE=1095;
	public static final int TOK_TXN_ACCESS_MODE=1096;
	public static final int TOK_TXN_READ_ONLY=1097;
	public static final int TOK_TXN_READ_WRITE=1098;
	public static final int TOK_UNIONALL=1099;
	public static final int TOK_UNIONDISTINCT=1100;
	public static final int TOK_UNIONTYPE=1101;
	public static final int TOK_UNIQUE=1102;
	public static final int TOK_UNIQUEJOIN=1103;
	public static final int TOK_UNLOCKDB=1104;
	public static final int TOK_UNLOCKTABLE=1105;
	public static final int TOK_UNMANAGED=1106;
	public static final int TOK_UPDATE=1107;
	public static final int TOK_UPDATE_TABLE=1108;
	public static final int TOK_URI_TYPE=1109;
	public static final int TOK_USER=1110;
	public static final int TOK_USERSCRIPTCOLNAMES=1111;
	public static final int TOK_USERSCRIPTCOLSCHEMA=1112;
	public static final int TOK_VALIDATE=1113;
	public static final int TOK_VARCHAR=1114;
	public static final int TOK_VIEWCLUSTERCOLS=1115;
	public static final int TOK_VIEWDISTRIBUTECOLS=1116;
	public static final int TOK_VIEWPARTCOLS=1117;
	public static final int TOK_VIEWSORTCOLS=1118;
	public static final int TOK_WHERE=1119;
	public static final int TOK_WINDOWDEF=1120;
	public static final int TOK_WINDOWRANGE=1121;
	public static final int TOK_WINDOWSPEC=1122;
	public static final int TOK_WINDOWVALUES=1123;

	// delegates
	public HiveParser_SelectClauseParser gSelectClauseParser;
	public HiveParser_FromClauseParser gFromClauseParser;
	public HiveParser_IdentifiersParser gIdentifiersParser;
	public HiveParser_ResourcePlanParser gResourcePlanParser;
	public Parser[] getDelegates() {
		return new Parser[] {gSelectClauseParser, gFromClauseParser, gIdentifiersParser, gResourcePlanParser};
	}

	// delegators


	public HiveParser(TokenStream input) {
		this(input, new RecognizerSharedState());
	}
	public HiveParser(TokenStream input, RecognizerSharedState state) {
		super(input, state);
		gSelectClauseParser = new HiveParser_SelectClauseParser(input, state, this);
		gFromClauseParser = new HiveParser_FromClauseParser(input, state, this);
		gIdentifiersParser = new HiveParser_IdentifiersParser(input, state, this);
		gResourcePlanParser = new HiveParser_ResourcePlanParser(input, state, this);
	}

	protected TreeAdaptor adaptor = new CommonTreeAdaptor();

	public void setTreeAdaptor(TreeAdaptor adaptor) {
		this.adaptor = adaptor;
		gSelectClauseParser.setTreeAdaptor(this.adaptor);gFromClauseParser.setTreeAdaptor(this.adaptor);gIdentifiersParser.setTreeAdaptor(this.adaptor);gResourcePlanParser.setTreeAdaptor(this.adaptor);
	}
	public TreeAdaptor getTreeAdaptor() {
		return adaptor;
	}
	@Override public String[] getTokenNames() { return HiveParser.tokenNames; }
	@Override public String getGrammarFileName() { return "org/apache/hadoop/hive/ql/parse/HiveParser.g"; }


	  ArrayList<ParseError> errors = new ArrayList<ParseError>();
	  Stack msgs = new Stack<String>();

	  private static HashMap<String, String> xlateMap;
	  static {
	    //this is used to support auto completion in CLI
	    xlateMap = new HashMap<String, String>();

	    // Keywords
	    xlateMap.put("KW_TRUE", "TRUE");
	    xlateMap.put("KW_FALSE", "FALSE");
	    xlateMap.put("KW_ALL", "ALL");
	    xlateMap.put("KW_NONE", "NONE");
	    xlateMap.put("KW_AND", "AND");
	    xlateMap.put("KW_OR", "OR");
	    xlateMap.put("KW_NOT", "NOT");
	    xlateMap.put("KW_LIKE", "LIKE");

	    xlateMap.put("KW_ASC", "ASC");
	    xlateMap.put("KW_DESC", "DESC");
	    xlateMap.put("KW_NULLS", "NULLS");
	    xlateMap.put("KW_LAST", "LAST");
	    xlateMap.put("KW_ORDER", "ORDER");
	    xlateMap.put("KW_BY", "BY");
	    xlateMap.put("KW_GROUP", "GROUP");
	    xlateMap.put("KW_WHERE", "WHERE");
	    xlateMap.put("KW_FROM", "FROM");
	    xlateMap.put("KW_AS", "AS");
	    xlateMap.put("KW_SELECT", "SELECT");
	    xlateMap.put("KW_DISTINCT", "DISTINCT");
	    xlateMap.put("KW_INSERT", "INSERT");
	    xlateMap.put("KW_OVERWRITE", "OVERWRITE");
	    xlateMap.put("KW_OUTER", "OUTER");
	    xlateMap.put("KW_JOIN", "JOIN");
	    xlateMap.put("KW_LEFT", "LEFT");
	    xlateMap.put("KW_RIGHT", "RIGHT");
	    xlateMap.put("KW_FULL", "FULL");
	    xlateMap.put("KW_ON", "ON");
	    xlateMap.put("KW_PARTITION", "PARTITION");
	    xlateMap.put("KW_PARTITIONS", "PARTITIONS");
	    xlateMap.put("KW_TABLE", "TABLE");
	    xlateMap.put("KW_TABLES", "TABLES");
	    xlateMap.put("KW_TBLPROPERTIES", "TBLPROPERTIES");
	    xlateMap.put("KW_SHOW", "SHOW");
	    xlateMap.put("KW_MSCK", "MSCK");
	    xlateMap.put("KW_DIRECTORY", "DIRECTORY");
	    xlateMap.put("KW_LOCAL", "LOCAL");
	    xlateMap.put("KW_TRANSFORM", "TRANSFORM");
	    xlateMap.put("KW_USING", "USING");
	    xlateMap.put("KW_CLUSTER", "CLUSTER");
	    xlateMap.put("KW_DISTRIBUTE", "DISTRIBUTE");
	    xlateMap.put("KW_SORT", "SORT");
	    xlateMap.put("KW_SYNC", "SYNC");
	    xlateMap.put("KW_UNION", "UNION");
	    xlateMap.put("KW_INTERSECT", "INTERSECT");
	    xlateMap.put("KW_EXCEPT", "EXCEPT");
	    xlateMap.put("KW_LOAD", "LOAD");
	    xlateMap.put("KW_DATA", "DATA");
	    xlateMap.put("KW_INPATH", "INPATH");
	    xlateMap.put("KW_IS", "IS");
	    xlateMap.put("KW_NULL", "NULL");
	    xlateMap.put("KW_CREATE", "CREATE");
	    xlateMap.put("KW_EXTERNAL", "EXTERNAL");
	    xlateMap.put("KW_ALTER", "ALTER");
	    xlateMap.put("KW_DESCRIBE", "DESCRIBE");
	    xlateMap.put("KW_DROP", "DROP");
	    xlateMap.put("KW_RENAME", "RENAME");
	    xlateMap.put("KW_TO", "TO");
	    xlateMap.put("KW_COMMENT", "COMMENT");
	    xlateMap.put("KW_BOOLEAN", "BOOLEAN");
	    xlateMap.put("KW_TINYINT", "TINYINT");
	    xlateMap.put("KW_SMALLINT", "SMALLINT");
	    xlateMap.put("KW_INT", "INT");
	    xlateMap.put("KW_BIGINT", "BIGINT");
	    xlateMap.put("KW_FLOAT", "FLOAT");
	    xlateMap.put("KW_DOUBLE", "DOUBLE");
	    xlateMap.put("KW_PRECISION", "PRECISION");
	    xlateMap.put("KW_DATE", "DATE");
	    xlateMap.put("KW_DATETIME", "DATETIME");
	    xlateMap.put("KW_TIMESTAMP", "TIMESTAMP");
	    xlateMap.put("KW_TIMESTAMPLOCALTZ", "TIMESTAMPLOCALTZ");
	    xlateMap.put("KW_TIME", "TIME");
	    xlateMap.put("KW_ZONE", "ZONE");
	    xlateMap.put("KW_STRING", "STRING");
	    xlateMap.put("KW_BINARY", "BINARY");
	    xlateMap.put("KW_ARRAY", "ARRAY");
	    xlateMap.put("KW_MAP", "MAP");
	    xlateMap.put("KW_REDUCE", "REDUCE");
	    xlateMap.put("KW_PARTITIONED", "PARTITIONED");
	    xlateMap.put("KW_CLUSTERED", "CLUSTERED");
	    xlateMap.put("KW_SORTED", "SORTED");
	    xlateMap.put("KW_INTO", "INTO");
	    xlateMap.put("KW_BUCKETS", "BUCKETS");
	    xlateMap.put("KW_ROW", "ROW");
	    xlateMap.put("KW_FORMAT", "FORMAT");
	    xlateMap.put("KW_DELIMITED", "DELIMITED");
	    xlateMap.put("KW_FIELDS", "FIELDS");
	    xlateMap.put("KW_TERMINATED", "TERMINATED");
	    xlateMap.put("KW_COLLECTION", "COLLECTION");
	    xlateMap.put("KW_ITEMS", "ITEMS");
	    xlateMap.put("KW_KEYS", "KEYS");
	    xlateMap.put("KW_KEY_TYPE", "$KEY$");
	    xlateMap.put("KW_LINES", "LINES");
	    xlateMap.put("KW_STORED", "STORED");
	    xlateMap.put("KW_SEQUENCEFILE", "SEQUENCEFILE");
	    xlateMap.put("KW_TEXTFILE", "TEXTFILE");
	    xlateMap.put("KW_INPUTFORMAT", "INPUTFORMAT");
	    xlateMap.put("KW_OUTPUTFORMAT", "OUTPUTFORMAT");
	    xlateMap.put("KW_LOCATION", "LOCATION");
	    xlateMap.put("KW_TABLESAMPLE", "TABLESAMPLE");
	    xlateMap.put("KW_BUCKET", "BUCKET");
	    xlateMap.put("KW_OUT", "OUT");
	    xlateMap.put("KW_OF", "OF");
	    xlateMap.put("KW_CAST", "CAST");
	    xlateMap.put("KW_ADD", "ADD");
	    xlateMap.put("KW_REPLACE", "REPLACE");
	    xlateMap.put("KW_COLUMNS", "COLUMNS");
	    xlateMap.put("KW_RLIKE", "RLIKE");
	    xlateMap.put("KW_REGEXP", "REGEXP");
	    xlateMap.put("KW_TEMPORARY", "TEMPORARY");
	    xlateMap.put("KW_FUNCTION", "FUNCTION");
	    xlateMap.put("KW_FUNCTIONS", "FUNCTIONS");
	    xlateMap.put("KW_EXPLAIN", "EXPLAIN");
	    xlateMap.put("KW_EXTENDED", "EXTENDED");
	    xlateMap.put("KW_DEBUG", "DEBUG");
	    xlateMap.put("KW_SERDE", "SERDE");
	    xlateMap.put("KW_WITH", "WITH");
	    xlateMap.put("KW_SERDEPROPERTIES", "SERDEPROPERTIES");
	    xlateMap.put("KW_LIMIT", "LIMIT");
	    xlateMap.put("KW_OFFSET", "OFFSET");
	    xlateMap.put("KW_SET", "SET");
	    xlateMap.put("KW_PROPERTIES", "TBLPROPERTIES");
	    xlateMap.put("KW_VALUE_TYPE", "$VALUE$");
	    xlateMap.put("KW_ELEM_TYPE", "$ELEM$");
	    xlateMap.put("KW_DEFINED", "DEFINED");
	    xlateMap.put("KW_SUBQUERY", "SUBQUERY");
	    xlateMap.put("KW_REWRITE", "REWRITE");
	    xlateMap.put("KW_UPDATE", "UPDATE");
	    xlateMap.put("KW_VALUES", "VALUES");
	    xlateMap.put("KW_PURGE", "PURGE");
	    xlateMap.put("KW_UNIQUE", "UNIQUE");
	    xlateMap.put("KW_PRIMARY", "PRIMARY");
	    xlateMap.put("KW_FOREIGN", "FOREIGN");
	    xlateMap.put("KW_KEY", "KEY");
	    xlateMap.put("KW_REFERENCES", "REFERENCES");
	    xlateMap.put("KW_CONSTRAINT", "CONSTRAINT");
	    xlateMap.put("KW_ENABLE", "ENABLE");
	    xlateMap.put("KW_DISABLE", "DISABLE");
	    xlateMap.put("KW_VALIDATE", "VALIDATE");
	    xlateMap.put("KW_NOVALIDATE", "NOVALIDATE");
	    xlateMap.put("KW_RELY", "RELY");
	    xlateMap.put("KW_NORELY", "NORELY");
	    xlateMap.put("KW_ABORT", "ABORT");
	    xlateMap.put("KW_TRANSACTIONS", "TRANSACTIONS");
	    xlateMap.put("KW_COMPACTIONS", "COMPACTIONS");
	    xlateMap.put("KW_COMPACT", "COMPACT");
	    xlateMap.put("KW_WAIT", "WAIT");
	    xlateMap.put("KW_KILL", "KILL");
	    xlateMap.put("KW_QUERY", "QUERY");
	    xlateMap.put("KW_RESOURCE", "RESOURCE");
	    xlateMap.put("KW_PLAN", "PLAN");
	    xlateMap.put("KW_QUERY_PARALLELISM", "QUERY_PARALLELISM");
	    xlateMap.put("KW_PLANS", "PLANS");
	    xlateMap.put("KW_ACTIVATE", "ACTIVATE");
	    xlateMap.put("KW_DEFAULT", "DEFAULT");
	    xlateMap.put("KW_CHECK", "CHECK");
	    xlateMap.put("KW_POOL", "POOL");
	    xlateMap.put("KW_MOVE", "MOVE");
	    xlateMap.put("KW_DO", "DO");
	    xlateMap.put("KW_ALLOC_FRACTION", "ALLOC_FRACTION");
	    xlateMap.put("KW_SCHEDULING_POLICY", "SCHEDULING_POLICY");
	    xlateMap.put("KW_PATH", "PATH");
	    xlateMap.put("KW_AST", "AST");
	    xlateMap.put("KW_TRANSACTIONAL", "TRANSACTIONAL");

	    // Operators
	    xlateMap.put("DOT", ".");
	    xlateMap.put("COLON", ":");
	    xlateMap.put("COMMA", ",");
	    xlateMap.put("SEMICOLON", ");");

	    xlateMap.put("LPAREN", "(");
	    xlateMap.put("RPAREN", ")");
	    xlateMap.put("LSQUARE", "[");
	    xlateMap.put("RSQUARE", "]");

	    xlateMap.put("EQUAL", "=");
	    xlateMap.put("NOTEQUAL", "<>");
	    xlateMap.put("EQUAL_NS", "<=>");
	    xlateMap.put("LESSTHANOREQUALTO", "<=");
	    xlateMap.put("LESSTHAN", "<");
	    xlateMap.put("GREATERTHANOREQUALTO", ">=");
	    xlateMap.put("GREATERTHAN", ">");

	    xlateMap.put("DIVIDE", "/");
	    xlateMap.put("PLUS", "+");
	    xlateMap.put("MINUS", "-");
	    xlateMap.put("STAR", "*");
	    xlateMap.put("MOD", "%");

	    xlateMap.put("AMPERSAND", "&");
	    xlateMap.put("TILDE", "~");
	    xlateMap.put("BITWISEOR", "|");
	    xlateMap.put("BITWISEXOR", "^");
	    xlateMap.put("CharSetLiteral", "\\'");
	  }

	  public static Collection<String> getKeywords() {
	    return xlateMap.values();
	  }

	  private static String xlate(String name) {

	    String ret = xlateMap.get(name);
	    if (ret == null) {
	      ret = name;
	    }

	    return ret;
	  }

	  @Override
	  public Object recoverFromMismatchedSet(IntStream input,
	      RecognitionException re, BitSet follow) throws RecognitionException {
	    throw re;
	  }

	  @Override
	  public void displayRecognitionError(String[] tokenNames,
	      RecognitionException e) {
	    errors.add(new ParseError(this, e, tokenNames));
	  }

	  @Override
	  public String getErrorHeader(RecognitionException e) {
	    String header = null;
	    if (e.charPositionInLine < 0 && input.LT(-1) != null) {
	      Token t = input.LT(-1);
	      header = "line " + t.getLine() + ":" + t.getCharPositionInLine();
	    } else {
	      header = super.getErrorHeader(e);
	    }

	    return header;
	  }
	  
	  @Override
	  public String getErrorMessage(RecognitionException e, String[] tokenNames) {
	    String msg = null;

	    // Translate the token names to something that the user can understand
	    String[] xlateNames = new String[tokenNames.length];
	    for (int i = 0; i < tokenNames.length; ++i) {
	      xlateNames[i] = HiveParser.xlate(tokenNames[i]);
	    }

	    if (e instanceof NoViableAltException) {
	      @SuppressWarnings("unused")
	      NoViableAltException nvae = (NoViableAltException) e;
	      // for development, can add
	      // "decision=<<"+nvae.grammarDecisionDescription+">>"
	      // and "(decision="+nvae.decisionNumber+") and
	      // "state "+nvae.stateNumber
	      msg = "cannot recognize input near"
	              + (input.LT(1) != null ? " " + getTokenErrorDisplay(input.LT(1)) : "")
	              + (input.LT(2) != null ? " " + getTokenErrorDisplay(input.LT(2)) : "")
	              + (input.LT(3) != null ? " " + getTokenErrorDisplay(input.LT(3)) : "");
	    } else if (e instanceof MismatchedTokenException) {
	      MismatchedTokenException mte = (MismatchedTokenException) e;
	      msg = super.getErrorMessage(e, xlateNames) + (input.LT(-1) == null ? "":" near '" + input.LT(-1).getText()) + "'";
	    } else if (e instanceof FailedPredicateException) {
	      FailedPredicateException fpe = (FailedPredicateException) e;
	      msg = "Failed to recognize predicate '" + fpe.token.getText() + "'. Failed rule: '" + fpe.ruleName + "'";
	    } else {
	      msg = super.getErrorMessage(e, xlateNames);
	    }

	    if (msgs.size() > 0) {
	      msg = msg + " in " + msgs.peek();
	    }
	    return msg;
	  }
	  
	  public void pushMsg(String msg, RecognizerSharedState state) {
	    // ANTLR generated code does not wrap the @init code wit this backtracking check,
	    //  even if the matching @after has it. If we have parser rules with that are doing
	    // some lookahead with syntactic predicates this can cause the push() and pop() calls
	    // to become unbalanced, so make sure both push/pop check the backtracking state.
	    if (state.backtracking == 0) {
	      msgs.push(msg);
	    }
	  }

	  public void popMsg(RecognizerSharedState state) {
	    if (state.backtracking == 0) {
	      Object o = msgs.pop();
	    }
	  }

	  // counter to generate unique union aliases
	  private int aliasCounter;
	  private String generateUnionAlias() {
	    return "__u" + (++aliasCounter);
	  }
	  private char [] excludedCharForColumnName = {'.', ':'};
	  private boolean containExcludedCharForCreateTableColumnName(String input) {
	    for(char c : excludedCharForColumnName) {
	      if(input.indexOf(c)>-1) {
	        return true;
	      }
	    }
	    return false;
	  }
	  private CommonTree throwSetOpException() throws RecognitionException {
	    throw new FailedPredicateException(input, "orderByClause clusterByClause distributeByClause sortByClause limitClause can only be applied to the whole union.", "");
	  }
	  private CommonTree throwColumnNameException() throws RecognitionException {
	    throw new FailedPredicateException(input, Arrays.toString(excludedCharForColumnName) + " can not be used in column name in create table statement.", "");
	  }
	  private Configuration hiveConf;
	  public void setHiveConf(Configuration hiveConf) {
	    this.hiveConf = hiveConf;
	  }
	  protected boolean nullsLast() {
	    if(hiveConf == null){
	      return false;
	    }
	    return HiveConf.getBoolVar(hiveConf, HiveConf.ConfVars.HIVE_DEFAULT_NULLS_LAST);
	  }


	public static class statement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "statement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:789:1: statement : ( explainStatement EOF | execStatement EOF );
	public final HiveParser.statement_return statement() throws RecognitionException {
		HiveParser.statement_return retval = new HiveParser.statement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token EOF2=null;
		Token EOF4=null;
		ParserRuleReturnScope explainStatement1 =null;
		ParserRuleReturnScope execStatement3 =null;

		ASTNode EOF2_tree=null;
		ASTNode EOF4_tree=null;

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:790:2: ( explainStatement EOF | execStatement EOF )
			int alt1=2;
			int LA1_0 = input.LA(1);
			if ( (LA1_0==KW_EXPLAIN) ) {
				alt1=1;
			}
			else if ( (LA1_0==KW_ABORT||(LA1_0 >= KW_ALTER && LA1_0 <= KW_ANALYZE)||LA1_0==KW_COMMIT||LA1_0==KW_CREATE||LA1_0==KW_DELETE||(LA1_0 >= KW_DESC && LA1_0 <= KW_DESCRIBE)||LA1_0==KW_DISABLE||LA1_0==KW_DROP||LA1_0==KW_ENABLE||LA1_0==KW_EXPORT||LA1_0==KW_FROM||LA1_0==KW_GRANT||LA1_0==KW_IMPORT||LA1_0==KW_INSERT||LA1_0==KW_KILL||LA1_0==KW_LOAD||LA1_0==KW_LOCK||LA1_0==KW_MAP||LA1_0==KW_MERGE||LA1_0==KW_MSCK||LA1_0==KW_REDUCE||LA1_0==KW_RELOAD||(LA1_0 >= KW_REPL && LA1_0 <= KW_REPLACE)||LA1_0==KW_REVOKE||LA1_0==KW_ROLLBACK||LA1_0==KW_SELECT||LA1_0==KW_SET||LA1_0==KW_SHOW||LA1_0==KW_START||LA1_0==KW_TRUNCATE||LA1_0==KW_UNLOCK||LA1_0==KW_UPDATE||LA1_0==KW_USE||LA1_0==KW_WITH||LA1_0==LPAREN) ) {
				alt1=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 1, 0, input);
				throw nvae;
			}

			switch (alt1) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:790:4: explainStatement EOF
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_explainStatement_in_statement1298);
					explainStatement1=explainStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, explainStatement1.getTree());

					EOF2=(Token)match(input,EOF,FOLLOW_EOF_in_statement1300); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					EOF2_tree = (ASTNode)adaptor.create(EOF2);
					adaptor.addChild(root_0, EOF2_tree);
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:791:4: execStatement EOF
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_execStatement_in_statement1305);
					execStatement3=execStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, execStatement3.getTree());

					EOF4=(Token)match(input,EOF,FOLLOW_EOF_in_statement1307); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					EOF4_tree = (ASTNode)adaptor.create(EOF4);
					adaptor.addChild(root_0, EOF4_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "statement"


	public static class explainStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "explainStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:794:1: explainStatement : KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) ;
	public final HiveParser.explainStatement_return explainStatement() throws RecognitionException {
		HiveParser.explainStatement_return retval = new HiveParser.explainStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_EXPLAIN5=null;
		Token KW_REWRITE8=null;
		ParserRuleReturnScope explainOption6 =null;
		ParserRuleReturnScope execStatement7 =null;
		ParserRuleReturnScope queryStatementExpression9 =null;

		ASTNode KW_EXPLAIN5_tree=null;
		ASTNode KW_REWRITE8_tree=null;
		RewriteRuleTokenStream stream_KW_REWRITE=new RewriteRuleTokenStream(adaptor,"token KW_REWRITE");
		RewriteRuleTokenStream stream_KW_EXPLAIN=new RewriteRuleTokenStream(adaptor,"token KW_EXPLAIN");
		RewriteRuleSubtreeStream stream_queryStatementExpression=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpression");
		RewriteRuleSubtreeStream stream_explainOption=new RewriteRuleSubtreeStream(adaptor,"rule explainOption");
		RewriteRuleSubtreeStream stream_execStatement=new RewriteRuleSubtreeStream(adaptor,"rule execStatement");

		 pushMsg("explain statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:797:2: ( KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:797:4: KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
			{
			KW_EXPLAIN5=(Token)match(input,KW_EXPLAIN,FOLLOW_KW_EXPLAIN_in_explainStatement1328); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXPLAIN.add(KW_EXPLAIN5);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:797:15: ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
			int alt3=2;
			int LA3_0 = input.LA(1);
			if ( (LA3_0==KW_ABORT||(LA3_0 >= KW_ALTER && LA3_0 <= KW_ANALYZE)||LA3_0==KW_AUTHORIZATION||LA3_0==KW_CBO||LA3_0==KW_COMMIT||LA3_0==KW_CREATE||LA3_0==KW_DEBUG||LA3_0==KW_DELETE||(LA3_0 >= KW_DEPENDENCY && LA3_0 <= KW_DESCRIBE)||LA3_0==KW_DISABLE||LA3_0==KW_DROP||LA3_0==KW_ENABLE||LA3_0==KW_EXPORT||LA3_0==KW_EXTENDED||(LA3_0 >= KW_FORMATTED && LA3_0 <= KW_FROM)||LA3_0==KW_GRANT||LA3_0==KW_IMPORT||LA3_0==KW_INSERT||LA3_0==KW_KILL||LA3_0==KW_LOAD||(LA3_0 >= KW_LOCK && LA3_0 <= KW_LOGICAL)||LA3_0==KW_MAP||LA3_0==KW_MERGE||LA3_0==KW_MSCK||LA3_0==KW_REDUCE||LA3_0==KW_RELOAD||LA3_0==KW_REOPTIMIZATION||(LA3_0 >= KW_REPL && LA3_0 <= KW_REPLACE)||LA3_0==KW_REVOKE||LA3_0==KW_ROLLBACK||LA3_0==KW_SELECT||LA3_0==KW_SET||LA3_0==KW_SHOW||LA3_0==KW_START||LA3_0==KW_TRUNCATE||LA3_0==KW_UNLOCK||LA3_0==KW_UPDATE||LA3_0==KW_USE||LA3_0==KW_VECTORIZATION||LA3_0==KW_WITH||LA3_0==LPAREN) ) {
				alt3=1;
			}
			else if ( (LA3_0==KW_REWRITE) ) {
				alt3=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 3, 0, input);
				throw nvae;
			}

			switch (alt3) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:798:6: ( explainOption )* execStatement
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:798:6: ( explainOption )*
					loop2:
					while (true) {
						int alt2=2;
						alt2 = dfa2.predict(input);
						switch (alt2) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:798:6: explainOption
							{
							pushFollow(FOLLOW_explainOption_in_explainStatement1337);
							explainOption6=explainOption();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_explainOption.add(explainOption6.getTree());
							}
							break;

						default :
							break loop2;
						}
					}

					pushFollow(FOLLOW_execStatement_in_explainStatement1340);
					execStatement7=execStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_execStatement.add(execStatement7.getTree());
					// AST REWRITE
					// elements: explainOption, execStatement
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 798:35: -> ^( TOK_EXPLAIN execStatement ( explainOption )* )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:798:38: ^( TOK_EXPLAIN execStatement ( explainOption )* )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPLAIN, "TOK_EXPLAIN"), root_1);
						adaptor.addChild(root_1, stream_execStatement.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:798:66: ( explainOption )*
						while ( stream_explainOption.hasNext() ) {
							adaptor.addChild(root_1, stream_explainOption.nextTree());
						}
						stream_explainOption.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:800:9: KW_REWRITE queryStatementExpression
					{
					KW_REWRITE8=(Token)match(input,KW_REWRITE,FOLLOW_KW_REWRITE_in_explainStatement1371); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REWRITE.add(KW_REWRITE8);

					pushFollow(FOLLOW_queryStatementExpression_in_explainStatement1373);
					queryStatementExpression9=queryStatementExpression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_queryStatementExpression.add(queryStatementExpression9.getTree());
					// AST REWRITE
					// elements: queryStatementExpression
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 800:45: -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:800:48: ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPLAIN_SQ_REWRITE, "TOK_EXPLAIN_SQ_REWRITE"), root_1);
						adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "explainStatement"


	public static class explainOption_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "explainOption"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:804:1: explainOption : ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_CBO ( KW_COST | KW_JOINCOST )? | KW_LOGICAL | KW_AUTHORIZATION | KW_ANALYZE | KW_REOPTIMIZATION | KW_LOCKS | ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? ) | KW_DEBUG );
	public final HiveParser.explainOption_return explainOption() throws RecognitionException {
		HiveParser.explainOption_return retval = new HiveParser.explainOption_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_EXTENDED10=null;
		Token KW_FORMATTED11=null;
		Token KW_DEPENDENCY12=null;
		Token KW_CBO13=null;
		Token set14=null;
		Token KW_LOGICAL15=null;
		Token KW_AUTHORIZATION16=null;
		Token KW_ANALYZE17=null;
		Token KW_REOPTIMIZATION18=null;
		Token KW_LOCKS19=null;
		Token KW_VECTORIZATION20=null;
		Token KW_DEBUG23=null;
		ParserRuleReturnScope vectorizationOnly21 =null;
		ParserRuleReturnScope vectorizatonDetail22 =null;

		ASTNode KW_EXTENDED10_tree=null;
		ASTNode KW_FORMATTED11_tree=null;
		ASTNode KW_DEPENDENCY12_tree=null;
		ASTNode KW_CBO13_tree=null;
		ASTNode set14_tree=null;
		ASTNode KW_LOGICAL15_tree=null;
		ASTNode KW_AUTHORIZATION16_tree=null;
		ASTNode KW_ANALYZE17_tree=null;
		ASTNode KW_REOPTIMIZATION18_tree=null;
		ASTNode KW_LOCKS19_tree=null;
		ASTNode KW_VECTORIZATION20_tree=null;
		ASTNode KW_DEBUG23_tree=null;

		 msgs.push("explain option"); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:807:5: ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_CBO ( KW_COST | KW_JOINCOST )? | KW_LOGICAL | KW_AUTHORIZATION | KW_ANALYZE | KW_REOPTIMIZATION | KW_LOCKS | ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? ) | KW_DEBUG )
			int alt7=11;
			switch ( input.LA(1) ) {
			case KW_EXTENDED:
				{
				alt7=1;
				}
				break;
			case KW_FORMATTED:
				{
				alt7=2;
				}
				break;
			case KW_DEPENDENCY:
				{
				alt7=3;
				}
				break;
			case KW_CBO:
				{
				alt7=4;
				}
				break;
			case KW_LOGICAL:
				{
				alt7=5;
				}
				break;
			case KW_AUTHORIZATION:
				{
				alt7=6;
				}
				break;
			case KW_ANALYZE:
				{
				alt7=7;
				}
				break;
			case KW_REOPTIMIZATION:
				{
				alt7=8;
				}
				break;
			case KW_LOCKS:
				{
				alt7=9;
				}
				break;
			case KW_VECTORIZATION:
				{
				alt7=10;
				}
				break;
			case KW_DEBUG:
				{
				alt7=11;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 7, 0, input);
				throw nvae;
			}
			switch (alt7) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:807:7: KW_EXTENDED
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_EXTENDED10=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_explainOption1413); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_EXTENDED10_tree = (ASTNode)adaptor.create(KW_EXTENDED10);
					adaptor.addChild(root_0, KW_EXTENDED10_tree);
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:808:7: KW_FORMATTED
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_FORMATTED11=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_explainOption1421); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_FORMATTED11_tree = (ASTNode)adaptor.create(KW_FORMATTED11);
					adaptor.addChild(root_0, KW_FORMATTED11_tree);
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:809:7: KW_DEPENDENCY
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_DEPENDENCY12=(Token)match(input,KW_DEPENDENCY,FOLLOW_KW_DEPENDENCY_in_explainOption1429); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_DEPENDENCY12_tree = (ASTNode)adaptor.create(KW_DEPENDENCY12);
					adaptor.addChild(root_0, KW_DEPENDENCY12_tree);
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:810:7: KW_CBO ( KW_COST | KW_JOINCOST )?
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_CBO13=(Token)match(input,KW_CBO,FOLLOW_KW_CBO_in_explainOption1437); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_CBO13_tree = (ASTNode)adaptor.create(KW_CBO13);
					adaptor.addChild(root_0, KW_CBO13_tree);
					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:810:14: ( KW_COST | KW_JOINCOST )?
					int alt4=2;
					int LA4_0 = input.LA(1);
					if ( (LA4_0==KW_COST||LA4_0==KW_JOINCOST) ) {
						alt4=1;
					}
					switch (alt4) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:
							{
							set14=input.LT(1);
							if ( input.LA(1)==KW_COST||input.LA(1)==KW_JOINCOST ) {
								input.consume();
								if ( state.backtracking==0 ) adaptor.addChild(root_0, (ASTNode)adaptor.create(set14));
								state.errorRecovery=false;
								state.failed=false;
							}
							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								MismatchedSetException mse = new MismatchedSetException(null,input);
								throw mse;
							}
							}
							break;

					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:811:7: KW_LOGICAL
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_LOGICAL15=(Token)match(input,KW_LOGICAL,FOLLOW_KW_LOGICAL_in_explainOption1454); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_LOGICAL15_tree = (ASTNode)adaptor.create(KW_LOGICAL15);
					adaptor.addChild(root_0, KW_LOGICAL15_tree);
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:812:7: KW_AUTHORIZATION
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_AUTHORIZATION16=(Token)match(input,KW_AUTHORIZATION,FOLLOW_KW_AUTHORIZATION_in_explainOption1462); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_AUTHORIZATION16_tree = (ASTNode)adaptor.create(KW_AUTHORIZATION16);
					adaptor.addChild(root_0, KW_AUTHORIZATION16_tree);
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:813:7: KW_ANALYZE
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_ANALYZE17=(Token)match(input,KW_ANALYZE,FOLLOW_KW_ANALYZE_in_explainOption1470); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_ANALYZE17_tree = (ASTNode)adaptor.create(KW_ANALYZE17);
					adaptor.addChild(root_0, KW_ANALYZE17_tree);
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:814:7: KW_REOPTIMIZATION
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_REOPTIMIZATION18=(Token)match(input,KW_REOPTIMIZATION,FOLLOW_KW_REOPTIMIZATION_in_explainOption1478); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_REOPTIMIZATION18_tree = (ASTNode)adaptor.create(KW_REOPTIMIZATION18);
					adaptor.addChild(root_0, KW_REOPTIMIZATION18_tree);
					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:815:7: KW_LOCKS
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_LOCKS19=(Token)match(input,KW_LOCKS,FOLLOW_KW_LOCKS_in_explainOption1486); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_LOCKS19_tree = (ASTNode)adaptor.create(KW_LOCKS19);
					adaptor.addChild(root_0, KW_LOCKS19_tree);
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:816:7: ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:816:7: ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:816:8: KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )?
					{
					KW_VECTORIZATION20=(Token)match(input,KW_VECTORIZATION,FOLLOW_KW_VECTORIZATION_in_explainOption1495); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_VECTORIZATION20_tree = (ASTNode)adaptor.create(KW_VECTORIZATION20);
					adaptor.addChild(root_0, KW_VECTORIZATION20_tree);
					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:816:25: ( vectorizationOnly )?
					int alt5=2;
					int LA5_0 = input.LA(1);
					if ( (LA5_0==KW_ONLY) ) {
						alt5=1;
					}
					switch (alt5) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:816:25: vectorizationOnly
							{
							pushFollow(FOLLOW_vectorizationOnly_in_explainOption1497);
							vectorizationOnly21=vectorizationOnly();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, vectorizationOnly21.getTree());

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:816:44: ( vectorizatonDetail )?
					int alt6=2;
					int LA6_0 = input.LA(1);
					if ( (LA6_0==KW_DETAIL||LA6_0==KW_EXPRESSION||LA6_0==KW_OPERATOR||LA6_0==KW_SUMMARY) ) {
						alt6=1;
					}
					switch (alt6) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:816:44: vectorizatonDetail
							{
							pushFollow(FOLLOW_vectorizatonDetail_in_explainOption1500);
							vectorizatonDetail22=vectorizatonDetail();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, vectorizatonDetail22.getTree());

							}
							break;

					}

					}

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:817:7: KW_DEBUG
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_DEBUG23=(Token)match(input,KW_DEBUG,FOLLOW_KW_DEBUG_in_explainOption1510); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_DEBUG23_tree = (ASTNode)adaptor.create(KW_DEBUG23);
					adaptor.addChild(root_0, KW_DEBUG23_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { msgs.pop(); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "explainOption"


	public static class vectorizationOnly_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "vectorizationOnly"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:820:1: vectorizationOnly : KW_ONLY -> ^( TOK_ONLY ) ;
	public final HiveParser.vectorizationOnly_return vectorizationOnly() throws RecognitionException {
		HiveParser.vectorizationOnly_return retval = new HiveParser.vectorizationOnly_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ONLY24=null;

		ASTNode KW_ONLY24_tree=null;
		RewriteRuleTokenStream stream_KW_ONLY=new RewriteRuleTokenStream(adaptor,"token KW_ONLY");

		 pushMsg("vectorization's only clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:823:5: ( KW_ONLY -> ^( TOK_ONLY ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:823:7: KW_ONLY
			{
			KW_ONLY24=(Token)match(input,KW_ONLY,FOLLOW_KW_ONLY_in_vectorizationOnly1537); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ONLY.add(KW_ONLY24);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 824:5: -> ^( TOK_ONLY )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:824:8: ^( TOK_ONLY )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ONLY, "TOK_ONLY"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "vectorizationOnly"


	public static class vectorizatonDetail_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "vectorizatonDetail"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:827:1: vectorizatonDetail : ( KW_SUMMARY -> ^( TOK_SUMMARY ) | KW_OPERATOR -> ^( TOK_OPERATOR ) | KW_EXPRESSION -> ^( TOK_EXPRESSION ) | KW_DETAIL -> ^( TOK_DETAIL ) );
	public final HiveParser.vectorizatonDetail_return vectorizatonDetail() throws RecognitionException {
		HiveParser.vectorizatonDetail_return retval = new HiveParser.vectorizatonDetail_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SUMMARY25=null;
		Token KW_OPERATOR26=null;
		Token KW_EXPRESSION27=null;
		Token KW_DETAIL28=null;

		ASTNode KW_SUMMARY25_tree=null;
		ASTNode KW_OPERATOR26_tree=null;
		ASTNode KW_EXPRESSION27_tree=null;
		ASTNode KW_DETAIL28_tree=null;
		RewriteRuleTokenStream stream_KW_SUMMARY=new RewriteRuleTokenStream(adaptor,"token KW_SUMMARY");
		RewriteRuleTokenStream stream_KW_DETAIL=new RewriteRuleTokenStream(adaptor,"token KW_DETAIL");
		RewriteRuleTokenStream stream_KW_OPERATOR=new RewriteRuleTokenStream(adaptor,"token KW_OPERATOR");
		RewriteRuleTokenStream stream_KW_EXPRESSION=new RewriteRuleTokenStream(adaptor,"token KW_EXPRESSION");

		 pushMsg("vectorization's detail level clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:830:5: ( KW_SUMMARY -> ^( TOK_SUMMARY ) | KW_OPERATOR -> ^( TOK_OPERATOR ) | KW_EXPRESSION -> ^( TOK_EXPRESSION ) | KW_DETAIL -> ^( TOK_DETAIL ) )
			int alt8=4;
			switch ( input.LA(1) ) {
			case KW_SUMMARY:
				{
				alt8=1;
				}
				break;
			case KW_OPERATOR:
				{
				alt8=2;
				}
				break;
			case KW_EXPRESSION:
				{
				alt8=3;
				}
				break;
			case KW_DETAIL:
				{
				alt8=4;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 8, 0, input);
				throw nvae;
			}
			switch (alt8) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:830:7: KW_SUMMARY
					{
					KW_SUMMARY25=(Token)match(input,KW_SUMMARY,FOLLOW_KW_SUMMARY_in_vectorizatonDetail1574); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SUMMARY.add(KW_SUMMARY25);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 831:5: -> ^( TOK_SUMMARY )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:831:8: ^( TOK_SUMMARY )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUMMARY, "TOK_SUMMARY"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:832:7: KW_OPERATOR
					{
					KW_OPERATOR26=(Token)match(input,KW_OPERATOR,FOLLOW_KW_OPERATOR_in_vectorizatonDetail1592); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OPERATOR.add(KW_OPERATOR26);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 833:5: -> ^( TOK_OPERATOR )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:833:8: ^( TOK_OPERATOR )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_OPERATOR, "TOK_OPERATOR"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:834:7: KW_EXPRESSION
					{
					KW_EXPRESSION27=(Token)match(input,KW_EXPRESSION,FOLLOW_KW_EXPRESSION_in_vectorizatonDetail1610); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXPRESSION.add(KW_EXPRESSION27);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 835:5: -> ^( TOK_EXPRESSION )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:835:8: ^( TOK_EXPRESSION )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPRESSION, "TOK_EXPRESSION"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:836:7: KW_DETAIL
					{
					KW_DETAIL28=(Token)match(input,KW_DETAIL,FOLLOW_KW_DETAIL_in_vectorizatonDetail1628); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DETAIL.add(KW_DETAIL28);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 837:5: -> ^( TOK_DETAIL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:837:8: ^( TOK_DETAIL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DETAIL, "TOK_DETAIL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "vectorizatonDetail"


	public static class execStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "execStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:840:1: execStatement : ( queryStatementExpression | loadStatement | exportStatement | importStatement | replDumpStatement | replLoadStatement | replStatusStatement | ddlStatement | deleteStatement | updateStatement | sqlTransactionStatement | mergeStatement );
	public final HiveParser.execStatement_return execStatement() throws RecognitionException {
		HiveParser.execStatement_return retval = new HiveParser.execStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope queryStatementExpression29 =null;
		ParserRuleReturnScope loadStatement30 =null;
		ParserRuleReturnScope exportStatement31 =null;
		ParserRuleReturnScope importStatement32 =null;
		ParserRuleReturnScope replDumpStatement33 =null;
		ParserRuleReturnScope replLoadStatement34 =null;
		ParserRuleReturnScope replStatusStatement35 =null;
		ParserRuleReturnScope ddlStatement36 =null;
		ParserRuleReturnScope deleteStatement37 =null;
		ParserRuleReturnScope updateStatement38 =null;
		ParserRuleReturnScope sqlTransactionStatement39 =null;
		ParserRuleReturnScope mergeStatement40 =null;


		 pushMsg("statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:843:5: ( queryStatementExpression | loadStatement | exportStatement | importStatement | replDumpStatement | replLoadStatement | replStatusStatement | ddlStatement | deleteStatement | updateStatement | sqlTransactionStatement | mergeStatement )
			int alt9=12;
			switch ( input.LA(1) ) {
			case KW_FROM:
			case KW_INSERT:
			case KW_MAP:
			case KW_REDUCE:
			case KW_SELECT:
			case KW_WITH:
			case LPAREN:
				{
				alt9=1;
				}
				break;
			case KW_LOAD:
				{
				alt9=2;
				}
				break;
			case KW_EXPORT:
				{
				alt9=3;
				}
				break;
			case KW_IMPORT:
				{
				alt9=4;
				}
				break;
			case KW_REPL:
				{
				switch ( input.LA(2) ) {
				case KW_DUMP:
					{
					alt9=5;
					}
					break;
				case KW_LOAD:
					{
					alt9=6;
					}
					break;
				case KW_STATUS:
					{
					alt9=7;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 9, 11, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
				}
				break;
			case KW_ABORT:
			case KW_ALTER:
			case KW_ANALYZE:
			case KW_CREATE:
			case KW_DESC:
			case KW_DESCRIBE:
			case KW_DISABLE:
			case KW_DROP:
			case KW_ENABLE:
			case KW_GRANT:
			case KW_KILL:
			case KW_LOCK:
			case KW_MSCK:
			case KW_RELOAD:
			case KW_REPLACE:
			case KW_REVOKE:
			case KW_SHOW:
			case KW_TRUNCATE:
			case KW_UNLOCK:
			case KW_USE:
				{
				alt9=8;
				}
				break;
			case KW_SET:
				{
				int LA9_27 = input.LA(2);
				if ( (LA9_27==KW_ROLE) ) {
					alt9=8;
				}
				else if ( (LA9_27==KW_AUTOCOMMIT) ) {
					alt9=11;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 9, 27, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_DELETE:
				{
				alt9=9;
				}
				break;
			case KW_UPDATE:
				{
				alt9=10;
				}
				break;
			case KW_COMMIT:
			case KW_ROLLBACK:
			case KW_START:
				{
				alt9=11;
				}
				break;
			case KW_MERGE:
				{
				alt9=12;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 9, 0, input);
				throw nvae;
			}
			switch (alt9) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:843:7: queryStatementExpression
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_queryStatementExpression_in_execStatement1665);
					queryStatementExpression29=queryStatementExpression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, queryStatementExpression29.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:844:7: loadStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_loadStatement_in_execStatement1673);
					loadStatement30=loadStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, loadStatement30.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:845:7: exportStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_exportStatement_in_execStatement1681);
					exportStatement31=exportStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, exportStatement31.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:846:7: importStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_importStatement_in_execStatement1689);
					importStatement32=importStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, importStatement32.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:847:7: replDumpStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_replDumpStatement_in_execStatement1697);
					replDumpStatement33=replDumpStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, replDumpStatement33.getTree());

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:848:7: replLoadStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_replLoadStatement_in_execStatement1705);
					replLoadStatement34=replLoadStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, replLoadStatement34.getTree());

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:849:7: replStatusStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_replStatusStatement_in_execStatement1713);
					replStatusStatement35=replStatusStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, replStatusStatement35.getTree());

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:850:7: ddlStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_ddlStatement_in_execStatement1721);
					ddlStatement36=ddlStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, ddlStatement36.getTree());

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:851:7: deleteStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_deleteStatement_in_execStatement1729);
					deleteStatement37=deleteStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, deleteStatement37.getTree());

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:852:7: updateStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_updateStatement_in_execStatement1737);
					updateStatement38=updateStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, updateStatement38.getTree());

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:853:7: sqlTransactionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_sqlTransactionStatement_in_execStatement1745);
					sqlTransactionStatement39=sqlTransactionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, sqlTransactionStatement39.getTree());

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:854:7: mergeStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_mergeStatement_in_execStatement1753);
					mergeStatement40=mergeStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, mergeStatement40.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "execStatement"


	public static class loadStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "loadStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:857:1: loadStatement : KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) ( inputFileFormat )? -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? ) ;
	public final HiveParser.loadStatement_return loadStatement() throws RecognitionException {
		HiveParser.loadStatement_return retval = new HiveParser.loadStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token islocal=null;
		Token path=null;
		Token isoverwrite=null;
		Token KW_LOAD41=null;
		Token KW_DATA42=null;
		Token KW_INPATH43=null;
		Token KW_INTO44=null;
		Token KW_TABLE45=null;
		ParserRuleReturnScope tab =null;
		ParserRuleReturnScope inputFileFormat46 =null;

		ASTNode islocal_tree=null;
		ASTNode path_tree=null;
		ASTNode isoverwrite_tree=null;
		ASTNode KW_LOAD41_tree=null;
		ASTNode KW_DATA42_tree=null;
		ASTNode KW_INPATH43_tree=null;
		ASTNode KW_INTO44_tree=null;
		ASTNode KW_TABLE45_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_INPATH=new RewriteRuleTokenStream(adaptor,"token KW_INPATH");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
		RewriteRuleTokenStream stream_KW_LOAD=new RewriteRuleTokenStream(adaptor,"token KW_LOAD");
		RewriteRuleTokenStream stream_KW_DATA=new RewriteRuleTokenStream(adaptor,"token KW_DATA");
		RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
		RewriteRuleSubtreeStream stream_inputFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule inputFileFormat");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");

		 pushMsg("load statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:5: ( KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) ( inputFileFormat )? -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:7: KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) ( inputFileFormat )?
			{
			KW_LOAD41=(Token)match(input,KW_LOAD,FOLLOW_KW_LOAD_in_loadStatement1780); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOAD.add(KW_LOAD41);

			KW_DATA42=(Token)match(input,KW_DATA,FOLLOW_KW_DATA_in_loadStatement1782); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DATA.add(KW_DATA42);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:23: (islocal= KW_LOCAL )?
			int alt10=2;
			int LA10_0 = input.LA(1);
			if ( (LA10_0==KW_LOCAL) ) {
				alt10=1;
			}
			switch (alt10) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:24: islocal= KW_LOCAL
					{
					islocal=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_loadStatement1787); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCAL.add(islocal);

					}
					break;

			}

			KW_INPATH43=(Token)match(input,KW_INPATH,FOLLOW_KW_INPATH_in_loadStatement1791); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INPATH.add(KW_INPATH43);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:53: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:54: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_loadStatement1796); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:74: (isoverwrite= KW_OVERWRITE )?
			int alt11=2;
			int LA11_0 = input.LA(1);
			if ( (LA11_0==KW_OVERWRITE) ) {
				alt11=1;
			}
			switch (alt11) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:75: isoverwrite= KW_OVERWRITE
					{
					isoverwrite=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_loadStatement1802); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(isoverwrite);

					}
					break;

			}

			KW_INTO44=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_loadStatement1806); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO44);

			KW_TABLE45=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_loadStatement1808); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE45);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:119: (tab= tableOrPartition )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:120: tab= tableOrPartition
			{
			pushFollow(FOLLOW_tableOrPartition_in_loadStatement1813);
			tab=tableOrPartition();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:142: ( inputFileFormat )?
			int alt12=2;
			int LA12_0 = input.LA(1);
			if ( (LA12_0==KW_INPUTFORMAT) ) {
				alt12=1;
			}
			switch (alt12) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:142: inputFileFormat
					{
					pushFollow(FOLLOW_inputFileFormat_in_loadStatement1816);
					inputFileFormat46=inputFileFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_inputFileFormat.add(inputFileFormat46.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: path, isoverwrite, tab, inputFileFormat, islocal
			// token labels: islocal, path, isoverwrite
			// rule labels: tab, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_islocal=new RewriteRuleTokenStream(adaptor,"token islocal",islocal);
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleTokenStream stream_isoverwrite=new RewriteRuleTokenStream(adaptor,"token isoverwrite",isoverwrite);
			RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 861:5: -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:861:8: ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LOAD, "TOK_LOAD"), root_1);
				adaptor.addChild(root_1, stream_path.nextNode());
				adaptor.addChild(root_1, stream_tab.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:861:31: ( $islocal)?
				if ( stream_islocal.hasNext() ) {
					adaptor.addChild(root_1, stream_islocal.nextNode());
				}
				stream_islocal.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:861:41: ( $isoverwrite)?
				if ( stream_isoverwrite.hasNext() ) {
					adaptor.addChild(root_1, stream_isoverwrite.nextNode());
				}
				stream_isoverwrite.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:861:54: ( inputFileFormat )?
				if ( stream_inputFileFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_inputFileFormat.nextTree());
				}
				stream_inputFileFormat.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "loadStatement"


	public static class replicationClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replicationClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:864:1: replicationClause : KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) ;
	public final HiveParser.replicationClause_return replicationClause() throws RecognitionException {
		HiveParser.replicationClause_return retval = new HiveParser.replicationClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token isMetadataOnly=null;
		Token replId=null;
		Token KW_FOR47=null;
		Token KW_REPLICATION48=null;
		Token LPAREN49=null;
		Token RPAREN50=null;

		ASTNode isMetadataOnly_tree=null;
		ASTNode replId_tree=null;
		ASTNode KW_FOR47_tree=null;
		ASTNode KW_REPLICATION48_tree=null;
		ASTNode LPAREN49_tree=null;
		ASTNode RPAREN50_tree=null;
		RewriteRuleTokenStream stream_KW_REPLICATION=new RewriteRuleTokenStream(adaptor,"token KW_REPLICATION");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_METADATA=new RewriteRuleTokenStream(adaptor,"token KW_METADATA");

		 pushMsg("replication clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:867:5: ( KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:867:7: KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN
			{
			KW_FOR47=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_replicationClause1871); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR47);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:867:14: (isMetadataOnly= KW_METADATA )?
			int alt13=2;
			int LA13_0 = input.LA(1);
			if ( (LA13_0==KW_METADATA) ) {
				alt13=1;
			}
			switch (alt13) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:867:15: isMetadataOnly= KW_METADATA
					{
					isMetadataOnly=(Token)match(input,KW_METADATA,FOLLOW_KW_METADATA_in_replicationClause1876); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_METADATA.add(isMetadataOnly);

					}
					break;

			}

			KW_REPLICATION48=(Token)match(input,KW_REPLICATION,FOLLOW_KW_REPLICATION_in_replicationClause1880); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPLICATION.add(KW_REPLICATION48);

			LPAREN49=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_replicationClause1882); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN49);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:867:66: (replId= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:867:67: replId= StringLiteral
			{
			replId=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replicationClause1887); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(replId);

			}

			RPAREN50=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_replicationClause1890); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN50);

			// AST REWRITE
			// elements: replId, isMetadataOnly
			// token labels: replId, isMetadataOnly
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_replId=new RewriteRuleTokenStream(adaptor,"token replId",replId);
			RewriteRuleTokenStream stream_isMetadataOnly=new RewriteRuleTokenStream(adaptor,"token isMetadataOnly",isMetadataOnly);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 868:5: -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:868:8: ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPLICATION, "TOK_REPLICATION"), root_1);
				adaptor.addChild(root_1, stream_replId.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:868:35: ( $isMetadataOnly)?
				if ( stream_isMetadataOnly.hasNext() ) {
					adaptor.addChild(root_1, stream_isMetadataOnly.nextNode());
				}
				stream_isMetadataOnly.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replicationClause"


	public static class exportStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "exportStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:871:1: exportStatement : KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) ;
	public final HiveParser.exportStatement_return exportStatement() throws RecognitionException {
		HiveParser.exportStatement_return retval = new HiveParser.exportStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_EXPORT51=null;
		Token KW_TABLE52=null;
		Token KW_TO53=null;
		ParserRuleReturnScope tab =null;
		ParserRuleReturnScope replicationClause54 =null;

		ASTNode path_tree=null;
		ASTNode KW_EXPORT51_tree=null;
		ASTNode KW_TABLE52_tree=null;
		ASTNode KW_TO53_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_EXPORT=new RewriteRuleTokenStream(adaptor,"token KW_EXPORT");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
		RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");

		 pushMsg("export statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:874:5: ( KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:874:7: KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )?
			{
			KW_EXPORT51=(Token)match(input,KW_EXPORT,FOLLOW_KW_EXPORT_in_exportStatement1934); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXPORT.add(KW_EXPORT51);

			KW_TABLE52=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_exportStatement1942); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE52);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:875:16: (tab= tableOrPartition )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:875:17: tab= tableOrPartition
			{
			pushFollow(FOLLOW_tableOrPartition_in_exportStatement1947);
			tab=tableOrPartition();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());
			}

			KW_TO53=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_exportStatement1956); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO53);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:876:13: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:876:14: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_exportStatement1961); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:877:7: ( replicationClause )?
			int alt14=2;
			int LA14_0 = input.LA(1);
			if ( (LA14_0==KW_FOR) ) {
				alt14=1;
			}
			switch (alt14) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:877:7: replicationClause
					{
					pushFollow(FOLLOW_replicationClause_in_exportStatement1970);
					replicationClause54=replicationClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause54.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tab, path, replicationClause
			// token labels: path
			// rule labels: tab, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 878:5: -> ^( TOK_EXPORT $tab $path ( replicationClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:878:8: ^( TOK_EXPORT $tab $path ( replicationClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPORT, "TOK_EXPORT"), root_1);
				adaptor.addChild(root_1, stream_tab.nextTree());
				adaptor.addChild(root_1, stream_path.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:878:32: ( replicationClause )?
				if ( stream_replicationClause.hasNext() ) {
					adaptor.addChild(root_1, stream_replicationClause.nextTree());
				}
				stream_replicationClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "exportStatement"


	public static class importStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "importStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:881:1: importStatement : KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? ) ;
	public final HiveParser.importStatement_return importStatement() throws RecognitionException {
		HiveParser.importStatement_return retval = new HiveParser.importStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token ext=null;
		Token path=null;
		Token KW_IMPORT55=null;
		Token KW_TABLE56=null;
		Token KW_FROM57=null;
		ParserRuleReturnScope tab =null;
		ParserRuleReturnScope tableLocation58 =null;

		ASTNode ext_tree=null;
		ASTNode path_tree=null;
		ASTNode KW_IMPORT55_tree=null;
		ASTNode KW_TABLE56_tree=null;
		ASTNode KW_FROM57_tree=null;
		RewriteRuleTokenStream stream_KW_EXTERNAL=new RewriteRuleTokenStream(adaptor,"token KW_EXTERNAL");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_IMPORT=new RewriteRuleTokenStream(adaptor,"token KW_IMPORT");
		RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");

		 pushMsg("import statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:884:8: ( KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:884:10: KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )?
			{
			KW_IMPORT55=(Token)match(input,KW_IMPORT,FOLLOW_KW_IMPORT_in_importStatement2020); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_IMPORT.add(KW_IMPORT55);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:885:10: ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )?
			int alt16=2;
			int LA16_0 = input.LA(1);
			if ( (LA16_0==KW_EXTERNAL||LA16_0==KW_TABLE) ) {
				alt16=1;
			}
			switch (alt16) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:885:11: (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:885:11: (ext= KW_EXTERNAL )?
					int alt15=2;
					int LA15_0 = input.LA(1);
					if ( (LA15_0==KW_EXTERNAL) ) {
						alt15=1;
					}
					switch (alt15) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:885:12: ext= KW_EXTERNAL
							{
							ext=(Token)match(input,KW_EXTERNAL,FOLLOW_KW_EXTERNAL_in_importStatement2035); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTERNAL.add(ext);

							}
							break;

					}

					KW_TABLE56=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_importStatement2039); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE56);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:885:39: (tab= tableOrPartition )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:885:40: tab= tableOrPartition
					{
					pushFollow(FOLLOW_tableOrPartition_in_importStatement2044);
					tab=tableOrPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());
					}

					}
					break;

			}

			KW_FROM57=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_importStatement2058); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM57);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:886:18: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:886:19: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_importStatement2063); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:10: ( tableLocation )?
			int alt17=2;
			int LA17_0 = input.LA(1);
			if ( (LA17_0==KW_LOCATION) ) {
				alt17=1;
			}
			switch (alt17) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:10: tableLocation
					{
					pushFollow(FOLLOW_tableLocation_in_importStatement2075);
					tableLocation58=tableLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation58.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableLocation, path, ext, tab
			// token labels: ext, path
			// rule labels: tab, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_ext=new RewriteRuleTokenStream(adaptor,"token ext",ext);
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 888:5: -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:888:8: ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_IMPORT, "TOK_IMPORT"), root_1);
				adaptor.addChild(root_1, stream_path.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:888:28: ( $tab)?
				if ( stream_tab.hasNext() ) {
					adaptor.addChild(root_1, stream_tab.nextTree());
				}
				stream_tab.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:888:34: ( $ext)?
				if ( stream_ext.hasNext() ) {
					adaptor.addChild(root_1, stream_ext.nextNode());
				}
				stream_ext.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:888:39: ( tableLocation )?
				if ( stream_tableLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_tableLocation.nextTree());
				}
				stream_tableLocation.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "importStatement"


	public static class replDumpStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replDumpStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:891:1: replDumpStatement : KW_REPL KW_DUMP (dbPolicy= replDbPolicy ) ( KW_REPLACE oldDbPolicy= replDbPolicy )? ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )? ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? ( $replConf)? ) ;
	public final HiveParser.replDumpStatement_return replDumpStatement() throws RecognitionException {
		HiveParser.replDumpStatement_return retval = new HiveParser.replDumpStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token eventId=null;
		Token rangeEnd=null;
		Token batchSize=null;
		Token KW_REPL59=null;
		Token KW_DUMP60=null;
		Token KW_REPLACE61=null;
		Token KW_FROM62=null;
		Token KW_TO63=null;
		Token KW_LIMIT64=null;
		Token KW_WITH65=null;
		ParserRuleReturnScope dbPolicy =null;
		ParserRuleReturnScope oldDbPolicy =null;
		ParserRuleReturnScope replConf =null;

		ASTNode eventId_tree=null;
		ASTNode rangeEnd_tree=null;
		ASTNode batchSize_tree=null;
		ASTNode KW_REPL59_tree=null;
		ASTNode KW_DUMP60_tree=null;
		ASTNode KW_REPLACE61_tree=null;
		ASTNode KW_FROM62_tree=null;
		ASTNode KW_TO63_tree=null;
		ASTNode KW_LIMIT64_tree=null;
		ASTNode KW_WITH65_tree=null;
		RewriteRuleTokenStream stream_KW_DUMP=new RewriteRuleTokenStream(adaptor,"token KW_DUMP");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_LIMIT=new RewriteRuleTokenStream(adaptor,"token KW_LIMIT");
		RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
		RewriteRuleSubtreeStream stream_replDbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule replDbPolicy");
		RewriteRuleSubtreeStream stream_replConfigs=new RewriteRuleSubtreeStream(adaptor,"rule replConfigs");

		 pushMsg("Replication dump statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:894:7: ( KW_REPL KW_DUMP (dbPolicy= replDbPolicy ) ( KW_REPLACE oldDbPolicy= replDbPolicy )? ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )? ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? ( $replConf)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:894:9: KW_REPL KW_DUMP (dbPolicy= replDbPolicy ) ( KW_REPLACE oldDbPolicy= replDbPolicy )? ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )? ( KW_WITH replConf= replConfigs )?
			{
			KW_REPL59=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replDumpStatement2129); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL59);

			KW_DUMP60=(Token)match(input,KW_DUMP,FOLLOW_KW_DUMP_in_replDumpStatement2131); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DUMP.add(KW_DUMP60);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:895:9: (dbPolicy= replDbPolicy )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:895:10: dbPolicy= replDbPolicy
			{
			pushFollow(FOLLOW_replDbPolicy_in_replDumpStatement2144);
			dbPolicy=replDbPolicy();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_replDbPolicy.add(dbPolicy.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:896:9: ( KW_REPLACE oldDbPolicy= replDbPolicy )?
			int alt18=2;
			int LA18_0 = input.LA(1);
			if ( (LA18_0==KW_REPLACE) ) {
				alt18=1;
			}
			switch (alt18) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:896:10: KW_REPLACE oldDbPolicy= replDbPolicy
					{
					KW_REPLACE61=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_replDumpStatement2156); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REPLACE.add(KW_REPLACE61);

					pushFollow(FOLLOW_replDbPolicy_in_replDumpStatement2160);
					oldDbPolicy=replDbPolicy();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replDbPolicy.add(oldDbPolicy.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:897:9: ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )?
			int alt21=2;
			int LA21_0 = input.LA(1);
			if ( (LA21_0==KW_FROM) ) {
				alt21=1;
			}
			switch (alt21) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:897:10: KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )?
					{
					KW_FROM62=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_replDumpStatement2173); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM62);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:897:18: (eventId= Number )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:897:19: eventId= Number
					{
					eventId=(Token)match(input,Number,FOLLOW_Number_in_replDumpStatement2178); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(eventId);

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:898:11: ( KW_TO (rangeEnd= Number ) )?
					int alt19=2;
					int LA19_0 = input.LA(1);
					if ( (LA19_0==KW_TO) ) {
						alt19=1;
					}
					switch (alt19) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:898:12: KW_TO (rangeEnd= Number )
							{
							KW_TO63=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_replDumpStatement2192); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO63);

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:898:18: (rangeEnd= Number )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:898:19: rangeEnd= Number
							{
							rangeEnd=(Token)match(input,Number,FOLLOW_Number_in_replDumpStatement2197); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(rangeEnd);

							}

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:899:11: ( KW_LIMIT (batchSize= Number ) )?
					int alt20=2;
					int LA20_0 = input.LA(1);
					if ( (LA20_0==KW_LIMIT) ) {
						alt20=1;
					}
					switch (alt20) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:899:12: KW_LIMIT (batchSize= Number )
							{
							KW_LIMIT64=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_replDumpStatement2213); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT64);

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:899:21: (batchSize= Number )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:899:22: batchSize= Number
							{
							batchSize=(Token)match(input,Number,FOLLOW_Number_in_replDumpStatement2218); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(batchSize);

							}

							}
							break;

					}

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:901:9: ( KW_WITH replConf= replConfigs )?
			int alt22=2;
			int LA22_0 = input.LA(1);
			if ( (LA22_0==KW_WITH) ) {
				alt22=1;
			}
			switch (alt22) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:901:10: KW_WITH replConf= replConfigs
					{
					KW_WITH65=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_replDumpStatement2243); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH65);

					pushFollow(FOLLOW_replConfigs_in_replDumpStatement2247);
					replConf=replConfigs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replConfigs.add(replConf.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: oldDbPolicy, eventId, rangeEnd, dbPolicy, batchSize, replConf
			// token labels: eventId, batchSize, rangeEnd
			// rule labels: oldDbPolicy, dbPolicy, retval, replConf
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_eventId=new RewriteRuleTokenStream(adaptor,"token eventId",eventId);
			RewriteRuleTokenStream stream_batchSize=new RewriteRuleTokenStream(adaptor,"token batchSize",batchSize);
			RewriteRuleTokenStream stream_rangeEnd=new RewriteRuleTokenStream(adaptor,"token rangeEnd",rangeEnd);
			RewriteRuleSubtreeStream stream_oldDbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule oldDbPolicy",oldDbPolicy!=null?oldDbPolicy.getTree():null);
			RewriteRuleSubtreeStream stream_dbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule dbPolicy",dbPolicy!=null?dbPolicy.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_replConf=new RewriteRuleSubtreeStream(adaptor,"rule replConf",replConf!=null?replConf.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 902:5: -> ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? ( $replConf)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:8: ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? ( $replConf)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_DUMP, "TOK_REPL_DUMP"), root_1);
				adaptor.addChild(root_1, stream_dbPolicy.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:34: ( ^( TOK_REPLACE $oldDbPolicy) )?
				if ( stream_oldDbPolicy.hasNext() ) {
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:34: ^( TOK_REPLACE $oldDbPolicy)
					{
					ASTNode root_2 = (ASTNode)adaptor.nil();
					root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPLACE, "TOK_REPLACE"), root_2);
					adaptor.addChild(root_2, stream_oldDbPolicy.nextTree());
					adaptor.addChild(root_1, root_2);
					}

				}
				stream_oldDbPolicy.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:63: ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )?
				if ( stream_eventId.hasNext()||stream_rangeEnd.hasNext()||stream_batchSize.hasNext() ) {
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:63: ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? )
					{
					ASTNode root_2 = (ASTNode)adaptor.nil();
					root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
					adaptor.addChild(root_2, stream_eventId.nextNode());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:83: ( TOK_TO $rangeEnd)?
					if ( stream_rangeEnd.hasNext() ) {
						adaptor.addChild(root_2, (ASTNode)adaptor.create(TOK_TO, "TOK_TO"));
						adaptor.addChild(root_2, stream_rangeEnd.nextNode());
					}
					stream_rangeEnd.reset();

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:103: ( TOK_LIMIT $batchSize)?
					if ( stream_batchSize.hasNext() ) {
						adaptor.addChild(root_2, (ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT"));
						adaptor.addChild(root_2, stream_batchSize.nextNode());
					}
					stream_batchSize.reset();

					adaptor.addChild(root_1, root_2);
					}

				}
				stream_eventId.reset();
				stream_rangeEnd.reset();
				stream_batchSize.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:130: ( $replConf)?
				if ( stream_replConf.hasNext() ) {
					adaptor.addChild(root_1, stream_replConf.nextTree());
				}
				stream_replConf.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replDumpStatement"


	public static class replDbPolicy_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replDbPolicy"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:905:1: replDbPolicy : (dbName= identifier ) ( DOT tablePolicy= replTableLevelPolicy )? -> $dbName ( $tablePolicy)? ;
	public final HiveParser.replDbPolicy_return replDbPolicy() throws RecognitionException {
		HiveParser.replDbPolicy_return retval = new HiveParser.replDbPolicy_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token DOT66=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope tablePolicy =null;

		ASTNode DOT66_tree=null;
		RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_replTableLevelPolicy=new RewriteRuleSubtreeStream(adaptor,"rule replTableLevelPolicy");

		 pushMsg("Repl dump DB replication policy", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:908:5: ( (dbName= identifier ) ( DOT tablePolicy= replTableLevelPolicy )? -> $dbName ( $tablePolicy)? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:909:7: (dbName= identifier ) ( DOT tablePolicy= replTableLevelPolicy )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:909:7: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:909:8: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_replDbPolicy2334);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:909:27: ( DOT tablePolicy= replTableLevelPolicy )?
			int alt23=2;
			int LA23_0 = input.LA(1);
			if ( (LA23_0==DOT) ) {
				alt23=1;
			}
			switch (alt23) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:909:28: DOT tablePolicy= replTableLevelPolicy
					{
					DOT66=(Token)match(input,DOT,FOLLOW_DOT_in_replDbPolicy2338); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_DOT.add(DOT66);

					pushFollow(FOLLOW_replTableLevelPolicy_in_replDbPolicy2342);
					tablePolicy=replTableLevelPolicy();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replTableLevelPolicy.add(tablePolicy.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tablePolicy, dbName
			// token labels: 
			// rule labels: dbName, tablePolicy, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_tablePolicy=new RewriteRuleSubtreeStream(adaptor,"rule tablePolicy",tablePolicy!=null?tablePolicy.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 909:67: -> $dbName ( $tablePolicy)?
			{
				adaptor.addChild(root_0, stream_dbName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:909:79: ( $tablePolicy)?
				if ( stream_tablePolicy.hasNext() ) {
					adaptor.addChild(root_0, stream_tablePolicy.nextTree());
				}
				stream_tablePolicy.reset();

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replDbPolicy"


	public static class replLoadStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replLoadStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:912:1: replLoadStatement : KW_REPL KW_LOAD (dbName= identifier )? KW_FROM (path= StringLiteral ) ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_LOAD $path ( ^( TOK_DBNAME $dbName) )? ( $replConf)? ) ;
	public final HiveParser.replLoadStatement_return replLoadStatement() throws RecognitionException {
		HiveParser.replLoadStatement_return retval = new HiveParser.replLoadStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_REPL67=null;
		Token KW_LOAD68=null;
		Token KW_FROM69=null;
		Token KW_WITH70=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope replConf =null;

		ASTNode path_tree=null;
		ASTNode KW_REPL67_tree=null;
		ASTNode KW_LOAD68_tree=null;
		ASTNode KW_FROM69_tree=null;
		ASTNode KW_WITH70_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_LOAD=new RewriteRuleTokenStream(adaptor,"token KW_LOAD");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_replConfigs=new RewriteRuleSubtreeStream(adaptor,"rule replConfigs");

		 pushMsg("Replication load statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:915:7: ( KW_REPL KW_LOAD (dbName= identifier )? KW_FROM (path= StringLiteral ) ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_LOAD $path ( ^( TOK_DBNAME $dbName) )? ( $replConf)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:915:9: KW_REPL KW_LOAD (dbName= identifier )? KW_FROM (path= StringLiteral ) ( KW_WITH replConf= replConfigs )?
			{
			KW_REPL67=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replLoadStatement2382); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL67);

			KW_LOAD68=(Token)match(input,KW_LOAD,FOLLOW_KW_LOAD_in_replLoadStatement2384); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOAD.add(KW_LOAD68);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:916:9: (dbName= identifier )?
			int alt24=2;
			int LA24_0 = input.LA(1);
			if ( (LA24_0==Identifier||(LA24_0 >= KW_ABORT && LA24_0 <= KW_AFTER)||LA24_0==KW_ALLOC_FRACTION||LA24_0==KW_ANALYZE||LA24_0==KW_ARCHIVE||LA24_0==KW_ASC||(LA24_0 >= KW_AUTOCOMMIT && LA24_0 <= KW_BEFORE)||(LA24_0 >= KW_BUCKET && LA24_0 <= KW_BUCKETS)||(LA24_0 >= KW_CACHE && LA24_0 <= KW_CASCADE)||(LA24_0 >= KW_CBO && LA24_0 <= KW_CHANGE)||(LA24_0 >= KW_CHECK && LA24_0 <= KW_COLLECTION)||(LA24_0 >= KW_COLUMNS && LA24_0 <= KW_COMMENT)||(LA24_0 >= KW_COMPACT && LA24_0 <= KW_CONCATENATE)||(LA24_0 >= KW_CONTINUE && LA24_0 <= KW_COST)||LA24_0==KW_DATA||LA24_0==KW_DATABASES||(LA24_0 >= KW_DATETIME && LA24_0 <= KW_DEBUG)||(LA24_0 >= KW_DEFAULT && LA24_0 <= KW_DEFINED)||(LA24_0 >= KW_DELIMITED && LA24_0 <= KW_DESC)||(LA24_0 >= KW_DETAIL && LA24_0 <= KW_DISABLE)||(LA24_0 >= KW_DISTRIBUTE && LA24_0 <= KW_DO)||LA24_0==KW_DOW||(LA24_0 >= KW_DUMP && LA24_0 <= KW_ELEM_TYPE)||LA24_0==KW_ENABLE||(LA24_0 >= KW_ENFORCED && LA24_0 <= KW_ESCAPED)||LA24_0==KW_EXCLUSIVE||(LA24_0 >= KW_EXPLAIN && LA24_0 <= KW_EXPRESSION)||(LA24_0 >= KW_FIELDS && LA24_0 <= KW_FIRST)||(LA24_0 >= KW_FORMAT && LA24_0 <= KW_FORMATTED)||LA24_0==KW_FUNCTIONS||(LA24_0 >= KW_HOUR && LA24_0 <= KW_IDXPROPERTIES)||(LA24_0 >= KW_INDEX && LA24_0 <= KW_INDEXES)||(LA24_0 >= KW_INPATH && LA24_0 <= KW_INPUTFORMAT)||(LA24_0 >= KW_ISOLATION && LA24_0 <= KW_JAR)||(LA24_0 >= KW_JOINCOST && LA24_0 <= KW_LAST)||LA24_0==KW_LEVEL||(LA24_0 >= KW_LIMIT && LA24_0 <= KW_LOAD)||(LA24_0 >= KW_LOCATION && LA24_0 <= KW_LONG)||LA24_0==KW_MANAGEMENT||(LA24_0 >= KW_MAPJOIN && LA24_0 <= KW_MATERIALIZED)||LA24_0==KW_METADATA||(LA24_0 >= KW_MINUTE && LA24_0 <= KW_MONTH)||(LA24_0 >= KW_MOVE && LA24_0 <= KW_MSCK)||(LA24_0 >= KW_NORELY && LA24_0 <= KW_NOSCAN)||LA24_0==KW_NOVALIDATE||LA24_0==KW_NULLS||LA24_0==KW_OFFSET||(LA24_0 >= KW_OPERATOR && LA24_0 <= KW_OPTION)||(LA24_0 >= KW_OUTPUTDRIVER && LA24_0 <= KW_OUTPUTFORMAT)||(LA24_0 >= KW_OVERWRITE && LA24_0 <= KW_OWNER)||(LA24_0 >= KW_PARTITIONED && LA24_0 <= KW_PATH)||(LA24_0 >= KW_PLAN && LA24_0 <= KW_POOL)||LA24_0==KW_PRINCIPALS||(LA24_0 >= KW_PURGE && LA24_0 <= KW_QUERY_PARALLELISM)||LA24_0==KW_READ||(LA24_0 >= KW_REBUILD && LA24_0 <= KW_RECORDWRITER)||(LA24_0 >= KW_RELOAD && LA24_0 <= KW_RESTRICT)||LA24_0==KW_REWRITE||(LA24_0 >= KW_ROLE && LA24_0 <= KW_ROLES)||(LA24_0 >= KW_SCHEDULING_POLICY && LA24_0 <= KW_SECOND)||(LA24_0 >= KW_SEMI && LA24_0 <= KW_SERVER)||(LA24_0 >= KW_SETS && LA24_0 <= KW_SKEWED)||(LA24_0 >= KW_SNAPSHOT && LA24_0 <= KW_SSL)||(LA24_0 >= KW_STATISTICS && LA24_0 <= KW_SUMMARY)||LA24_0==KW_TABLES||(LA24_0 >= KW_TBLPROPERTIES && LA24_0 <= KW_TERMINATED)||LA24_0==KW_TINYINT||(LA24_0 >= KW_TOUCH && LA24_0 <= KW_TRANSACTIONS)||LA24_0==KW_UNARCHIVE||LA24_0==KW_UNDO||LA24_0==KW_UNIONTYPE||(LA24_0 >= KW_UNLOCK && LA24_0 <= KW_UNSIGNED)||(LA24_0 >= KW_URI && LA24_0 <= KW_USE)||(LA24_0 >= KW_UTC && LA24_0 <= KW_VALIDATE)||LA24_0==KW_VALUE_TYPE||(LA24_0 >= KW_VECTORIZATION && LA24_0 <= KW_WEEK)||LA24_0==KW_WHILE||(LA24_0 >= KW_WORK && LA24_0 <= KW_ZONE)||LA24_0==KW_BATCH||LA24_0==KW_DAYOFWEEK||LA24_0==KW_HOLD_DDLTIME||LA24_0==KW_IGNORE||LA24_0==KW_NO_DROP||LA24_0==KW_OFFLINE||LA24_0==KW_PROTECTION||LA24_0==KW_READONLY||LA24_0==KW_TIMESTAMPTZ) ) {
				alt24=1;
			}
			switch (alt24) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:916:10: dbName= identifier
					{
					pushFollow(FOLLOW_identifier_in_replLoadStatement2397);
					dbName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
					}
					break;

			}

			KW_FROM69=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_replLoadStatement2409); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM69);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:917:17: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:917:18: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replLoadStatement2414); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:918:9: ( KW_WITH replConf= replConfigs )?
			int alt25=2;
			int LA25_0 = input.LA(1);
			if ( (LA25_0==KW_WITH) ) {
				alt25=1;
			}
			switch (alt25) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:918:10: KW_WITH replConf= replConfigs
					{
					KW_WITH70=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_replLoadStatement2426); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH70);

					pushFollow(FOLLOW_replConfigs_in_replLoadStatement2430);
					replConf=replConfigs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replConfigs.add(replConf.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: path, dbName, replConf
			// token labels: path
			// rule labels: dbName, retval, replConf
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_replConf=new RewriteRuleSubtreeStream(adaptor,"rule replConf",replConf!=null?replConf.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 919:7: -> ^( TOK_REPL_LOAD $path ( ^( TOK_DBNAME $dbName) )? ( $replConf)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:919:10: ^( TOK_REPL_LOAD $path ( ^( TOK_DBNAME $dbName) )? ( $replConf)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_LOAD, "TOK_REPL_LOAD"), root_1);
				adaptor.addChild(root_1, stream_path.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:919:32: ( ^( TOK_DBNAME $dbName) )?
				if ( stream_dbName.hasNext() ) {
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:919:32: ^( TOK_DBNAME $dbName)
					{
					ASTNode root_2 = (ASTNode)adaptor.nil();
					root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DBNAME, "TOK_DBNAME"), root_2);
					adaptor.addChild(root_2, stream_dbName.nextTree());
					adaptor.addChild(root_1, root_2);
					}

				}
				stream_dbName.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:919:56: ( $replConf)?
				if ( stream_replConf.hasNext() ) {
					adaptor.addChild(root_1, stream_replConf.nextTree());
				}
				stream_replConf.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replLoadStatement"


	public static class replConfigs_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replConfigs"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:922:1: replConfigs : LPAREN replConfigsList RPAREN -> ^( TOK_REPL_CONFIG replConfigsList ) ;
	public final HiveParser.replConfigs_return replConfigs() throws RecognitionException {
		HiveParser.replConfigs_return retval = new HiveParser.replConfigs_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN71=null;
		Token RPAREN73=null;
		ParserRuleReturnScope replConfigsList72 =null;

		ASTNode LPAREN71_tree=null;
		ASTNode RPAREN73_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_replConfigsList=new RewriteRuleSubtreeStream(adaptor,"rule replConfigsList");

		 pushMsg("Repl configurations", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:925:5: ( LPAREN replConfigsList RPAREN -> ^( TOK_REPL_CONFIG replConfigsList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:926:7: LPAREN replConfigsList RPAREN
			{
			LPAREN71=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_replConfigs2494); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN71);

			pushFollow(FOLLOW_replConfigsList_in_replConfigs2496);
			replConfigsList72=replConfigsList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_replConfigsList.add(replConfigsList72.getTree());
			RPAREN73=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_replConfigs2498); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN73);

			// AST REWRITE
			// elements: replConfigsList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 926:37: -> ^( TOK_REPL_CONFIG replConfigsList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:926:40: ^( TOK_REPL_CONFIG replConfigsList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_CONFIG, "TOK_REPL_CONFIG"), root_1);
				adaptor.addChild(root_1, stream_replConfigsList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replConfigs"


	public static class replConfigsList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replConfigsList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:929:1: replConfigsList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ ) ;
	public final HiveParser.replConfigsList_return replConfigsList() throws RecognitionException {
		HiveParser.replConfigsList_return retval = new HiveParser.replConfigsList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA75=null;
		ParserRuleReturnScope keyValueProperty74 =null;
		ParserRuleReturnScope keyValueProperty76 =null;

		ASTNode COMMA75_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");

		 pushMsg("Repl configurations list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:932:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:933:7: keyValueProperty ( COMMA keyValueProperty )*
			{
			pushFollow(FOLLOW_keyValueProperty_in_replConfigsList2539);
			keyValueProperty74=keyValueProperty();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty74.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:933:24: ( COMMA keyValueProperty )*
			loop26:
			while (true) {
				int alt26=2;
				int LA26_0 = input.LA(1);
				if ( (LA26_0==COMMA) ) {
					alt26=1;
				}

				switch (alt26) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:933:25: COMMA keyValueProperty
					{
					COMMA75=(Token)match(input,COMMA,FOLLOW_COMMA_in_replConfigsList2542); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA75);

					pushFollow(FOLLOW_keyValueProperty_in_replConfigsList2544);
					keyValueProperty76=keyValueProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty76.getTree());
					}
					break;

				default :
					break loop26;
				}
			}

			// AST REWRITE
			// elements: keyValueProperty
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 933:50: -> ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:933:53: ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_CONFIG_LIST, "TOK_REPL_CONFIG_LIST"), root_1);
				if ( !(stream_keyValueProperty.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_keyValueProperty.hasNext() ) {
					adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
				}
				stream_keyValueProperty.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replConfigsList"


	public static class replTableLevelPolicy_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replTableLevelPolicy"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:936:1: replTableLevelPolicy : ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? ) -> ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? ) ;
	public final HiveParser.replTableLevelPolicy_return replTableLevelPolicy() throws RecognitionException {
		HiveParser.replTableLevelPolicy_return retval = new HiveParser.replTableLevelPolicy_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token replTablesIncludeList=null;
		Token replTablesExcludeList=null;
		Token DOT77=null;

		ASTNode replTablesIncludeList_tree=null;
		ASTNode replTablesExcludeList_tree=null;
		ASTNode DOT77_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");

		 pushMsg("Replication table level policy definition", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:939:5: ( ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? ) -> ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:940:7: ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? )
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:940:7: ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:940:8: (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:940:8: (replTablesIncludeList= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:940:9: replTablesIncludeList= StringLiteral
			{
			replTablesIncludeList=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replTableLevelPolicy2592); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(replTablesIncludeList);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:940:46: ( DOT replTablesExcludeList= StringLiteral )?
			int alt27=2;
			int LA27_0 = input.LA(1);
			if ( (LA27_0==DOT) ) {
				alt27=1;
			}
			switch (alt27) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:940:47: DOT replTablesExcludeList= StringLiteral
					{
					DOT77=(Token)match(input,DOT,FOLLOW_DOT_in_replTableLevelPolicy2596); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_DOT.add(DOT77);

					replTablesExcludeList=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replTableLevelPolicy2600); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(replTablesExcludeList);

					}
					break;

			}

			}

			// AST REWRITE
			// elements: replTablesIncludeList, replTablesExcludeList
			// token labels: replTablesExcludeList, replTablesIncludeList
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_replTablesExcludeList=new RewriteRuleTokenStream(adaptor,"token replTablesExcludeList",replTablesExcludeList);
			RewriteRuleTokenStream stream_replTablesIncludeList=new RewriteRuleTokenStream(adaptor,"token replTablesIncludeList",replTablesIncludeList);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 941:7: -> ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:941:10: ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_TABLES, "TOK_REPL_TABLES"), root_1);
				adaptor.addChild(root_1, stream_replTablesIncludeList.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:941:52: ( $replTablesExcludeList)?
				if ( stream_replTablesExcludeList.hasNext() ) {
					adaptor.addChild(root_1, stream_replTablesExcludeList.nextNode());
				}
				stream_replTablesExcludeList.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replTableLevelPolicy"


	public static class replStatusStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replStatusStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:944:1: replStatusStatement : KW_REPL KW_STATUS (dbName= identifier ) ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_STATUS $dbName ( $replConf)? ) ;
	public final HiveParser.replStatusStatement_return replStatusStatement() throws RecognitionException {
		HiveParser.replStatusStatement_return retval = new HiveParser.replStatusStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REPL78=null;
		Token KW_STATUS79=null;
		Token KW_WITH80=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope replConf =null;

		ASTNode KW_REPL78_tree=null;
		ASTNode KW_STATUS79_tree=null;
		ASTNode KW_WITH80_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_STATUS=new RewriteRuleTokenStream(adaptor,"token KW_STATUS");
		RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_replConfigs=new RewriteRuleSubtreeStream(adaptor,"rule replConfigs");

		 pushMsg("replication status statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:947:7: ( KW_REPL KW_STATUS (dbName= identifier ) ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_STATUS $dbName ( $replConf)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:947:9: KW_REPL KW_STATUS (dbName= identifier ) ( KW_WITH replConf= replConfigs )?
			{
			KW_REPL78=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replStatusStatement2651); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL78);

			KW_STATUS79=(Token)match(input,KW_STATUS,FOLLOW_KW_STATUS_in_replStatusStatement2653); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STATUS.add(KW_STATUS79);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:948:9: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:948:10: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_replStatusStatement2666);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:949:9: ( KW_WITH replConf= replConfigs )?
			int alt28=2;
			int LA28_0 = input.LA(1);
			if ( (LA28_0==KW_WITH) ) {
				alt28=1;
			}
			switch (alt28) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:949:10: KW_WITH replConf= replConfigs
					{
					KW_WITH80=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_replStatusStatement2678); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH80);

					pushFollow(FOLLOW_replConfigs_in_replStatusStatement2682);
					replConf=replConfigs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replConfigs.add(replConf.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: replConf, dbName
			// token labels: 
			// rule labels: dbName, retval, replConf
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_replConf=new RewriteRuleSubtreeStream(adaptor,"rule replConf",replConf!=null?replConf.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 950:7: -> ^( TOK_REPL_STATUS $dbName ( $replConf)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:950:10: ^( TOK_REPL_STATUS $dbName ( $replConf)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_STATUS, "TOK_REPL_STATUS"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:950:37: ( $replConf)?
				if ( stream_replConf.hasNext() ) {
					adaptor.addChild(root_1, stream_replConf.nextTree());
				}
				stream_replConf.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replStatusStatement"


	public static class ddlStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "ddlStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:953:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement | dropViewStatement | dropMaterializedViewStatement | createFunctionStatement | createMacroStatement | dropFunctionStatement | reloadFunctionsStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements );
	public final HiveParser.ddlStatement_return ddlStatement() throws RecognitionException {
		HiveParser.ddlStatement_return retval = new HiveParser.ddlStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope createDatabaseStatement81 =null;
		ParserRuleReturnScope switchDatabaseStatement82 =null;
		ParserRuleReturnScope dropDatabaseStatement83 =null;
		ParserRuleReturnScope createTableStatement84 =null;
		ParserRuleReturnScope dropTableStatement85 =null;
		ParserRuleReturnScope truncateTableStatement86 =null;
		ParserRuleReturnScope alterStatement87 =null;
		ParserRuleReturnScope descStatement88 =null;
		ParserRuleReturnScope showStatement89 =null;
		ParserRuleReturnScope metastoreCheck90 =null;
		ParserRuleReturnScope createViewStatement91 =null;
		ParserRuleReturnScope createMaterializedViewStatement92 =null;
		ParserRuleReturnScope dropViewStatement93 =null;
		ParserRuleReturnScope dropMaterializedViewStatement94 =null;
		ParserRuleReturnScope createFunctionStatement95 =null;
		ParserRuleReturnScope createMacroStatement96 =null;
		ParserRuleReturnScope dropFunctionStatement97 =null;
		ParserRuleReturnScope reloadFunctionsStatement98 =null;
		ParserRuleReturnScope dropMacroStatement99 =null;
		ParserRuleReturnScope analyzeStatement100 =null;
		ParserRuleReturnScope lockStatement101 =null;
		ParserRuleReturnScope unlockStatement102 =null;
		ParserRuleReturnScope lockDatabase103 =null;
		ParserRuleReturnScope unlockDatabase104 =null;
		ParserRuleReturnScope createRoleStatement105 =null;
		ParserRuleReturnScope dropRoleStatement106 =null;
		ParserRuleReturnScope grantPrivileges107 =null;
		ParserRuleReturnScope revokePrivileges108 =null;
		ParserRuleReturnScope showGrants109 =null;
		ParserRuleReturnScope showRoleGrants110 =null;
		ParserRuleReturnScope showRolePrincipals111 =null;
		ParserRuleReturnScope showRoles112 =null;
		ParserRuleReturnScope grantRole113 =null;
		ParserRuleReturnScope revokeRole114 =null;
		ParserRuleReturnScope setRole115 =null;
		ParserRuleReturnScope showCurrentRole116 =null;
		ParserRuleReturnScope abortTransactionStatement117 =null;
		ParserRuleReturnScope killQueryStatement118 =null;
		ParserRuleReturnScope resourcePlanDdlStatements119 =null;


		 pushMsg("ddl statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:956:5: ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement | dropViewStatement | dropMaterializedViewStatement | createFunctionStatement | createMacroStatement | dropFunctionStatement | reloadFunctionsStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements )
			int alt29=39;
			alt29 = dfa29.predict(input);
			switch (alt29) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:956:7: createDatabaseStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createDatabaseStatement_in_ddlStatement2732);
					createDatabaseStatement81=createDatabaseStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createDatabaseStatement81.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:957:7: switchDatabaseStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_switchDatabaseStatement_in_ddlStatement2740);
					switchDatabaseStatement82=switchDatabaseStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, switchDatabaseStatement82.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:958:7: dropDatabaseStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropDatabaseStatement_in_ddlStatement2748);
					dropDatabaseStatement83=dropDatabaseStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropDatabaseStatement83.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:959:7: createTableStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createTableStatement_in_ddlStatement2756);
					createTableStatement84=createTableStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createTableStatement84.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:960:7: dropTableStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropTableStatement_in_ddlStatement2764);
					dropTableStatement85=dropTableStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropTableStatement85.getTree());

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:961:7: truncateTableStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_truncateTableStatement_in_ddlStatement2772);
					truncateTableStatement86=truncateTableStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, truncateTableStatement86.getTree());

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:962:7: alterStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatement_in_ddlStatement2780);
					alterStatement87=alterStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatement87.getTree());

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:963:7: descStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_descStatement_in_ddlStatement2788);
					descStatement88=descStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, descStatement88.getTree());

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:964:7: showStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showStatement_in_ddlStatement2796);
					showStatement89=showStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showStatement89.getTree());

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:965:7: metastoreCheck
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_metastoreCheck_in_ddlStatement2804);
					metastoreCheck90=metastoreCheck();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, metastoreCheck90.getTree());

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:966:7: createViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createViewStatement_in_ddlStatement2812);
					createViewStatement91=createViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createViewStatement91.getTree());

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:967:7: createMaterializedViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createMaterializedViewStatement_in_ddlStatement2820);
					createMaterializedViewStatement92=createMaterializedViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createMaterializedViewStatement92.getTree());

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:968:7: dropViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropViewStatement_in_ddlStatement2828);
					dropViewStatement93=dropViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropViewStatement93.getTree());

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:7: dropMaterializedViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropMaterializedViewStatement_in_ddlStatement2836);
					dropMaterializedViewStatement94=dropMaterializedViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropMaterializedViewStatement94.getTree());

					}
					break;
				case 15 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:970:7: createFunctionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createFunctionStatement_in_ddlStatement2844);
					createFunctionStatement95=createFunctionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createFunctionStatement95.getTree());

					}
					break;
				case 16 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:971:7: createMacroStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createMacroStatement_in_ddlStatement2852);
					createMacroStatement96=createMacroStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createMacroStatement96.getTree());

					}
					break;
				case 17 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:972:7: dropFunctionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropFunctionStatement_in_ddlStatement2860);
					dropFunctionStatement97=dropFunctionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropFunctionStatement97.getTree());

					}
					break;
				case 18 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:973:7: reloadFunctionsStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_reloadFunctionsStatement_in_ddlStatement2868);
					reloadFunctionsStatement98=reloadFunctionsStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, reloadFunctionsStatement98.getTree());

					}
					break;
				case 19 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:974:7: dropMacroStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropMacroStatement_in_ddlStatement2876);
					dropMacroStatement99=dropMacroStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropMacroStatement99.getTree());

					}
					break;
				case 20 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:975:7: analyzeStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_analyzeStatement_in_ddlStatement2884);
					analyzeStatement100=analyzeStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, analyzeStatement100.getTree());

					}
					break;
				case 21 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:976:7: lockStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_lockStatement_in_ddlStatement2892);
					lockStatement101=lockStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, lockStatement101.getTree());

					}
					break;
				case 22 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:977:7: unlockStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_unlockStatement_in_ddlStatement2900);
					unlockStatement102=unlockStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, unlockStatement102.getTree());

					}
					break;
				case 23 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:978:7: lockDatabase
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_lockDatabase_in_ddlStatement2908);
					lockDatabase103=lockDatabase();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, lockDatabase103.getTree());

					}
					break;
				case 24 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:979:7: unlockDatabase
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_unlockDatabase_in_ddlStatement2916);
					unlockDatabase104=unlockDatabase();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, unlockDatabase104.getTree());

					}
					break;
				case 25 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:980:7: createRoleStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createRoleStatement_in_ddlStatement2924);
					createRoleStatement105=createRoleStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createRoleStatement105.getTree());

					}
					break;
				case 26 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:981:7: dropRoleStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropRoleStatement_in_ddlStatement2932);
					dropRoleStatement106=dropRoleStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropRoleStatement106.getTree());

					}
					break;
				case 27 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:982:7: ( grantPrivileges )=> grantPrivileges
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_grantPrivileges_in_ddlStatement2946);
					grantPrivileges107=grantPrivileges();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, grantPrivileges107.getTree());

					}
					break;
				case 28 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:983:7: ( revokePrivileges )=> revokePrivileges
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_revokePrivileges_in_ddlStatement2960);
					revokePrivileges108=revokePrivileges();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, revokePrivileges108.getTree());

					}
					break;
				case 29 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:984:7: showGrants
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showGrants_in_ddlStatement2968);
					showGrants109=showGrants();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showGrants109.getTree());

					}
					break;
				case 30 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:985:7: showRoleGrants
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showRoleGrants_in_ddlStatement2976);
					showRoleGrants110=showRoleGrants();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showRoleGrants110.getTree());

					}
					break;
				case 31 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:986:7: showRolePrincipals
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showRolePrincipals_in_ddlStatement2984);
					showRolePrincipals111=showRolePrincipals();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showRolePrincipals111.getTree());

					}
					break;
				case 32 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:987:7: showRoles
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showRoles_in_ddlStatement2992);
					showRoles112=showRoles();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showRoles112.getTree());

					}
					break;
				case 33 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:988:7: grantRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_grantRole_in_ddlStatement3000);
					grantRole113=grantRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, grantRole113.getTree());

					}
					break;
				case 34 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:989:7: revokeRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_revokeRole_in_ddlStatement3008);
					revokeRole114=revokeRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, revokeRole114.getTree());

					}
					break;
				case 35 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:990:7: setRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_setRole_in_ddlStatement3016);
					setRole115=setRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, setRole115.getTree());

					}
					break;
				case 36 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:991:7: showCurrentRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showCurrentRole_in_ddlStatement3024);
					showCurrentRole116=showCurrentRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showCurrentRole116.getTree());

					}
					break;
				case 37 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:992:7: abortTransactionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_abortTransactionStatement_in_ddlStatement3032);
					abortTransactionStatement117=abortTransactionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, abortTransactionStatement117.getTree());

					}
					break;
				case 38 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:993:7: killQueryStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_killQueryStatement_in_ddlStatement3040);
					killQueryStatement118=killQueryStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, killQueryStatement118.getTree());

					}
					break;
				case 39 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:994:7: resourcePlanDdlStatements
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_resourcePlanDdlStatements_in_ddlStatement3048);
					resourcePlanDdlStatements119=resourcePlanDdlStatements();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, resourcePlanDdlStatements119.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "ddlStatement"


	public static class ifExists_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "ifExists"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:997:1: ifExists : KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) ;
	public final HiveParser.ifExists_return ifExists() throws RecognitionException {
		HiveParser.ifExists_return retval = new HiveParser.ifExists_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_IF120=null;
		Token KW_EXISTS121=null;

		ASTNode KW_IF120_tree=null;
		ASTNode KW_EXISTS121_tree=null;
		RewriteRuleTokenStream stream_KW_EXISTS=new RewriteRuleTokenStream(adaptor,"token KW_EXISTS");
		RewriteRuleTokenStream stream_KW_IF=new RewriteRuleTokenStream(adaptor,"token KW_IF");

		 pushMsg("if exists clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1000:5: ( KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1000:7: KW_IF KW_EXISTS
			{
			KW_IF120=(Token)match(input,KW_IF,FOLLOW_KW_IF_in_ifExists3075); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_IF.add(KW_IF120);

			KW_EXISTS121=(Token)match(input,KW_EXISTS,FOLLOW_KW_EXISTS_in_ifExists3077); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXISTS.add(KW_EXISTS121);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1001:5: -> ^( TOK_IFEXISTS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1001:8: ^( TOK_IFEXISTS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_IFEXISTS, "TOK_IFEXISTS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "ifExists"


	public static class restrictOrCascade_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "restrictOrCascade"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:1: restrictOrCascade : ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) );
	public final HiveParser.restrictOrCascade_return restrictOrCascade() throws RecognitionException {
		HiveParser.restrictOrCascade_return retval = new HiveParser.restrictOrCascade_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RESTRICT122=null;
		Token KW_CASCADE123=null;

		ASTNode KW_RESTRICT122_tree=null;
		ASTNode KW_CASCADE123_tree=null;
		RewriteRuleTokenStream stream_KW_CASCADE=new RewriteRuleTokenStream(adaptor,"token KW_CASCADE");
		RewriteRuleTokenStream stream_KW_RESTRICT=new RewriteRuleTokenStream(adaptor,"token KW_RESTRICT");

		 pushMsg("restrict or cascade clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1007:5: ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) )
			int alt30=2;
			int LA30_0 = input.LA(1);
			if ( (LA30_0==KW_RESTRICT) ) {
				alt30=1;
			}
			else if ( (LA30_0==KW_CASCADE) ) {
				alt30=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 30, 0, input);
				throw nvae;
			}

			switch (alt30) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1007:7: KW_RESTRICT
					{
					KW_RESTRICT122=(Token)match(input,KW_RESTRICT,FOLLOW_KW_RESTRICT_in_restrictOrCascade3114); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RESTRICT.add(KW_RESTRICT122);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1008:5: -> ^( TOK_RESTRICT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1008:8: ^( TOK_RESTRICT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESTRICT, "TOK_RESTRICT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1009:7: KW_CASCADE
					{
					KW_CASCADE123=(Token)match(input,KW_CASCADE,FOLLOW_KW_CASCADE_in_restrictOrCascade3132); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CASCADE.add(KW_CASCADE123);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1010:5: -> ^( TOK_CASCADE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1010:8: ^( TOK_CASCADE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CASCADE, "TOK_CASCADE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "restrictOrCascade"


	public static class ifNotExists_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "ifNotExists"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1013:1: ifNotExists : KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) ;
	public final HiveParser.ifNotExists_return ifNotExists() throws RecognitionException {
		HiveParser.ifNotExists_return retval = new HiveParser.ifNotExists_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_IF124=null;
		Token KW_NOT125=null;
		Token KW_EXISTS126=null;

		ASTNode KW_IF124_tree=null;
		ASTNode KW_NOT125_tree=null;
		ASTNode KW_EXISTS126_tree=null;
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_EXISTS=new RewriteRuleTokenStream(adaptor,"token KW_EXISTS");
		RewriteRuleTokenStream stream_KW_IF=new RewriteRuleTokenStream(adaptor,"token KW_IF");

		 pushMsg("if not exists clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1016:5: ( KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1016:7: KW_IF KW_NOT KW_EXISTS
			{
			KW_IF124=(Token)match(input,KW_IF,FOLLOW_KW_IF_in_ifNotExists3169); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_IF.add(KW_IF124);

			KW_NOT125=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_ifNotExists3171); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT125);

			KW_EXISTS126=(Token)match(input,KW_EXISTS,FOLLOW_KW_EXISTS_in_ifNotExists3173); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXISTS.add(KW_EXISTS126);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1017:5: -> ^( TOK_IFNOTEXISTS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1017:8: ^( TOK_IFNOTEXISTS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_IFNOTEXISTS, "TOK_IFNOTEXISTS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "ifNotExists"


	public static class force_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "force"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1020:1: force : KW_FORCE -> ^( TOK_FORCE ) ;
	public final HiveParser.force_return force() throws RecognitionException {
		HiveParser.force_return retval = new HiveParser.force_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_FORCE127=null;

		ASTNode KW_FORCE127_tree=null;
		RewriteRuleTokenStream stream_KW_FORCE=new RewriteRuleTokenStream(adaptor,"token KW_FORCE");

		 msgs.push("force clause"); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1023:5: ( KW_FORCE -> ^( TOK_FORCE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1023:7: KW_FORCE
			{
			KW_FORCE127=(Token)match(input,KW_FORCE,FOLLOW_KW_FORCE_in_force3210); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FORCE.add(KW_FORCE127);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1024:5: -> ^( TOK_FORCE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:8: ^( TOK_FORCE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FORCE, "TOK_FORCE"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { msgs.pop(); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "force"


	public static class rewriteEnabled_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rewriteEnabled"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1027:1: rewriteEnabled : KW_ENABLE KW_REWRITE -> ^( TOK_REWRITE_ENABLED ) ;
	public final HiveParser.rewriteEnabled_return rewriteEnabled() throws RecognitionException {
		HiveParser.rewriteEnabled_return retval = new HiveParser.rewriteEnabled_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ENABLE128=null;
		Token KW_REWRITE129=null;

		ASTNode KW_ENABLE128_tree=null;
		ASTNode KW_REWRITE129_tree=null;
		RewriteRuleTokenStream stream_KW_REWRITE=new RewriteRuleTokenStream(adaptor,"token KW_REWRITE");
		RewriteRuleTokenStream stream_KW_ENABLE=new RewriteRuleTokenStream(adaptor,"token KW_ENABLE");

		 pushMsg("rewrite enabled clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1030:5: ( KW_ENABLE KW_REWRITE -> ^( TOK_REWRITE_ENABLED ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1030:7: KW_ENABLE KW_REWRITE
			{
			KW_ENABLE128=(Token)match(input,KW_ENABLE,FOLLOW_KW_ENABLE_in_rewriteEnabled3247); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ENABLE.add(KW_ENABLE128);

			KW_REWRITE129=(Token)match(input,KW_REWRITE,FOLLOW_KW_REWRITE_in_rewriteEnabled3249); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REWRITE.add(KW_REWRITE129);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1031:5: -> ^( TOK_REWRITE_ENABLED )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1031:8: ^( TOK_REWRITE_ENABLED )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REWRITE_ENABLED, "TOK_REWRITE_ENABLED"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rewriteEnabled"


	public static class rewriteDisabled_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rewriteDisabled"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1034:1: rewriteDisabled : KW_DISABLE KW_REWRITE -> ^( TOK_REWRITE_DISABLED ) ;
	public final HiveParser.rewriteDisabled_return rewriteDisabled() throws RecognitionException {
		HiveParser.rewriteDisabled_return retval = new HiveParser.rewriteDisabled_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DISABLE130=null;
		Token KW_REWRITE131=null;

		ASTNode KW_DISABLE130_tree=null;
		ASTNode KW_REWRITE131_tree=null;
		RewriteRuleTokenStream stream_KW_DISABLE=new RewriteRuleTokenStream(adaptor,"token KW_DISABLE");
		RewriteRuleTokenStream stream_KW_REWRITE=new RewriteRuleTokenStream(adaptor,"token KW_REWRITE");

		 pushMsg("rewrite disabled clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1037:5: ( KW_DISABLE KW_REWRITE -> ^( TOK_REWRITE_DISABLED ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1037:7: KW_DISABLE KW_REWRITE
			{
			KW_DISABLE130=(Token)match(input,KW_DISABLE,FOLLOW_KW_DISABLE_in_rewriteDisabled3286); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DISABLE.add(KW_DISABLE130);

			KW_REWRITE131=(Token)match(input,KW_REWRITE,FOLLOW_KW_REWRITE_in_rewriteDisabled3288); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REWRITE.add(KW_REWRITE131);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1038:5: -> ^( TOK_REWRITE_DISABLED )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1038:8: ^( TOK_REWRITE_DISABLED )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REWRITE_DISABLED, "TOK_REWRITE_DISABLED"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rewriteDisabled"


	public static class storedAsDirs_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "storedAsDirs"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1041:1: storedAsDirs : KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) ;
	public final HiveParser.storedAsDirs_return storedAsDirs() throws RecognitionException {
		HiveParser.storedAsDirs_return retval = new HiveParser.storedAsDirs_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_STORED132=null;
		Token KW_AS133=null;
		Token KW_DIRECTORIES134=null;

		ASTNode KW_STORED132_tree=null;
		ASTNode KW_AS133_tree=null;
		ASTNode KW_DIRECTORIES134_tree=null;
		RewriteRuleTokenStream stream_KW_DIRECTORIES=new RewriteRuleTokenStream(adaptor,"token KW_DIRECTORIES");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_STORED=new RewriteRuleTokenStream(adaptor,"token KW_STORED");

		 pushMsg("stored as directories", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1044:5: ( KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1044:7: KW_STORED KW_AS KW_DIRECTORIES
			{
			KW_STORED132=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_storedAsDirs3325); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED132);

			KW_AS133=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_storedAsDirs3327); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS133);

			KW_DIRECTORIES134=(Token)match(input,KW_DIRECTORIES,FOLLOW_KW_DIRECTORIES_in_storedAsDirs3329); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DIRECTORIES.add(KW_DIRECTORIES134);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1045:5: -> ^( TOK_STOREDASDIRS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1045:8: ^( TOK_STOREDASDIRS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_STOREDASDIRS, "TOK_STOREDASDIRS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "storedAsDirs"


	public static class orReplace_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "orReplace"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1048:1: orReplace : KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) ;
	public final HiveParser.orReplace_return orReplace() throws RecognitionException {
		HiveParser.orReplace_return retval = new HiveParser.orReplace_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_OR135=null;
		Token KW_REPLACE136=null;

		ASTNode KW_OR135_tree=null;
		ASTNode KW_REPLACE136_tree=null;
		RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
		RewriteRuleTokenStream stream_KW_OR=new RewriteRuleTokenStream(adaptor,"token KW_OR");

		 pushMsg("or replace clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1051:5: ( KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1051:7: KW_OR KW_REPLACE
			{
			KW_OR135=(Token)match(input,KW_OR,FOLLOW_KW_OR_in_orReplace3366); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OR.add(KW_OR135);

			KW_REPLACE136=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_orReplace3368); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPLACE.add(KW_REPLACE136);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1052:5: -> ^( TOK_ORREPLACE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1052:8: ^( TOK_ORREPLACE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ORREPLACE, "TOK_ORREPLACE"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "orReplace"


	public static class createDatabaseStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createDatabaseStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1055:1: createDatabaseStatement : KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? ) ;
	public final HiveParser.createDatabaseStatement_return createDatabaseStatement() throws RecognitionException {
		HiveParser.createDatabaseStatement_return retval = new HiveParser.createDatabaseStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE137=null;
		Token KW_DATABASE138=null;
		Token KW_SCHEMA139=null;
		Token KW_WITH143=null;
		Token KW_DBPROPERTIES144=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope dbprops =null;
		ParserRuleReturnScope ifNotExists140 =null;
		ParserRuleReturnScope databaseComment141 =null;
		ParserRuleReturnScope dbLocation142 =null;

		ASTNode KW_CREATE137_tree=null;
		ASTNode KW_DATABASE138_tree=null;
		ASTNode KW_SCHEMA139_tree=null;
		ASTNode KW_WITH143_tree=null;
		ASTNode KW_DBPROPERTIES144_tree=null;
		RewriteRuleTokenStream stream_KW_DBPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_DBPROPERTIES");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_dbProperties=new RewriteRuleSubtreeStream(adaptor,"rule dbProperties");
		RewriteRuleSubtreeStream stream_databaseComment=new RewriteRuleSubtreeStream(adaptor,"rule databaseComment");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_dbLocation=new RewriteRuleSubtreeStream(adaptor,"rule dbLocation");

		 pushMsg("create database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:5: ( KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:7: KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
			{
			KW_CREATE137=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createDatabaseStatement3405); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE137);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:17: ( KW_DATABASE | KW_SCHEMA )
			int alt31=2;
			int LA31_0 = input.LA(1);
			if ( (LA31_0==KW_DATABASE) ) {
				alt31=1;
			}
			else if ( (LA31_0==KW_SCHEMA) ) {
				alt31=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 31, 0, input);
				throw nvae;
			}

			switch (alt31) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:18: KW_DATABASE
					{
					KW_DATABASE138=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_createDatabaseStatement3408); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE138);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:30: KW_SCHEMA
					{
					KW_SCHEMA139=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_createDatabaseStatement3410); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA139);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1059:9: ( ifNotExists )?
			int alt32=2;
			int LA32_0 = input.LA(1);
			if ( (LA32_0==KW_IF) ) {
				alt32=1;
			}
			switch (alt32) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1059:9: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_createDatabaseStatement3421);
					ifNotExists140=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists140.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_createDatabaseStatement3434);
			name=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1061:9: ( databaseComment )?
			int alt33=2;
			int LA33_0 = input.LA(1);
			if ( (LA33_0==KW_COMMENT) ) {
				alt33=1;
			}
			switch (alt33) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1061:9: databaseComment
					{
					pushFollow(FOLLOW_databaseComment_in_createDatabaseStatement3444);
					databaseComment141=databaseComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_databaseComment.add(databaseComment141.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1062:9: ( dbLocation )?
			int alt34=2;
			int LA34_0 = input.LA(1);
			if ( (LA34_0==KW_LOCATION) ) {
				alt34=1;
			}
			switch (alt34) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1062:9: dbLocation
					{
					pushFollow(FOLLOW_dbLocation_in_createDatabaseStatement3455);
					dbLocation142=dbLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_dbLocation.add(dbLocation142.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1063:9: ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
			int alt35=2;
			int LA35_0 = input.LA(1);
			if ( (LA35_0==KW_WITH) ) {
				alt35=1;
			}
			switch (alt35) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1063:10: KW_WITH KW_DBPROPERTIES dbprops= dbProperties
					{
					KW_WITH143=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_createDatabaseStatement3467); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH143);

					KW_DBPROPERTIES144=(Token)match(input,KW_DBPROPERTIES,FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement3469); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES144);

					pushFollow(FOLLOW_dbProperties_in_createDatabaseStatement3473);
					dbprops=dbProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_dbProperties.add(dbprops.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: ifNotExists, databaseComment, dbLocation, dbprops, name
			// token labels: 
			// rule labels: name, dbprops, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_dbprops=new RewriteRuleSubtreeStream(adaptor,"rule dbprops",dbprops!=null?dbprops.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1064:5: -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:8: ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEDATABASE, "TOK_CREATEDATABASE"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:35: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:48: ( dbLocation )?
				if ( stream_dbLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_dbLocation.nextTree());
				}
				stream_dbLocation.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:60: ( databaseComment )?
				if ( stream_databaseComment.hasNext() ) {
					adaptor.addChild(root_1, stream_databaseComment.nextTree());
				}
				stream_databaseComment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:78: ( $dbprops)?
				if ( stream_dbprops.hasNext() ) {
					adaptor.addChild(root_1, stream_dbprops.nextTree());
				}
				stream_dbprops.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createDatabaseStatement"


	public static class dbLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1067:1: dbLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_DATABASELOCATION $locn) ;
	public final HiveParser.dbLocation_return dbLocation() throws RecognitionException {
		HiveParser.dbLocation_return retval = new HiveParser.dbLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token locn=null;
		Token KW_LOCATION145=null;

		ASTNode locn_tree=null;
		ASTNode KW_LOCATION145_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

		 pushMsg("database location specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1070:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_DATABASELOCATION $locn) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1071:7: KW_LOCATION locn= StringLiteral
			{
			KW_LOCATION145=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_dbLocation3534); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION145);

			locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_dbLocation3538); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(locn);

			// AST REWRITE
			// elements: locn
			// token labels: locn
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1071:38: -> ^( TOK_DATABASELOCATION $locn)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1071:41: ^( TOK_DATABASELOCATION $locn)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASELOCATION, "TOK_DATABASELOCATION"), root_1);
				adaptor.addChild(root_1, stream_locn.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbLocation"


	public static class dbProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1074:1: dbProperties : LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) ;
	public final HiveParser.dbProperties_return dbProperties() throws RecognitionException {
		HiveParser.dbProperties_return retval = new HiveParser.dbProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN146=null;
		Token RPAREN148=null;
		ParserRuleReturnScope dbPropertiesList147 =null;

		ASTNode LPAREN146_tree=null;
		ASTNode RPAREN148_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_dbPropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule dbPropertiesList");

		 pushMsg("dbproperties", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1077:5: ( LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1078:7: LPAREN dbPropertiesList RPAREN
			{
			LPAREN146=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_dbProperties3580); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN146);

			pushFollow(FOLLOW_dbPropertiesList_in_dbProperties3582);
			dbPropertiesList147=dbPropertiesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_dbPropertiesList.add(dbPropertiesList147.getTree());
			RPAREN148=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_dbProperties3584); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN148);

			// AST REWRITE
			// elements: dbPropertiesList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1078:38: -> ^( TOK_DATABASEPROPERTIES dbPropertiesList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1078:41: ^( TOK_DATABASEPROPERTIES dbPropertiesList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASEPROPERTIES, "TOK_DATABASEPROPERTIES"), root_1);
				adaptor.addChild(root_1, stream_dbPropertiesList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbProperties"


	public static class dbPropertiesList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbPropertiesList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1081:1: dbPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) ;
	public final HiveParser.dbPropertiesList_return dbPropertiesList() throws RecognitionException {
		HiveParser.dbPropertiesList_return retval = new HiveParser.dbPropertiesList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA150=null;
		ParserRuleReturnScope keyValueProperty149 =null;
		ParserRuleReturnScope keyValueProperty151 =null;

		ASTNode COMMA150_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");

		 pushMsg("database properties list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1084:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1085:7: keyValueProperty ( COMMA keyValueProperty )*
			{
			pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList3625);
			keyValueProperty149=keyValueProperty();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty149.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1085:24: ( COMMA keyValueProperty )*
			loop36:
			while (true) {
				int alt36=2;
				int LA36_0 = input.LA(1);
				if ( (LA36_0==COMMA) ) {
					alt36=1;
				}

				switch (alt36) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1085:25: COMMA keyValueProperty
					{
					COMMA150=(Token)match(input,COMMA,FOLLOW_COMMA_in_dbPropertiesList3628); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA150);

					pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList3630);
					keyValueProperty151=keyValueProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty151.getTree());
					}
					break;

				default :
					break loop36;
				}
			}

			// AST REWRITE
			// elements: keyValueProperty
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1085:50: -> ^( TOK_DBPROPLIST ( keyValueProperty )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1085:53: ^( TOK_DBPROPLIST ( keyValueProperty )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DBPROPLIST, "TOK_DBPROPLIST"), root_1);
				if ( !(stream_keyValueProperty.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_keyValueProperty.hasNext() ) {
					adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
				}
				stream_keyValueProperty.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbPropertiesList"


	public static class switchDatabaseStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "switchDatabaseStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1089:1: switchDatabaseStatement : KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) ;
	public final HiveParser.switchDatabaseStatement_return switchDatabaseStatement() throws RecognitionException {
		HiveParser.switchDatabaseStatement_return retval = new HiveParser.switchDatabaseStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_USE152=null;
		ParserRuleReturnScope identifier153 =null;

		ASTNode KW_USE152_tree=null;
		RewriteRuleTokenStream stream_KW_USE=new RewriteRuleTokenStream(adaptor,"token KW_USE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("switch database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:5: ( KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:7: KW_USE identifier
			{
			KW_USE152=(Token)match(input,KW_USE,FOLLOW_KW_USE_in_switchDatabaseStatement3669); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_USE.add(KW_USE152);

			pushFollow(FOLLOW_identifier_in_switchDatabaseStatement3671);
			identifier153=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier153.getTree());
			// AST REWRITE
			// elements: identifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1093:5: -> ^( TOK_SWITCHDATABASE identifier )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1093:8: ^( TOK_SWITCHDATABASE identifier )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SWITCHDATABASE, "TOK_SWITCHDATABASE"), root_1);
				adaptor.addChild(root_1, stream_identifier.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "switchDatabaseStatement"


	public static class dropDatabaseStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropDatabaseStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1096:1: dropDatabaseStatement : KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) ;
	public final HiveParser.dropDatabaseStatement_return dropDatabaseStatement() throws RecognitionException {
		HiveParser.dropDatabaseStatement_return retval = new HiveParser.dropDatabaseStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP154=null;
		Token KW_DATABASE155=null;
		Token KW_SCHEMA156=null;
		ParserRuleReturnScope ifExists157 =null;
		ParserRuleReturnScope identifier158 =null;
		ParserRuleReturnScope restrictOrCascade159 =null;

		ASTNode KW_DROP154_tree=null;
		ASTNode KW_DATABASE155_tree=null;
		ASTNode KW_SCHEMA156_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");

		 pushMsg("drop database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:5: ( KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:7: KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )?
			{
			KW_DROP154=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropDatabaseStatement3710); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP154);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:15: ( KW_DATABASE | KW_SCHEMA )
			int alt37=2;
			int LA37_0 = input.LA(1);
			if ( (LA37_0==KW_DATABASE) ) {
				alt37=1;
			}
			else if ( (LA37_0==KW_SCHEMA) ) {
				alt37=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 37, 0, input);
				throw nvae;
			}

			switch (alt37) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:16: KW_DATABASE
					{
					KW_DATABASE155=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_dropDatabaseStatement3713); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE155);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:28: KW_SCHEMA
					{
					KW_SCHEMA156=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_dropDatabaseStatement3715); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA156);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:39: ( ifExists )?
			int alt38=2;
			int LA38_0 = input.LA(1);
			if ( (LA38_0==KW_IF) ) {
				alt38=1;
			}
			switch (alt38) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:39: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropDatabaseStatement3718);
					ifExists157=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists157.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_dropDatabaseStatement3721);
			identifier158=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier158.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:60: ( restrictOrCascade )?
			int alt39=2;
			int LA39_0 = input.LA(1);
			if ( (LA39_0==KW_CASCADE||LA39_0==KW_RESTRICT) ) {
				alt39=1;
			}
			switch (alt39) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:60: restrictOrCascade
					{
					pushFollow(FOLLOW_restrictOrCascade_in_dropDatabaseStatement3723);
					restrictOrCascade159=restrictOrCascade();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade159.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: ifExists, identifier, restrictOrCascade
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1100:5: -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1100:8: ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPDATABASE, "TOK_DROPDATABASE"), root_1);
				adaptor.addChild(root_1, stream_identifier.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1100:38: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1100:48: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropDatabaseStatement"


	public static class databaseComment_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "databaseComment"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1103:1: databaseComment : KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) ;
	public final HiveParser.databaseComment_return databaseComment() throws RecognitionException {
		HiveParser.databaseComment_return retval = new HiveParser.databaseComment_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT160=null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT160_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

		 pushMsg("database's comment", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1106:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1106:7: KW_COMMENT comment= StringLiteral
			{
			KW_COMMENT160=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_databaseComment3769); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT160);

			comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_databaseComment3773); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

			// AST REWRITE
			// elements: comment
			// token labels: comment
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1107:5: -> ^( TOK_DATABASECOMMENT $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1107:8: ^( TOK_DATABASECOMMENT $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASECOMMENT, "TOK_DATABASECOMMENT"), root_1);
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "databaseComment"


	public static class createTableStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTableStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1110:1: createTableStatement : KW_CREATE (temp= KW_TEMPORARY )? (trans= KW_TRANSACTIONAL )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrConstraintList RPAREN )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? ) -> ^( TOK_CREATETABLE $name ( $temp)? ( $trans)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrConstraintList )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? ) ;
	public final HiveParser.createTableStatement_return createTableStatement() throws RecognitionException {
		HiveParser.createTableStatement_return retval = new HiveParser.createTableStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token temp=null;
		Token trans=null;
		Token ext=null;
		Token like=null;
		Token KW_CREATE161=null;
		Token KW_TABLE162=null;
		Token LPAREN168=null;
		Token RPAREN170=null;
		Token KW_AS179=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope likeName =null;
		ParserRuleReturnScope ifNotExists163 =null;
		ParserRuleReturnScope tableRowFormat164 =null;
		ParserRuleReturnScope tableFileFormat165 =null;
		ParserRuleReturnScope tableLocation166 =null;
		ParserRuleReturnScope tablePropertiesPrefixed167 =null;
		ParserRuleReturnScope columnNameTypeOrConstraintList169 =null;
		ParserRuleReturnScope tableComment171 =null;
		ParserRuleReturnScope createTablePartitionSpec172 =null;
		ParserRuleReturnScope tableBuckets173 =null;
		ParserRuleReturnScope tableSkewed174 =null;
		ParserRuleReturnScope tableRowFormat175 =null;
		ParserRuleReturnScope tableFileFormat176 =null;
		ParserRuleReturnScope tableLocation177 =null;
		ParserRuleReturnScope tablePropertiesPrefixed178 =null;
		ParserRuleReturnScope selectStatementWithCTE180 =null;

		ASTNode temp_tree=null;
		ASTNode trans_tree=null;
		ASTNode ext_tree=null;
		ASTNode like_tree=null;
		ASTNode KW_CREATE161_tree=null;
		ASTNode KW_TABLE162_tree=null;
		ASTNode LPAREN168_tree=null;
		ASTNode RPAREN170_tree=null;
		ASTNode KW_AS179_tree=null;
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_EXTERNAL=new RewriteRuleTokenStream(adaptor,"token KW_EXTERNAL");
		RewriteRuleTokenStream stream_KW_TRANSACTIONAL=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTIONAL");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_LIKE=new RewriteRuleTokenStream(adaptor,"token KW_LIKE");
		RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
		RewriteRuleSubtreeStream stream_selectStatementWithCTE=new RewriteRuleSubtreeStream(adaptor,"rule selectStatementWithCTE");
		RewriteRuleSubtreeStream stream_createTablePartitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule createTablePartitionSpec");
		RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
		RewriteRuleSubtreeStream stream_columnNameTypeOrConstraintList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeOrConstraintList");
		RewriteRuleSubtreeStream stream_tableSkewed=new RewriteRuleSubtreeStream(adaptor,"rule tableSkewed");
		RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
		RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
		RewriteRuleSubtreeStream stream_tableBuckets=new RewriteRuleSubtreeStream(adaptor,"rule tableBuckets");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("create table statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:5: ( KW_CREATE (temp= KW_TEMPORARY )? (trans= KW_TRANSACTIONAL )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrConstraintList RPAREN )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? ) -> ^( TOK_CREATETABLE $name ( $temp)? ( $trans)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrConstraintList )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:7: KW_CREATE (temp= KW_TEMPORARY )? (trans= KW_TRANSACTIONAL )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrConstraintList RPAREN )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? )
			{
			KW_CREATE161=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createTableStatement3813); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE161);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:17: (temp= KW_TEMPORARY )?
			int alt40=2;
			int LA40_0 = input.LA(1);
			if ( (LA40_0==KW_TEMPORARY) ) {
				alt40=1;
			}
			switch (alt40) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:18: temp= KW_TEMPORARY
					{
					temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createTableStatement3818); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:38: (trans= KW_TRANSACTIONAL )?
			int alt41=2;
			int LA41_0 = input.LA(1);
			if ( (LA41_0==KW_TRANSACTIONAL) ) {
				alt41=1;
			}
			switch (alt41) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:39: trans= KW_TRANSACTIONAL
					{
					trans=(Token)match(input,KW_TRANSACTIONAL,FOLLOW_KW_TRANSACTIONAL_in_createTableStatement3825); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TRANSACTIONAL.add(trans);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:64: (ext= KW_EXTERNAL )?
			int alt42=2;
			int LA42_0 = input.LA(1);
			if ( (LA42_0==KW_EXTERNAL) ) {
				alt42=1;
			}
			switch (alt42) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:65: ext= KW_EXTERNAL
					{
					ext=(Token)match(input,KW_EXTERNAL,FOLLOW_KW_EXTERNAL_in_createTableStatement3832); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXTERNAL.add(ext);

					}
					break;

			}

			KW_TABLE162=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_createTableStatement3836); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE162);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:92: ( ifNotExists )?
			int alt43=2;
			int LA43_0 = input.LA(1);
			if ( (LA43_0==KW_IF) ) {
				alt43=1;
			}
			switch (alt43) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:92: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_createTableStatement3838);
					ifNotExists163=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists163.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_createTableStatement3843);
			name=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(name.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1114:7: (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrConstraintList RPAREN )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? )
			int alt58=2;
			int LA58_0 = input.LA(1);
			if ( (LA58_0==KW_LIKE) ) {
				alt58=1;
			}
			else if ( (LA58_0==EOF||LA58_0==KW_AS||LA58_0==KW_CLUSTERED||LA58_0==KW_COMMENT||LA58_0==KW_LOCATION||LA58_0==KW_PARTITIONED||LA58_0==KW_ROW||LA58_0==KW_SKEWED||LA58_0==KW_STORED||LA58_0==KW_TBLPROPERTIES||LA58_0==LPAREN) ) {
				alt58=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 58, 0, input);
				throw nvae;
			}

			switch (alt58) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1114:10: like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )?
					{
					like=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_createTableStatement3856); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIKE.add(like);

					pushFollow(FOLLOW_tableName_in_createTableStatement3860);
					likeName=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(likeName.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1115:10: ( tableRowFormat )?
					int alt44=2;
					int LA44_0 = input.LA(1);
					if ( (LA44_0==KW_ROW) ) {
						alt44=1;
					}
					switch (alt44) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1115:10: tableRowFormat
							{
							pushFollow(FOLLOW_tableRowFormat_in_createTableStatement3871);
							tableRowFormat164=tableRowFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat164.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1116:10: ( tableFileFormat )?
					int alt45=2;
					int LA45_0 = input.LA(1);
					if ( (LA45_0==KW_STORED) ) {
						alt45=1;
					}
					switch (alt45) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1116:10: tableFileFormat
							{
							pushFollow(FOLLOW_tableFileFormat_in_createTableStatement3883);
							tableFileFormat165=tableFileFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat165.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1117:10: ( tableLocation )?
					int alt46=2;
					int LA46_0 = input.LA(1);
					if ( (LA46_0==KW_LOCATION) ) {
						alt46=1;
					}
					switch (alt46) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1117:10: tableLocation
							{
							pushFollow(FOLLOW_tableLocation_in_createTableStatement3895);
							tableLocation166=tableLocation();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation166.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:10: ( tablePropertiesPrefixed )?
					int alt47=2;
					int LA47_0 = input.LA(1);
					if ( (LA47_0==KW_TBLPROPERTIES) ) {
						alt47=1;
					}
					switch (alt47) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:10: tablePropertiesPrefixed
							{
							pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement3907);
							tablePropertiesPrefixed167=tablePropertiesPrefixed();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed167.getTree());
							}
							break;

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1119:10: ( LPAREN columnNameTypeOrConstraintList RPAREN )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1119:10: ( LPAREN columnNameTypeOrConstraintList RPAREN )?
					int alt48=2;
					int LA48_0 = input.LA(1);
					if ( (LA48_0==LPAREN) ) {
						alt48=1;
					}
					switch (alt48) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1119:11: LPAREN columnNameTypeOrConstraintList RPAREN
							{
							LPAREN168=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createTableStatement3920); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN168);

							pushFollow(FOLLOW_columnNameTypeOrConstraintList_in_createTableStatement3922);
							columnNameTypeOrConstraintList169=columnNameTypeOrConstraintList();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_columnNameTypeOrConstraintList.add(columnNameTypeOrConstraintList169.getTree());
							RPAREN170=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createTableStatement3924); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN170);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1120:10: ( tableComment )?
					int alt49=2;
					int LA49_0 = input.LA(1);
					if ( (LA49_0==KW_COMMENT) ) {
						alt49=1;
					}
					switch (alt49) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1120:10: tableComment
							{
							pushFollow(FOLLOW_tableComment_in_createTableStatement3937);
							tableComment171=tableComment();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableComment.add(tableComment171.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1121:10: ( createTablePartitionSpec )?
					int alt50=2;
					int LA50_0 = input.LA(1);
					if ( (LA50_0==KW_PARTITIONED) ) {
						alt50=1;
					}
					switch (alt50) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1121:10: createTablePartitionSpec
							{
							pushFollow(FOLLOW_createTablePartitionSpec_in_createTableStatement3949);
							createTablePartitionSpec172=createTablePartitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_createTablePartitionSpec.add(createTablePartitionSpec172.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1122:10: ( tableBuckets )?
					int alt51=2;
					int LA51_0 = input.LA(1);
					if ( (LA51_0==KW_CLUSTERED) ) {
						alt51=1;
					}
					switch (alt51) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1122:10: tableBuckets
							{
							pushFollow(FOLLOW_tableBuckets_in_createTableStatement3961);
							tableBuckets173=tableBuckets();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableBuckets.add(tableBuckets173.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1123:10: ( tableSkewed )?
					int alt52=2;
					int LA52_0 = input.LA(1);
					if ( (LA52_0==KW_SKEWED) ) {
						alt52=1;
					}
					switch (alt52) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1123:10: tableSkewed
							{
							pushFollow(FOLLOW_tableSkewed_in_createTableStatement3973);
							tableSkewed174=tableSkewed();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableSkewed.add(tableSkewed174.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1124:10: ( tableRowFormat )?
					int alt53=2;
					int LA53_0 = input.LA(1);
					if ( (LA53_0==KW_ROW) ) {
						alt53=1;
					}
					switch (alt53) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1124:10: tableRowFormat
							{
							pushFollow(FOLLOW_tableRowFormat_in_createTableStatement3985);
							tableRowFormat175=tableRowFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat175.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1125:10: ( tableFileFormat )?
					int alt54=2;
					int LA54_0 = input.LA(1);
					if ( (LA54_0==KW_STORED) ) {
						alt54=1;
					}
					switch (alt54) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1125:10: tableFileFormat
							{
							pushFollow(FOLLOW_tableFileFormat_in_createTableStatement3997);
							tableFileFormat176=tableFileFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat176.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1126:10: ( tableLocation )?
					int alt55=2;
					int LA55_0 = input.LA(1);
					if ( (LA55_0==KW_LOCATION) ) {
						alt55=1;
					}
					switch (alt55) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1126:10: tableLocation
							{
							pushFollow(FOLLOW_tableLocation_in_createTableStatement4009);
							tableLocation177=tableLocation();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation177.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1127:10: ( tablePropertiesPrefixed )?
					int alt56=2;
					int LA56_0 = input.LA(1);
					if ( (LA56_0==KW_TBLPROPERTIES) ) {
						alt56=1;
					}
					switch (alt56) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1127:10: tablePropertiesPrefixed
							{
							pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement4021);
							tablePropertiesPrefixed178=tablePropertiesPrefixed();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed178.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1128:10: ( KW_AS selectStatementWithCTE )?
					int alt57=2;
					int LA57_0 = input.LA(1);
					if ( (LA57_0==KW_AS) ) {
						alt57=1;
					}
					switch (alt57) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1128:11: KW_AS selectStatementWithCTE
							{
							KW_AS179=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createTableStatement4034); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS179);

							pushFollow(FOLLOW_selectStatementWithCTE_in_createTableStatement4036);
							selectStatementWithCTE180=selectStatementWithCTE();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_selectStatementWithCTE.add(selectStatementWithCTE180.getTree());
							}
							break;

					}

					}
					break;

			}

			// AST REWRITE
			// elements: tableBuckets, name, tableComment, tableSkewed, trans, columnNameTypeOrConstraintList, likeName, ext, tableRowFormat, temp, selectStatementWithCTE, tablePropertiesPrefixed, createTablePartitionSpec, tableLocation, ifNotExists, tableFileFormat
			// token labels: ext, temp, trans
			// rule labels: likeName, name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_ext=new RewriteRuleTokenStream(adaptor,"token ext",ext);
			RewriteRuleTokenStream stream_temp=new RewriteRuleTokenStream(adaptor,"token temp",temp);
			RewriteRuleTokenStream stream_trans=new RewriteRuleTokenStream(adaptor,"token trans",trans);
			RewriteRuleSubtreeStream stream_likeName=new RewriteRuleSubtreeStream(adaptor,"rule likeName",likeName!=null?likeName.getTree():null);
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1130:5: -> ^( TOK_CREATETABLE $name ( $temp)? ( $trans)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrConstraintList )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1130:8: ^( TOK_CREATETABLE $name ( $temp)? ( $trans)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrConstraintList )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATETABLE, "TOK_CREATETABLE"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1130:33: ( $temp)?
				if ( stream_temp.hasNext() ) {
					adaptor.addChild(root_1, stream_temp.nextNode());
				}
				stream_temp.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1130:40: ( $trans)?
				if ( stream_trans.hasNext() ) {
					adaptor.addChild(root_1, stream_trans.nextNode());
				}
				stream_trans.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1130:48: ( $ext)?
				if ( stream_ext.hasNext() ) {
					adaptor.addChild(root_1, stream_ext.nextNode());
				}
				stream_ext.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1130:53: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:10: ^( TOK_LIKETABLE ( $likeName)? )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIKETABLE, "TOK_LIKETABLE"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:27: ( $likeName)?
				if ( stream_likeName.hasNext() ) {
					adaptor.addChild(root_2, stream_likeName.nextTree());
				}
				stream_likeName.reset();

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1132:10: ( columnNameTypeOrConstraintList )?
				if ( stream_columnNameTypeOrConstraintList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeOrConstraintList.nextTree());
				}
				stream_columnNameTypeOrConstraintList.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1133:10: ( tableComment )?
				if ( stream_tableComment.hasNext() ) {
					adaptor.addChild(root_1, stream_tableComment.nextTree());
				}
				stream_tableComment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1134:10: ( createTablePartitionSpec )?
				if ( stream_createTablePartitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_createTablePartitionSpec.nextTree());
				}
				stream_createTablePartitionSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1135:10: ( tableBuckets )?
				if ( stream_tableBuckets.hasNext() ) {
					adaptor.addChild(root_1, stream_tableBuckets.nextTree());
				}
				stream_tableBuckets.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1136:10: ( tableSkewed )?
				if ( stream_tableSkewed.hasNext() ) {
					adaptor.addChild(root_1, stream_tableSkewed.nextTree());
				}
				stream_tableSkewed.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:10: ( tableRowFormat )?
				if ( stream_tableRowFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
				}
				stream_tableRowFormat.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:10: ( tableFileFormat )?
				if ( stream_tableFileFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
				}
				stream_tableFileFormat.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1139:10: ( tableLocation )?
				if ( stream_tableLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_tableLocation.nextTree());
				}
				stream_tableLocation.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1140:10: ( tablePropertiesPrefixed )?
				if ( stream_tablePropertiesPrefixed.hasNext() ) {
					adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
				}
				stream_tablePropertiesPrefixed.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1141:10: ( selectStatementWithCTE )?
				if ( stream_selectStatementWithCTE.hasNext() ) {
					adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());
				}
				stream_selectStatementWithCTE.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTableStatement"


	public static class truncateTableStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "truncateTableStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1145:1: truncateTableStatement : KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? ( force )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? ) ;
	public final HiveParser.truncateTableStatement_return truncateTableStatement() throws RecognitionException {
		HiveParser.truncateTableStatement_return retval = new HiveParser.truncateTableStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_TRUNCATE181=null;
		Token KW_TABLE182=null;
		Token KW_COLUMNS184=null;
		Token LPAREN185=null;
		Token RPAREN187=null;
		ParserRuleReturnScope tablePartitionPrefix183 =null;
		ParserRuleReturnScope columnNameList186 =null;
		ParserRuleReturnScope force188 =null;

		ASTNode KW_TRUNCATE181_tree=null;
		ASTNode KW_TABLE182_tree=null;
		ASTNode KW_COLUMNS184_tree=null;
		ASTNode LPAREN185_tree=null;
		ASTNode RPAREN187_tree=null;
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_TRUNCATE=new RewriteRuleTokenStream(adaptor,"token KW_TRUNCATE");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_force=new RewriteRuleSubtreeStream(adaptor,"rule force");
		RewriteRuleSubtreeStream stream_tablePartitionPrefix=new RewriteRuleSubtreeStream(adaptor,"rule tablePartitionPrefix");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("truncate table statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:5: ( KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? ( force )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:7: KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? ( force )?
			{
			KW_TRUNCATE181=(Token)match(input,KW_TRUNCATE,FOLLOW_KW_TRUNCATE_in_truncateTableStatement4247); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TRUNCATE.add(KW_TRUNCATE181);

			KW_TABLE182=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_truncateTableStatement4249); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE182);

			pushFollow(FOLLOW_tablePartitionPrefix_in_truncateTableStatement4251);
			tablePartitionPrefix183=tablePartitionPrefix();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tablePartitionPrefix.add(tablePartitionPrefix183.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:49: ( KW_COLUMNS LPAREN columnNameList RPAREN )?
			int alt59=2;
			int LA59_0 = input.LA(1);
			if ( (LA59_0==KW_COLUMNS) ) {
				alt59=1;
			}
			switch (alt59) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:50: KW_COLUMNS LPAREN columnNameList RPAREN
					{
					KW_COLUMNS184=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_truncateTableStatement4254); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS184);

					LPAREN185=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_truncateTableStatement4256); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN185);

					pushFollow(FOLLOW_columnNameList_in_truncateTableStatement4258);
					columnNameList186=columnNameList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList186.getTree());
					RPAREN187=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_truncateTableStatement4260); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN187);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:92: ( force )?
			int alt60=2;
			int LA60_0 = input.LA(1);
			if ( (LA60_0==KW_FORCE) ) {
				alt60=1;
			}
			switch (alt60) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:92: force
					{
					pushFollow(FOLLOW_force_in_truncateTableStatement4264);
					force188=force();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_force.add(force188.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: force, tablePartitionPrefix, columnNameList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1149:5: -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1149:8: ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TRUNCATETABLE, "TOK_TRUNCATETABLE"), root_1);
				adaptor.addChild(root_1, stream_tablePartitionPrefix.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1149:49: ( columnNameList )?
				if ( stream_columnNameList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameList.nextTree());
				}
				stream_columnNameList.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1149:65: ( force )?
				if ( stream_force.hasNext() ) {
					adaptor.addChild(root_1, stream_force.nextTree());
				}
				stream_force.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "truncateTableStatement"


	public static class dropTableStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropTableStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:1: dropTableStatement : KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) ;
	public final HiveParser.dropTableStatement_return dropTableStatement() throws RecognitionException {
		HiveParser.dropTableStatement_return retval = new HiveParser.dropTableStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP189=null;
		Token KW_TABLE190=null;
		Token KW_PURGE193=null;
		ParserRuleReturnScope ifExists191 =null;
		ParserRuleReturnScope tableName192 =null;
		ParserRuleReturnScope replicationClause194 =null;

		ASTNode KW_DROP189_tree=null;
		ASTNode KW_TABLE190_tree=null;
		ASTNode KW_PURGE193_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_PURGE=new RewriteRuleTokenStream(adaptor,"token KW_PURGE");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("drop statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:5: ( KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:7: KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )?
			{
			KW_DROP189=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropTableStatement4305); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP189);

			KW_TABLE190=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_dropTableStatement4307); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE190);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:24: ( ifExists )?
			int alt61=2;
			int LA61_0 = input.LA(1);
			if ( (LA61_0==KW_IF) ) {
				alt61=1;
			}
			switch (alt61) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:24: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropTableStatement4309);
					ifExists191=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists191.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_dropTableStatement4312);
			tableName192=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName192.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:44: ( KW_PURGE )?
			int alt62=2;
			int LA62_0 = input.LA(1);
			if ( (LA62_0==KW_PURGE) ) {
				alt62=1;
			}
			switch (alt62) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:44: KW_PURGE
					{
					KW_PURGE193=(Token)match(input,KW_PURGE,FOLLOW_KW_PURGE_in_dropTableStatement4314); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PURGE.add(KW_PURGE193);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:54: ( replicationClause )?
			int alt63=2;
			int LA63_0 = input.LA(1);
			if ( (LA63_0==KW_FOR) ) {
				alt63=1;
			}
			switch (alt63) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:54: replicationClause
					{
					pushFollow(FOLLOW_replicationClause_in_dropTableStatement4317);
					replicationClause194=replicationClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause194.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableName, replicationClause, KW_PURGE, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1155:5: -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:8: ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPTABLE, "TOK_DROPTABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:34: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:44: ( KW_PURGE )?
				if ( stream_KW_PURGE.hasNext() ) {
					adaptor.addChild(root_1, stream_KW_PURGE.nextNode());
				}
				stream_KW_PURGE.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:54: ( replicationClause )?
				if ( stream_replicationClause.hasNext() ) {
					adaptor.addChild(root_1, stream_replicationClause.nextTree());
				}
				stream_replicationClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropTableStatement"


	public static class alterStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1158:1: alterStatement : ( KW_ALTER KW_TABLE tableName alterTableStatementSuffix -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix ) | KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix ) | KW_ALTER KW_MATERIALIZED KW_VIEW tableName alterMaterializedViewStatementSuffix -> ^( TOK_ALTER_MATERIALIZED_VIEW tableName alterMaterializedViewStatementSuffix ) | KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix -> alterDatabaseStatementSuffix );
	public final HiveParser.alterStatement_return alterStatement() throws RecognitionException {
		HiveParser.alterStatement_return retval = new HiveParser.alterStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ALTER195=null;
		Token KW_TABLE196=null;
		Token KW_ALTER199=null;
		Token KW_VIEW200=null;
		Token KW_AS202=null;
		Token KW_ALTER204=null;
		Token KW_MATERIALIZED205=null;
		Token KW_VIEW206=null;
		Token KW_ALTER209=null;
		Token KW_DATABASE210=null;
		Token KW_SCHEMA211=null;
		ParserRuleReturnScope tableName197 =null;
		ParserRuleReturnScope alterTableStatementSuffix198 =null;
		ParserRuleReturnScope tableName201 =null;
		ParserRuleReturnScope alterViewStatementSuffix203 =null;
		ParserRuleReturnScope tableName207 =null;
		ParserRuleReturnScope alterMaterializedViewStatementSuffix208 =null;
		ParserRuleReturnScope alterDatabaseStatementSuffix212 =null;

		ASTNode KW_ALTER195_tree=null;
		ASTNode KW_TABLE196_tree=null;
		ASTNode KW_ALTER199_tree=null;
		ASTNode KW_VIEW200_tree=null;
		ASTNode KW_AS202_tree=null;
		ASTNode KW_ALTER204_tree=null;
		ASTNode KW_MATERIALIZED205_tree=null;
		ASTNode KW_VIEW206_tree=null;
		ASTNode KW_ALTER209_tree=null;
		ASTNode KW_DATABASE210_tree=null;
		ASTNode KW_SCHEMA211_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_ALTER=new RewriteRuleTokenStream(adaptor,"token KW_ALTER");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleSubtreeStream stream_alterMaterializedViewStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterMaterializedViewStatementSuffix");
		RewriteRuleSubtreeStream stream_alterTableStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterTableStatementSuffix");
		RewriteRuleSubtreeStream stream_alterViewStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterViewStatementSuffix");
		RewriteRuleSubtreeStream stream_alterDatabaseStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterDatabaseStatementSuffix");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("alter statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1161:5: ( KW_ALTER KW_TABLE tableName alterTableStatementSuffix -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix ) | KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix ) | KW_ALTER KW_MATERIALIZED KW_VIEW tableName alterMaterializedViewStatementSuffix -> ^( TOK_ALTER_MATERIALIZED_VIEW tableName alterMaterializedViewStatementSuffix ) | KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix -> alterDatabaseStatementSuffix )
			int alt66=4;
			int LA66_0 = input.LA(1);
			if ( (LA66_0==KW_ALTER) ) {
				switch ( input.LA(2) ) {
				case KW_TABLE:
					{
					alt66=1;
					}
					break;
				case KW_VIEW:
					{
					alt66=2;
					}
					break;
				case KW_MATERIALIZED:
					{
					alt66=3;
					}
					break;
				case KW_DATABASE:
				case KW_SCHEMA:
					{
					alt66=4;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 66, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 66, 0, input);
				throw nvae;
			}

			switch (alt66) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1161:7: KW_ALTER KW_TABLE tableName alterTableStatementSuffix
					{
					KW_ALTER195=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4366); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER195);

					KW_TABLE196=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_alterStatement4368); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE196);

					pushFollow(FOLLOW_tableName_in_alterStatement4370);
					tableName197=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName197.getTree());
					pushFollow(FOLLOW_alterTableStatementSuffix_in_alterStatement4372);
					alterTableStatementSuffix198=alterTableStatementSuffix();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterTableStatementSuffix.add(alterTableStatementSuffix198.getTree());
					// AST REWRITE
					// elements: alterTableStatementSuffix, tableName
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1161:61: -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1161:64: ^( TOK_ALTERTABLE tableName alterTableStatementSuffix )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE, "TOK_ALTERTABLE"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						adaptor.addChild(root_1, stream_alterTableStatementSuffix.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1162:7: KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix
					{
					KW_ALTER199=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4390); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER199);

					KW_VIEW200=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_alterStatement4392); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW200);

					pushFollow(FOLLOW_tableName_in_alterStatement4394);
					tableName201=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName201.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1162:34: ( KW_AS )?
					int alt64=2;
					int LA64_0 = input.LA(1);
					if ( (LA64_0==KW_AS) ) {
						alt64=1;
					}
					switch (alt64) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1162:34: KW_AS
							{
							KW_AS202=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_alterStatement4396); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS202);

							}
							break;

					}

					pushFollow(FOLLOW_alterViewStatementSuffix_in_alterStatement4399);
					alterViewStatementSuffix203=alterViewStatementSuffix();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterViewStatementSuffix.add(alterViewStatementSuffix203.getTree());
					// AST REWRITE
					// elements: alterViewStatementSuffix, tableName
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1162:66: -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1162:69: ^( TOK_ALTERVIEW tableName alterViewStatementSuffix )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW, "TOK_ALTERVIEW"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						adaptor.addChild(root_1, stream_alterViewStatementSuffix.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:7: KW_ALTER KW_MATERIALIZED KW_VIEW tableName alterMaterializedViewStatementSuffix
					{
					KW_ALTER204=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4417); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER204);

					KW_MATERIALIZED205=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_alterStatement4419); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED205);

					KW_VIEW206=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_alterStatement4421); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW206);

					pushFollow(FOLLOW_tableName_in_alterStatement4423);
					tableName207=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName207.getTree());
					pushFollow(FOLLOW_alterMaterializedViewStatementSuffix_in_alterStatement4425);
					alterMaterializedViewStatementSuffix208=alterMaterializedViewStatementSuffix();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterMaterializedViewStatementSuffix.add(alterMaterializedViewStatementSuffix208.getTree());
					// AST REWRITE
					// elements: tableName, alterMaterializedViewStatementSuffix
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1164:5: -> ^( TOK_ALTER_MATERIALIZED_VIEW tableName alterMaterializedViewStatementSuffix )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1164:8: ^( TOK_ALTER_MATERIALIZED_VIEW tableName alterMaterializedViewStatementSuffix )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTER_MATERIALIZED_VIEW, "TOK_ALTER_MATERIALIZED_VIEW"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						adaptor.addChild(root_1, stream_alterMaterializedViewStatementSuffix.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:7: KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix
					{
					KW_ALTER209=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4447); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER209);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:16: ( KW_DATABASE | KW_SCHEMA )
					int alt65=2;
					int LA65_0 = input.LA(1);
					if ( (LA65_0==KW_DATABASE) ) {
						alt65=1;
					}
					else if ( (LA65_0==KW_SCHEMA) ) {
						alt65=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 65, 0, input);
						throw nvae;
					}

					switch (alt65) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:17: KW_DATABASE
							{
							KW_DATABASE210=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_alterStatement4450); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE210);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:29: KW_SCHEMA
							{
							KW_SCHEMA211=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_alterStatement4452); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA211);

							}
							break;

					}

					pushFollow(FOLLOW_alterDatabaseStatementSuffix_in_alterStatement4455);
					alterDatabaseStatementSuffix212=alterDatabaseStatementSuffix();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterDatabaseStatementSuffix.add(alterDatabaseStatementSuffix212.getTree());
					// AST REWRITE
					// elements: alterDatabaseStatementSuffix
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1165:69: -> alterDatabaseStatementSuffix
					{
						adaptor.addChild(root_0, stream_alterDatabaseStatementSuffix.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatement"


	public static class alterTableStatementSuffix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterTableStatementSuffix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:1: alterTableStatementSuffix : ( ( alterStatementSuffixRename[true] )=> alterStatementSuffixRename[true] | alterStatementSuffixDropPartitions[true] | alterStatementSuffixAddPartitions[true] | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition | alterStatementPartitionKeyType | alterStatementSuffixDropConstraint | alterStatementSuffixAddConstraint | ( partitionSpec )? alterTblPartitionStatementSuffix -> alterTblPartitionStatementSuffix ( partitionSpec )? | alterStatementSuffixSetOwner );
	public final HiveParser.alterTableStatementSuffix_return alterTableStatementSuffix() throws RecognitionException {
		HiveParser.alterTableStatementSuffix_return retval = new HiveParser.alterTableStatementSuffix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterStatementSuffixRename213 =null;
		ParserRuleReturnScope alterStatementSuffixDropPartitions214 =null;
		ParserRuleReturnScope alterStatementSuffixAddPartitions215 =null;
		ParserRuleReturnScope alterStatementSuffixTouch216 =null;
		ParserRuleReturnScope alterStatementSuffixArchive217 =null;
		ParserRuleReturnScope alterStatementSuffixUnArchive218 =null;
		ParserRuleReturnScope alterStatementSuffixProperties219 =null;
		ParserRuleReturnScope alterStatementSuffixSkewedby220 =null;
		ParserRuleReturnScope alterStatementSuffixExchangePartition221 =null;
		ParserRuleReturnScope alterStatementPartitionKeyType222 =null;
		ParserRuleReturnScope alterStatementSuffixDropConstraint223 =null;
		ParserRuleReturnScope alterStatementSuffixAddConstraint224 =null;
		ParserRuleReturnScope partitionSpec225 =null;
		ParserRuleReturnScope alterTblPartitionStatementSuffix226 =null;
		ParserRuleReturnScope alterStatementSuffixSetOwner227 =null;

		RewriteRuleSubtreeStream stream_alterTblPartitionStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterTblPartitionStatementSuffix");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");

		 pushMsg("alter table statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1171:5: ( ( alterStatementSuffixRename[true] )=> alterStatementSuffixRename[true] | alterStatementSuffixDropPartitions[true] | alterStatementSuffixAddPartitions[true] | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition | alterStatementPartitionKeyType | alterStatementSuffixDropConstraint | alterStatementSuffixAddConstraint | ( partitionSpec )? alterTblPartitionStatementSuffix -> alterTblPartitionStatementSuffix ( partitionSpec )? | alterStatementSuffixSetOwner )
			int alt68=14;
			switch ( input.LA(1) ) {
			case KW_RENAME:
				{
				int LA68_1 = input.LA(2);
				if ( (LA68_1==KW_TO) ) {
					int LA68_20 = input.LA(3);
					if ( (LA68_20==Identifier) && (synpred3_HiveParser())) {
						alt68=1;
					}
					else if ( ((LA68_20 >= KW_ABORT && LA68_20 <= KW_AFTER)||LA68_20==KW_ALLOC_FRACTION||LA68_20==KW_ANALYZE||LA68_20==KW_ARCHIVE||LA68_20==KW_ASC||(LA68_20 >= KW_AUTOCOMMIT && LA68_20 <= KW_BEFORE)||(LA68_20 >= KW_BUCKET && LA68_20 <= KW_BUCKETS)||(LA68_20 >= KW_CACHE && LA68_20 <= KW_CASCADE)||(LA68_20 >= KW_CBO && LA68_20 <= KW_CHANGE)||(LA68_20 >= KW_CHECK && LA68_20 <= KW_COLLECTION)||(LA68_20 >= KW_COLUMNS && LA68_20 <= KW_COMMENT)||(LA68_20 >= KW_COMPACT && LA68_20 <= KW_CONCATENATE)||(LA68_20 >= KW_CONTINUE && LA68_20 <= KW_COST)||LA68_20==KW_DATA||LA68_20==KW_DATABASES||(LA68_20 >= KW_DATETIME && LA68_20 <= KW_DEBUG)||(LA68_20 >= KW_DEFAULT && LA68_20 <= KW_DEFINED)||(LA68_20 >= KW_DELIMITED && LA68_20 <= KW_DESC)||(LA68_20 >= KW_DETAIL && LA68_20 <= KW_DISABLE)||(LA68_20 >= KW_DISTRIBUTE && LA68_20 <= KW_DO)||LA68_20==KW_DOW||(LA68_20 >= KW_DUMP && LA68_20 <= KW_ELEM_TYPE)||LA68_20==KW_ENABLE||(LA68_20 >= KW_ENFORCED && LA68_20 <= KW_ESCAPED)||LA68_20==KW_EXCLUSIVE||(LA68_20 >= KW_EXPLAIN && LA68_20 <= KW_EXPRESSION)||(LA68_20 >= KW_FIELDS && LA68_20 <= KW_FIRST)||(LA68_20 >= KW_FORMAT && LA68_20 <= KW_FORMATTED)||LA68_20==KW_FUNCTIONS||(LA68_20 >= KW_HOUR && LA68_20 <= KW_IDXPROPERTIES)||(LA68_20 >= KW_INDEX && LA68_20 <= KW_INDEXES)||(LA68_20 >= KW_INPATH && LA68_20 <= KW_INPUTFORMAT)||(LA68_20 >= KW_ISOLATION && LA68_20 <= KW_JAR)||(LA68_20 >= KW_JOINCOST && LA68_20 <= KW_LAST)||LA68_20==KW_LEVEL||(LA68_20 >= KW_LIMIT && LA68_20 <= KW_LOAD)||(LA68_20 >= KW_LOCATION && LA68_20 <= KW_LONG)||LA68_20==KW_MANAGEMENT||(LA68_20 >= KW_MAPJOIN && LA68_20 <= KW_MATERIALIZED)||LA68_20==KW_METADATA||(LA68_20 >= KW_MINUTE && LA68_20 <= KW_MONTH)||(LA68_20 >= KW_MOVE && LA68_20 <= KW_MSCK)||(LA68_20 >= KW_NORELY && LA68_20 <= KW_NOSCAN)||LA68_20==KW_NOVALIDATE||LA68_20==KW_NULLS||LA68_20==KW_OFFSET||(LA68_20 >= KW_OPERATOR && LA68_20 <= KW_OPTION)||(LA68_20 >= KW_OUTPUTDRIVER && LA68_20 <= KW_OUTPUTFORMAT)||(LA68_20 >= KW_OVERWRITE && LA68_20 <= KW_OWNER)||(LA68_20 >= KW_PARTITIONED && LA68_20 <= KW_PATH)||(LA68_20 >= KW_PLAN && LA68_20 <= KW_POOL)||LA68_20==KW_PRINCIPALS||(LA68_20 >= KW_PURGE && LA68_20 <= KW_QUERY_PARALLELISM)||LA68_20==KW_READ||(LA68_20 >= KW_REBUILD && LA68_20 <= KW_RECORDWRITER)||(LA68_20 >= KW_RELOAD && LA68_20 <= KW_RESTRICT)||LA68_20==KW_REWRITE||(LA68_20 >= KW_ROLE && LA68_20 <= KW_ROLES)||(LA68_20 >= KW_SCHEDULING_POLICY && LA68_20 <= KW_SECOND)||(LA68_20 >= KW_SEMI && LA68_20 <= KW_SERVER)||(LA68_20 >= KW_SETS && LA68_20 <= KW_SKEWED)||(LA68_20 >= KW_SNAPSHOT && LA68_20 <= KW_SSL)||(LA68_20 >= KW_STATISTICS && LA68_20 <= KW_SUMMARY)||LA68_20==KW_TABLES||(LA68_20 >= KW_TBLPROPERTIES && LA68_20 <= KW_TERMINATED)||LA68_20==KW_TINYINT||(LA68_20 >= KW_TOUCH && LA68_20 <= KW_TRANSACTIONS)||LA68_20==KW_UNARCHIVE||LA68_20==KW_UNDO||LA68_20==KW_UNIONTYPE||(LA68_20 >= KW_UNLOCK && LA68_20 <= KW_UNSIGNED)||(LA68_20 >= KW_URI && LA68_20 <= KW_USE)||(LA68_20 >= KW_UTC && LA68_20 <= KW_VALIDATE)||LA68_20==KW_VALUE_TYPE||(LA68_20 >= KW_VECTORIZATION && LA68_20 <= KW_WEEK)||LA68_20==KW_WHILE||(LA68_20 >= KW_WORK && LA68_20 <= KW_ZONE)||LA68_20==KW_BATCH||LA68_20==KW_DAYOFWEEK||LA68_20==KW_HOLD_DDLTIME||LA68_20==KW_IGNORE||LA68_20==KW_NO_DROP||LA68_20==KW_OFFLINE||LA68_20==KW_PROTECTION||LA68_20==KW_READONLY||LA68_20==KW_TIMESTAMPTZ) && (synpred3_HiveParser())) {
						alt68=1;
					}
					else if ( (LA68_20==KW_PARTITION) ) {
						alt68=13;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 68, 20, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_DROP:
				{
				int LA68_2 = input.LA(2);
				if ( (LA68_2==KW_CONSTRAINT) ) {
					alt68=11;
				}
				else if ( (LA68_2==KW_IF||LA68_2==KW_PARTITION) ) {
					alt68=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_ADD:
				{
				switch ( input.LA(2) ) {
				case KW_IF:
				case KW_PARTITION:
					{
					alt68=3;
					}
					break;
				case KW_CONSTRAINT:
					{
					alt68=12;
					}
					break;
				case KW_COLUMNS:
					{
					alt68=13;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 3, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
				}
				break;
			case KW_TOUCH:
				{
				alt68=4;
				}
				break;
			case KW_ARCHIVE:
				{
				alt68=5;
				}
				break;
			case KW_UNARCHIVE:
				{
				alt68=6;
				}
				break;
			case KW_SET:
				{
				switch ( input.LA(2) ) {
				case KW_TBLPROPERTIES:
					{
					alt68=7;
					}
					break;
				case KW_FILEFORMAT:
				case KW_LOCATION:
				case KW_SERDE:
				case KW_SERDEPROPERTIES:
				case KW_SKEWED:
					{
					alt68=13;
					}
					break;
				case KW_OWNER:
					{
					alt68=14;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 7, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
				}
				break;
			case KW_UNSET:
				{
				alt68=7;
				}
				break;
			case KW_SKEWED:
				{
				alt68=8;
				}
				break;
			case KW_NOT:
				{
				int LA68_10 = input.LA(2);
				if ( (LA68_10==KW_SKEWED||LA68_10==KW_STORED) ) {
					alt68=8;
				}
				else if ( (LA68_10==KW_CLUSTERED||LA68_10==KW_SORTED) ) {
					alt68=13;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 10, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_EXCHANGE:
				{
				alt68=9;
				}
				break;
			case KW_PARTITION:
				{
				int LA68_12 = input.LA(2);
				if ( (LA68_12==KW_COLUMN) ) {
					alt68=10;
				}
				else if ( (LA68_12==LPAREN) ) {
					alt68=13;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 12, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_CHANGE:
			case KW_CLUSTERED:
			case KW_COMPACT:
			case KW_CONCATENATE:
			case KW_INTO:
			case KW_REPLACE:
			case KW_UPDATE:
				{
				alt68=13;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 68, 0, input);
				throw nvae;
			}
			switch (alt68) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1171:7: ( alterStatementSuffixRename[true] )=> alterStatementSuffixRename[true]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix4493);
					alterStatementSuffixRename213=alterStatementSuffixRename(true);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRename213.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:7: alterStatementSuffixDropPartitions[true]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix4502);
					alterStatementSuffixDropPartitions214=alterStatementSuffixDropPartitions(true);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixDropPartitions214.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:7: alterStatementSuffixAddPartitions[true]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix4511);
					alterStatementSuffixAddPartitions215=alterStatementSuffixAddPartitions(true);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddPartitions215.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1174:7: alterStatementSuffixTouch
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix4520);
					alterStatementSuffixTouch216=alterStatementSuffixTouch();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixTouch216.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1175:7: alterStatementSuffixArchive
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix4528);
					alterStatementSuffixArchive217=alterStatementSuffixArchive();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixArchive217.getTree());

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1176:7: alterStatementSuffixUnArchive
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix4536);
					alterStatementSuffixUnArchive218=alterStatementSuffixUnArchive();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUnArchive218.getTree());

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:7: alterStatementSuffixProperties
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix4544);
					alterStatementSuffixProperties219=alterStatementSuffixProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixProperties219.getTree());

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1178:7: alterStatementSuffixSkewedby
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix4552);
					alterStatementSuffixSkewedby220=alterStatementSuffixSkewedby();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixSkewedby220.getTree());

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:7: alterStatementSuffixExchangePartition
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix4560);
					alterStatementSuffixExchangePartition221=alterStatementSuffixExchangePartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixExchangePartition221.getTree());

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:7: alterStatementPartitionKeyType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementPartitionKeyType_in_alterTableStatementSuffix4568);
					alterStatementPartitionKeyType222=alterStatementPartitionKeyType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementPartitionKeyType222.getTree());

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1181:7: alterStatementSuffixDropConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixDropConstraint_in_alterTableStatementSuffix4576);
					alterStatementSuffixDropConstraint223=alterStatementSuffixDropConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixDropConstraint223.getTree());

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1182:7: alterStatementSuffixAddConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixAddConstraint_in_alterTableStatementSuffix4584);
					alterStatementSuffixAddConstraint224=alterStatementSuffixAddConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddConstraint224.getTree());

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:7: ( partitionSpec )? alterTblPartitionStatementSuffix
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:7: ( partitionSpec )?
					int alt67=2;
					int LA67_0 = input.LA(1);
					if ( (LA67_0==KW_PARTITION) ) {
						alt67=1;
					}
					switch (alt67) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:7: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_alterTableStatementSuffix4592);
							partitionSpec225=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec225.getTree());
							}
							break;

					}

					pushFollow(FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix4595);
					alterTblPartitionStatementSuffix226=alterTblPartitionStatementSuffix();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterTblPartitionStatementSuffix.add(alterTblPartitionStatementSuffix226.getTree());
					// AST REWRITE
					// elements: alterTblPartitionStatementSuffix, partitionSpec
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1183:55: -> alterTblPartitionStatementSuffix ( partitionSpec )?
					{
						adaptor.addChild(root_0, stream_alterTblPartitionStatementSuffix.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:91: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_0, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

					}


					retval.tree = root_0;
					}

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1184:7: alterStatementSuffixSetOwner
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixSetOwner_in_alterTableStatementSuffix4610);
					alterStatementSuffixSetOwner227=alterStatementSuffixSetOwner();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixSetOwner227.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterTableStatementSuffix"


	public static class alterTblPartitionStatementSuffix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterTblPartitionStatementSuffix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:1: alterTblPartitionStatementSuffix : ( alterStatementSuffixFileFormat | alterStatementSuffixLocation | alterStatementSuffixMergeFiles | alterStatementSuffixSerdeProperties | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby | alterStatementSuffixCompact | alterStatementSuffixUpdateStatsCol | alterStatementSuffixUpdateStats | alterStatementSuffixRenameCol | alterStatementSuffixAddCol | alterStatementSuffixUpdateColumns );
	public final HiveParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix() throws RecognitionException {
		HiveParser.alterTblPartitionStatementSuffix_return retval = new HiveParser.alterTblPartitionStatementSuffix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterStatementSuffixFileFormat228 =null;
		ParserRuleReturnScope alterStatementSuffixLocation229 =null;
		ParserRuleReturnScope alterStatementSuffixMergeFiles230 =null;
		ParserRuleReturnScope alterStatementSuffixSerdeProperties231 =null;
		ParserRuleReturnScope alterStatementSuffixRenamePart232 =null;
		ParserRuleReturnScope alterStatementSuffixBucketNum233 =null;
		ParserRuleReturnScope alterTblPartitionStatementSuffixSkewedLocation234 =null;
		ParserRuleReturnScope alterStatementSuffixClusterbySortby235 =null;
		ParserRuleReturnScope alterStatementSuffixCompact236 =null;
		ParserRuleReturnScope alterStatementSuffixUpdateStatsCol237 =null;
		ParserRuleReturnScope alterStatementSuffixUpdateStats238 =null;
		ParserRuleReturnScope alterStatementSuffixRenameCol239 =null;
		ParserRuleReturnScope alterStatementSuffixAddCol240 =null;
		ParserRuleReturnScope alterStatementSuffixUpdateColumns241 =null;


		pushMsg("alter table partition statement suffix", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:3: ( alterStatementSuffixFileFormat | alterStatementSuffixLocation | alterStatementSuffixMergeFiles | alterStatementSuffixSerdeProperties | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby | alterStatementSuffixCompact | alterStatementSuffixUpdateStatsCol | alterStatementSuffixUpdateStats | alterStatementSuffixRenameCol | alterStatementSuffixAddCol | alterStatementSuffixUpdateColumns )
			int alt69=14;
			switch ( input.LA(1) ) {
			case KW_SET:
				{
				switch ( input.LA(2) ) {
				case KW_FILEFORMAT:
					{
					alt69=1;
					}
					break;
				case KW_LOCATION:
					{
					alt69=2;
					}
					break;
				case KW_SERDE:
				case KW_SERDEPROPERTIES:
					{
					alt69=4;
					}
					break;
				case KW_SKEWED:
					{
					alt69=7;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 69, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
				}
				break;
			case KW_CONCATENATE:
				{
				alt69=3;
				}
				break;
			case KW_RENAME:
				{
				alt69=5;
				}
				break;
			case KW_INTO:
				{
				alt69=6;
				}
				break;
			case KW_CLUSTERED:
			case KW_NOT:
				{
				alt69=8;
				}
				break;
			case KW_COMPACT:
				{
				alt69=9;
				}
				break;
			case KW_UPDATE:
				{
				int LA69_8 = input.LA(2);
				if ( (LA69_8==KW_STATISTICS) ) {
					int LA69_17 = input.LA(3);
					if ( (LA69_17==KW_FOR) ) {
						alt69=10;
					}
					else if ( (LA69_17==KW_SET) ) {
						alt69=11;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 69, 17, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( (LA69_8==KW_COLUMNS) ) {
					alt69=14;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 69, 8, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_CHANGE:
				{
				alt69=12;
				}
				break;
			case KW_ADD:
			case KW_REPLACE:
				{
				alt69=13;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 69, 0, input);
				throw nvae;
			}
			switch (alt69) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:5: alterStatementSuffixFileFormat
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix4635);
					alterStatementSuffixFileFormat228=alterStatementSuffixFileFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixFileFormat228.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1191:5: alterStatementSuffixLocation
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix4641);
					alterStatementSuffixLocation229=alterStatementSuffixLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixLocation229.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:5: alterStatementSuffixMergeFiles
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix4647);
					alterStatementSuffixMergeFiles230=alterStatementSuffixMergeFiles();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixMergeFiles230.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1193:5: alterStatementSuffixSerdeProperties
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix4653);
					alterStatementSuffixSerdeProperties231=alterStatementSuffixSerdeProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixSerdeProperties231.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1194:5: alterStatementSuffixRenamePart
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix4659);
					alterStatementSuffixRenamePart232=alterStatementSuffixRenamePart();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRenamePart232.getTree());

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1195:5: alterStatementSuffixBucketNum
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix4665);
					alterStatementSuffixBucketNum233=alterStatementSuffixBucketNum();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixBucketNum233.getTree());

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1196:5: alterTblPartitionStatementSuffixSkewedLocation
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix4671);
					alterTblPartitionStatementSuffixSkewedLocation234=alterTblPartitionStatementSuffixSkewedLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterTblPartitionStatementSuffixSkewedLocation234.getTree());

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:5: alterStatementSuffixClusterbySortby
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix4677);
					alterStatementSuffixClusterbySortby235=alterStatementSuffixClusterbySortby();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixClusterbySortby235.getTree());

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1198:5: alterStatementSuffixCompact
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixCompact_in_alterTblPartitionStatementSuffix4683);
					alterStatementSuffixCompact236=alterStatementSuffixCompact();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixCompact236.getTree());

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1199:5: alterStatementSuffixUpdateStatsCol
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTblPartitionStatementSuffix4689);
					alterStatementSuffixUpdateStatsCol237=alterStatementSuffixUpdateStatsCol();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUpdateStatsCol237.getTree());

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1200:5: alterStatementSuffixUpdateStats
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixUpdateStats_in_alterTblPartitionStatementSuffix4695);
					alterStatementSuffixUpdateStats238=alterStatementSuffixUpdateStats();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUpdateStats238.getTree());

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1201:5: alterStatementSuffixRenameCol
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixRenameCol_in_alterTblPartitionStatementSuffix4701);
					alterStatementSuffixRenameCol239=alterStatementSuffixRenameCol();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRenameCol239.getTree());

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1202:5: alterStatementSuffixAddCol
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixAddCol_in_alterTblPartitionStatementSuffix4707);
					alterStatementSuffixAddCol240=alterStatementSuffixAddCol();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddCol240.getTree());

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1203:5: alterStatementSuffixUpdateColumns
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixUpdateColumns_in_alterTblPartitionStatementSuffix4713);
					alterStatementSuffixUpdateColumns241=alterStatementSuffixUpdateColumns();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUpdateColumns241.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterTblPartitionStatementSuffix"


	public static class alterStatementPartitionKeyType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementPartitionKeyType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:1: alterStatementPartitionKeyType : KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType ) ;
	public final HiveParser.alterStatementPartitionKeyType_return alterStatementPartitionKeyType() throws RecognitionException {
		HiveParser.alterStatementPartitionKeyType_return retval = new HiveParser.alterStatementPartitionKeyType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PARTITION242=null;
		Token KW_COLUMN243=null;
		Token LPAREN244=null;
		Token RPAREN246=null;
		ParserRuleReturnScope columnNameType245 =null;

		ASTNode KW_PARTITION242_tree=null;
		ASTNode KW_COLUMN243_tree=null;
		ASTNode LPAREN244_tree=null;
		ASTNode RPAREN246_tree=null;
		RewriteRuleTokenStream stream_KW_PARTITION=new RewriteRuleTokenStream(adaptor,"token KW_PARTITION");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
		RewriteRuleSubtreeStream stream_columnNameType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameType");

		msgs.push("alter partition key type"); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:2: ( KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:4: KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN
			{
			KW_PARTITION242=(Token)match(input,KW_PARTITION,FOLLOW_KW_PARTITION_in_alterStatementPartitionKeyType4735); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_PARTITION.add(KW_PARTITION242);

			KW_COLUMN243=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementPartitionKeyType4737); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN243);

			LPAREN244=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterStatementPartitionKeyType4739); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN244);

			pushFollow(FOLLOW_columnNameType_in_alterStatementPartitionKeyType4741);
			columnNameType245=columnNameType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType245.getTree());
			RPAREN246=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterStatementPartitionKeyType4743); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN246);

			// AST REWRITE
			// elements: columnNameType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1210:2: -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:5: ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_PARTCOLTYPE, "TOK_ALTERTABLE_PARTCOLTYPE"), root_1);
				adaptor.addChild(root_1, stream_columnNameType.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {msgs.pop();}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementPartitionKeyType"


	public static class alterViewStatementSuffix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterViewStatementSuffix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1213:1: alterViewStatementSuffix : ( alterViewSuffixProperties | alterStatementSuffixRename[false] | alterStatementSuffixAddPartitions[false] | alterStatementSuffixDropPartitions[false] | selectStatementWithCTE );
	public final HiveParser.alterViewStatementSuffix_return alterViewStatementSuffix() throws RecognitionException {
		HiveParser.alterViewStatementSuffix_return retval = new HiveParser.alterViewStatementSuffix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterViewSuffixProperties247 =null;
		ParserRuleReturnScope alterStatementSuffixRename248 =null;
		ParserRuleReturnScope alterStatementSuffixAddPartitions249 =null;
		ParserRuleReturnScope alterStatementSuffixDropPartitions250 =null;
		ParserRuleReturnScope selectStatementWithCTE251 =null;


		 pushMsg("alter view statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1216:5: ( alterViewSuffixProperties | alterStatementSuffixRename[false] | alterStatementSuffixAddPartitions[false] | alterStatementSuffixDropPartitions[false] | selectStatementWithCTE )
			int alt70=5;
			switch ( input.LA(1) ) {
			case KW_SET:
			case KW_UNSET:
				{
				alt70=1;
				}
				break;
			case KW_RENAME:
				{
				alt70=2;
				}
				break;
			case KW_ADD:
				{
				alt70=3;
				}
				break;
			case KW_DROP:
				{
				alt70=4;
				}
				break;
			case KW_MAP:
			case KW_REDUCE:
			case KW_SELECT:
			case KW_WITH:
			case LPAREN:
				{
				alt70=5;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 70, 0, input);
				throw nvae;
			}
			switch (alt70) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1216:7: alterViewSuffixProperties
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix4776);
					alterViewSuffixProperties247=alterViewSuffixProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterViewSuffixProperties247.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:7: alterStatementSuffixRename[false]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix4784);
					alterStatementSuffixRename248=alterStatementSuffixRename(false);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRename248.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:7: alterStatementSuffixAddPartitions[false]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix4793);
					alterStatementSuffixAddPartitions249=alterStatementSuffixAddPartitions(false);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddPartitions249.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1219:7: alterStatementSuffixDropPartitions[false]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix4802);
					alterStatementSuffixDropPartitions250=alterStatementSuffixDropPartitions(false);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixDropPartitions250.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1220:7: selectStatementWithCTE
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_selectStatementWithCTE_in_alterViewStatementSuffix4811);
					selectStatementWithCTE251=selectStatementWithCTE();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatementWithCTE251.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterViewStatementSuffix"


	public static class alterMaterializedViewStatementSuffix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterMaterializedViewStatementSuffix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1223:1: alterMaterializedViewStatementSuffix : ( alterMaterializedViewSuffixRewrite | alterMaterializedViewSuffixRebuild );
	public final HiveParser.alterMaterializedViewStatementSuffix_return alterMaterializedViewStatementSuffix() throws RecognitionException {
		HiveParser.alterMaterializedViewStatementSuffix_return retval = new HiveParser.alterMaterializedViewStatementSuffix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterMaterializedViewSuffixRewrite252 =null;
		ParserRuleReturnScope alterMaterializedViewSuffixRebuild253 =null;


		 pushMsg("alter materialized view statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:5: ( alterMaterializedViewSuffixRewrite | alterMaterializedViewSuffixRebuild )
			int alt71=2;
			int LA71_0 = input.LA(1);
			if ( (LA71_0==KW_DISABLE||LA71_0==KW_ENABLE) ) {
				alt71=1;
			}
			else if ( (LA71_0==KW_REBUILD) ) {
				alt71=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 71, 0, input);
				throw nvae;
			}

			switch (alt71) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:7: alterMaterializedViewSuffixRewrite
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterMaterializedViewSuffixRewrite_in_alterMaterializedViewStatementSuffix4838);
					alterMaterializedViewSuffixRewrite252=alterMaterializedViewSuffixRewrite();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterMaterializedViewSuffixRewrite252.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1227:7: alterMaterializedViewSuffixRebuild
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterMaterializedViewSuffixRebuild_in_alterMaterializedViewStatementSuffix4846);
					alterMaterializedViewSuffixRebuild253=alterMaterializedViewSuffixRebuild();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterMaterializedViewSuffixRebuild253.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterMaterializedViewStatementSuffix"


	public static class alterDatabaseStatementSuffix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterDatabaseStatementSuffix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1230:1: alterDatabaseStatementSuffix : ( alterDatabaseSuffixProperties | alterDatabaseSuffixSetOwner | alterDatabaseSuffixSetLocation );
	public final HiveParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix() throws RecognitionException {
		HiveParser.alterDatabaseStatementSuffix_return retval = new HiveParser.alterDatabaseStatementSuffix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterDatabaseSuffixProperties254 =null;
		ParserRuleReturnScope alterDatabaseSuffixSetOwner255 =null;
		ParserRuleReturnScope alterDatabaseSuffixSetLocation256 =null;


		 pushMsg("alter database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1233:5: ( alterDatabaseSuffixProperties | alterDatabaseSuffixSetOwner | alterDatabaseSuffixSetLocation )
			int alt72=3;
			int LA72_0 = input.LA(1);
			if ( (LA72_0==Identifier) ) {
				int LA72_1 = input.LA(2);
				if ( (LA72_1==KW_SET) ) {
					switch ( input.LA(3) ) {
					case KW_DBPROPERTIES:
						{
						alt72=1;
						}
						break;
					case KW_OWNER:
						{
						alt72=2;
						}
						break;
					case KW_LOCATION:
						{
						alt72=3;
						}
						break;
					default:
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 72, 3, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 72, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( ((LA72_0 >= KW_ABORT && LA72_0 <= KW_AFTER)||LA72_0==KW_ALLOC_FRACTION||LA72_0==KW_ANALYZE||LA72_0==KW_ARCHIVE||LA72_0==KW_ASC||(LA72_0 >= KW_AUTOCOMMIT && LA72_0 <= KW_BEFORE)||(LA72_0 >= KW_BUCKET && LA72_0 <= KW_BUCKETS)||(LA72_0 >= KW_CACHE && LA72_0 <= KW_CASCADE)||(LA72_0 >= KW_CBO && LA72_0 <= KW_CHANGE)||(LA72_0 >= KW_CHECK && LA72_0 <= KW_COLLECTION)||(LA72_0 >= KW_COLUMNS && LA72_0 <= KW_COMMENT)||(LA72_0 >= KW_COMPACT && LA72_0 <= KW_CONCATENATE)||(LA72_0 >= KW_CONTINUE && LA72_0 <= KW_COST)||LA72_0==KW_DATA||LA72_0==KW_DATABASES||(LA72_0 >= KW_DATETIME && LA72_0 <= KW_DEBUG)||(LA72_0 >= KW_DEFAULT && LA72_0 <= KW_DEFINED)||(LA72_0 >= KW_DELIMITED && LA72_0 <= KW_DESC)||(LA72_0 >= KW_DETAIL && LA72_0 <= KW_DISABLE)||(LA72_0 >= KW_DISTRIBUTE && LA72_0 <= KW_DO)||LA72_0==KW_DOW||(LA72_0 >= KW_DUMP && LA72_0 <= KW_ELEM_TYPE)||LA72_0==KW_ENABLE||(LA72_0 >= KW_ENFORCED && LA72_0 <= KW_ESCAPED)||LA72_0==KW_EXCLUSIVE||(LA72_0 >= KW_EXPLAIN && LA72_0 <= KW_EXPRESSION)||(LA72_0 >= KW_FIELDS && LA72_0 <= KW_FIRST)||(LA72_0 >= KW_FORMAT && LA72_0 <= KW_FORMATTED)||LA72_0==KW_FUNCTIONS||(LA72_0 >= KW_HOUR && LA72_0 <= KW_IDXPROPERTIES)||(LA72_0 >= KW_INDEX && LA72_0 <= KW_INDEXES)||(LA72_0 >= KW_INPATH && LA72_0 <= KW_INPUTFORMAT)||(LA72_0 >= KW_ISOLATION && LA72_0 <= KW_JAR)||(LA72_0 >= KW_JOINCOST && LA72_0 <= KW_LAST)||LA72_0==KW_LEVEL||(LA72_0 >= KW_LIMIT && LA72_0 <= KW_LOAD)||(LA72_0 >= KW_LOCATION && LA72_0 <= KW_LONG)||LA72_0==KW_MANAGEMENT||(LA72_0 >= KW_MAPJOIN && LA72_0 <= KW_MATERIALIZED)||LA72_0==KW_METADATA||(LA72_0 >= KW_MINUTE && LA72_0 <= KW_MONTH)||(LA72_0 >= KW_MOVE && LA72_0 <= KW_MSCK)||(LA72_0 >= KW_NORELY && LA72_0 <= KW_NOSCAN)||LA72_0==KW_NOVALIDATE||LA72_0==KW_NULLS||LA72_0==KW_OFFSET||(LA72_0 >= KW_OPERATOR && LA72_0 <= KW_OPTION)||(LA72_0 >= KW_OUTPUTDRIVER && LA72_0 <= KW_OUTPUTFORMAT)||(LA72_0 >= KW_OVERWRITE && LA72_0 <= KW_OWNER)||(LA72_0 >= KW_PARTITIONED && LA72_0 <= KW_PATH)||(LA72_0 >= KW_PLAN && LA72_0 <= KW_POOL)||LA72_0==KW_PRINCIPALS||(LA72_0 >= KW_PURGE && LA72_0 <= KW_QUERY_PARALLELISM)||LA72_0==KW_READ||(LA72_0 >= KW_REBUILD && LA72_0 <= KW_RECORDWRITER)||(LA72_0 >= KW_RELOAD && LA72_0 <= KW_RESTRICT)||LA72_0==KW_REWRITE||(LA72_0 >= KW_ROLE && LA72_0 <= KW_ROLES)||(LA72_0 >= KW_SCHEDULING_POLICY && LA72_0 <= KW_SECOND)||(LA72_0 >= KW_SEMI && LA72_0 <= KW_SERVER)||(LA72_0 >= KW_SETS && LA72_0 <= KW_SKEWED)||(LA72_0 >= KW_SNAPSHOT && LA72_0 <= KW_SSL)||(LA72_0 >= KW_STATISTICS && LA72_0 <= KW_SUMMARY)||LA72_0==KW_TABLES||(LA72_0 >= KW_TBLPROPERTIES && LA72_0 <= KW_TERMINATED)||LA72_0==KW_TINYINT||(LA72_0 >= KW_TOUCH && LA72_0 <= KW_TRANSACTIONS)||LA72_0==KW_UNARCHIVE||LA72_0==KW_UNDO||LA72_0==KW_UNIONTYPE||(LA72_0 >= KW_UNLOCK && LA72_0 <= KW_UNSIGNED)||(LA72_0 >= KW_URI && LA72_0 <= KW_USE)||(LA72_0 >= KW_UTC && LA72_0 <= KW_VALIDATE)||LA72_0==KW_VALUE_TYPE||(LA72_0 >= KW_VECTORIZATION && LA72_0 <= KW_WEEK)||LA72_0==KW_WHILE||(LA72_0 >= KW_WORK && LA72_0 <= KW_ZONE)||LA72_0==KW_BATCH||LA72_0==KW_DAYOFWEEK||LA72_0==KW_HOLD_DDLTIME||LA72_0==KW_IGNORE||LA72_0==KW_NO_DROP||LA72_0==KW_OFFLINE||LA72_0==KW_PROTECTION||LA72_0==KW_READONLY||LA72_0==KW_TIMESTAMPTZ) ) {
				int LA72_2 = input.LA(2);
				if ( (LA72_2==KW_SET) ) {
					switch ( input.LA(3) ) {
					case KW_DBPROPERTIES:
						{
						alt72=1;
						}
						break;
					case KW_OWNER:
						{
						alt72=2;
						}
						break;
					case KW_LOCATION:
						{
						alt72=3;
						}
						break;
					default:
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 72, 4, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 72, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 72, 0, input);
				throw nvae;
			}

			switch (alt72) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1233:7: alterDatabaseSuffixProperties
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix4873);
					alterDatabaseSuffixProperties254=alterDatabaseSuffixProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterDatabaseSuffixProperties254.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:7: alterDatabaseSuffixSetOwner
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterDatabaseSuffixSetOwner_in_alterDatabaseStatementSuffix4881);
					alterDatabaseSuffixSetOwner255=alterDatabaseSuffixSetOwner();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterDatabaseSuffixSetOwner255.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:7: alterDatabaseSuffixSetLocation
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterDatabaseSuffixSetLocation_in_alterDatabaseStatementSuffix4889);
					alterDatabaseSuffixSetLocation256=alterDatabaseSuffixSetLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterDatabaseSuffixSetLocation256.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterDatabaseStatementSuffix"


	public static class alterDatabaseSuffixProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterDatabaseSuffixProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1238:1: alterDatabaseSuffixProperties : name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) ;
	public final HiveParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties() throws RecognitionException {
		HiveParser.alterDatabaseSuffixProperties_return retval = new HiveParser.alterDatabaseSuffixProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET257=null;
		Token KW_DBPROPERTIES258=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope dbProperties259 =null;

		ASTNode KW_SET257_tree=null;
		ASTNode KW_DBPROPERTIES258_tree=null;
		RewriteRuleTokenStream stream_KW_DBPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_DBPROPERTIES");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_dbProperties=new RewriteRuleSubtreeStream(adaptor,"rule dbProperties");

		 pushMsg("alter database properties statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1241:5: (name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1241:7: name= identifier KW_SET KW_DBPROPERTIES dbProperties
			{
			pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixProperties4918);
			name=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
			KW_SET257=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixProperties4920); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET257);

			KW_DBPROPERTIES258=(Token)match(input,KW_DBPROPERTIES,FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties4922); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES258);

			pushFollow(FOLLOW_dbProperties_in_alterDatabaseSuffixProperties4924);
			dbProperties259=dbProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_dbProperties.add(dbProperties259.getTree());
			// AST REWRITE
			// elements: name, dbProperties
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1242:5: -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:8: ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERDATABASE_PROPERTIES, "TOK_ALTERDATABASE_PROPERTIES"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				adaptor.addChild(root_1, stream_dbProperties.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterDatabaseSuffixProperties"


	public static class alterDatabaseSuffixSetOwner_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterDatabaseSuffixSetOwner"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1245:1: alterDatabaseSuffixSetOwner : dbName= identifier KW_SET KW_OWNER principalName -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName ) ;
	public final HiveParser.alterDatabaseSuffixSetOwner_return alterDatabaseSuffixSetOwner() throws RecognitionException {
		HiveParser.alterDatabaseSuffixSetOwner_return retval = new HiveParser.alterDatabaseSuffixSetOwner_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET260=null;
		Token KW_OWNER261=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope principalName262 =null;

		ASTNode KW_SET260_tree=null;
		ASTNode KW_OWNER261_tree=null;
		RewriteRuleTokenStream stream_KW_OWNER=new RewriteRuleTokenStream(adaptor,"token KW_OWNER");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		 pushMsg("alter database set owner", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1248:5: (dbName= identifier KW_SET KW_OWNER principalName -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1248:7: dbName= identifier KW_SET KW_OWNER principalName
			{
			pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixSetOwner4968);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			KW_SET260=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixSetOwner4970); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET260);

			KW_OWNER261=(Token)match(input,KW_OWNER,FOLLOW_KW_OWNER_in_alterDatabaseSuffixSetOwner4972); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OWNER.add(KW_OWNER261);

			pushFollow(FOLLOW_principalName_in_alterDatabaseSuffixSetOwner4974);
			principalName262=principalName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalName.add(principalName262.getTree());
			// AST REWRITE
			// elements: principalName, dbName
			// token labels: 
			// rule labels: dbName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1249:5: -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1249:8: ^( TOK_ALTERDATABASE_OWNER $dbName principalName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERDATABASE_OWNER, "TOK_ALTERDATABASE_OWNER"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				adaptor.addChild(root_1, stream_principalName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterDatabaseSuffixSetOwner"


	public static class alterDatabaseSuffixSetLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterDatabaseSuffixSetLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1252:1: alterDatabaseSuffixSetLocation : dbName= identifier KW_SET KW_LOCATION newLocation= StringLiteral -> ^( TOK_ALTERDATABASE_LOCATION $dbName $newLocation) ;
	public final HiveParser.alterDatabaseSuffixSetLocation_return alterDatabaseSuffixSetLocation() throws RecognitionException {
		HiveParser.alterDatabaseSuffixSetLocation_return retval = new HiveParser.alterDatabaseSuffixSetLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token newLocation=null;
		Token KW_SET263=null;
		Token KW_LOCATION264=null;
		ParserRuleReturnScope dbName =null;

		ASTNode newLocation_tree=null;
		ASTNode KW_SET263_tree=null;
		ASTNode KW_LOCATION264_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("alter database set location", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1255:5: (dbName= identifier KW_SET KW_LOCATION newLocation= StringLiteral -> ^( TOK_ALTERDATABASE_LOCATION $dbName $newLocation) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1255:7: dbName= identifier KW_SET KW_LOCATION newLocation= StringLiteral
			{
			pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixSetLocation5018);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			KW_SET263=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixSetLocation5020); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET263);

			KW_LOCATION264=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_alterDatabaseSuffixSetLocation5022); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION264);

			newLocation=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterDatabaseSuffixSetLocation5026); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(newLocation);

			// AST REWRITE
			// elements: dbName, newLocation
			// token labels: newLocation
			// rule labels: dbName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_newLocation=new RewriteRuleTokenStream(adaptor,"token newLocation",newLocation);
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1256:5: -> ^( TOK_ALTERDATABASE_LOCATION $dbName $newLocation)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1256:8: ^( TOK_ALTERDATABASE_LOCATION $dbName $newLocation)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERDATABASE_LOCATION, "TOK_ALTERDATABASE_LOCATION"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				adaptor.addChild(root_1, stream_newLocation.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterDatabaseSuffixSetLocation"


	public static class alterStatementSuffixRename_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixRename"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1259:1: alterStatementSuffixRename[boolean table] : KW_RENAME KW_TO tableName -> { table }? ^( TOK_ALTERTABLE_RENAME tableName ) -> ^( TOK_ALTERVIEW_RENAME tableName ) ;
	public final HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename(boolean table) throws RecognitionException {
		HiveParser.alterStatementSuffixRename_return retval = new HiveParser.alterStatementSuffixRename_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RENAME265=null;
		Token KW_TO266=null;
		ParserRuleReturnScope tableName267 =null;

		ASTNode KW_RENAME265_tree=null;
		ASTNode KW_TO266_tree=null;
		RewriteRuleTokenStream stream_KW_RENAME=new RewriteRuleTokenStream(adaptor,"token KW_RENAME");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("rename statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1262:5: ( KW_RENAME KW_TO tableName -> { table }? ^( TOK_ALTERTABLE_RENAME tableName ) -> ^( TOK_ALTERVIEW_RENAME tableName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1262:7: KW_RENAME KW_TO tableName
			{
			KW_RENAME265=(Token)match(input,KW_RENAME,FOLLOW_KW_RENAME_in_alterStatementSuffixRename5070); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_RENAME.add(KW_RENAME265);

			KW_TO266=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_alterStatementSuffixRename5072); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO266);

			pushFollow(FOLLOW_tableName_in_alterStatementSuffixRename5074);
			tableName267=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName267.getTree());
			// AST REWRITE
			// elements: tableName, tableName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1263:5: -> { table }? ^( TOK_ALTERTABLE_RENAME tableName )
			if ( table ) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:19: ^( TOK_ALTERTABLE_RENAME tableName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_RENAME, "TOK_ALTERTABLE_RENAME"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1264:5: -> ^( TOK_ALTERVIEW_RENAME tableName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1264:19: ^( TOK_ALTERVIEW_RENAME tableName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW_RENAME, "TOK_ALTERVIEW_RENAME"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixRename"


	public static class alterStatementSuffixAddCol_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixAddCol"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1267:1: alterStatementSuffixAddCol : (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )? -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? ) -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? ) ;
	public final HiveParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol() throws RecognitionException {
		HiveParser.alterStatementSuffixAddCol_return retval = new HiveParser.alterStatementSuffixAddCol_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token add=null;
		Token replace=null;
		Token KW_COLUMNS268=null;
		Token LPAREN269=null;
		Token RPAREN271=null;
		ParserRuleReturnScope columnNameTypeList270 =null;
		ParserRuleReturnScope restrictOrCascade272 =null;

		ASTNode add_tree=null;
		ASTNode replace_tree=null;
		ASTNode KW_COLUMNS268_tree=null;
		ASTNode LPAREN269_tree=null;
		ASTNode RPAREN271_tree=null;
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
		RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
		RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");
		RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");

		 pushMsg("add column statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:5: ( (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )? -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? ) -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:7: (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:7: (add= KW_ADD |replace= KW_REPLACE )
			int alt73=2;
			int LA73_0 = input.LA(1);
			if ( (LA73_0==KW_ADD) ) {
				alt73=1;
			}
			else if ( (LA73_0==KW_REPLACE) ) {
				alt73=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 73, 0, input);
				throw nvae;
			}

			switch (alt73) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:8: add= KW_ADD
					{
					add=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddCol5141); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ADD.add(add);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:21: replace= KW_REPLACE
					{
					replace=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol5147); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REPLACE.add(replace);

					}
					break;

			}

			KW_COLUMNS268=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol5150); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS268);

			LPAREN269=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterStatementSuffixAddCol5152); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN269);

			pushFollow(FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol5154);
			columnNameTypeList270=columnNameTypeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameTypeList.add(columnNameTypeList270.getTree());
			RPAREN271=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterStatementSuffixAddCol5156); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN271);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:85: ( restrictOrCascade )?
			int alt74=2;
			int LA74_0 = input.LA(1);
			if ( (LA74_0==KW_CASCADE||LA74_0==KW_RESTRICT) ) {
				alt74=1;
			}
			switch (alt74) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:85: restrictOrCascade
					{
					pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixAddCol5158);
					restrictOrCascade272=restrictOrCascade();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade272.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: restrictOrCascade, restrictOrCascade, columnNameTypeList, columnNameTypeList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1271:5: -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? )
			if (add != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:24: ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_ADDCOLS, "TOK_ALTERTABLE_ADDCOLS"), root_1);
				adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:68: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1272:5: -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1272:24: ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_REPLACECOLS, "TOK_ALTERTABLE_REPLACECOLS"), root_1);
				adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1272:72: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixAddCol"


	public static class alterStatementSuffixAddConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixAddConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1275:1: alterStatementSuffixAddConstraint : KW_ADD (fk= alterForeignKeyWithName | alterConstraintWithName ) -> {fk != null}? ^( TOK_ALTERTABLE_ADDCONSTRAINT alterForeignKeyWithName ) -> ^( TOK_ALTERTABLE_ADDCONSTRAINT alterConstraintWithName ) ;
	public final HiveParser.alterStatementSuffixAddConstraint_return alterStatementSuffixAddConstraint() throws RecognitionException {
		HiveParser.alterStatementSuffixAddConstraint_return retval = new HiveParser.alterStatementSuffixAddConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ADD273=null;
		ParserRuleReturnScope fk =null;
		ParserRuleReturnScope alterConstraintWithName274 =null;

		ASTNode KW_ADD273_tree=null;
		RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
		RewriteRuleSubtreeStream stream_alterForeignKeyWithName=new RewriteRuleSubtreeStream(adaptor,"rule alterForeignKeyWithName");
		RewriteRuleSubtreeStream stream_alterConstraintWithName=new RewriteRuleSubtreeStream(adaptor,"rule alterConstraintWithName");

		 pushMsg("add constraint statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:4: ( KW_ADD (fk= alterForeignKeyWithName | alterConstraintWithName ) -> {fk != null}? ^( TOK_ALTERTABLE_ADDCONSTRAINT alterForeignKeyWithName ) -> ^( TOK_ALTERTABLE_ADDCONSTRAINT alterConstraintWithName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:7: KW_ADD (fk= alterForeignKeyWithName | alterConstraintWithName )
			{
			KW_ADD273=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddConstraint5234); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ADD.add(KW_ADD273);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:14: (fk= alterForeignKeyWithName | alterConstraintWithName )
			int alt75=2;
			int LA75_0 = input.LA(1);
			if ( (LA75_0==KW_CONSTRAINT) ) {
				int LA75_1 = input.LA(2);
				if ( (LA75_1==Identifier) ) {
					int LA75_2 = input.LA(3);
					if ( (LA75_2==KW_FOREIGN) ) {
						alt75=1;
					}
					else if ( (LA75_2==KW_CHECK||LA75_2==KW_PRIMARY||LA75_2==KW_UNIQUE) ) {
						alt75=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 75, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA75_1 >= KW_ABORT && LA75_1 <= KW_AFTER)||LA75_1==KW_ALLOC_FRACTION||LA75_1==KW_ANALYZE||LA75_1==KW_ARCHIVE||LA75_1==KW_ASC||(LA75_1 >= KW_AUTOCOMMIT && LA75_1 <= KW_BEFORE)||(LA75_1 >= KW_BUCKET && LA75_1 <= KW_BUCKETS)||(LA75_1 >= KW_CACHE && LA75_1 <= KW_CASCADE)||(LA75_1 >= KW_CBO && LA75_1 <= KW_CHANGE)||(LA75_1 >= KW_CHECK && LA75_1 <= KW_COLLECTION)||(LA75_1 >= KW_COLUMNS && LA75_1 <= KW_COMMENT)||(LA75_1 >= KW_COMPACT && LA75_1 <= KW_CONCATENATE)||(LA75_1 >= KW_CONTINUE && LA75_1 <= KW_COST)||LA75_1==KW_DATA||LA75_1==KW_DATABASES||(LA75_1 >= KW_DATETIME && LA75_1 <= KW_DEBUG)||(LA75_1 >= KW_DEFAULT && LA75_1 <= KW_DEFINED)||(LA75_1 >= KW_DELIMITED && LA75_1 <= KW_DESC)||(LA75_1 >= KW_DETAIL && LA75_1 <= KW_DISABLE)||(LA75_1 >= KW_DISTRIBUTE && LA75_1 <= KW_DO)||LA75_1==KW_DOW||(LA75_1 >= KW_DUMP && LA75_1 <= KW_ELEM_TYPE)||LA75_1==KW_ENABLE||(LA75_1 >= KW_ENFORCED && LA75_1 <= KW_ESCAPED)||LA75_1==KW_EXCLUSIVE||(LA75_1 >= KW_EXPLAIN && LA75_1 <= KW_EXPRESSION)||(LA75_1 >= KW_FIELDS && LA75_1 <= KW_FIRST)||(LA75_1 >= KW_FORMAT && LA75_1 <= KW_FORMATTED)||LA75_1==KW_FUNCTIONS||(LA75_1 >= KW_HOUR && LA75_1 <= KW_IDXPROPERTIES)||(LA75_1 >= KW_INDEX && LA75_1 <= KW_INDEXES)||(LA75_1 >= KW_INPATH && LA75_1 <= KW_INPUTFORMAT)||(LA75_1 >= KW_ISOLATION && LA75_1 <= KW_JAR)||(LA75_1 >= KW_JOINCOST && LA75_1 <= KW_LAST)||LA75_1==KW_LEVEL||(LA75_1 >= KW_LIMIT && LA75_1 <= KW_LOAD)||(LA75_1 >= KW_LOCATION && LA75_1 <= KW_LONG)||LA75_1==KW_MANAGEMENT||(LA75_1 >= KW_MAPJOIN && LA75_1 <= KW_MATERIALIZED)||LA75_1==KW_METADATA||(LA75_1 >= KW_MINUTE && LA75_1 <= KW_MONTH)||(LA75_1 >= KW_MOVE && LA75_1 <= KW_MSCK)||(LA75_1 >= KW_NORELY && LA75_1 <= KW_NOSCAN)||LA75_1==KW_NOVALIDATE||LA75_1==KW_NULLS||LA75_1==KW_OFFSET||(LA75_1 >= KW_OPERATOR && LA75_1 <= KW_OPTION)||(LA75_1 >= KW_OUTPUTDRIVER && LA75_1 <= KW_OUTPUTFORMAT)||(LA75_1 >= KW_OVERWRITE && LA75_1 <= KW_OWNER)||(LA75_1 >= KW_PARTITIONED && LA75_1 <= KW_PATH)||(LA75_1 >= KW_PLAN && LA75_1 <= KW_POOL)||LA75_1==KW_PRINCIPALS||(LA75_1 >= KW_PURGE && LA75_1 <= KW_QUERY_PARALLELISM)||LA75_1==KW_READ||(LA75_1 >= KW_REBUILD && LA75_1 <= KW_RECORDWRITER)||(LA75_1 >= KW_RELOAD && LA75_1 <= KW_RESTRICT)||LA75_1==KW_REWRITE||(LA75_1 >= KW_ROLE && LA75_1 <= KW_ROLES)||(LA75_1 >= KW_SCHEDULING_POLICY && LA75_1 <= KW_SECOND)||(LA75_1 >= KW_SEMI && LA75_1 <= KW_SERVER)||(LA75_1 >= KW_SETS && LA75_1 <= KW_SKEWED)||(LA75_1 >= KW_SNAPSHOT && LA75_1 <= KW_SSL)||(LA75_1 >= KW_STATISTICS && LA75_1 <= KW_SUMMARY)||LA75_1==KW_TABLES||(LA75_1 >= KW_TBLPROPERTIES && LA75_1 <= KW_TERMINATED)||LA75_1==KW_TINYINT||(LA75_1 >= KW_TOUCH && LA75_1 <= KW_TRANSACTIONS)||LA75_1==KW_UNARCHIVE||LA75_1==KW_UNDO||LA75_1==KW_UNIONTYPE||(LA75_1 >= KW_UNLOCK && LA75_1 <= KW_UNSIGNED)||(LA75_1 >= KW_URI && LA75_1 <= KW_USE)||(LA75_1 >= KW_UTC && LA75_1 <= KW_VALIDATE)||LA75_1==KW_VALUE_TYPE||(LA75_1 >= KW_VECTORIZATION && LA75_1 <= KW_WEEK)||LA75_1==KW_WHILE||(LA75_1 >= KW_WORK && LA75_1 <= KW_ZONE)||LA75_1==KW_BATCH||LA75_1==KW_DAYOFWEEK||LA75_1==KW_HOLD_DDLTIME||LA75_1==KW_IGNORE||LA75_1==KW_NO_DROP||LA75_1==KW_OFFLINE||LA75_1==KW_PROTECTION||LA75_1==KW_READONLY||LA75_1==KW_TIMESTAMPTZ) ) {
					int LA75_3 = input.LA(3);
					if ( (LA75_3==KW_FOREIGN) ) {
						alt75=1;
					}
					else if ( (LA75_3==KW_CHECK||LA75_3==KW_PRIMARY||LA75_3==KW_UNIQUE) ) {
						alt75=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 75, 3, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 75, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 75, 0, input);
				throw nvae;
			}

			switch (alt75) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:15: fk= alterForeignKeyWithName
					{
					pushFollow(FOLLOW_alterForeignKeyWithName_in_alterStatementSuffixAddConstraint5239);
					fk=alterForeignKeyWithName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterForeignKeyWithName.add(fk.getTree());
					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:44: alterConstraintWithName
					{
					pushFollow(FOLLOW_alterConstraintWithName_in_alterStatementSuffixAddConstraint5243);
					alterConstraintWithName274=alterConstraintWithName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterConstraintWithName.add(alterConstraintWithName274.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: alterForeignKeyWithName, alterConstraintWithName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1279:4: -> {fk != null}? ^( TOK_ALTERTABLE_ADDCONSTRAINT alterForeignKeyWithName )
			if (fk != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1279:21: ^( TOK_ALTERTABLE_ADDCONSTRAINT alterForeignKeyWithName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_ADDCONSTRAINT, "TOK_ALTERTABLE_ADDCONSTRAINT"), root_1);
				adaptor.addChild(root_1, stream_alterForeignKeyWithName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1280:4: -> ^( TOK_ALTERTABLE_ADDCONSTRAINT alterConstraintWithName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1280:21: ^( TOK_ALTERTABLE_ADDCONSTRAINT alterConstraintWithName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_ADDCONSTRAINT, "TOK_ALTERTABLE_ADDCONSTRAINT"), root_1);
				adaptor.addChild(root_1, stream_alterConstraintWithName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixAddConstraint"


	public static class alterStatementSuffixUpdateColumns_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixUpdateColumns"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1283:1: alterStatementSuffixUpdateColumns : KW_UPDATE KW_COLUMNS ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_UPDATECOLUMNS ( restrictOrCascade )? ) ;
	public final HiveParser.alterStatementSuffixUpdateColumns_return alterStatementSuffixUpdateColumns() throws RecognitionException {
		HiveParser.alterStatementSuffixUpdateColumns_return retval = new HiveParser.alterStatementSuffixUpdateColumns_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UPDATE275=null;
		Token KW_COLUMNS276=null;
		ParserRuleReturnScope restrictOrCascade277 =null;

		ASTNode KW_UPDATE275_tree=null;
		ASTNode KW_COLUMNS276_tree=null;
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");

		 pushMsg("update columns statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1286:5: ( KW_UPDATE KW_COLUMNS ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_UPDATECOLUMNS ( restrictOrCascade )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1286:7: KW_UPDATE KW_COLUMNS ( restrictOrCascade )?
			{
			KW_UPDATE275=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateColumns5308); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE275);

			KW_COLUMNS276=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_alterStatementSuffixUpdateColumns5310); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS276);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1286:28: ( restrictOrCascade )?
			int alt76=2;
			int LA76_0 = input.LA(1);
			if ( (LA76_0==KW_CASCADE||LA76_0==KW_RESTRICT) ) {
				alt76=1;
			}
			switch (alt76) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1286:28: restrictOrCascade
					{
					pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixUpdateColumns5312);
					restrictOrCascade277=restrictOrCascade();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade277.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: restrictOrCascade
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1287:5: -> ^( TOK_ALTERTABLE_UPDATECOLUMNS ( restrictOrCascade )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:8: ^( TOK_ALTERTABLE_UPDATECOLUMNS ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATECOLUMNS, "TOK_ALTERTABLE_UPDATECOLUMNS"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:39: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixUpdateColumns"


	public static class alterStatementSuffixDropConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixDropConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1290:1: alterStatementSuffixDropConstraint : KW_DROP KW_CONSTRAINT cName= identifier -> ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName) ;
	public final HiveParser.alterStatementSuffixDropConstraint_return alterStatementSuffixDropConstraint() throws RecognitionException {
		HiveParser.alterStatementSuffixDropConstraint_return retval = new HiveParser.alterStatementSuffixDropConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP278=null;
		Token KW_CONSTRAINT279=null;
		ParserRuleReturnScope cName =null;

		ASTNode KW_DROP278_tree=null;
		ASTNode KW_CONSTRAINT279_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("drop constraint statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1293:4: ( KW_DROP KW_CONSTRAINT cName= identifier -> ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1293:6: KW_DROP KW_CONSTRAINT cName= identifier
			{
			KW_DROP278=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_alterStatementSuffixDropConstraint5352); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP278);

			KW_CONSTRAINT279=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterStatementSuffixDropConstraint5354); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT279);

			pushFollow(FOLLOW_identifier_in_alterStatementSuffixDropConstraint5358);
			cName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(cName.getTree());
			// AST REWRITE
			// elements: cName
			// token labels: 
			// rule labels: cName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_cName=new RewriteRuleSubtreeStream(adaptor,"rule cName",cName!=null?cName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1294:4: -> ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1294:6: ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_DROPCONSTRAINT, "TOK_ALTERTABLE_DROPCONSTRAINT"), root_1);
				adaptor.addChild(root_1, stream_cName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixDropConstraint"


	public static class alterStatementSuffixRenameCol_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixRenameCol"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1297:1: alterStatementSuffixRenameCol : KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( alterColumnConstraint[$newName.tree] )? ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterColumnConstraint )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? ) ;
	public final HiveParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol() throws RecognitionException {
		HiveParser.alterStatementSuffixRenameCol_return retval = new HiveParser.alterStatementSuffixRenameCol_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_CHANGE280=null;
		Token KW_COLUMN281=null;
		Token KW_COMMENT284=null;
		ParserRuleReturnScope oldName =null;
		ParserRuleReturnScope newName =null;
		ParserRuleReturnScope colType282 =null;
		ParserRuleReturnScope alterColumnConstraint283 =null;
		ParserRuleReturnScope alterStatementChangeColPosition285 =null;
		ParserRuleReturnScope restrictOrCascade286 =null;

		ASTNode comment_tree=null;
		ASTNode KW_CHANGE280_tree=null;
		ASTNode KW_COLUMN281_tree=null;
		ASTNode KW_COMMENT284_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
		RewriteRuleTokenStream stream_KW_CHANGE=new RewriteRuleTokenStream(adaptor,"token KW_CHANGE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");
		RewriteRuleSubtreeStream stream_alterStatementChangeColPosition=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementChangeColPosition");
		RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");
		RewriteRuleSubtreeStream stream_alterColumnConstraint=new RewriteRuleSubtreeStream(adaptor,"rule alterColumnConstraint");

		 pushMsg("rename column name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:5: ( KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( alterColumnConstraint[$newName.tree] )? ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterColumnConstraint )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:7: KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( alterColumnConstraint[$newName.tree] )? ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )?
			{
			KW_CHANGE280=(Token)match(input,KW_CHANGE,FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol5395); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CHANGE.add(KW_CHANGE280);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:17: ( KW_COLUMN )?
			int alt77=2;
			int LA77_0 = input.LA(1);
			if ( (LA77_0==KW_COLUMN) ) {
				alt77=1;
			}
			switch (alt77) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:17: KW_COLUMN
					{
					KW_COLUMN281=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol5397); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN281);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol5402);
			oldName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(oldName.getTree());
			pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol5406);
			newName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(newName.getTree());
			pushFollow(FOLLOW_colType_in_alterStatementSuffixRenameCol5408);
			colType282=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType282.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:74: ( alterColumnConstraint[$newName.tree] )?
			int alt78=2;
			int LA78_0 = input.LA(1);
			if ( (LA78_0==KW_CHECK||LA78_0==KW_CONSTRAINT||LA78_0==KW_DEFAULT||LA78_0==KW_NOT||LA78_0==KW_PRIMARY||LA78_0==KW_REFERENCES||LA78_0==KW_UNIQUE) ) {
				alt78=1;
			}
			switch (alt78) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:74: alterColumnConstraint[$newName.tree]
					{
					pushFollow(FOLLOW_alterColumnConstraint_in_alterStatementSuffixRenameCol5410);
					alterColumnConstraint283=alterColumnConstraint((newName!=null?((ASTNode)newName.getTree()):null));
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterColumnConstraint.add(alterColumnConstraint283.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:112: ( KW_COMMENT comment= StringLiteral )?
			int alt79=2;
			int LA79_0 = input.LA(1);
			if ( (LA79_0==KW_COMMENT) ) {
				alt79=1;
			}
			switch (alt79) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:113: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT284=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol5415); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT284);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol5419); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:148: ( alterStatementChangeColPosition )?
			int alt80=2;
			int LA80_0 = input.LA(1);
			if ( (LA80_0==KW_AFTER||LA80_0==KW_FIRST) ) {
				alt80=1;
			}
			switch (alt80) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:148: alterStatementChangeColPosition
					{
					pushFollow(FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol5423);
					alterStatementChangeColPosition285=alterStatementChangeColPosition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterStatementChangeColPosition.add(alterStatementChangeColPosition285.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:181: ( restrictOrCascade )?
			int alt81=2;
			int LA81_0 = input.LA(1);
			if ( (LA81_0==KW_CASCADE||LA81_0==KW_RESTRICT) ) {
				alt81=1;
			}
			switch (alt81) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:181: restrictOrCascade
					{
					pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixRenameCol5426);
					restrictOrCascade286=restrictOrCascade();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade286.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: oldName, restrictOrCascade, newName, comment, alterStatementChangeColPosition, colType, alterColumnConstraint
			// token labels: comment
			// rule labels: newName, oldName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_newName=new RewriteRuleSubtreeStream(adaptor,"rule newName",newName!=null?newName.getTree():null);
			RewriteRuleSubtreeStream stream_oldName=new RewriteRuleSubtreeStream(adaptor,"rule oldName",oldName!=null?oldName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1301:5: -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterColumnConstraint )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1301:7: ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterColumnConstraint )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_RENAMECOL, "TOK_ALTERTABLE_RENAMECOL"), root_1);
				adaptor.addChild(root_1, stream_oldName.nextTree());
				adaptor.addChild(root_1, stream_newName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1301:61: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1301:70: ( alterColumnConstraint )?
				if ( stream_alterColumnConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_alterColumnConstraint.nextTree());
				}
				stream_alterColumnConstraint.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1301:93: ( alterStatementChangeColPosition )?
				if ( stream_alterStatementChangeColPosition.hasNext() ) {
					adaptor.addChild(root_1, stream_alterStatementChangeColPosition.nextTree());
				}
				stream_alterStatementChangeColPosition.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1301:126: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixRenameCol"


	public static class alterStatementSuffixUpdateStatsCol_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixUpdateStatsCol"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1304:1: alterStatementSuffixUpdateStatsCol : KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) ;
	public final HiveParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol() throws RecognitionException {
		HiveParser.alterStatementSuffixUpdateStatsCol_return retval = new HiveParser.alterStatementSuffixUpdateStatsCol_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_UPDATE287=null;
		Token KW_STATISTICS288=null;
		Token KW_FOR289=null;
		Token KW_COLUMN290=null;
		Token KW_SET291=null;
		Token KW_COMMENT293=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope tableProperties292 =null;

		ASTNode comment_tree=null;
		ASTNode KW_UPDATE287_tree=null;
		ASTNode KW_STATISTICS288_tree=null;
		ASTNode KW_FOR289_tree=null;
		ASTNode KW_COLUMN290_tree=null;
		ASTNode KW_SET291_tree=null;
		ASTNode KW_COMMENT293_tree=null;
		RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("update column statistics", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:5: ( KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:7: KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )?
			{
			KW_UPDATE287=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStatsCol5484); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE287);

			KW_STATISTICS288=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStatsCol5486); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS288);

			KW_FOR289=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_alterStatementSuffixUpdateStatsCol5488); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR289);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:38: ( KW_COLUMN )?
			int alt82=2;
			int LA82_0 = input.LA(1);
			if ( (LA82_0==KW_COLUMN) ) {
				alt82=1;
			}
			switch (alt82) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:38: KW_COLUMN
					{
					KW_COLUMN290=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementSuffixUpdateStatsCol5490); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN290);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_alterStatementSuffixUpdateStatsCol5495);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			KW_SET291=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixUpdateStatsCol5497); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET291);

			pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixUpdateStatsCol5499);
			tableProperties292=tableProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties292.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:91: ( KW_COMMENT comment= StringLiteral )?
			int alt83=2;
			int LA83_0 = input.LA(1);
			if ( (LA83_0==KW_COMMENT) ) {
				alt83=1;
			}
			switch (alt83) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:92: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT293=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_alterStatementSuffixUpdateStatsCol5502); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT293);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixUpdateStatsCol5506); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: tableProperties, comment, colName
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1308:5: -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1308:7: ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATECOLSTATS, "TOK_ALTERTABLE_UPDATECOLSTATS"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_tableProperties.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1308:65: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixUpdateStatsCol"


	public static class alterStatementSuffixUpdateStats_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixUpdateStats"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1311:1: alterStatementSuffixUpdateStats : KW_UPDATE KW_STATISTICS KW_SET tableProperties -> ^( TOK_ALTERTABLE_UPDATESTATS tableProperties ) ;
	public final HiveParser.alterStatementSuffixUpdateStats_return alterStatementSuffixUpdateStats() throws RecognitionException {
		HiveParser.alterStatementSuffixUpdateStats_return retval = new HiveParser.alterStatementSuffixUpdateStats_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UPDATE294=null;
		Token KW_STATISTICS295=null;
		Token KW_SET296=null;
		ParserRuleReturnScope tableProperties297 =null;

		ASTNode KW_UPDATE294_tree=null;
		ASTNode KW_STATISTICS295_tree=null;
		ASTNode KW_SET296_tree=null;
		RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("update basic statistics", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1314:5: ( KW_UPDATE KW_STATISTICS KW_SET tableProperties -> ^( TOK_ALTERTABLE_UPDATESTATS tableProperties ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1314:7: KW_UPDATE KW_STATISTICS KW_SET tableProperties
			{
			KW_UPDATE294=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStats5553); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE294);

			KW_STATISTICS295=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStats5555); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS295);

			KW_SET296=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixUpdateStats5557); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET296);

			pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixUpdateStats5559);
			tableProperties297=tableProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties297.getTree());
			// AST REWRITE
			// elements: tableProperties
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1315:5: -> ^( TOK_ALTERTABLE_UPDATESTATS tableProperties )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1315:7: ^( TOK_ALTERTABLE_UPDATESTATS tableProperties )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATESTATS, "TOK_ALTERTABLE_UPDATESTATS"), root_1);
				adaptor.addChild(root_1, stream_tableProperties.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixUpdateStats"


	public static class alterStatementChangeColPosition_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementChangeColPosition"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1318:1: alterStatementChangeColPosition : (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) );
	public final HiveParser.alterStatementChangeColPosition_return alterStatementChangeColPosition() throws RecognitionException {
		HiveParser.alterStatementChangeColPosition_return retval = new HiveParser.alterStatementChangeColPosition_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token first=null;
		Token KW_AFTER298=null;
		ParserRuleReturnScope afterCol =null;

		ASTNode first_tree=null;
		ASTNode KW_AFTER298_tree=null;
		RewriteRuleTokenStream stream_KW_AFTER=new RewriteRuleTokenStream(adaptor,"token KW_AFTER");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:5: (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) )
			int alt84=2;
			int LA84_0 = input.LA(1);
			if ( (LA84_0==KW_FIRST) ) {
				alt84=1;
			}
			else if ( (LA84_0==KW_AFTER) ) {
				alt84=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 84, 0, input);
				throw nvae;
			}

			switch (alt84) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:7: first= KW_FIRST
					{
					root_0 = (ASTNode)adaptor.nil();


					first=(Token)match(input,KW_FIRST,FOLLOW_KW_FIRST_in_alterStatementChangeColPosition5589); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					first_tree = (ASTNode)adaptor.create(first);
					adaptor.addChild(root_0, first_tree);
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:22: KW_AFTER afterCol= identifier
					{
					KW_AFTER298=(Token)match(input,KW_AFTER,FOLLOW_KW_AFTER_in_alterStatementChangeColPosition5591); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AFTER.add(KW_AFTER298);

					pushFollow(FOLLOW_identifier_in_alterStatementChangeColPosition5595);
					afterCol=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(afterCol.getTree());
					// AST REWRITE
					// elements: afterCol
					// token labels: 
					// rule labels: afterCol, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_afterCol=new RewriteRuleSubtreeStream(adaptor,"rule afterCol",afterCol!=null?afterCol.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1320:5: -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
					if (first != null) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1320:25: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION, "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}

					else // 1321:5: -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1321:8: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION, "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION"), root_1);
						adaptor.addChild(root_1, stream_afterCol.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementChangeColPosition"


	public static class alterStatementSuffixAddPartitions_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixAddPartitions"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:1: alterStatementSuffixAddPartitions[boolean table] : KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) ;
	public final HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions(boolean table) throws RecognitionException {
		HiveParser.alterStatementSuffixAddPartitions_return retval = new HiveParser.alterStatementSuffixAddPartitions_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ADD299=null;
		ParserRuleReturnScope ifNotExists300 =null;
		ParserRuleReturnScope alterStatementSuffixAddPartitionsElement301 =null;

		ASTNode KW_ADD299_tree=null;
		RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_alterStatementSuffixAddPartitionsElement=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementSuffixAddPartitionsElement");

		 pushMsg("add partition statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:5: ( KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:7: KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+
			{
			KW_ADD299=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions5648); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ADD.add(KW_ADD299);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:14: ( ifNotExists )?
			int alt85=2;
			int LA85_0 = input.LA(1);
			if ( (LA85_0==KW_IF) ) {
				alt85=1;
			}
			switch (alt85) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:14: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions5650);
					ifNotExists300=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists300.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:27: ( alterStatementSuffixAddPartitionsElement )+
			int cnt86=0;
			loop86:
			while (true) {
				int alt86=2;
				int LA86_0 = input.LA(1);
				if ( (LA86_0==KW_PARTITION) ) {
					alt86=1;
				}

				switch (alt86) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:27: alterStatementSuffixAddPartitionsElement
					{
					pushFollow(FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions5653);
					alterStatementSuffixAddPartitionsElement301=alterStatementSuffixAddPartitionsElement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterStatementSuffixAddPartitionsElement.add(alterStatementSuffixAddPartitionsElement301.getTree());
					}
					break;

				default :
					if ( cnt86 >= 1 ) break loop86;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(86, input);
					throw eee;
				}
				cnt86++;
			}

			// AST REWRITE
			// elements: ifNotExists, ifNotExists, alterStatementSuffixAddPartitionsElement, alterStatementSuffixAddPartitionsElement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1328:5: -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
			if ( table ) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:19: ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_ADDPARTS, "TOK_ALTERTABLE_ADDPARTS"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:45: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				if ( !(stream_alterStatementSuffixAddPartitionsElement.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_alterStatementSuffixAddPartitionsElement.hasNext() ) {
					adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());
				}
				stream_alterStatementSuffixAddPartitionsElement.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1329:5: -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:19: ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW_ADDPARTS, "TOK_ALTERVIEW_ADDPARTS"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:44: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				if ( !(stream_alterStatementSuffixAddPartitionsElement.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_alterStatementSuffixAddPartitionsElement.hasNext() ) {
					adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());
				}
				stream_alterStatementSuffixAddPartitionsElement.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixAddPartitions"


	public static class alterStatementSuffixAddPartitionsElement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixAddPartitionsElement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:1: alterStatementSuffixAddPartitionsElement : partitionSpec ( partitionLocation )? ;
	public final HiveParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement() throws RecognitionException {
		HiveParser.alterStatementSuffixAddPartitionsElement_return retval = new HiveParser.alterStatementSuffixAddPartitionsElement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope partitionSpec302 =null;
		ParserRuleReturnScope partitionLocation303 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1333:5: ( partitionSpec ( partitionLocation )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1333:7: partitionSpec ( partitionLocation )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement5716);
			partitionSpec302=partitionSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, partitionSpec302.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1333:21: ( partitionLocation )?
			int alt87=2;
			int LA87_0 = input.LA(1);
			if ( (LA87_0==KW_LOCATION) ) {
				alt87=1;
			}
			switch (alt87) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1333:21: partitionLocation
					{
					pushFollow(FOLLOW_partitionLocation_in_alterStatementSuffixAddPartitionsElement5718);
					partitionLocation303=partitionLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, partitionLocation303.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixAddPartitionsElement"


	public static class alterStatementSuffixTouch_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixTouch"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1336:1: alterStatementSuffixTouch : KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* ) ;
	public final HiveParser.alterStatementSuffixTouch_return alterStatementSuffixTouch() throws RecognitionException {
		HiveParser.alterStatementSuffixTouch_return retval = new HiveParser.alterStatementSuffixTouch_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_TOUCH304=null;
		ParserRuleReturnScope partitionSpec305 =null;

		ASTNode KW_TOUCH304_tree=null;
		RewriteRuleTokenStream stream_KW_TOUCH=new RewriteRuleTokenStream(adaptor,"token KW_TOUCH");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");

		 pushMsg("touch statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1339:5: ( KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1339:7: KW_TOUCH ( partitionSpec )*
			{
			KW_TOUCH304=(Token)match(input,KW_TOUCH,FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch5746); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TOUCH.add(KW_TOUCH304);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1339:16: ( partitionSpec )*
			loop88:
			while (true) {
				int alt88=2;
				int LA88_0 = input.LA(1);
				if ( (LA88_0==KW_PARTITION) ) {
					alt88=1;
				}

				switch (alt88) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1339:17: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixTouch5749);
					partitionSpec305=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec305.getTree());
					}
					break;

				default :
					break loop88;
				}
			}

			// AST REWRITE
			// elements: partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1340:5: -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:8: ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_TOUCH, "TOK_ALTERTABLE_TOUCH"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:31: ( partitionSpec )*
				while ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixTouch"


	public static class alterStatementSuffixArchive_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixArchive"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:1: alterStatementSuffixArchive : KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* ) ;
	public final HiveParser.alterStatementSuffixArchive_return alterStatementSuffixArchive() throws RecognitionException {
		HiveParser.alterStatementSuffixArchive_return retval = new HiveParser.alterStatementSuffixArchive_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ARCHIVE306=null;
		ParserRuleReturnScope partitionSpec307 =null;

		ASTNode KW_ARCHIVE306_tree=null;
		RewriteRuleTokenStream stream_KW_ARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_ARCHIVE");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");

		 pushMsg("archive statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:5: ( KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:7: KW_ARCHIVE ( partitionSpec )*
			{
			KW_ARCHIVE306=(Token)match(input,KW_ARCHIVE,FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive5793); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ARCHIVE.add(KW_ARCHIVE306);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:18: ( partitionSpec )*
			loop89:
			while (true) {
				int alt89=2;
				int LA89_0 = input.LA(1);
				if ( (LA89_0==KW_PARTITION) ) {
					alt89=1;
				}

				switch (alt89) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:19: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixArchive5796);
					partitionSpec307=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec307.getTree());
					}
					break;

				default :
					break loop89;
				}
			}

			// AST REWRITE
			// elements: partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1347:5: -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1347:8: ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_ARCHIVE, "TOK_ALTERTABLE_ARCHIVE"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1347:33: ( partitionSpec )*
				while ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixArchive"


	public static class alterStatementSuffixUnArchive_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixUnArchive"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:1: alterStatementSuffixUnArchive : KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* ) ;
	public final HiveParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive() throws RecognitionException {
		HiveParser.alterStatementSuffixUnArchive_return retval = new HiveParser.alterStatementSuffixUnArchive_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNARCHIVE308=null;
		ParserRuleReturnScope partitionSpec309 =null;

		ASTNode KW_UNARCHIVE308_tree=null;
		RewriteRuleTokenStream stream_KW_UNARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_UNARCHIVE");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");

		 pushMsg("unarchive statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:5: ( KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:7: KW_UNARCHIVE ( partitionSpec )*
			{
			KW_UNARCHIVE308=(Token)match(input,KW_UNARCHIVE,FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive5840); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNARCHIVE.add(KW_UNARCHIVE308);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:20: ( partitionSpec )*
			loop90:
			while (true) {
				int alt90=2;
				int LA90_0 = input.LA(1);
				if ( (LA90_0==KW_PARTITION) ) {
					alt90=1;
				}

				switch (alt90) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:21: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive5843);
					partitionSpec309=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec309.getTree());
					}
					break;

				default :
					break loop90;
				}
			}

			// AST REWRITE
			// elements: partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1354:5: -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1354:8: ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_UNARCHIVE, "TOK_ALTERTABLE_UNARCHIVE"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1354:35: ( partitionSpec )*
				while ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixUnArchive"


	public static class partitionLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "partitionLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1357:1: partitionLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_PARTITIONLOCATION $locn) ;
	public final HiveParser.partitionLocation_return partitionLocation() throws RecognitionException {
		HiveParser.partitionLocation_return retval = new HiveParser.partitionLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token locn=null;
		Token KW_LOCATION310=null;

		ASTNode locn_tree=null;
		ASTNode KW_LOCATION310_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

		 pushMsg("partition location", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_PARTITIONLOCATION $locn) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:7: KW_LOCATION locn= StringLiteral
			{
			KW_LOCATION310=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_partitionLocation5893); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION310);

			locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_partitionLocation5897); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(locn);

			// AST REWRITE
			// elements: locn
			// token labels: locn
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1361:38: -> ^( TOK_PARTITIONLOCATION $locn)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:41: ^( TOK_PARTITIONLOCATION $locn)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PARTITIONLOCATION, "TOK_PARTITIONLOCATION"), root_1);
				adaptor.addChild(root_1, stream_locn.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "partitionLocation"


	public static class alterStatementSuffixDropPartitions_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixDropPartitions"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1364:1: alterStatementSuffixDropPartitions[boolean table] : KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( KW_PURGE )? ( replicationClause )? -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? ) ;
	public final HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions(boolean table) throws RecognitionException {
		HiveParser.alterStatementSuffixDropPartitions_return retval = new HiveParser.alterStatementSuffixDropPartitions_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP311=null;
		Token COMMA314=null;
		Token KW_PURGE316=null;
		ParserRuleReturnScope ifExists312 =null;
		ParserRuleReturnScope dropPartitionSpec313 =null;
		ParserRuleReturnScope dropPartitionSpec315 =null;
		ParserRuleReturnScope replicationClause317 =null;

		ASTNode KW_DROP311_tree=null;
		ASTNode COMMA314_tree=null;
		ASTNode KW_PURGE316_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_PURGE=new RewriteRuleTokenStream(adaptor,"token KW_PURGE");
		RewriteRuleSubtreeStream stream_dropPartitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule dropPartitionSpec");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");

		 pushMsg("drop partition statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:5: ( KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( KW_PURGE )? ( replicationClause )? -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:7: KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( KW_PURGE )? ( replicationClause )?
			{
			KW_DROP311=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions5934); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP311);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:15: ( ifExists )?
			int alt91=2;
			int LA91_0 = input.LA(1);
			if ( (LA91_0==KW_IF) ) {
				alt91=1;
			}
			switch (alt91) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:15: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_alterStatementSuffixDropPartitions5936);
					ifExists312=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists312.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5939);
			dropPartitionSpec313=dropPartitionSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_dropPartitionSpec.add(dropPartitionSpec313.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:43: ( COMMA dropPartitionSpec )*
			loop92:
			while (true) {
				int alt92=2;
				int LA92_0 = input.LA(1);
				if ( (LA92_0==COMMA) ) {
					alt92=1;
				}

				switch (alt92) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:44: COMMA dropPartitionSpec
					{
					COMMA314=(Token)match(input,COMMA,FOLLOW_COMMA_in_alterStatementSuffixDropPartitions5942); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA314);

					pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5944);
					dropPartitionSpec315=dropPartitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_dropPartitionSpec.add(dropPartitionSpec315.getTree());
					}
					break;

				default :
					break loop92;
				}
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:70: ( KW_PURGE )?
			int alt93=2;
			int LA93_0 = input.LA(1);
			if ( (LA93_0==KW_PURGE) ) {
				alt93=1;
			}
			switch (alt93) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:70: KW_PURGE
					{
					KW_PURGE316=(Token)match(input,KW_PURGE,FOLLOW_KW_PURGE_in_alterStatementSuffixDropPartitions5948); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PURGE.add(KW_PURGE316);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:80: ( replicationClause )?
			int alt94=2;
			int LA94_0 = input.LA(1);
			if ( (LA94_0==KW_FOR) ) {
				alt94=1;
			}
			switch (alt94) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:80: replicationClause
					{
					pushFollow(FOLLOW_replicationClause_in_alterStatementSuffixDropPartitions5951);
					replicationClause317=replicationClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause317.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: dropPartitionSpec, dropPartitionSpec, KW_PURGE, ifExists, replicationClause, ifExists, replicationClause
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1368:5: -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
			if ( table ) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:19: ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_DROPPARTS, "TOK_ALTERTABLE_DROPPARTS"), root_1);
				if ( !(stream_dropPartitionSpec.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_dropPartitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());
				}
				stream_dropPartitionSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:65: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:75: ( KW_PURGE )?
				if ( stream_KW_PURGE.hasNext() ) {
					adaptor.addChild(root_1, stream_KW_PURGE.nextNode());
				}
				stream_KW_PURGE.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:85: ( replicationClause )?
				if ( stream_replicationClause.hasNext() ) {
					adaptor.addChild(root_1, stream_replicationClause.nextTree());
				}
				stream_replicationClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1369:5: -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:19: ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW_DROPPARTS, "TOK_ALTERVIEW_DROPPARTS"), root_1);
				if ( !(stream_dropPartitionSpec.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_dropPartitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());
				}
				stream_dropPartitionSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:64: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:74: ( replicationClause )?
				if ( stream_replicationClause.hasNext() ) {
					adaptor.addChild(root_1, stream_replicationClause.nextTree());
				}
				stream_replicationClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixDropPartitions"


	public static class alterStatementSuffixProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1372:1: alterStatementSuffixProperties : ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? ) );
	public final HiveParser.alterStatementSuffixProperties_return alterStatementSuffixProperties() throws RecognitionException {
		HiveParser.alterStatementSuffixProperties_return retval = new HiveParser.alterStatementSuffixProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET318=null;
		Token KW_TBLPROPERTIES319=null;
		Token KW_UNSET321=null;
		Token KW_TBLPROPERTIES322=null;
		ParserRuleReturnScope tableProperties320 =null;
		ParserRuleReturnScope ifExists323 =null;
		ParserRuleReturnScope tableProperties324 =null;

		ASTNode KW_SET318_tree=null;
		ASTNode KW_TBLPROPERTIES319_tree=null;
		ASTNode KW_UNSET321_tree=null;
		ASTNode KW_TBLPROPERTIES322_tree=null;
		RewriteRuleTokenStream stream_KW_UNSET=new RewriteRuleTokenStream(adaptor,"token KW_UNSET");
		RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("alter properties statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1375:5: ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? ) )
			int alt96=2;
			int LA96_0 = input.LA(1);
			if ( (LA96_0==KW_SET) ) {
				alt96=1;
			}
			else if ( (LA96_0==KW_UNSET) ) {
				alt96=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 96, 0, input);
				throw nvae;
			}

			switch (alt96) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1375:7: KW_SET KW_TBLPROPERTIES tableProperties
					{
					KW_SET318=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixProperties6033); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET318);

					KW_TBLPROPERTIES319=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties6035); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES319);

					pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties6037);
					tableProperties320=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties320.getTree());
					// AST REWRITE
					// elements: tableProperties
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1376:5: -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1376:8: ^( TOK_ALTERTABLE_PROPERTIES tableProperties )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_PROPERTIES, "TOK_ALTERTABLE_PROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:7: KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
					{
					KW_UNSET321=(Token)match(input,KW_UNSET,FOLLOW_KW_UNSET_in_alterStatementSuffixProperties6057); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNSET.add(KW_UNSET321);

					KW_TBLPROPERTIES322=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties6059); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES322);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:33: ( ifExists )?
					int alt95=2;
					int LA95_0 = input.LA(1);
					if ( (LA95_0==KW_IF) ) {
						alt95=1;
					}
					switch (alt95) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:33: ifExists
							{
							pushFollow(FOLLOW_ifExists_in_alterStatementSuffixProperties6061);
							ifExists323=ifExists();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_ifExists.add(ifExists323.getTree());
							}
							break;

					}

					pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties6064);
					tableProperties324=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties324.getTree());
					// AST REWRITE
					// elements: ifExists, tableProperties
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1378:5: -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1378:8: ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_DROPPROPERTIES, "TOK_ALTERTABLE_DROPPROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1378:56: ( ifExists )?
						if ( stream_ifExists.hasNext() ) {
							adaptor.addChild(root_1, stream_ifExists.nextTree());
						}
						stream_ifExists.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixProperties"


	public static class alterViewSuffixProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterViewSuffixProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1381:1: alterViewSuffixProperties : ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? ) );
	public final HiveParser.alterViewSuffixProperties_return alterViewSuffixProperties() throws RecognitionException {
		HiveParser.alterViewSuffixProperties_return retval = new HiveParser.alterViewSuffixProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET325=null;
		Token KW_TBLPROPERTIES326=null;
		Token KW_UNSET328=null;
		Token KW_TBLPROPERTIES329=null;
		ParserRuleReturnScope tableProperties327 =null;
		ParserRuleReturnScope ifExists330 =null;
		ParserRuleReturnScope tableProperties331 =null;

		ASTNode KW_SET325_tree=null;
		ASTNode KW_TBLPROPERTIES326_tree=null;
		ASTNode KW_UNSET328_tree=null;
		ASTNode KW_TBLPROPERTIES329_tree=null;
		RewriteRuleTokenStream stream_KW_UNSET=new RewriteRuleTokenStream(adaptor,"token KW_UNSET");
		RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("alter view properties statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1384:5: ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? ) )
			int alt98=2;
			int LA98_0 = input.LA(1);
			if ( (LA98_0==KW_SET) ) {
				alt98=1;
			}
			else if ( (LA98_0==KW_UNSET) ) {
				alt98=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 98, 0, input);
				throw nvae;
			}

			switch (alt98) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1384:7: KW_SET KW_TBLPROPERTIES tableProperties
					{
					KW_SET325=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterViewSuffixProperties6106); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET325);

					KW_TBLPROPERTIES326=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties6108); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES326);

					pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties6110);
					tableProperties327=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties327.getTree());
					// AST REWRITE
					// elements: tableProperties
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1385:5: -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1385:8: ^( TOK_ALTERVIEW_PROPERTIES tableProperties )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW_PROPERTIES, "TOK_ALTERVIEW_PROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:7: KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
					{
					KW_UNSET328=(Token)match(input,KW_UNSET,FOLLOW_KW_UNSET_in_alterViewSuffixProperties6130); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNSET.add(KW_UNSET328);

					KW_TBLPROPERTIES329=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties6132); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES329);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:33: ( ifExists )?
					int alt97=2;
					int LA97_0 = input.LA(1);
					if ( (LA97_0==KW_IF) ) {
						alt97=1;
					}
					switch (alt97) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:33: ifExists
							{
							pushFollow(FOLLOW_ifExists_in_alterViewSuffixProperties6134);
							ifExists330=ifExists();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_ifExists.add(ifExists330.getTree());
							}
							break;

					}

					pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties6137);
					tableProperties331=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties331.getTree());
					// AST REWRITE
					// elements: tableProperties, ifExists
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1387:5: -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1387:8: ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW_DROPPROPERTIES, "TOK_ALTERVIEW_DROPPROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1387:55: ( ifExists )?
						if ( stream_ifExists.hasNext() ) {
							adaptor.addChild(root_1, stream_ifExists.nextTree());
						}
						stream_ifExists.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterViewSuffixProperties"


	public static class alterMaterializedViewSuffixRewrite_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterMaterializedViewSuffixRewrite"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1390:1: alterMaterializedViewSuffixRewrite : (mvRewriteFlag= rewriteEnabled |mvRewriteFlag= rewriteDisabled ) -> ^( TOK_ALTER_MATERIALIZED_VIEW_REWRITE $mvRewriteFlag) ;
	public final HiveParser.alterMaterializedViewSuffixRewrite_return alterMaterializedViewSuffixRewrite() throws RecognitionException {
		HiveParser.alterMaterializedViewSuffixRewrite_return retval = new HiveParser.alterMaterializedViewSuffixRewrite_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope mvRewriteFlag =null;

		RewriteRuleSubtreeStream stream_rewriteEnabled=new RewriteRuleSubtreeStream(adaptor,"rule rewriteEnabled");
		RewriteRuleSubtreeStream stream_rewriteDisabled=new RewriteRuleSubtreeStream(adaptor,"rule rewriteDisabled");

		 pushMsg("alter materialized view rewrite statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1393:5: ( (mvRewriteFlag= rewriteEnabled |mvRewriteFlag= rewriteDisabled ) -> ^( TOK_ALTER_MATERIALIZED_VIEW_REWRITE $mvRewriteFlag) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1393:7: (mvRewriteFlag= rewriteEnabled |mvRewriteFlag= rewriteDisabled )
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1393:7: (mvRewriteFlag= rewriteEnabled |mvRewriteFlag= rewriteDisabled )
			int alt99=2;
			int LA99_0 = input.LA(1);
			if ( (LA99_0==KW_ENABLE) ) {
				alt99=1;
			}
			else if ( (LA99_0==KW_DISABLE) ) {
				alt99=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 99, 0, input);
				throw nvae;
			}

			switch (alt99) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1393:8: mvRewriteFlag= rewriteEnabled
					{
					pushFollow(FOLLOW_rewriteEnabled_in_alterMaterializedViewSuffixRewrite6182);
					mvRewriteFlag=rewriteEnabled();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rewriteEnabled.add(mvRewriteFlag.getTree());
					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1393:39: mvRewriteFlag= rewriteDisabled
					{
					pushFollow(FOLLOW_rewriteDisabled_in_alterMaterializedViewSuffixRewrite6188);
					mvRewriteFlag=rewriteDisabled();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rewriteDisabled.add(mvRewriteFlag.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: mvRewriteFlag
			// token labels: 
			// rule labels: mvRewriteFlag, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_mvRewriteFlag=new RewriteRuleSubtreeStream(adaptor,"rule mvRewriteFlag",mvRewriteFlag!=null?mvRewriteFlag.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1394:5: -> ^( TOK_ALTER_MATERIALIZED_VIEW_REWRITE $mvRewriteFlag)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1394:8: ^( TOK_ALTER_MATERIALIZED_VIEW_REWRITE $mvRewriteFlag)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTER_MATERIALIZED_VIEW_REWRITE, "TOK_ALTER_MATERIALIZED_VIEW_REWRITE"), root_1);
				adaptor.addChild(root_1, stream_mvRewriteFlag.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterMaterializedViewSuffixRewrite"


	public static class alterMaterializedViewSuffixRebuild_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterMaterializedViewSuffixRebuild"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1397:1: alterMaterializedViewSuffixRebuild : KW_REBUILD -> ^( TOK_ALTER_MATERIALIZED_VIEW_REBUILD ) ;
	public final HiveParser.alterMaterializedViewSuffixRebuild_return alterMaterializedViewSuffixRebuild() throws RecognitionException {
		HiveParser.alterMaterializedViewSuffixRebuild_return retval = new HiveParser.alterMaterializedViewSuffixRebuild_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REBUILD332=null;

		ASTNode KW_REBUILD332_tree=null;
		RewriteRuleTokenStream stream_KW_REBUILD=new RewriteRuleTokenStream(adaptor,"token KW_REBUILD");

		 pushMsg("alter materialized view rebuild statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1400:5: ( KW_REBUILD -> ^( TOK_ALTER_MATERIALIZED_VIEW_REBUILD ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1400:7: KW_REBUILD
			{
			KW_REBUILD332=(Token)match(input,KW_REBUILD,FOLLOW_KW_REBUILD_in_alterMaterializedViewSuffixRebuild6229); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REBUILD.add(KW_REBUILD332);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1400:18: -> ^( TOK_ALTER_MATERIALIZED_VIEW_REBUILD )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1400:21: ^( TOK_ALTER_MATERIALIZED_VIEW_REBUILD )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTER_MATERIALIZED_VIEW_REBUILD, "TOK_ALTER_MATERIALIZED_VIEW_REBUILD"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterMaterializedViewSuffixRebuild"


	public static class alterStatementSuffixSerdeProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixSerdeProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1403:1: alterStatementSuffixSerdeProperties : ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) );
	public final HiveParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties() throws RecognitionException {
		HiveParser.alterStatementSuffixSerdeProperties_return retval = new HiveParser.alterStatementSuffixSerdeProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token serdeName=null;
		Token KW_SET333=null;
		Token KW_SERDE334=null;
		Token KW_WITH335=null;
		Token KW_SERDEPROPERTIES336=null;
		Token KW_SET338=null;
		Token KW_SERDEPROPERTIES339=null;
		ParserRuleReturnScope tableProperties337 =null;
		ParserRuleReturnScope tableProperties340 =null;

		ASTNode serdeName_tree=null;
		ASTNode KW_SET333_tree=null;
		ASTNode KW_SERDE334_tree=null;
		ASTNode KW_WITH335_tree=null;
		ASTNode KW_SERDEPROPERTIES336_tree=null;
		ASTNode KW_SET338_tree=null;
		ASTNode KW_SERDEPROPERTIES339_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
		RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("alter serdes statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1406:5: ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) )
			int alt101=2;
			int LA101_0 = input.LA(1);
			if ( (LA101_0==KW_SET) ) {
				int LA101_1 = input.LA(2);
				if ( (LA101_1==KW_SERDE) ) {
					alt101=1;
				}
				else if ( (LA101_1==KW_SERDEPROPERTIES) ) {
					alt101=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 101, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 101, 0, input);
				throw nvae;
			}

			switch (alt101) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1406:7: KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
					{
					KW_SET333=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties6262); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET333);

					KW_SERDE334=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties6264); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE334);

					serdeName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties6268); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(serdeName);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1406:47: ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
					int alt100=2;
					int LA100_0 = input.LA(1);
					if ( (LA100_0==KW_WITH) ) {
						alt100=1;
					}
					switch (alt100) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1406:48: KW_WITH KW_SERDEPROPERTIES tableProperties
							{
							KW_WITH335=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties6271); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH335);

							KW_SERDEPROPERTIES336=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties6273); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES336);

							pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties6275);
							tableProperties337=tableProperties();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties337.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: tableProperties, serdeName
					// token labels: serdeName
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_serdeName=new RewriteRuleTokenStream(adaptor,"token serdeName",serdeName);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1407:5: -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1407:8: ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SERIALIZER, "TOK_ALTERTABLE_SERIALIZER"), root_1);
						adaptor.addChild(root_1, stream_serdeName.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1407:47: ( tableProperties )?
						if ( stream_tableProperties.hasNext() ) {
							adaptor.addChild(root_1, stream_tableProperties.nextTree());
						}
						stream_tableProperties.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1408:7: KW_SET KW_SERDEPROPERTIES tableProperties
					{
					KW_SET338=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties6301); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET338);

					KW_SERDEPROPERTIES339=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties6303); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES339);

					pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties6305);
					tableProperties340=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties340.getTree());
					// AST REWRITE
					// elements: tableProperties
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1409:5: -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1409:8: ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SERDEPROPERTIES, "TOK_ALTERTABLE_SERDEPROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixSerdeProperties"


	public static class tablePartitionPrefix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tablePartitionPrefix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1412:1: tablePartitionPrefix : tableName ( partitionSpec )? -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? ) ;
	public final HiveParser.tablePartitionPrefix_return tablePartitionPrefix() throws RecognitionException {
		HiveParser.tablePartitionPrefix_return retval = new HiveParser.tablePartitionPrefix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tableName341 =null;
		ParserRuleReturnScope partitionSpec342 =null;

		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		pushMsg("table partition prefix", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:3: ( tableName ( partitionSpec )? -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:5: tableName ( partitionSpec )?
			{
			pushFollow(FOLLOW_tableName_in_tablePartitionPrefix6342);
			tableName341=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName341.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:15: ( partitionSpec )?
			int alt102=2;
			int LA102_0 = input.LA(1);
			if ( (LA102_0==KW_PARTITION) ) {
				alt102=1;
			}
			switch (alt102) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:15: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_tablePartitionPrefix6344);
					partitionSpec342=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec342.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableName, partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1416:3: -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1416:5: ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_PARTITION, "TOK_TABLE_PARTITION"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1416:37: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tablePartitionPrefix"


	public static class alterStatementSuffixFileFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixFileFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1419:1: alterStatementSuffixFileFormat : KW_SET KW_FILEFORMAT fileFormat -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) ;
	public final HiveParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat() throws RecognitionException {
		HiveParser.alterStatementSuffixFileFormat_return retval = new HiveParser.alterStatementSuffixFileFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET343=null;
		Token KW_FILEFORMAT344=null;
		ParserRuleReturnScope fileFormat345 =null;

		ASTNode KW_SET343_tree=null;
		ASTNode KW_FILEFORMAT344_tree=null;
		RewriteRuleTokenStream stream_KW_FILEFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FILEFORMAT");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_fileFormat=new RewriteRuleSubtreeStream(adaptor,"rule fileFormat");

		pushMsg("alter fileformat statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1422:2: ( KW_SET KW_FILEFORMAT fileFormat -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1422:4: KW_SET KW_FILEFORMAT fileFormat
			{
			KW_SET343=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixFileFormat6379); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET343);

			KW_FILEFORMAT344=(Token)match(input,KW_FILEFORMAT,FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat6381); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FILEFORMAT.add(KW_FILEFORMAT344);

			pushFollow(FOLLOW_fileFormat_in_alterStatementSuffixFileFormat6383);
			fileFormat345=fileFormat();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_fileFormat.add(fileFormat345.getTree());
			// AST REWRITE
			// elements: fileFormat
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1423:2: -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1423:5: ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_FILEFORMAT, "TOK_ALTERTABLE_FILEFORMAT"), root_1);
				adaptor.addChild(root_1, stream_fileFormat.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixFileFormat"


	public static class alterStatementSuffixClusterbySortby_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixClusterbySortby"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1426:1: alterStatementSuffixClusterbySortby : ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) );
	public final HiveParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby() throws RecognitionException {
		HiveParser.alterStatementSuffixClusterbySortby_return retval = new HiveParser.alterStatementSuffixClusterbySortby_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_NOT346=null;
		Token KW_CLUSTERED347=null;
		Token KW_NOT348=null;
		Token KW_SORTED349=null;
		ParserRuleReturnScope tableBuckets350 =null;

		ASTNode KW_NOT346_tree=null;
		ASTNode KW_CLUSTERED347_tree=null;
		ASTNode KW_NOT348_tree=null;
		ASTNode KW_SORTED349_tree=null;
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
		RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
		RewriteRuleSubtreeStream stream_tableBuckets=new RewriteRuleSubtreeStream(adaptor,"rule tableBuckets");

		pushMsg("alter partition cluster by sort by statement", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:3: ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) )
			int alt103=3;
			int LA103_0 = input.LA(1);
			if ( (LA103_0==KW_NOT) ) {
				int LA103_1 = input.LA(2);
				if ( (LA103_1==KW_CLUSTERED) ) {
					alt103=1;
				}
				else if ( (LA103_1==KW_SORTED) ) {
					alt103=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 103, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( (LA103_0==KW_CLUSTERED) ) {
				alt103=3;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 103, 0, input);
				throw nvae;
			}

			switch (alt103) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:5: KW_NOT KW_CLUSTERED
					{
					KW_NOT346=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6414); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT346);

					KW_CLUSTERED347=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby6416); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CLUSTERED.add(KW_CLUSTERED347);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1429:25: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:28: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);
						adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_NOT_CLUSTERED, "TOK_NOT_CLUSTERED"));
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1430:5: KW_NOT KW_SORTED
					{
					KW_NOT348=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6430); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT348);

					KW_SORTED349=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby6432); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED349);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1430:22: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1430:25: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);
						adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_NOT_SORTED, "TOK_NOT_SORTED"));
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:5: tableBuckets
					{
					pushFollow(FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby6446);
					tableBuckets350=tableBuckets();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableBuckets.add(tableBuckets350.getTree());
					// AST REWRITE
					// elements: tableBuckets
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1431:18: -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:21: ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);
						adaptor.addChild(root_1, stream_tableBuckets.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixClusterbySortby"


	public static class alterTblPartitionStatementSuffixSkewedLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterTblPartitionStatementSuffixSkewedLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:1: alterTblPartitionStatementSuffixSkewedLocation : KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations ) ;
	public final HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation() throws RecognitionException {
		HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return retval = new HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET351=null;
		Token KW_SKEWED352=null;
		Token KW_LOCATION353=null;
		ParserRuleReturnScope skewedLocations354 =null;

		ASTNode KW_SET351_tree=null;
		ASTNode KW_SKEWED352_tree=null;
		ASTNode KW_LOCATION353_tree=null;
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");
		RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_skewedLocations=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocations");

		pushMsg("alter partition skewed location", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1437:3: ( KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1437:5: KW_SET KW_SKEWED KW_LOCATION skewedLocations
			{
			KW_SET351=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation6477); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET351);

			KW_SKEWED352=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation6479); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SKEWED.add(KW_SKEWED352);

			KW_LOCATION353=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation6481); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION353);

			pushFollow(FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation6483);
			skewedLocations354=skewedLocations();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedLocations.add(skewedLocations354.getTree());
			// AST REWRITE
			// elements: skewedLocations
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1438:3: -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:6: ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED_LOCATION, "TOK_ALTERTABLE_SKEWED_LOCATION"), root_1);
				adaptor.addChild(root_1, stream_skewedLocations.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterTblPartitionStatementSuffixSkewedLocation"


	public static class skewedLocations_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedLocations"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:1: skewedLocations : LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) ;
	public final HiveParser.skewedLocations_return skewedLocations() throws RecognitionException {
		HiveParser.skewedLocations_return retval = new HiveParser.skewedLocations_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN355=null;
		Token RPAREN357=null;
		ParserRuleReturnScope skewedLocationsList356 =null;

		ASTNode LPAREN355_tree=null;
		ASTNode RPAREN357_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_skewedLocationsList=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocationsList");

		 pushMsg("skewed locations", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1444:5: ( LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:7: LPAREN skewedLocationsList RPAREN
			{
			LPAREN355=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_skewedLocations6526); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN355);

			pushFollow(FOLLOW_skewedLocationsList_in_skewedLocations6528);
			skewedLocationsList356=skewedLocationsList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedLocationsList.add(skewedLocationsList356.getTree());
			RPAREN357=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_skewedLocations6530); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN357);

			// AST REWRITE
			// elements: skewedLocationsList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1445:41: -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:44: ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SKEWED_LOCATIONS, "TOK_SKEWED_LOCATIONS"), root_1);
				adaptor.addChild(root_1, stream_skewedLocationsList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedLocations"


	public static class skewedLocationsList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedLocationsList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:1: skewedLocationsList : skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) ;
	public final HiveParser.skewedLocationsList_return skewedLocationsList() throws RecognitionException {
		HiveParser.skewedLocationsList_return retval = new HiveParser.skewedLocationsList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA359=null;
		ParserRuleReturnScope skewedLocationMap358 =null;
		ParserRuleReturnScope skewedLocationMap360 =null;

		ASTNode COMMA359_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_skewedLocationMap=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocationMap");

		 pushMsg("skewed locations list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1451:5: ( skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1452:7: skewedLocationMap ( COMMA skewedLocationMap )*
			{
			pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList6571);
			skewedLocationMap358=skewedLocationMap();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedLocationMap.add(skewedLocationMap358.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1452:25: ( COMMA skewedLocationMap )*
			loop104:
			while (true) {
				int alt104=2;
				int LA104_0 = input.LA(1);
				if ( (LA104_0==COMMA) ) {
					alt104=1;
				}

				switch (alt104) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1452:26: COMMA skewedLocationMap
					{
					COMMA359=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedLocationsList6574); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA359);

					pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList6576);
					skewedLocationMap360=skewedLocationMap();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_skewedLocationMap.add(skewedLocationMap360.getTree());
					}
					break;

				default :
					break loop104;
				}
			}

			// AST REWRITE
			// elements: skewedLocationMap
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1452:52: -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1452:55: ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SKEWED_LOCATION_LIST, "TOK_SKEWED_LOCATION_LIST"), root_1);
				if ( !(stream_skewedLocationMap.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_skewedLocationMap.hasNext() ) {
					adaptor.addChild(root_1, stream_skewedLocationMap.nextTree());
				}
				stream_skewedLocationMap.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedLocationsList"


	public static class skewedLocationMap_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedLocationMap"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1455:1: skewedLocationMap : key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) ;
	public final HiveParser.skewedLocationMap_return skewedLocationMap() throws RecognitionException {
		HiveParser.skewedLocationMap_return retval = new HiveParser.skewedLocationMap_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token value=null;
		Token EQUAL361=null;
		ParserRuleReturnScope key =null;

		ASTNode value_tree=null;
		ASTNode EQUAL361_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");
		RewriteRuleSubtreeStream stream_skewedValueLocationElement=new RewriteRuleSubtreeStream(adaptor,"rule skewedValueLocationElement");

		 pushMsg("specifying skewed location map", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1458:5: (key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1459:7: key= skewedValueLocationElement EQUAL value= StringLiteral
			{
			pushFollow(FOLLOW_skewedValueLocationElement_in_skewedLocationMap6622);
			key=skewedValueLocationElement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedValueLocationElement.add(key.getTree());
			EQUAL361=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_skewedLocationMap6624); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL361);

			value=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_skewedLocationMap6628); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(value);

			// AST REWRITE
			// elements: key, value
			// token labels: value
			// rule labels: key, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
			RewriteRuleSubtreeStream stream_key=new RewriteRuleSubtreeStream(adaptor,"rule key",key!=null?key.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1459:64: -> ^( TOK_SKEWED_LOCATION_MAP $key $value)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1459:67: ^( TOK_SKEWED_LOCATION_MAP $key $value)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SKEWED_LOCATION_MAP, "TOK_SKEWED_LOCATION_MAP"), root_1);
				adaptor.addChild(root_1, stream_key.nextTree());
				adaptor.addChild(root_1, stream_value.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedLocationMap"


	public static class alterStatementSuffixLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:1: alterStatementSuffixLocation : KW_SET KW_LOCATION newLoc= StringLiteral -> ^( TOK_ALTERTABLE_LOCATION $newLoc) ;
	public final HiveParser.alterStatementSuffixLocation_return alterStatementSuffixLocation() throws RecognitionException {
		HiveParser.alterStatementSuffixLocation_return retval = new HiveParser.alterStatementSuffixLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token newLoc=null;
		Token KW_SET362=null;
		Token KW_LOCATION363=null;

		ASTNode newLoc_tree=null;
		ASTNode KW_SET362_tree=null;
		ASTNode KW_LOCATION363_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");

		pushMsg("alter location", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1465:3: ( KW_SET KW_LOCATION newLoc= StringLiteral -> ^( TOK_ALTERTABLE_LOCATION $newLoc) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1465:5: KW_SET KW_LOCATION newLoc= StringLiteral
			{
			KW_SET362=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixLocation6665); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET362);

			KW_LOCATION363=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_alterStatementSuffixLocation6667); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION363);

			newLoc=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixLocation6671); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(newLoc);

			// AST REWRITE
			// elements: newLoc
			// token labels: newLoc
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_newLoc=new RewriteRuleTokenStream(adaptor,"token newLoc",newLoc);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1466:3: -> ^( TOK_ALTERTABLE_LOCATION $newLoc)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:6: ^( TOK_ALTERTABLE_LOCATION $newLoc)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_LOCATION, "TOK_ALTERTABLE_LOCATION"), root_1);
				adaptor.addChild(root_1, stream_newLoc.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixLocation"


	public static class alterStatementSuffixSkewedby_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixSkewedby"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1470:1: alterStatementSuffixSkewedby : ( tableSkewed -> ^( TOK_ALTERTABLE_SKEWED tableSkewed ) | KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED ) | KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs ) );
	public final HiveParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby() throws RecognitionException {
		HiveParser.alterStatementSuffixSkewedby_return retval = new HiveParser.alterStatementSuffixSkewedby_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_NOT365=null;
		Token KW_SKEWED366=null;
		Token KW_NOT367=null;
		ParserRuleReturnScope tableSkewed364 =null;
		ParserRuleReturnScope storedAsDirs368 =null;

		ASTNode KW_NOT365_tree=null;
		ASTNode KW_SKEWED366_tree=null;
		ASTNode KW_NOT367_tree=null;
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
		RewriteRuleSubtreeStream stream_tableSkewed=new RewriteRuleSubtreeStream(adaptor,"rule tableSkewed");
		RewriteRuleSubtreeStream stream_storedAsDirs=new RewriteRuleSubtreeStream(adaptor,"rule storedAsDirs");

		pushMsg("alter skewed by statement", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1473:2: ( tableSkewed -> ^( TOK_ALTERTABLE_SKEWED tableSkewed ) | KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED ) | KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs ) )
			int alt105=3;
			int LA105_0 = input.LA(1);
			if ( (LA105_0==KW_SKEWED) ) {
				alt105=1;
			}
			else if ( (LA105_0==KW_NOT) ) {
				int LA105_2 = input.LA(2);
				if ( (LA105_2==KW_SKEWED) ) {
					alt105=2;
				}
				else if ( (LA105_2==KW_STORED) ) {
					alt105=3;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 105, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 105, 0, input);
				throw nvae;
			}

			switch (alt105) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1473:4: tableSkewed
					{
					pushFollow(FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby6705);
					tableSkewed364=tableSkewed();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableSkewed.add(tableSkewed364.getTree());
					// AST REWRITE
					// elements: tableSkewed
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1474:2: -> ^( TOK_ALTERTABLE_SKEWED tableSkewed )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1474:4: ^( TOK_ALTERTABLE_SKEWED tableSkewed )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);
						adaptor.addChild(root_1, stream_tableSkewed.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:3: KW_NOT KW_SKEWED
					{
					KW_NOT365=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby6720); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT365);

					KW_SKEWED366=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby6722); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SKEWED.add(KW_SKEWED366);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1477:2: -> ^( TOK_ALTERTABLE_SKEWED )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:4: ^( TOK_ALTERTABLE_SKEWED )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1479:3: KW_NOT storedAsDirs
					{
					KW_NOT367=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby6735); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT367);

					pushFollow(FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby6737);
					storedAsDirs368=storedAsDirs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_storedAsDirs.add(storedAsDirs368.getTree());
					// AST REWRITE
					// elements: storedAsDirs
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1480:2: -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1480:4: ^( TOK_ALTERTABLE_SKEWED storedAsDirs )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);
						adaptor.addChild(root_1, stream_storedAsDirs.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixSkewedby"


	public static class alterStatementSuffixExchangePartition_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixExchangePartition"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1483:1: alterStatementSuffixExchangePartition : KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename) ;
	public final HiveParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition() throws RecognitionException {
		HiveParser.alterStatementSuffixExchangePartition_return retval = new HiveParser.alterStatementSuffixExchangePartition_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_EXCHANGE369=null;
		Token KW_WITH371=null;
		Token KW_TABLE372=null;
		ParserRuleReturnScope exchangename =null;
		ParserRuleReturnScope partitionSpec370 =null;

		ASTNode KW_EXCHANGE369_tree=null;
		ASTNode KW_WITH371_tree=null;
		ASTNode KW_TABLE372_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_EXCHANGE=new RewriteRuleTokenStream(adaptor,"token KW_EXCHANGE");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		pushMsg("alter exchange partition", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1486:5: ( KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1486:7: KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName
			{
			KW_EXCHANGE369=(Token)match(input,KW_EXCHANGE,FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition6768); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXCHANGE.add(KW_EXCHANGE369);

			pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition6770);
			partitionSpec370=partitionSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec370.getTree());
			KW_WITH371=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition6772); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH371);

			KW_TABLE372=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition6774); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE372);

			pushFollow(FOLLOW_tableName_in_alterStatementSuffixExchangePartition6778);
			exchangename=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(exchangename.getTree());
			// AST REWRITE
			// elements: exchangename, partitionSpec
			// token labels: 
			// rule labels: exchangename, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_exchangename=new RewriteRuleSubtreeStream(adaptor,"rule exchangename",exchangename!=null?exchangename.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1487:5: -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1487:8: ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_EXCHANGEPARTITION, "TOK_ALTERTABLE_EXCHANGEPARTITION"), root_1);
				adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				adaptor.addChild(root_1, stream_exchangename.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixExchangePartition"


	public static class alterStatementSuffixRenamePart_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixRenamePart"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:1: alterStatementSuffixRenamePart : KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) ;
	public final HiveParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart() throws RecognitionException {
		HiveParser.alterStatementSuffixRenamePart_return retval = new HiveParser.alterStatementSuffixRenamePart_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RENAME373=null;
		Token KW_TO374=null;
		ParserRuleReturnScope partitionSpec375 =null;

		ASTNode KW_RENAME373_tree=null;
		ASTNode KW_TO374_tree=null;
		RewriteRuleTokenStream stream_KW_RENAME=new RewriteRuleTokenStream(adaptor,"token KW_RENAME");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");

		 pushMsg("alter table rename partition statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1493:5: ( KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1493:7: KW_RENAME KW_TO partitionSpec
			{
			KW_RENAME373=(Token)match(input,KW_RENAME,FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart6820); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_RENAME.add(KW_RENAME373);

			KW_TO374=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_alterStatementSuffixRenamePart6822); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO374);

			pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart6824);
			partitionSpec375=partitionSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec375.getTree());
			// AST REWRITE
			// elements: partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1494:5: -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1494:7: ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_RENAMEPART, "TOK_ALTERTABLE_RENAMEPART"), root_1);
				adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixRenamePart"


	public static class alterStatementSuffixStatsPart_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixStatsPart"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1497:1: alterStatementSuffixStatsPart : KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) ;
	public final HiveParser.alterStatementSuffixStatsPart_return alterStatementSuffixStatsPart() throws RecognitionException {
		HiveParser.alterStatementSuffixStatsPart_return retval = new HiveParser.alterStatementSuffixStatsPart_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_UPDATE376=null;
		Token KW_STATISTICS377=null;
		Token KW_FOR378=null;
		Token KW_COLUMN379=null;
		Token KW_SET380=null;
		Token KW_COMMENT382=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope tableProperties381 =null;

		ASTNode comment_tree=null;
		ASTNode KW_UPDATE376_tree=null;
		ASTNode KW_STATISTICS377_tree=null;
		ASTNode KW_FOR378_tree=null;
		ASTNode KW_COLUMN379_tree=null;
		ASTNode KW_SET380_tree=null;
		ASTNode KW_COMMENT382_tree=null;
		RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("alter table stats partition statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:5: ( KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:7: KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )?
			{
			KW_UPDATE376=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixStatsPart6862); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE376);

			KW_STATISTICS377=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_alterStatementSuffixStatsPart6864); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS377);

			KW_FOR378=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_alterStatementSuffixStatsPart6866); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR378);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:38: ( KW_COLUMN )?
			int alt106=2;
			int LA106_0 = input.LA(1);
			if ( (LA106_0==KW_COLUMN) ) {
				alt106=1;
			}
			switch (alt106) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:38: KW_COLUMN
					{
					KW_COLUMN379=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementSuffixStatsPart6868); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN379);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_alterStatementSuffixStatsPart6873);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			KW_SET380=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixStatsPart6875); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET380);

			pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixStatsPart6877);
			tableProperties381=tableProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties381.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:91: ( KW_COMMENT comment= StringLiteral )?
			int alt107=2;
			int LA107_0 = input.LA(1);
			if ( (LA107_0==KW_COMMENT) ) {
				alt107=1;
			}
			switch (alt107) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:92: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT382=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_alterStatementSuffixStatsPart6880); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT382);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixStatsPart6884); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: tableProperties, comment, colName
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1501:5: -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1501:7: ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATECOLSTATS, "TOK_ALTERTABLE_UPDATECOLSTATS"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_tableProperties.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1501:65: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixStatsPart"


	public static class alterStatementSuffixMergeFiles_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixMergeFiles"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:1: alterStatementSuffixMergeFiles : KW_CONCATENATE -> ^( TOK_ALTERTABLE_MERGEFILES ) ;
	public final HiveParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles() throws RecognitionException {
		HiveParser.alterStatementSuffixMergeFiles_return retval = new HiveParser.alterStatementSuffixMergeFiles_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONCATENATE383=null;

		ASTNode KW_CONCATENATE383_tree=null;
		RewriteRuleTokenStream stream_KW_CONCATENATE=new RewriteRuleTokenStream(adaptor,"token KW_CONCATENATE");

		 pushMsg("", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1507:5: ( KW_CONCATENATE -> ^( TOK_ALTERTABLE_MERGEFILES ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1507:7: KW_CONCATENATE
			{
			KW_CONCATENATE383=(Token)match(input,KW_CONCATENATE,FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles6931); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CONCATENATE.add(KW_CONCATENATE383);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1508:5: -> ^( TOK_ALTERTABLE_MERGEFILES )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:8: ^( TOK_ALTERTABLE_MERGEFILES )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_MERGEFILES, "TOK_ALTERTABLE_MERGEFILES"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixMergeFiles"


	public static class alterStatementSuffixBucketNum_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixBucketNum"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:1: alterStatementSuffixBucketNum : KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $num) ;
	public final HiveParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum() throws RecognitionException {
		HiveParser.alterStatementSuffixBucketNum_return retval = new HiveParser.alterStatementSuffixBucketNum_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token num=null;
		Token KW_INTO384=null;
		Token KW_BUCKETS385=null;

		ASTNode num_tree=null;
		ASTNode KW_INTO384_tree=null;
		ASTNode KW_BUCKETS385_tree=null;
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_BUCKETS=new RewriteRuleTokenStream(adaptor,"token KW_BUCKETS");

		 pushMsg("", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:5: ( KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $num) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:7: KW_INTO num= Number KW_BUCKETS
			{
			KW_INTO384=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum6968); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO384);

			num=(Token)match(input,Number,FOLLOW_Number_in_alterStatementSuffixBucketNum6972); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Number.add(num);

			KW_BUCKETS385=(Token)match(input,KW_BUCKETS,FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum6974); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BUCKETS.add(KW_BUCKETS385);

			// AST REWRITE
			// elements: num
			// token labels: num
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1515:5: -> ^( TOK_ALTERTABLE_BUCKETS $num)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1515:8: ^( TOK_ALTERTABLE_BUCKETS $num)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS"), root_1);
				adaptor.addChild(root_1, stream_num.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixBucketNum"


	public static class blocking_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "blocking"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:1: blocking : KW_AND KW_WAIT -> TOK_BLOCKING ;
	public final HiveParser.blocking_return blocking() throws RecognitionException {
		HiveParser.blocking_return retval = new HiveParser.blocking_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_AND386=null;
		Token KW_WAIT387=null;

		ASTNode KW_AND386_tree=null;
		ASTNode KW_WAIT387_tree=null;
		RewriteRuleTokenStream stream_KW_WAIT=new RewriteRuleTokenStream(adaptor,"token KW_WAIT");
		RewriteRuleTokenStream stream_KW_AND=new RewriteRuleTokenStream(adaptor,"token KW_AND");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:3: ( KW_AND KW_WAIT -> TOK_BLOCKING )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:5: KW_AND KW_WAIT
			{
			KW_AND386=(Token)match(input,KW_AND,FOLLOW_KW_AND_in_blocking7002); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AND.add(KW_AND386);

			KW_WAIT387=(Token)match(input,KW_WAIT,FOLLOW_KW_WAIT_in_blocking7004); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WAIT.add(KW_WAIT387);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1520:3: -> TOK_BLOCKING
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BLOCKING, "TOK_BLOCKING"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "blocking"


	public static class alterStatementSuffixCompact_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixCompact"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1523:1: alterStatementSuffixCompact : KW_COMPACT compactType= StringLiteral ( blocking )? ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_COMPACT $compactType ( blocking )? ( tableProperties )? ) ;
	public final HiveParser.alterStatementSuffixCompact_return alterStatementSuffixCompact() throws RecognitionException {
		HiveParser.alterStatementSuffixCompact_return retval = new HiveParser.alterStatementSuffixCompact_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token compactType=null;
		Token KW_COMPACT388=null;
		Token KW_WITH390=null;
		Token KW_OVERWRITE391=null;
		Token KW_TBLPROPERTIES392=null;
		ParserRuleReturnScope blocking389 =null;
		ParserRuleReturnScope tableProperties393 =null;

		ASTNode compactType_tree=null;
		ASTNode KW_COMPACT388_tree=null;
		ASTNode KW_WITH390_tree=null;
		ASTNode KW_OVERWRITE391_tree=null;
		ASTNode KW_TBLPROPERTIES392_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_COMPACT=new RewriteRuleTokenStream(adaptor,"token KW_COMPACT");
		RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
		RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
		RewriteRuleSubtreeStream stream_blocking=new RewriteRuleSubtreeStream(adaptor,"rule blocking");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 msgs.push("compaction request"); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1526:5: ( KW_COMPACT compactType= StringLiteral ( blocking )? ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_COMPACT $compactType ( blocking )? ( tableProperties )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1526:7: KW_COMPACT compactType= StringLiteral ( blocking )? ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )?
			{
			KW_COMPACT388=(Token)match(input,KW_COMPACT,FOLLOW_KW_COMPACT_in_alterStatementSuffixCompact7035); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMPACT.add(KW_COMPACT388);

			compactType=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixCompact7039); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(compactType);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1526:44: ( blocking )?
			int alt108=2;
			int LA108_0 = input.LA(1);
			if ( (LA108_0==KW_AND) ) {
				alt108=1;
			}
			switch (alt108) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1526:44: blocking
					{
					pushFollow(FOLLOW_blocking_in_alterStatementSuffixCompact7041);
					blocking389=blocking();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_blocking.add(blocking389.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1526:54: ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )?
			int alt109=2;
			int LA109_0 = input.LA(1);
			if ( (LA109_0==KW_WITH) ) {
				alt109=1;
			}
			switch (alt109) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1526:55: KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties
					{
					KW_WITH390=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixCompact7045); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH390);

					KW_OVERWRITE391=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_alterStatementSuffixCompact7047); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(KW_OVERWRITE391);

					KW_TBLPROPERTIES392=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixCompact7049); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES392);

					pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixCompact7051);
					tableProperties393=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties393.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: compactType, blocking, tableProperties
			// token labels: compactType
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_compactType=new RewriteRuleTokenStream(adaptor,"token compactType",compactType);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1527:5: -> ^( TOK_ALTERTABLE_COMPACT $compactType ( blocking )? ( tableProperties )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:8: ^( TOK_ALTERTABLE_COMPACT $compactType ( blocking )? ( tableProperties )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_COMPACT, "TOK_ALTERTABLE_COMPACT"), root_1);
				adaptor.addChild(root_1, stream_compactType.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:46: ( blocking )?
				if ( stream_blocking.hasNext() ) {
					adaptor.addChild(root_1, stream_blocking.nextTree());
				}
				stream_blocking.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:56: ( tableProperties )?
				if ( stream_tableProperties.hasNext() ) {
					adaptor.addChild(root_1, stream_tableProperties.nextTree());
				}
				stream_tableProperties.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { msgs.pop(); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixCompact"


	public static class alterStatementSuffixSetOwner_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixSetOwner"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1530:1: alterStatementSuffixSetOwner : KW_SET KW_OWNER principalName -> ^( TOK_ALTERTABLE_OWNER principalName ) ;
	public final HiveParser.alterStatementSuffixSetOwner_return alterStatementSuffixSetOwner() throws RecognitionException {
		HiveParser.alterStatementSuffixSetOwner_return retval = new HiveParser.alterStatementSuffixSetOwner_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET394=null;
		Token KW_OWNER395=null;
		ParserRuleReturnScope principalName396 =null;

		ASTNode KW_SET394_tree=null;
		ASTNode KW_OWNER395_tree=null;
		RewriteRuleTokenStream stream_KW_OWNER=new RewriteRuleTokenStream(adaptor,"token KW_OWNER");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		 pushMsg("alter table set owner", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1533:5: ( KW_SET KW_OWNER principalName -> ^( TOK_ALTERTABLE_OWNER principalName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1533:7: KW_SET KW_OWNER principalName
			{
			KW_SET394=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixSetOwner7099); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET394);

			KW_OWNER395=(Token)match(input,KW_OWNER,FOLLOW_KW_OWNER_in_alterStatementSuffixSetOwner7101); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OWNER.add(KW_OWNER395);

			pushFollow(FOLLOW_principalName_in_alterStatementSuffixSetOwner7103);
			principalName396=principalName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalName.add(principalName396.getTree());
			// AST REWRITE
			// elements: principalName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1534:5: -> ^( TOK_ALTERTABLE_OWNER principalName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1534:8: ^( TOK_ALTERTABLE_OWNER principalName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_OWNER, "TOK_ALTERTABLE_OWNER"), root_1);
				adaptor.addChild(root_1, stream_principalName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixSetOwner"


	public static class fileFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "fileFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1537:1: fileFormat : ( KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
	public final HiveParser.fileFormat_return fileFormat() throws RecognitionException {
		HiveParser.fileFormat_return retval = new HiveParser.fileFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token inFmt=null;
		Token outFmt=null;
		Token serdeCls=null;
		Token inDriver=null;
		Token outDriver=null;
		Token KW_INPUTFORMAT397=null;
		Token KW_OUTPUTFORMAT398=null;
		Token KW_SERDE399=null;
		Token KW_INPUTDRIVER400=null;
		Token KW_OUTPUTDRIVER401=null;
		ParserRuleReturnScope genericSpec =null;

		ASTNode inFmt_tree=null;
		ASTNode outFmt_tree=null;
		ASTNode serdeCls_tree=null;
		ASTNode inDriver_tree=null;
		ASTNode outDriver_tree=null;
		ASTNode KW_INPUTFORMAT397_tree=null;
		ASTNode KW_OUTPUTFORMAT398_tree=null;
		ASTNode KW_SERDE399_tree=null;
		ASTNode KW_INPUTDRIVER400_tree=null;
		ASTNode KW_OUTPUTDRIVER401_tree=null;
		RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_INPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_INPUTDRIVER");
		RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
		RewriteRuleTokenStream stream_KW_OUTPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTFORMAT");
		RewriteRuleTokenStream stream_KW_OUTPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTDRIVER");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("file format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1540:5: ( KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
			int alt111=2;
			int LA111_0 = input.LA(1);
			if ( (LA111_0==KW_INPUTFORMAT) ) {
				int LA111_1 = input.LA(2);
				if ( (LA111_1==StringLiteral) ) {
					alt111=1;
				}
				else if ( (LA111_1==EOF) ) {
					alt111=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 111, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( (LA111_0==Identifier||(LA111_0 >= KW_ABORT && LA111_0 <= KW_AFTER)||LA111_0==KW_ALLOC_FRACTION||LA111_0==KW_ANALYZE||LA111_0==KW_ARCHIVE||LA111_0==KW_ASC||(LA111_0 >= KW_AUTOCOMMIT && LA111_0 <= KW_BEFORE)||(LA111_0 >= KW_BUCKET && LA111_0 <= KW_BUCKETS)||(LA111_0 >= KW_CACHE && LA111_0 <= KW_CASCADE)||(LA111_0 >= KW_CBO && LA111_0 <= KW_CHANGE)||(LA111_0 >= KW_CHECK && LA111_0 <= KW_COLLECTION)||(LA111_0 >= KW_COLUMNS && LA111_0 <= KW_COMMENT)||(LA111_0 >= KW_COMPACT && LA111_0 <= KW_CONCATENATE)||(LA111_0 >= KW_CONTINUE && LA111_0 <= KW_COST)||LA111_0==KW_DATA||LA111_0==KW_DATABASES||(LA111_0 >= KW_DATETIME && LA111_0 <= KW_DEBUG)||(LA111_0 >= KW_DEFAULT && LA111_0 <= KW_DEFINED)||(LA111_0 >= KW_DELIMITED && LA111_0 <= KW_DESC)||(LA111_0 >= KW_DETAIL && LA111_0 <= KW_DISABLE)||(LA111_0 >= KW_DISTRIBUTE && LA111_0 <= KW_DO)||LA111_0==KW_DOW||(LA111_0 >= KW_DUMP && LA111_0 <= KW_ELEM_TYPE)||LA111_0==KW_ENABLE||(LA111_0 >= KW_ENFORCED && LA111_0 <= KW_ESCAPED)||LA111_0==KW_EXCLUSIVE||(LA111_0 >= KW_EXPLAIN && LA111_0 <= KW_EXPRESSION)||(LA111_0 >= KW_FIELDS && LA111_0 <= KW_FIRST)||(LA111_0 >= KW_FORMAT && LA111_0 <= KW_FORMATTED)||LA111_0==KW_FUNCTIONS||(LA111_0 >= KW_HOUR && LA111_0 <= KW_IDXPROPERTIES)||(LA111_0 >= KW_INDEX && LA111_0 <= KW_INDEXES)||(LA111_0 >= KW_INPATH && LA111_0 <= KW_INPUTDRIVER)||(LA111_0 >= KW_ISOLATION && LA111_0 <= KW_JAR)||(LA111_0 >= KW_JOINCOST && LA111_0 <= KW_LAST)||LA111_0==KW_LEVEL||(LA111_0 >= KW_LIMIT && LA111_0 <= KW_LOAD)||(LA111_0 >= KW_LOCATION && LA111_0 <= KW_LONG)||LA111_0==KW_MANAGEMENT||(LA111_0 >= KW_MAPJOIN && LA111_0 <= KW_MATERIALIZED)||LA111_0==KW_METADATA||(LA111_0 >= KW_MINUTE && LA111_0 <= KW_MONTH)||(LA111_0 >= KW_MOVE && LA111_0 <= KW_MSCK)||(LA111_0 >= KW_NORELY && LA111_0 <= KW_NOSCAN)||LA111_0==KW_NOVALIDATE||LA111_0==KW_NULLS||LA111_0==KW_OFFSET||(LA111_0 >= KW_OPERATOR && LA111_0 <= KW_OPTION)||(LA111_0 >= KW_OUTPUTDRIVER && LA111_0 <= KW_OUTPUTFORMAT)||(LA111_0 >= KW_OVERWRITE && LA111_0 <= KW_OWNER)||(LA111_0 >= KW_PARTITIONED && LA111_0 <= KW_PATH)||(LA111_0 >= KW_PLAN && LA111_0 <= KW_POOL)||LA111_0==KW_PRINCIPALS||(LA111_0 >= KW_PURGE && LA111_0 <= KW_QUERY_PARALLELISM)||LA111_0==KW_READ||(LA111_0 >= KW_REBUILD && LA111_0 <= KW_RECORDWRITER)||(LA111_0 >= KW_RELOAD && LA111_0 <= KW_RESTRICT)||LA111_0==KW_REWRITE||(LA111_0 >= KW_ROLE && LA111_0 <= KW_ROLES)||(LA111_0 >= KW_SCHEDULING_POLICY && LA111_0 <= KW_SECOND)||(LA111_0 >= KW_SEMI && LA111_0 <= KW_SERVER)||(LA111_0 >= KW_SETS && LA111_0 <= KW_SKEWED)||(LA111_0 >= KW_SNAPSHOT && LA111_0 <= KW_SSL)||(LA111_0 >= KW_STATISTICS && LA111_0 <= KW_SUMMARY)||LA111_0==KW_TABLES||(LA111_0 >= KW_TBLPROPERTIES && LA111_0 <= KW_TERMINATED)||LA111_0==KW_TINYINT||(LA111_0 >= KW_TOUCH && LA111_0 <= KW_TRANSACTIONS)||LA111_0==KW_UNARCHIVE||LA111_0==KW_UNDO||LA111_0==KW_UNIONTYPE||(LA111_0 >= KW_UNLOCK && LA111_0 <= KW_UNSIGNED)||(LA111_0 >= KW_URI && LA111_0 <= KW_USE)||(LA111_0 >= KW_UTC && LA111_0 <= KW_VALIDATE)||LA111_0==KW_VALUE_TYPE||(LA111_0 >= KW_VECTORIZATION && LA111_0 <= KW_WEEK)||LA111_0==KW_WHILE||(LA111_0 >= KW_WORK && LA111_0 <= KW_ZONE)||LA111_0==KW_BATCH||LA111_0==KW_DAYOFWEEK||LA111_0==KW_HOLD_DDLTIME||LA111_0==KW_IGNORE||LA111_0==KW_NO_DROP||LA111_0==KW_OFFLINE||LA111_0==KW_PROTECTION||LA111_0==KW_READONLY||LA111_0==KW_TIMESTAMPTZ) ) {
				alt111=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 111, 0, input);
				throw nvae;
			}

			switch (alt111) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1540:7: KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
					{
					KW_INPUTFORMAT397=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_fileFormat7142); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT397);

					inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat7146); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(inFmt);

					KW_OUTPUTFORMAT398=(Token)match(input,KW_OUTPUTFORMAT,FOLLOW_KW_OUTPUTFORMAT_in_fileFormat7148); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT398);

					outFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat7152); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(outFmt);

					KW_SERDE399=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_fileFormat7154); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE399);

					serdeCls=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat7158); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(serdeCls);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1540:111: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
					int alt110=2;
					int LA110_0 = input.LA(1);
					if ( (LA110_0==KW_INPUTDRIVER) ) {
						alt110=1;
					}
					switch (alt110) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1540:112: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
							{
							KW_INPUTDRIVER400=(Token)match(input,KW_INPUTDRIVER,FOLLOW_KW_INPUTDRIVER_in_fileFormat7161); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER400);

							inDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat7165); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(inDriver);

							KW_OUTPUTDRIVER401=(Token)match(input,KW_OUTPUTDRIVER,FOLLOW_KW_OUTPUTDRIVER_in_fileFormat7167); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER401);

							outDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat7171); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(outDriver);

							}
							break;

					}

					// AST REWRITE
					// elements: outFmt, inDriver, inFmt, serdeCls, outDriver
					// token labels: inFmt, inDriver, serdeCls, outDriver, outFmt
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
					RewriteRuleTokenStream stream_inDriver=new RewriteRuleTokenStream(adaptor,"token inDriver",inDriver);
					RewriteRuleTokenStream stream_serdeCls=new RewriteRuleTokenStream(adaptor,"token serdeCls",serdeCls);
					RewriteRuleTokenStream stream_outDriver=new RewriteRuleTokenStream(adaptor,"token outDriver",outDriver);
					RewriteRuleTokenStream stream_outFmt=new RewriteRuleTokenStream(adaptor,"token outFmt",outFmt);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1541:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1541:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT"), root_1);
						adaptor.addChild(root_1, stream_inFmt.nextNode());
						adaptor.addChild(root_1, stream_outFmt.nextNode());
						adaptor.addChild(root_1, stream_serdeCls.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1541:58: ( $inDriver)?
						if ( stream_inDriver.hasNext() ) {
							adaptor.addChild(root_1, stream_inDriver.nextNode());
						}
						stream_inDriver.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1541:69: ( $outDriver)?
						if ( stream_outDriver.hasNext() ) {
							adaptor.addChild(root_1, stream_outDriver.nextNode());
						}
						stream_outDriver.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:7: genericSpec= identifier
					{
					pushFollow(FOLLOW_identifier_in_fileFormat7212);
					genericSpec=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(genericSpec.getTree());
					// AST REWRITE
					// elements: genericSpec
					// token labels: 
					// rule labels: genericSpec, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_genericSpec=new RewriteRuleSubtreeStream(adaptor,"rule genericSpec",genericSpec!=null?genericSpec.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1542:30: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:33: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_1);
						adaptor.addChild(root_1, stream_genericSpec.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "fileFormat"


	public static class inputFileFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "inputFileFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1545:1: inputFileFormat : KW_INPUTFORMAT inFmt= StringLiteral KW_SERDE serdeCls= StringLiteral -> ^( TOK_INPUTFORMAT $inFmt $serdeCls) ;
	public final HiveParser.inputFileFormat_return inputFileFormat() throws RecognitionException {
		HiveParser.inputFileFormat_return retval = new HiveParser.inputFileFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token inFmt=null;
		Token serdeCls=null;
		Token KW_INPUTFORMAT402=null;
		Token KW_SERDE403=null;

		ASTNode inFmt_tree=null;
		ASTNode serdeCls_tree=null;
		ASTNode KW_INPUTFORMAT402_tree=null;
		ASTNode KW_SERDE403_tree=null;
		RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");

		 pushMsg("Load Data input file format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1548:5: ( KW_INPUTFORMAT inFmt= StringLiteral KW_SERDE serdeCls= StringLiteral -> ^( TOK_INPUTFORMAT $inFmt $serdeCls) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1548:7: KW_INPUTFORMAT inFmt= StringLiteral KW_SERDE serdeCls= StringLiteral
			{
			KW_INPUTFORMAT402=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_inputFileFormat7248); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT402);

			inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_inputFileFormat7252); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(inFmt);

			KW_SERDE403=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_inputFileFormat7254); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE403);

			serdeCls=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_inputFileFormat7258); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(serdeCls);

			// AST REWRITE
			// elements: inFmt, serdeCls
			// token labels: inFmt, serdeCls
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
			RewriteRuleTokenStream stream_serdeCls=new RewriteRuleTokenStream(adaptor,"token serdeCls",serdeCls);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1549:7: -> ^( TOK_INPUTFORMAT $inFmt $serdeCls)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1549:10: ^( TOK_INPUTFORMAT $inFmt $serdeCls)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INPUTFORMAT, "TOK_INPUTFORMAT"), root_1);
				adaptor.addChild(root_1, stream_inFmt.nextNode());
				adaptor.addChild(root_1, stream_serdeCls.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "inputFileFormat"


	public static class tabTypeExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tabTypeExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1552:1: tabTypeExpr : identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )? ;
	public final HiveParser.tabTypeExpr_return tabTypeExpr() throws RecognitionException {
		HiveParser.tabTypeExpr_return retval = new HiveParser.tabTypeExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token DOT405=null;
		Token DOT408=null;
		Token KW_ELEM_TYPE409=null;
		Token KW_KEY_TYPE410=null;
		Token KW_VALUE_TYPE411=null;
		ParserRuleReturnScope identifier404 =null;
		ParserRuleReturnScope identifier406 =null;
		ParserRuleReturnScope identifier407 =null;
		ParserRuleReturnScope identifier412 =null;

		ASTNode DOT405_tree=null;
		ASTNode DOT408_tree=null;
		ASTNode KW_ELEM_TYPE409_tree=null;
		ASTNode KW_KEY_TYPE410_tree=null;
		ASTNode KW_VALUE_TYPE411_tree=null;

		 pushMsg("specifying table types", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1555:4: ( identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1555:6: identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_identifier_in_tabTypeExpr7302);
			identifier404=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier404.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1555:17: ( DOT ^ identifier )?
			int alt112=2;
			int LA112_0 = input.LA(1);
			if ( (LA112_0==DOT) ) {
				alt112=1;
			}
			switch (alt112) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1555:18: DOT ^ identifier
					{
					DOT405=(Token)match(input,DOT,FOLLOW_DOT_in_tabTypeExpr7305); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					DOT405_tree = (ASTNode)adaptor.create(DOT405);
					root_0 = (ASTNode)adaptor.becomeRoot(DOT405_tree, root_0);
					}

					pushFollow(FOLLOW_identifier_in_tabTypeExpr7308);
					identifier406=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier406.getTree());

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1556:4: ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )?
			int alt115=2;
			int LA115_0 = input.LA(1);
			if ( (LA115_0==Identifier||(LA115_0 >= KW_ABORT && LA115_0 <= KW_AFTER)||LA115_0==KW_ALLOC_FRACTION||LA115_0==KW_ANALYZE||LA115_0==KW_ARCHIVE||LA115_0==KW_ASC||(LA115_0 >= KW_AUTOCOMMIT && LA115_0 <= KW_BEFORE)||(LA115_0 >= KW_BUCKET && LA115_0 <= KW_BUCKETS)||(LA115_0 >= KW_CACHE && LA115_0 <= KW_CASCADE)||(LA115_0 >= KW_CBO && LA115_0 <= KW_CHANGE)||(LA115_0 >= KW_CHECK && LA115_0 <= KW_COLLECTION)||(LA115_0 >= KW_COLUMNS && LA115_0 <= KW_COMMENT)||(LA115_0 >= KW_COMPACT && LA115_0 <= KW_CONCATENATE)||(LA115_0 >= KW_CONTINUE && LA115_0 <= KW_COST)||LA115_0==KW_DATA||LA115_0==KW_DATABASES||(LA115_0 >= KW_DATETIME && LA115_0 <= KW_DEBUG)||(LA115_0 >= KW_DEFAULT && LA115_0 <= KW_DEFINED)||(LA115_0 >= KW_DELIMITED && LA115_0 <= KW_DESC)||(LA115_0 >= KW_DETAIL && LA115_0 <= KW_DISABLE)||(LA115_0 >= KW_DISTRIBUTE && LA115_0 <= KW_DO)||LA115_0==KW_DOW||(LA115_0 >= KW_DUMP && LA115_0 <= KW_ELEM_TYPE)||LA115_0==KW_ENABLE||(LA115_0 >= KW_ENFORCED && LA115_0 <= KW_ESCAPED)||LA115_0==KW_EXCLUSIVE||(LA115_0 >= KW_EXPLAIN && LA115_0 <= KW_EXPRESSION)||(LA115_0 >= KW_FIELDS && LA115_0 <= KW_FIRST)||(LA115_0 >= KW_FORMAT && LA115_0 <= KW_FORMATTED)||LA115_0==KW_FUNCTIONS||(LA115_0 >= KW_HOUR && LA115_0 <= KW_IDXPROPERTIES)||(LA115_0 >= KW_INDEX && LA115_0 <= KW_INDEXES)||(LA115_0 >= KW_INPATH && LA115_0 <= KW_INPUTFORMAT)||(LA115_0 >= KW_ISOLATION && LA115_0 <= KW_JAR)||(LA115_0 >= KW_JOINCOST && LA115_0 <= KW_LAST)||LA115_0==KW_LEVEL||(LA115_0 >= KW_LIMIT && LA115_0 <= KW_LOAD)||(LA115_0 >= KW_LOCATION && LA115_0 <= KW_LONG)||LA115_0==KW_MANAGEMENT||(LA115_0 >= KW_MAPJOIN && LA115_0 <= KW_MATERIALIZED)||LA115_0==KW_METADATA||(LA115_0 >= KW_MINUTE && LA115_0 <= KW_MONTH)||(LA115_0 >= KW_MOVE && LA115_0 <= KW_MSCK)||(LA115_0 >= KW_NORELY && LA115_0 <= KW_NOSCAN)||LA115_0==KW_NOVALIDATE||LA115_0==KW_NULLS||LA115_0==KW_OFFSET||(LA115_0 >= KW_OPERATOR && LA115_0 <= KW_OPTION)||(LA115_0 >= KW_OUTPUTDRIVER && LA115_0 <= KW_OUTPUTFORMAT)||(LA115_0 >= KW_OVERWRITE && LA115_0 <= KW_OWNER)||(LA115_0 >= KW_PARTITIONED && LA115_0 <= KW_PATH)||(LA115_0 >= KW_PLAN && LA115_0 <= KW_POOL)||LA115_0==KW_PRINCIPALS||(LA115_0 >= KW_PURGE && LA115_0 <= KW_QUERY_PARALLELISM)||LA115_0==KW_READ||(LA115_0 >= KW_REBUILD && LA115_0 <= KW_RECORDWRITER)||(LA115_0 >= KW_RELOAD && LA115_0 <= KW_RESTRICT)||LA115_0==KW_REWRITE||(LA115_0 >= KW_ROLE && LA115_0 <= KW_ROLES)||(LA115_0 >= KW_SCHEDULING_POLICY && LA115_0 <= KW_SECOND)||(LA115_0 >= KW_SEMI && LA115_0 <= KW_SERVER)||(LA115_0 >= KW_SETS && LA115_0 <= KW_SKEWED)||(LA115_0 >= KW_SNAPSHOT && LA115_0 <= KW_SSL)||(LA115_0 >= KW_STATISTICS && LA115_0 <= KW_SUMMARY)||LA115_0==KW_TABLES||(LA115_0 >= KW_TBLPROPERTIES && LA115_0 <= KW_TERMINATED)||LA115_0==KW_TINYINT||(LA115_0 >= KW_TOUCH && LA115_0 <= KW_TRANSACTIONS)||LA115_0==KW_UNARCHIVE||LA115_0==KW_UNDO||LA115_0==KW_UNIONTYPE||(LA115_0 >= KW_UNLOCK && LA115_0 <= KW_UNSIGNED)||(LA115_0 >= KW_URI && LA115_0 <= KW_USE)||(LA115_0 >= KW_UTC && LA115_0 <= KW_VALIDATE)||LA115_0==KW_VALUE_TYPE||(LA115_0 >= KW_VECTORIZATION && LA115_0 <= KW_WEEK)||LA115_0==KW_WHILE||(LA115_0 >= KW_WORK && LA115_0 <= KW_ZONE)||LA115_0==KW_BATCH||LA115_0==KW_DAYOFWEEK||LA115_0==KW_HOLD_DDLTIME||LA115_0==KW_IGNORE||LA115_0==KW_NO_DROP||LA115_0==KW_OFFLINE||LA115_0==KW_PROTECTION||LA115_0==KW_READONLY||LA115_0==KW_TIMESTAMPTZ) ) {
				alt115=1;
			}
			switch (alt115) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1556:5: identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
					{
					pushFollow(FOLLOW_identifier_in_tabTypeExpr7316);
					identifier407=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier407.getTree());

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1556:16: ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
					loop114:
					while (true) {
						int alt114=2;
						int LA114_0 = input.LA(1);
						if ( (LA114_0==DOT) ) {
							alt114=1;
						}

						switch (alt114) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1556:17: DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
							{
							DOT408=(Token)match(input,DOT,FOLLOW_DOT_in_tabTypeExpr7319); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							DOT408_tree = (ASTNode)adaptor.create(DOT408);
							root_0 = (ASTNode)adaptor.becomeRoot(DOT408_tree, root_0);
							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:4: ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
							int alt113=4;
							switch ( input.LA(1) ) {
							case KW_ELEM_TYPE:
								{
								int LA113_1 = input.LA(2);
								if ( (synpred4_HiveParser()) ) {
									alt113=1;
								}
								else if ( (true) ) {
									alt113=4;
								}

								}
								break;
							case KW_KEY_TYPE:
								{
								int LA113_2 = input.LA(2);
								if ( (synpred5_HiveParser()) ) {
									alt113=2;
								}
								else if ( (true) ) {
									alt113=4;
								}

								}
								break;
							case KW_VALUE_TYPE:
								{
								int LA113_3 = input.LA(2);
								if ( (synpred6_HiveParser()) ) {
									alt113=3;
								}
								else if ( (true) ) {
									alt113=4;
								}

								}
								break;
							case Identifier:
							case KW_ABORT:
							case KW_ACTIVATE:
							case KW_ACTIVE:
							case KW_ADD:
							case KW_ADMIN:
							case KW_AFTER:
							case KW_ALLOC_FRACTION:
							case KW_ANALYZE:
							case KW_ARCHIVE:
							case KW_ASC:
							case KW_AUTOCOMMIT:
							case KW_BEFORE:
							case KW_BUCKET:
							case KW_BUCKETS:
							case KW_CACHE:
							case KW_CASCADE:
							case KW_CBO:
							case KW_CHANGE:
							case KW_CHECK:
							case KW_CLUSTER:
							case KW_CLUSTERED:
							case KW_CLUSTERSTATUS:
							case KW_COLLECTION:
							case KW_COLUMNS:
							case KW_COMMENT:
							case KW_COMPACT:
							case KW_COMPACTIONS:
							case KW_COMPUTE:
							case KW_CONCATENATE:
							case KW_CONTINUE:
							case KW_COST:
							case KW_DATA:
							case KW_DATABASES:
							case KW_DATETIME:
							case KW_DAY:
							case KW_DBPROPERTIES:
							case KW_DEBUG:
							case KW_DEFAULT:
							case KW_DEFERRED:
							case KW_DEFINED:
							case KW_DELIMITED:
							case KW_DEPENDENCY:
							case KW_DESC:
							case KW_DETAIL:
							case KW_DIRECTORIES:
							case KW_DIRECTORY:
							case KW_DISABLE:
							case KW_DISTRIBUTE:
							case KW_DISTRIBUTED:
							case KW_DO:
							case KW_DOW:
							case KW_DUMP:
							case KW_ENABLE:
							case KW_ENFORCED:
							case KW_ESCAPED:
							case KW_EXCLUSIVE:
							case KW_EXPLAIN:
							case KW_EXPORT:
							case KW_EXPRESSION:
							case KW_FIELDS:
							case KW_FILE:
							case KW_FILEFORMAT:
							case KW_FIRST:
							case KW_FORMAT:
							case KW_FORMATTED:
							case KW_FUNCTIONS:
							case KW_HOUR:
							case KW_IDXPROPERTIES:
							case KW_INDEX:
							case KW_INDEXES:
							case KW_INPATH:
							case KW_INPUTDRIVER:
							case KW_INPUTFORMAT:
							case KW_ISOLATION:
							case KW_ITEMS:
							case KW_JAR:
							case KW_JOINCOST:
							case KW_KEY:
							case KW_KEYS:
							case KW_KILL:
							case KW_LAST:
							case KW_LEVEL:
							case KW_LIMIT:
							case KW_LINES:
							case KW_LOAD:
							case KW_LOCATION:
							case KW_LOCK:
							case KW_LOCKS:
							case KW_LOGICAL:
							case KW_LONG:
							case KW_MANAGEMENT:
							case KW_MAPJOIN:
							case KW_MAPPING:
							case KW_MATCHED:
							case KW_MATERIALIZED:
							case KW_METADATA:
							case KW_MINUTE:
							case KW_MONTH:
							case KW_MOVE:
							case KW_MSCK:
							case KW_NORELY:
							case KW_NOSCAN:
							case KW_NOVALIDATE:
							case KW_NULLS:
							case KW_OFFSET:
							case KW_OPERATOR:
							case KW_OPTION:
							case KW_OUTPUTDRIVER:
							case KW_OUTPUTFORMAT:
							case KW_OVERWRITE:
							case KW_OWNER:
							case KW_PARTITIONED:
							case KW_PARTITIONS:
							case KW_PATH:
							case KW_PLAN:
							case KW_PLANS:
							case KW_PLUS:
							case KW_POOL:
							case KW_PRINCIPALS:
							case KW_PURGE:
							case KW_QUARTER:
							case KW_QUERY:
							case KW_QUERY_PARALLELISM:
							case KW_READ:
							case KW_REBUILD:
							case KW_RECORDREADER:
							case KW_RECORDWRITER:
							case KW_RELOAD:
							case KW_RELY:
							case KW_RENAME:
							case KW_REOPTIMIZATION:
							case KW_REPAIR:
							case KW_REPL:
							case KW_REPLACE:
							case KW_REPLICATION:
							case KW_RESOURCE:
							case KW_RESTRICT:
							case KW_REWRITE:
							case KW_ROLE:
							case KW_ROLES:
							case KW_SCHEDULING_POLICY:
							case KW_SCHEMA:
							case KW_SCHEMAS:
							case KW_SECOND:
							case KW_SEMI:
							case KW_SERDE:
							case KW_SERDEPROPERTIES:
							case KW_SERVER:
							case KW_SETS:
							case KW_SHARED:
							case KW_SHOW:
							case KW_SHOW_DATABASE:
							case KW_SKEWED:
							case KW_SNAPSHOT:
							case KW_SORT:
							case KW_SORTED:
							case KW_SSL:
							case KW_STATISTICS:
							case KW_STATUS:
							case KW_STORED:
							case KW_STREAMTABLE:
							case KW_STRING:
							case KW_STRUCT:
							case KW_SUMMARY:
							case KW_TABLES:
							case KW_TBLPROPERTIES:
							case KW_TEMPORARY:
							case KW_TERMINATED:
							case KW_TINYINT:
							case KW_TOUCH:
							case KW_TRANSACTION:
							case KW_TRANSACTIONAL:
							case KW_TRANSACTIONS:
							case KW_UNARCHIVE:
							case KW_UNDO:
							case KW_UNIONTYPE:
							case KW_UNLOCK:
							case KW_UNMANAGED:
							case KW_UNSET:
							case KW_UNSIGNED:
							case KW_URI:
							case KW_USE:
							case KW_UTC:
							case KW_UTCTIMESTAMP:
							case KW_VALIDATE:
							case KW_VECTORIZATION:
							case KW_VIEW:
							case KW_VIEWS:
							case KW_WAIT:
							case KW_WEEK:
							case KW_WHILE:
							case KW_WORK:
							case KW_WORKLOAD:
							case KW_WRITE:
							case KW_YEAR:
							case KW_ZONE:
							case KW_BATCH:
							case KW_DAYOFWEEK:
							case KW_HOLD_DDLTIME:
							case KW_IGNORE:
							case KW_NO_DROP:
							case KW_OFFLINE:
							case KW_PROTECTION:
							case KW_READONLY:
							case KW_TIMESTAMPTZ:
								{
								alt113=4;
								}
								break;
							default:
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 113, 0, input);
								throw nvae;
							}
							switch (alt113) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1558:4: ( KW_ELEM_TYPE )=> KW_ELEM_TYPE
									{
									KW_ELEM_TYPE409=(Token)match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr7336); if (state.failed) return retval;
									if ( state.backtracking==0 ) {
									KW_ELEM_TYPE409_tree = (ASTNode)adaptor.create(KW_ELEM_TYPE409);
									adaptor.addChild(root_0, KW_ELEM_TYPE409_tree);
									}

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1560:4: ( KW_KEY_TYPE )=> KW_KEY_TYPE
									{
									KW_KEY_TYPE410=(Token)match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_tabTypeExpr7353); if (state.failed) return retval;
									if ( state.backtracking==0 ) {
									KW_KEY_TYPE410_tree = (ASTNode)adaptor.create(KW_KEY_TYPE410);
									adaptor.addChild(root_0, KW_KEY_TYPE410_tree);
									}

									}
									break;
								case 3 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1562:4: ( KW_VALUE_TYPE )=> KW_VALUE_TYPE
									{
									KW_VALUE_TYPE411=(Token)match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr7370); if (state.failed) return retval;
									if ( state.backtracking==0 ) {
									KW_VALUE_TYPE411_tree = (ASTNode)adaptor.create(KW_VALUE_TYPE411);
									adaptor.addChild(root_0, KW_VALUE_TYPE411_tree);
									}

									}
									break;
								case 4 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1563:6: identifier
									{
									pushFollow(FOLLOW_identifier_in_tabTypeExpr7378);
									identifier412=identifier();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier412.getTree());

									}
									break;

							}

							}
							break;

						default :
							break loop114;
						}
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tabTypeExpr"


	public static class partTypeExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "partTypeExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1568:1: partTypeExpr : tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) ;
	public final HiveParser.partTypeExpr_return partTypeExpr() throws RecognitionException {
		HiveParser.partTypeExpr_return retval = new HiveParser.partTypeExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tabTypeExpr413 =null;
		ParserRuleReturnScope partitionSpec414 =null;

		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tabTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule tabTypeExpr");

		 pushMsg("specifying table partitions", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1571:5: ( tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1571:8: tabTypeExpr ( partitionSpec )?
			{
			pushFollow(FOLLOW_tabTypeExpr_in_partTypeExpr7418);
			tabTypeExpr413=tabTypeExpr();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tabTypeExpr.add(tabTypeExpr413.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1571:20: ( partitionSpec )?
			int alt116=2;
			int LA116_0 = input.LA(1);
			if ( (LA116_0==KW_PARTITION) ) {
				alt116=1;
			}
			switch (alt116) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1571:20: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_partTypeExpr7420);
					partitionSpec414=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec414.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tabTypeExpr, partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1571:35: -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1571:38: ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABTYPE, "TOK_TABTYPE"), root_1);
				adaptor.addChild(root_1, stream_tabTypeExpr.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1571:64: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "partTypeExpr"


	public static class tabPartColTypeExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tabPartColTypeExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1574:1: tabPartColTypeExpr : tableName ( partitionSpec )? ( extColumnName )? -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? ) ;
	public final HiveParser.tabPartColTypeExpr_return tabPartColTypeExpr() throws RecognitionException {
		HiveParser.tabPartColTypeExpr_return retval = new HiveParser.tabPartColTypeExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tableName415 =null;
		ParserRuleReturnScope partitionSpec416 =null;
		ParserRuleReturnScope extColumnName417 =null;

		RewriteRuleSubtreeStream stream_extColumnName=new RewriteRuleSubtreeStream(adaptor,"rule extColumnName");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("specifying table partitions columnName", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:5: ( tableName ( partitionSpec )? ( extColumnName )? -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:8: tableName ( partitionSpec )? ( extColumnName )?
			{
			pushFollow(FOLLOW_tableName_in_tabPartColTypeExpr7460);
			tableName415=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName415.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:18: ( partitionSpec )?
			int alt117=2;
			int LA117_0 = input.LA(1);
			if ( (LA117_0==KW_PARTITION) ) {
				alt117=1;
			}
			switch (alt117) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:18: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_tabPartColTypeExpr7462);
					partitionSpec416=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec416.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:33: ( extColumnName )?
			int alt118=2;
			int LA118_0 = input.LA(1);
			if ( (LA118_0==Identifier||(LA118_0 >= KW_ABORT && LA118_0 <= KW_AFTER)||LA118_0==KW_ALLOC_FRACTION||LA118_0==KW_ANALYZE||LA118_0==KW_ARCHIVE||LA118_0==KW_ASC||(LA118_0 >= KW_AUTOCOMMIT && LA118_0 <= KW_BEFORE)||(LA118_0 >= KW_BUCKET && LA118_0 <= KW_BUCKETS)||(LA118_0 >= KW_CACHE && LA118_0 <= KW_CASCADE)||(LA118_0 >= KW_CBO && LA118_0 <= KW_CHANGE)||(LA118_0 >= KW_CHECK && LA118_0 <= KW_COLLECTION)||(LA118_0 >= KW_COLUMNS && LA118_0 <= KW_COMMENT)||(LA118_0 >= KW_COMPACT && LA118_0 <= KW_CONCATENATE)||(LA118_0 >= KW_CONTINUE && LA118_0 <= KW_COST)||LA118_0==KW_DATA||LA118_0==KW_DATABASES||(LA118_0 >= KW_DATETIME && LA118_0 <= KW_DEBUG)||(LA118_0 >= KW_DEFAULT && LA118_0 <= KW_DEFINED)||(LA118_0 >= KW_DELIMITED && LA118_0 <= KW_DESC)||(LA118_0 >= KW_DETAIL && LA118_0 <= KW_DISABLE)||(LA118_0 >= KW_DISTRIBUTE && LA118_0 <= KW_DO)||LA118_0==KW_DOW||(LA118_0 >= KW_DUMP && LA118_0 <= KW_ELEM_TYPE)||LA118_0==KW_ENABLE||(LA118_0 >= KW_ENFORCED && LA118_0 <= KW_ESCAPED)||LA118_0==KW_EXCLUSIVE||(LA118_0 >= KW_EXPLAIN && LA118_0 <= KW_EXPRESSION)||(LA118_0 >= KW_FIELDS && LA118_0 <= KW_FIRST)||(LA118_0 >= KW_FORMAT && LA118_0 <= KW_FORMATTED)||LA118_0==KW_FUNCTIONS||(LA118_0 >= KW_HOUR && LA118_0 <= KW_IDXPROPERTIES)||(LA118_0 >= KW_INDEX && LA118_0 <= KW_INDEXES)||(LA118_0 >= KW_INPATH && LA118_0 <= KW_INPUTFORMAT)||(LA118_0 >= KW_ISOLATION && LA118_0 <= KW_JAR)||(LA118_0 >= KW_JOINCOST && LA118_0 <= KW_LAST)||LA118_0==KW_LEVEL||(LA118_0 >= KW_LIMIT && LA118_0 <= KW_LOAD)||(LA118_0 >= KW_LOCATION && LA118_0 <= KW_LONG)||LA118_0==KW_MANAGEMENT||(LA118_0 >= KW_MAPJOIN && LA118_0 <= KW_MATERIALIZED)||LA118_0==KW_METADATA||(LA118_0 >= KW_MINUTE && LA118_0 <= KW_MONTH)||(LA118_0 >= KW_MOVE && LA118_0 <= KW_MSCK)||(LA118_0 >= KW_NORELY && LA118_0 <= KW_NOSCAN)||LA118_0==KW_NOVALIDATE||LA118_0==KW_NULLS||LA118_0==KW_OFFSET||(LA118_0 >= KW_OPERATOR && LA118_0 <= KW_OPTION)||(LA118_0 >= KW_OUTPUTDRIVER && LA118_0 <= KW_OUTPUTFORMAT)||(LA118_0 >= KW_OVERWRITE && LA118_0 <= KW_OWNER)||(LA118_0 >= KW_PARTITIONED && LA118_0 <= KW_PATH)||(LA118_0 >= KW_PLAN && LA118_0 <= KW_POOL)||LA118_0==KW_PRINCIPALS||(LA118_0 >= KW_PURGE && LA118_0 <= KW_QUERY_PARALLELISM)||LA118_0==KW_READ||(LA118_0 >= KW_REBUILD && LA118_0 <= KW_RECORDWRITER)||(LA118_0 >= KW_RELOAD && LA118_0 <= KW_RESTRICT)||LA118_0==KW_REWRITE||(LA118_0 >= KW_ROLE && LA118_0 <= KW_ROLES)||(LA118_0 >= KW_SCHEDULING_POLICY && LA118_0 <= KW_SECOND)||(LA118_0 >= KW_SEMI && LA118_0 <= KW_SERVER)||(LA118_0 >= KW_SETS && LA118_0 <= KW_SKEWED)||(LA118_0 >= KW_SNAPSHOT && LA118_0 <= KW_SSL)||(LA118_0 >= KW_STATISTICS && LA118_0 <= KW_SUMMARY)||LA118_0==KW_TABLES||(LA118_0 >= KW_TBLPROPERTIES && LA118_0 <= KW_TERMINATED)||LA118_0==KW_TINYINT||(LA118_0 >= KW_TOUCH && LA118_0 <= KW_TRANSACTIONS)||LA118_0==KW_UNARCHIVE||LA118_0==KW_UNDO||LA118_0==KW_UNIONTYPE||(LA118_0 >= KW_UNLOCK && LA118_0 <= KW_UNSIGNED)||(LA118_0 >= KW_URI && LA118_0 <= KW_USE)||(LA118_0 >= KW_UTC && LA118_0 <= KW_VALIDATE)||LA118_0==KW_VALUE_TYPE||(LA118_0 >= KW_VECTORIZATION && LA118_0 <= KW_WEEK)||LA118_0==KW_WHILE||(LA118_0 >= KW_WORK && LA118_0 <= KW_ZONE)||LA118_0==KW_BATCH||LA118_0==KW_DAYOFWEEK||LA118_0==KW_HOLD_DDLTIME||LA118_0==KW_IGNORE||LA118_0==KW_NO_DROP||LA118_0==KW_OFFLINE||LA118_0==KW_PROTECTION||LA118_0==KW_READONLY||LA118_0==KW_TIMESTAMPTZ) ) {
				alt118=1;
			}
			switch (alt118) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:33: extColumnName
					{
					pushFollow(FOLLOW_extColumnName_in_tabPartColTypeExpr7465);
					extColumnName417=extColumnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_extColumnName.add(extColumnName417.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: partitionSpec, extColumnName, tableName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1577:48: -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:51: ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABTYPE, "TOK_TABTYPE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:75: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:90: ( extColumnName )?
				if ( stream_extColumnName.hasNext() ) {
					adaptor.addChild(root_1, stream_extColumnName.nextTree());
				}
				stream_extColumnName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tabPartColTypeExpr"


	public static class descStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "descStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1580:1: descStatement : ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) ) ;
	public final HiveParser.descStatement_return descStatement() throws RecognitionException {
		HiveParser.descStatement_return retval = new HiveParser.descStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token descOptions=null;
		Token KW_DESCRIBE418=null;
		Token KW_DESC419=null;
		Token KW_DATABASE420=null;
		Token KW_SCHEMA421=null;
		Token KW_EXTENDED422=null;
		Token KW_FUNCTION423=null;
		Token KW_EXTENDED424=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope parttype =null;

		ASTNode descOptions_tree=null;
		ASTNode KW_DESCRIBE418_tree=null;
		ASTNode KW_DESC419_tree=null;
		ASTNode KW_DATABASE420_tree=null;
		ASTNode KW_SCHEMA421_tree=null;
		ASTNode KW_EXTENDED422_tree=null;
		ASTNode KW_FUNCTION423_tree=null;
		ASTNode KW_EXTENDED424_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
		RewriteRuleTokenStream stream_KW_DESC=new RewriteRuleTokenStream(adaptor,"token KW_DESC");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleTokenStream stream_KW_FORMATTED=new RewriteRuleTokenStream(adaptor,"token KW_FORMATTED");
		RewriteRuleTokenStream stream_KW_DESCRIBE=new RewriteRuleTokenStream(adaptor,"token KW_DESCRIBE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tabPartColTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule tabPartColTypeExpr");
		RewriteRuleSubtreeStream stream_descFuncNames=new RewriteRuleSubtreeStream(adaptor,"rule descFuncNames");

		 pushMsg("describe statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1583:5: ( ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1584:5: ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) )
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1584:5: ( KW_DESCRIBE | KW_DESC )
			int alt119=2;
			int LA119_0 = input.LA(1);
			if ( (LA119_0==KW_DESCRIBE) ) {
				alt119=1;
			}
			else if ( (LA119_0==KW_DESC) ) {
				alt119=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 119, 0, input);
				throw nvae;
			}

			switch (alt119) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1584:6: KW_DESCRIBE
					{
					KW_DESCRIBE418=(Token)match(input,KW_DESCRIBE,FOLLOW_KW_DESCRIBE_in_descStatement7512); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DESCRIBE.add(KW_DESCRIBE418);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1584:18: KW_DESC
					{
					KW_DESC419=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_descStatement7514); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DESC.add(KW_DESC419);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1585:5: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) )
			int alt124=4;
			int LA124_0 = input.LA(1);
			if ( (LA124_0==KW_DATABASE) && (synpred7_HiveParser())) {
				alt124=1;
			}
			else if ( (LA124_0==KW_SCHEMA) ) {
				int LA124_2 = input.LA(2);
				if ( (LA124_2==KW_EXTENDED) && (synpred7_HiveParser())) {
					alt124=1;
				}
				else if ( (LA124_2==Identifier) ) {
					int LA124_9 = input.LA(3);
					if ( (synpred7_HiveParser()) ) {
						alt124=1;
					}
					else if ( (true) ) {
						alt124=4;
					}

				}
				else if ( ((LA124_2 >= KW_ABORT && LA124_2 <= KW_AFTER)||LA124_2==KW_ALLOC_FRACTION||LA124_2==KW_ANALYZE||LA124_2==KW_ARCHIVE||LA124_2==KW_ASC||(LA124_2 >= KW_AUTOCOMMIT && LA124_2 <= KW_BEFORE)||(LA124_2 >= KW_BUCKET && LA124_2 <= KW_BUCKETS)||(LA124_2 >= KW_CACHE && LA124_2 <= KW_CASCADE)||(LA124_2 >= KW_CBO && LA124_2 <= KW_CHANGE)||(LA124_2 >= KW_CHECK && LA124_2 <= KW_COLLECTION)||(LA124_2 >= KW_COLUMNS && LA124_2 <= KW_COMMENT)||(LA124_2 >= KW_COMPACT && LA124_2 <= KW_CONCATENATE)||(LA124_2 >= KW_CONTINUE && LA124_2 <= KW_COST)||LA124_2==KW_DATA||LA124_2==KW_DATABASES||(LA124_2 >= KW_DATETIME && LA124_2 <= KW_DEBUG)||(LA124_2 >= KW_DEFAULT && LA124_2 <= KW_DEFINED)||(LA124_2 >= KW_DELIMITED && LA124_2 <= KW_DESC)||(LA124_2 >= KW_DETAIL && LA124_2 <= KW_DISABLE)||(LA124_2 >= KW_DISTRIBUTE && LA124_2 <= KW_DO)||LA124_2==KW_DOW||(LA124_2 >= KW_DUMP && LA124_2 <= KW_ELEM_TYPE)||LA124_2==KW_ENABLE||(LA124_2 >= KW_ENFORCED && LA124_2 <= KW_ESCAPED)||LA124_2==KW_EXCLUSIVE||(LA124_2 >= KW_EXPLAIN && LA124_2 <= KW_EXPRESSION)||(LA124_2 >= KW_FIELDS && LA124_2 <= KW_FIRST)||(LA124_2 >= KW_FORMAT && LA124_2 <= KW_FORMATTED)||LA124_2==KW_FUNCTIONS||(LA124_2 >= KW_HOUR && LA124_2 <= KW_IDXPROPERTIES)||(LA124_2 >= KW_INDEX && LA124_2 <= KW_INDEXES)||(LA124_2 >= KW_INPATH && LA124_2 <= KW_INPUTFORMAT)||(LA124_2 >= KW_ISOLATION && LA124_2 <= KW_JAR)||(LA124_2 >= KW_JOINCOST && LA124_2 <= KW_LAST)||LA124_2==KW_LEVEL||(LA124_2 >= KW_LIMIT && LA124_2 <= KW_LOAD)||(LA124_2 >= KW_LOCATION && LA124_2 <= KW_LONG)||LA124_2==KW_MANAGEMENT||(LA124_2 >= KW_MAPJOIN && LA124_2 <= KW_MATERIALIZED)||LA124_2==KW_METADATA||(LA124_2 >= KW_MINUTE && LA124_2 <= KW_MONTH)||(LA124_2 >= KW_MOVE && LA124_2 <= KW_MSCK)||(LA124_2 >= KW_NORELY && LA124_2 <= KW_NOSCAN)||LA124_2==KW_NOVALIDATE||LA124_2==KW_NULLS||LA124_2==KW_OFFSET||(LA124_2 >= KW_OPERATOR && LA124_2 <= KW_OPTION)||(LA124_2 >= KW_OUTPUTDRIVER && LA124_2 <= KW_OUTPUTFORMAT)||(LA124_2 >= KW_OVERWRITE && LA124_2 <= KW_OWNER)||(LA124_2 >= KW_PARTITIONED && LA124_2 <= KW_PATH)||(LA124_2 >= KW_PLAN && LA124_2 <= KW_POOL)||LA124_2==KW_PRINCIPALS||(LA124_2 >= KW_PURGE && LA124_2 <= KW_QUERY_PARALLELISM)||LA124_2==KW_READ||(LA124_2 >= KW_REBUILD && LA124_2 <= KW_RECORDWRITER)||(LA124_2 >= KW_RELOAD && LA124_2 <= KW_RESTRICT)||LA124_2==KW_REWRITE||(LA124_2 >= KW_ROLE && LA124_2 <= KW_ROLES)||(LA124_2 >= KW_SCHEDULING_POLICY && LA124_2 <= KW_SECOND)||(LA124_2 >= KW_SEMI && LA124_2 <= KW_SERVER)||(LA124_2 >= KW_SETS && LA124_2 <= KW_SKEWED)||(LA124_2 >= KW_SNAPSHOT && LA124_2 <= KW_SSL)||(LA124_2 >= KW_STATISTICS && LA124_2 <= KW_SUMMARY)||LA124_2==KW_TABLES||(LA124_2 >= KW_TBLPROPERTIES && LA124_2 <= KW_TERMINATED)||LA124_2==KW_TINYINT||(LA124_2 >= KW_TOUCH && LA124_2 <= KW_TRANSACTIONS)||LA124_2==KW_UNARCHIVE||LA124_2==KW_UNDO||LA124_2==KW_UNIONTYPE||(LA124_2 >= KW_UNLOCK && LA124_2 <= KW_UNSIGNED)||(LA124_2 >= KW_URI && LA124_2 <= KW_USE)||(LA124_2 >= KW_UTC && LA124_2 <= KW_VALIDATE)||LA124_2==KW_VALUE_TYPE||(LA124_2 >= KW_VECTORIZATION && LA124_2 <= KW_WEEK)||LA124_2==KW_WHILE||(LA124_2 >= KW_WORK && LA124_2 <= KW_ZONE)||LA124_2==KW_BATCH||LA124_2==KW_DAYOFWEEK||LA124_2==KW_HOLD_DDLTIME||LA124_2==KW_IGNORE||LA124_2==KW_NO_DROP||LA124_2==KW_OFFLINE||LA124_2==KW_PROTECTION||LA124_2==KW_READONLY||LA124_2==KW_TIMESTAMPTZ) ) {
					int LA124_10 = input.LA(3);
					if ( (synpred7_HiveParser()) ) {
						alt124=1;
					}
					else if ( (true) ) {
						alt124=4;
					}

				}
				else if ( (LA124_2==EOF||LA124_2==DOT||LA124_2==KW_PARTITION) ) {
					alt124=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 124, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( (LA124_0==KW_FUNCTION) && (synpred8_HiveParser())) {
				alt124=2;
			}
			else if ( (LA124_0==KW_FORMATTED) ) {
				switch ( input.LA(2) ) {
				case Identifier:
					{
					int LA124_14 = input.LA(3);
					if ( (synpred9_HiveParser()) ) {
						alt124=3;
					}
					else if ( (true) ) {
						alt124=4;
					}

					}
					break;
				case KW_ABORT:
				case KW_ACTIVATE:
				case KW_ACTIVE:
				case KW_ADD:
				case KW_ADMIN:
				case KW_AFTER:
				case KW_ALLOC_FRACTION:
				case KW_ANALYZE:
				case KW_ARCHIVE:
				case KW_ASC:
				case KW_AUTOCOMMIT:
				case KW_BEFORE:
				case KW_BUCKET:
				case KW_BUCKETS:
				case KW_CACHE:
				case KW_CASCADE:
				case KW_CBO:
				case KW_CHANGE:
				case KW_CHECK:
				case KW_CLUSTER:
				case KW_CLUSTERED:
				case KW_CLUSTERSTATUS:
				case KW_COLLECTION:
				case KW_COLUMNS:
				case KW_COMMENT:
				case KW_COMPACT:
				case KW_COMPACTIONS:
				case KW_COMPUTE:
				case KW_CONCATENATE:
				case KW_CONTINUE:
				case KW_COST:
				case KW_DATA:
				case KW_DATABASES:
				case KW_DATETIME:
				case KW_DAY:
				case KW_DBPROPERTIES:
				case KW_DEBUG:
				case KW_DEFAULT:
				case KW_DEFERRED:
				case KW_DEFINED:
				case KW_DELIMITED:
				case KW_DEPENDENCY:
				case KW_DESC:
				case KW_DETAIL:
				case KW_DIRECTORIES:
				case KW_DIRECTORY:
				case KW_DISABLE:
				case KW_DISTRIBUTE:
				case KW_DISTRIBUTED:
				case KW_DO:
				case KW_DOW:
				case KW_DUMP:
				case KW_ELEM_TYPE:
				case KW_ENABLE:
				case KW_ENFORCED:
				case KW_ESCAPED:
				case KW_EXCLUSIVE:
				case KW_EXPLAIN:
				case KW_EXPORT:
				case KW_EXPRESSION:
				case KW_FIELDS:
				case KW_FILE:
				case KW_FILEFORMAT:
				case KW_FIRST:
				case KW_FORMAT:
				case KW_FORMATTED:
				case KW_FUNCTIONS:
				case KW_HOUR:
				case KW_IDXPROPERTIES:
				case KW_INDEX:
				case KW_INDEXES:
				case KW_INPATH:
				case KW_INPUTDRIVER:
				case KW_INPUTFORMAT:
				case KW_ISOLATION:
				case KW_ITEMS:
				case KW_JAR:
				case KW_JOINCOST:
				case KW_KEY:
				case KW_KEYS:
				case KW_KEY_TYPE:
				case KW_KILL:
				case KW_LAST:
				case KW_LEVEL:
				case KW_LIMIT:
				case KW_LINES:
				case KW_LOAD:
				case KW_LOCATION:
				case KW_LOCK:
				case KW_LOCKS:
				case KW_LOGICAL:
				case KW_LONG:
				case KW_MANAGEMENT:
				case KW_MAPJOIN:
				case KW_MAPPING:
				case KW_MATCHED:
				case KW_MATERIALIZED:
				case KW_METADATA:
				case KW_MINUTE:
				case KW_MONTH:
				case KW_MOVE:
				case KW_MSCK:
				case KW_NORELY:
				case KW_NOSCAN:
				case KW_NOVALIDATE:
				case KW_NULLS:
				case KW_OFFSET:
				case KW_OPERATOR:
				case KW_OPTION:
				case KW_OUTPUTDRIVER:
				case KW_OUTPUTFORMAT:
				case KW_OVERWRITE:
				case KW_OWNER:
				case KW_PARTITIONED:
				case KW_PARTITIONS:
				case KW_PATH:
				case KW_PLAN:
				case KW_PLANS:
				case KW_PLUS:
				case KW_POOL:
				case KW_PRINCIPALS:
				case KW_PURGE:
				case KW_QUARTER:
				case KW_QUERY:
				case KW_QUERY_PARALLELISM:
				case KW_READ:
				case KW_REBUILD:
				case KW_RECORDREADER:
				case KW_RECORDWRITER:
				case KW_RELOAD:
				case KW_RELY:
				case KW_RENAME:
				case KW_REOPTIMIZATION:
				case KW_REPAIR:
				case KW_REPL:
				case KW_REPLACE:
				case KW_REPLICATION:
				case KW_RESOURCE:
				case KW_RESTRICT:
				case KW_REWRITE:
				case KW_ROLE:
				case KW_ROLES:
				case KW_SCHEDULING_POLICY:
				case KW_SCHEMA:
				case KW_SCHEMAS:
				case KW_SECOND:
				case KW_SEMI:
				case KW_SERDE:
				case KW_SERDEPROPERTIES:
				case KW_SERVER:
				case KW_SETS:
				case KW_SHARED:
				case KW_SHOW:
				case KW_SHOW_DATABASE:
				case KW_SKEWED:
				case KW_SNAPSHOT:
				case KW_SORT:
				case KW_SORTED:
				case KW_SSL:
				case KW_STATISTICS:
				case KW_STATUS:
				case KW_STORED:
				case KW_STREAMTABLE:
				case KW_STRING:
				case KW_STRUCT:
				case KW_SUMMARY:
				case KW_TABLES:
				case KW_TBLPROPERTIES:
				case KW_TEMPORARY:
				case KW_TERMINATED:
				case KW_TINYINT:
				case KW_TOUCH:
				case KW_TRANSACTION:
				case KW_TRANSACTIONAL:
				case KW_TRANSACTIONS:
				case KW_UNARCHIVE:
				case KW_UNDO:
				case KW_UNIONTYPE:
				case KW_UNLOCK:
				case KW_UNMANAGED:
				case KW_UNSET:
				case KW_UNSIGNED:
				case KW_URI:
				case KW_USE:
				case KW_UTC:
				case KW_UTCTIMESTAMP:
				case KW_VALIDATE:
				case KW_VALUE_TYPE:
				case KW_VECTORIZATION:
				case KW_VIEW:
				case KW_VIEWS:
				case KW_WAIT:
				case KW_WEEK:
				case KW_WHILE:
				case KW_WORK:
				case KW_WORKLOAD:
				case KW_WRITE:
				case KW_YEAR:
				case KW_ZONE:
				case KW_BATCH:
				case KW_DAYOFWEEK:
				case KW_HOLD_DDLTIME:
				case KW_IGNORE:
				case KW_NO_DROP:
				case KW_OFFLINE:
				case KW_PROTECTION:
				case KW_READONLY:
				case KW_TIMESTAMPTZ:
					{
					int LA124_15 = input.LA(3);
					if ( (synpred9_HiveParser()) ) {
						alt124=3;
					}
					else if ( (true) ) {
						alt124=4;
					}

					}
					break;
				case EOF:
				case DOT:
				case KW_PARTITION:
					{
					alt124=4;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 124, 4, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
			}
			else if ( (LA124_0==KW_EXTENDED) && (synpred9_HiveParser())) {
				alt124=3;
			}
			else if ( (LA124_0==Identifier||(LA124_0 >= KW_ABORT && LA124_0 <= KW_AFTER)||LA124_0==KW_ALLOC_FRACTION||LA124_0==KW_ANALYZE||LA124_0==KW_ARCHIVE||LA124_0==KW_ASC||(LA124_0 >= KW_AUTOCOMMIT && LA124_0 <= KW_BEFORE)||(LA124_0 >= KW_BUCKET && LA124_0 <= KW_BUCKETS)||(LA124_0 >= KW_CACHE && LA124_0 <= KW_CASCADE)||(LA124_0 >= KW_CBO && LA124_0 <= KW_CHANGE)||(LA124_0 >= KW_CHECK && LA124_0 <= KW_COLLECTION)||(LA124_0 >= KW_COLUMNS && LA124_0 <= KW_COMMENT)||(LA124_0 >= KW_COMPACT && LA124_0 <= KW_CONCATENATE)||(LA124_0 >= KW_CONTINUE && LA124_0 <= KW_COST)||LA124_0==KW_DATA||LA124_0==KW_DATABASES||(LA124_0 >= KW_DATETIME && LA124_0 <= KW_DEBUG)||(LA124_0 >= KW_DEFAULT && LA124_0 <= KW_DEFINED)||(LA124_0 >= KW_DELIMITED && LA124_0 <= KW_DESC)||(LA124_0 >= KW_DETAIL && LA124_0 <= KW_DISABLE)||(LA124_0 >= KW_DISTRIBUTE && LA124_0 <= KW_DO)||LA124_0==KW_DOW||(LA124_0 >= KW_DUMP && LA124_0 <= KW_ELEM_TYPE)||LA124_0==KW_ENABLE||(LA124_0 >= KW_ENFORCED && LA124_0 <= KW_ESCAPED)||LA124_0==KW_EXCLUSIVE||(LA124_0 >= KW_EXPLAIN && LA124_0 <= KW_EXPRESSION)||(LA124_0 >= KW_FIELDS && LA124_0 <= KW_FIRST)||LA124_0==KW_FORMAT||LA124_0==KW_FUNCTIONS||(LA124_0 >= KW_HOUR && LA124_0 <= KW_IDXPROPERTIES)||(LA124_0 >= KW_INDEX && LA124_0 <= KW_INDEXES)||(LA124_0 >= KW_INPATH && LA124_0 <= KW_INPUTFORMAT)||(LA124_0 >= KW_ISOLATION && LA124_0 <= KW_JAR)||(LA124_0 >= KW_JOINCOST && LA124_0 <= KW_LAST)||LA124_0==KW_LEVEL||(LA124_0 >= KW_LIMIT && LA124_0 <= KW_LOAD)||(LA124_0 >= KW_LOCATION && LA124_0 <= KW_LONG)||LA124_0==KW_MANAGEMENT||(LA124_0 >= KW_MAPJOIN && LA124_0 <= KW_MATERIALIZED)||LA124_0==KW_METADATA||(LA124_0 >= KW_MINUTE && LA124_0 <= KW_MONTH)||(LA124_0 >= KW_MOVE && LA124_0 <= KW_MSCK)||(LA124_0 >= KW_NORELY && LA124_0 <= KW_NOSCAN)||LA124_0==KW_NOVALIDATE||LA124_0==KW_NULLS||LA124_0==KW_OFFSET||(LA124_0 >= KW_OPERATOR && LA124_0 <= KW_OPTION)||(LA124_0 >= KW_OUTPUTDRIVER && LA124_0 <= KW_OUTPUTFORMAT)||(LA124_0 >= KW_OVERWRITE && LA124_0 <= KW_OWNER)||(LA124_0 >= KW_PARTITIONED && LA124_0 <= KW_PATH)||(LA124_0 >= KW_PLAN && LA124_0 <= KW_POOL)||LA124_0==KW_PRINCIPALS||(LA124_0 >= KW_PURGE && LA124_0 <= KW_QUERY_PARALLELISM)||LA124_0==KW_READ||(LA124_0 >= KW_REBUILD && LA124_0 <= KW_RECORDWRITER)||(LA124_0 >= KW_RELOAD && LA124_0 <= KW_RESTRICT)||LA124_0==KW_REWRITE||(LA124_0 >= KW_ROLE && LA124_0 <= KW_ROLES)||LA124_0==KW_SCHEDULING_POLICY||(LA124_0 >= KW_SCHEMAS && LA124_0 <= KW_SECOND)||(LA124_0 >= KW_SEMI && LA124_0 <= KW_SERVER)||(LA124_0 >= KW_SETS && LA124_0 <= KW_SKEWED)||(LA124_0 >= KW_SNAPSHOT && LA124_0 <= KW_SSL)||(LA124_0 >= KW_STATISTICS && LA124_0 <= KW_SUMMARY)||LA124_0==KW_TABLES||(LA124_0 >= KW_TBLPROPERTIES && LA124_0 <= KW_TERMINATED)||LA124_0==KW_TINYINT||(LA124_0 >= KW_TOUCH && LA124_0 <= KW_TRANSACTIONS)||LA124_0==KW_UNARCHIVE||LA124_0==KW_UNDO||LA124_0==KW_UNIONTYPE||(LA124_0 >= KW_UNLOCK && LA124_0 <= KW_UNSIGNED)||(LA124_0 >= KW_URI && LA124_0 <= KW_USE)||(LA124_0 >= KW_UTC && LA124_0 <= KW_VALIDATE)||LA124_0==KW_VALUE_TYPE||(LA124_0 >= KW_VECTORIZATION && LA124_0 <= KW_WEEK)||LA124_0==KW_WHILE||(LA124_0 >= KW_WORK && LA124_0 <= KW_ZONE)||LA124_0==KW_BATCH||LA124_0==KW_DAYOFWEEK||LA124_0==KW_HOLD_DDLTIME||LA124_0==KW_IGNORE||LA124_0==KW_NO_DROP||LA124_0==KW_OFFLINE||LA124_0==KW_PROTECTION||LA124_0==KW_READONLY||LA124_0==KW_TIMESTAMPTZ) ) {
				alt124=4;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 124, 0, input);
				throw nvae;
			}

			switch (alt124) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:5: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:32: ( KW_DATABASE | KW_SCHEMA )
					int alt120=2;
					int LA120_0 = input.LA(1);
					if ( (LA120_0==KW_DATABASE) ) {
						alt120=1;
					}
					else if ( (LA120_0==KW_SCHEMA) ) {
						alt120=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 120, 0, input);
						throw nvae;
					}

					switch (alt120) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:33: KW_DATABASE
							{
							KW_DATABASE420=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_descStatement7536); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE420);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:45: KW_SCHEMA
							{
							KW_SCHEMA421=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_descStatement7538); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA421);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:56: ( KW_EXTENDED )?
					int alt121=2;
					int LA121_0 = input.LA(1);
					if ( (LA121_0==KW_EXTENDED) ) {
						alt121=1;
					}
					switch (alt121) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:56: KW_EXTENDED
							{
							KW_EXTENDED422=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement7541); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED422);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:69: (dbName= identifier )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:70: dbName= identifier
					{
					pushFollow(FOLLOW_identifier_in_descStatement7547);
					dbName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
					}

					// AST REWRITE
					// elements: KW_EXTENDED, dbName
					// token labels: 
					// rule labels: dbName, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1586:89: -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:92: ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCDATABASE, "TOK_DESCDATABASE"), root_1);
						adaptor.addChild(root_1, stream_dbName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:119: ( KW_EXTENDED )?
						if ( stream_KW_EXTENDED.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
						}
						stream_KW_EXTENDED.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:5: ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames )
					{
					KW_FUNCTION423=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_descStatement7578); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION423);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:34: ( KW_EXTENDED )?
					int alt122=2;
					int LA122_0 = input.LA(1);
					if ( (LA122_0==KW_EXTENDED) ) {
						alt122=1;
					}
					switch (alt122) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:34: KW_EXTENDED
							{
							KW_EXTENDED424=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement7580); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED424);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:47: (name= descFuncNames )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:48: name= descFuncNames
					{
					pushFollow(FOLLOW_descFuncNames_in_descStatement7586);
					name=descFuncNames();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_descFuncNames.add(name.getTree());
					}

					// AST REWRITE
					// elements: KW_EXTENDED, name
					// token labels: 
					// rule labels: name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1588:68: -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:71: ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCFUNCTION, "TOK_DESCFUNCTION"), root_1);
						adaptor.addChild(root_1, stream_name.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:96: ( KW_EXTENDED )?
						if ( stream_KW_EXTENDED.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
						}
						stream_KW_EXTENDED.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1590:5: ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1590:35: ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1590:36: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1590:36: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED )
					int alt123=2;
					int LA123_0 = input.LA(1);
					if ( (LA123_0==KW_FORMATTED) ) {
						alt123=1;
					}
					else if ( (LA123_0==KW_EXTENDED) ) {
						alt123=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 123, 0, input);
						throw nvae;
					}

					switch (alt123) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1590:37: descOptions= KW_FORMATTED
							{
							descOptions=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_descStatement7623); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_FORMATTED.add(descOptions);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1590:62: descOptions= KW_EXTENDED
							{
							descOptions=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement7627); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(descOptions);

							}
							break;

					}

					pushFollow(FOLLOW_tabPartColTypeExpr_in_descStatement7632);
					parttype=tabPartColTypeExpr();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tabPartColTypeExpr.add(parttype.getTree());
					}

					// AST REWRITE
					// elements: descOptions, parttype
					// token labels: descOptions
					// rule labels: parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_descOptions=new RewriteRuleTokenStream(adaptor,"token descOptions",descOptions);
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1590:116: -> ^( TOK_DESCTABLE $parttype $descOptions)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1590:119: ^( TOK_DESCTABLE $parttype $descOptions)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						adaptor.addChild(root_1, stream_descOptions.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1592:5: parttype= tabPartColTypeExpr
					{
					pushFollow(FOLLOW_tabPartColTypeExpr_in_descStatement7659);
					parttype=tabPartColTypeExpr();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tabPartColTypeExpr.add(parttype.getTree());
					// AST REWRITE
					// elements: parttype
					// token labels: 
					// rule labels: parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1592:33: -> ^( TOK_DESCTABLE $parttype)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1592:36: ^( TOK_DESCTABLE $parttype)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "descStatement"


	public static class analyzeStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "analyzeStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1596:1: analyzeStatement : KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) ) ;
	public final HiveParser.analyzeStatement_return analyzeStatement() throws RecognitionException {
		HiveParser.analyzeStatement_return retval = new HiveParser.analyzeStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token noscan=null;
		Token KW_ANALYZE425=null;
		Token KW_TABLE426=null;
		Token KW_COMPUTE427=null;
		Token KW_STATISTICS428=null;
		Token KW_FOR429=null;
		Token KW_COLUMNS430=null;
		Token KW_CACHE431=null;
		Token KW_METADATA432=null;
		ParserRuleReturnScope parttype =null;
		ParserRuleReturnScope statsColumnName =null;

		ASTNode noscan_tree=null;
		ASTNode KW_ANALYZE425_tree=null;
		ASTNode KW_TABLE426_tree=null;
		ASTNode KW_COMPUTE427_tree=null;
		ASTNode KW_STATISTICS428_tree=null;
		ASTNode KW_FOR429_tree=null;
		ASTNode KW_COLUMNS430_tree=null;
		ASTNode KW_CACHE431_tree=null;
		ASTNode KW_METADATA432_tree=null;
		RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
		RewriteRuleTokenStream stream_KW_ANALYZE=new RewriteRuleTokenStream(adaptor,"token KW_ANALYZE");
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_COMPUTE=new RewriteRuleTokenStream(adaptor,"token KW_COMPUTE");
		RewriteRuleTokenStream stream_KW_METADATA=new RewriteRuleTokenStream(adaptor,"token KW_METADATA");
		RewriteRuleTokenStream stream_KW_NOSCAN=new RewriteRuleTokenStream(adaptor,"token KW_NOSCAN");
		RewriteRuleTokenStream stream_KW_CACHE=new RewriteRuleTokenStream(adaptor,"token KW_CACHE");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("analyze statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: ( KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:7: KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) )
			{
			KW_ANALYZE425=(Token)match(input,KW_ANALYZE,FOLLOW_KW_ANALYZE_in_analyzeStatement7701); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ANALYZE.add(KW_ANALYZE425);

			KW_TABLE426=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_analyzeStatement7703); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE426);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:27: (parttype= tableOrPartition )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:28: parttype= tableOrPartition
			{
			pushFollow(FOLLOW_tableOrPartition_in_analyzeStatement7708);
			parttype=tableOrPartition();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableOrPartition.add(parttype.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:7: ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) )
			int alt127=2;
			int LA127_0 = input.LA(1);
			if ( (LA127_0==KW_COMPUTE) && (synpred10_HiveParser())) {
				alt127=1;
			}
			else if ( (LA127_0==KW_CACHE) && (synpred11_HiveParser())) {
				alt127=2;
			}

			switch (alt127) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:7: ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
					{
					KW_COMPUTE427=(Token)match(input,KW_COMPUTE,FOLLOW_KW_COMPUTE_in_analyzeStatement7731); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMPUTE.add(KW_COMPUTE427);

					KW_STATISTICS428=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_analyzeStatement7733); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS428);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:48: ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
					int alt126=3;
					int LA126_0 = input.LA(1);
					if ( (LA126_0==KW_NOSCAN) ) {
						alt126=1;
					}
					else if ( (LA126_0==KW_FOR) ) {
						alt126=2;
					}
					switch (alt126) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:49: (noscan= KW_NOSCAN )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:49: (noscan= KW_NOSCAN )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:50: noscan= KW_NOSCAN
							{
							noscan=(Token)match(input,KW_NOSCAN,FOLLOW_KW_NOSCAN_in_analyzeStatement7739); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_NOSCAN.add(noscan);

							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1602:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1602:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1602:58: KW_FOR KW_COLUMNS (statsColumnName= columnNameList )?
							{
							KW_FOR429=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_analyzeStatement7799); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR429);

							KW_COLUMNS430=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_analyzeStatement7801); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS430);

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1602:76: (statsColumnName= columnNameList )?
							int alt125=2;
							int LA125_0 = input.LA(1);
							if ( (LA125_0==Identifier||(LA125_0 >= KW_ABORT && LA125_0 <= KW_AFTER)||LA125_0==KW_ALLOC_FRACTION||LA125_0==KW_ANALYZE||LA125_0==KW_ARCHIVE||LA125_0==KW_ASC||(LA125_0 >= KW_AUTOCOMMIT && LA125_0 <= KW_BEFORE)||(LA125_0 >= KW_BUCKET && LA125_0 <= KW_BUCKETS)||(LA125_0 >= KW_CACHE && LA125_0 <= KW_CASCADE)||(LA125_0 >= KW_CBO && LA125_0 <= KW_CHANGE)||(LA125_0 >= KW_CHECK && LA125_0 <= KW_COLLECTION)||(LA125_0 >= KW_COLUMNS && LA125_0 <= KW_COMMENT)||(LA125_0 >= KW_COMPACT && LA125_0 <= KW_CONCATENATE)||(LA125_0 >= KW_CONTINUE && LA125_0 <= KW_COST)||LA125_0==KW_DATA||LA125_0==KW_DATABASES||(LA125_0 >= KW_DATETIME && LA125_0 <= KW_DEBUG)||(LA125_0 >= KW_DEFAULT && LA125_0 <= KW_DEFINED)||(LA125_0 >= KW_DELIMITED && LA125_0 <= KW_DESC)||(LA125_0 >= KW_DETAIL && LA125_0 <= KW_DISABLE)||(LA125_0 >= KW_DISTRIBUTE && LA125_0 <= KW_DO)||LA125_0==KW_DOW||(LA125_0 >= KW_DUMP && LA125_0 <= KW_ELEM_TYPE)||LA125_0==KW_ENABLE||(LA125_0 >= KW_ENFORCED && LA125_0 <= KW_ESCAPED)||LA125_0==KW_EXCLUSIVE||(LA125_0 >= KW_EXPLAIN && LA125_0 <= KW_EXPRESSION)||(LA125_0 >= KW_FIELDS && LA125_0 <= KW_FIRST)||(LA125_0 >= KW_FORMAT && LA125_0 <= KW_FORMATTED)||LA125_0==KW_FUNCTIONS||(LA125_0 >= KW_HOUR && LA125_0 <= KW_IDXPROPERTIES)||(LA125_0 >= KW_INDEX && LA125_0 <= KW_INDEXES)||(LA125_0 >= KW_INPATH && LA125_0 <= KW_INPUTFORMAT)||(LA125_0 >= KW_ISOLATION && LA125_0 <= KW_JAR)||(LA125_0 >= KW_JOINCOST && LA125_0 <= KW_LAST)||LA125_0==KW_LEVEL||(LA125_0 >= KW_LIMIT && LA125_0 <= KW_LOAD)||(LA125_0 >= KW_LOCATION && LA125_0 <= KW_LONG)||LA125_0==KW_MANAGEMENT||(LA125_0 >= KW_MAPJOIN && LA125_0 <= KW_MATERIALIZED)||LA125_0==KW_METADATA||(LA125_0 >= KW_MINUTE && LA125_0 <= KW_MONTH)||(LA125_0 >= KW_MOVE && LA125_0 <= KW_MSCK)||(LA125_0 >= KW_NORELY && LA125_0 <= KW_NOSCAN)||LA125_0==KW_NOVALIDATE||LA125_0==KW_NULLS||LA125_0==KW_OFFSET||(LA125_0 >= KW_OPERATOR && LA125_0 <= KW_OPTION)||(LA125_0 >= KW_OUTPUTDRIVER && LA125_0 <= KW_OUTPUTFORMAT)||(LA125_0 >= KW_OVERWRITE && LA125_0 <= KW_OWNER)||(LA125_0 >= KW_PARTITIONED && LA125_0 <= KW_PATH)||(LA125_0 >= KW_PLAN && LA125_0 <= KW_POOL)||LA125_0==KW_PRINCIPALS||(LA125_0 >= KW_PURGE && LA125_0 <= KW_QUERY_PARALLELISM)||LA125_0==KW_READ||(LA125_0 >= KW_REBUILD && LA125_0 <= KW_RECORDWRITER)||(LA125_0 >= KW_RELOAD && LA125_0 <= KW_RESTRICT)||LA125_0==KW_REWRITE||(LA125_0 >= KW_ROLE && LA125_0 <= KW_ROLES)||(LA125_0 >= KW_SCHEDULING_POLICY && LA125_0 <= KW_SECOND)||(LA125_0 >= KW_SEMI && LA125_0 <= KW_SERVER)||(LA125_0 >= KW_SETS && LA125_0 <= KW_SKEWED)||(LA125_0 >= KW_SNAPSHOT && LA125_0 <= KW_SSL)||(LA125_0 >= KW_STATISTICS && LA125_0 <= KW_SUMMARY)||LA125_0==KW_TABLES||(LA125_0 >= KW_TBLPROPERTIES && LA125_0 <= KW_TERMINATED)||LA125_0==KW_TINYINT||(LA125_0 >= KW_TOUCH && LA125_0 <= KW_TRANSACTIONS)||LA125_0==KW_UNARCHIVE||LA125_0==KW_UNDO||LA125_0==KW_UNIONTYPE||(LA125_0 >= KW_UNLOCK && LA125_0 <= KW_UNSIGNED)||(LA125_0 >= KW_URI && LA125_0 <= KW_USE)||(LA125_0 >= KW_UTC && LA125_0 <= KW_VALIDATE)||LA125_0==KW_VALUE_TYPE||(LA125_0 >= KW_VECTORIZATION && LA125_0 <= KW_WEEK)||LA125_0==KW_WHILE||(LA125_0 >= KW_WORK && LA125_0 <= KW_ZONE)||LA125_0==KW_BATCH||LA125_0==KW_DAYOFWEEK||LA125_0==KW_HOLD_DDLTIME||LA125_0==KW_IGNORE||LA125_0==KW_NO_DROP||LA125_0==KW_OFFLINE||LA125_0==KW_PROTECTION||LA125_0==KW_READONLY||LA125_0==KW_TIMESTAMPTZ) ) {
								alt125=1;
							}
							switch (alt125) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1602:77: statsColumnName= columnNameList
									{
									pushFollow(FOLLOW_columnNameList_in_analyzeStatement7806);
									statsColumnName=columnNameList();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_columnNameList.add(statsColumnName.getTree());
									}
									break;

							}

							}

							}
							break;

					}

					// AST REWRITE
					// elements: parttype, statsColumnName, KW_COLUMNS, noscan
					// token labels: noscan
					// rule labels: statsColumnName, parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_noscan=new RewriteRuleTokenStream(adaptor,"token noscan",noscan);
					RewriteRuleSubtreeStream stream_statsColumnName=new RewriteRuleSubtreeStream(adaptor,"rule statsColumnName",statsColumnName!=null?statsColumnName.getTree():null);
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1603:7: -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:10: ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ANALYZE, "TOK_ANALYZE"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:35: ( $noscan)?
						if ( stream_noscan.hasNext() ) {
							adaptor.addChild(root_1, stream_noscan.nextNode());
						}
						stream_noscan.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:43: ( KW_COLUMNS )?
						if ( stream_KW_COLUMNS.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_COLUMNS.nextNode());
						}
						stream_KW_COLUMNS.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:56: ( $statsColumnName)?
						if ( stream_statsColumnName.hasNext() ) {
							adaptor.addChild(root_1, stream_statsColumnName.nextTree());
						}
						stream_statsColumnName.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1605:7: ( KW_CACHE )=> KW_CACHE KW_METADATA
					{
					KW_CACHE431=(Token)match(input,KW_CACHE,FOLLOW_KW_CACHE_in_analyzeStatement7859); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CACHE.add(KW_CACHE431);

					KW_METADATA432=(Token)match(input,KW_METADATA,FOLLOW_KW_METADATA_in_analyzeStatement7861); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_METADATA.add(KW_METADATA432);

					// AST REWRITE
					// elements: parttype
					// token labels: 
					// rule labels: parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1605:42: -> ^( TOK_CACHE_METADATA $parttype)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1605:45: ^( TOK_CACHE_METADATA $parttype)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CACHE_METADATA, "TOK_CACHE_METADATA"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "analyzeStatement"


	public static class showStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:1: showStatement : ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW (isExtended= KW_EXTENDED )? KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? (filter= showTablesFilterExpr )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? ) | KW_SHOW KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_MATERIALIZED KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ) | KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) ) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) ) | KW_SHOW KW_COMPACTIONS -> ^( TOK_SHOW_COMPACTIONS ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) | KW_SHOW KW_RESOURCE ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) ) );
	public final HiveParser.showStatement_return showStatement() throws RecognitionException {
		HiveParser.showStatement_return retval = new HiveParser.showStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token isExtended=null;
		Token prptyName=null;
		Token KW_SHOW433=null;
		Token KW_DATABASES434=null;
		Token KW_SCHEMAS435=null;
		Token KW_LIKE436=null;
		Token KW_SHOW438=null;
		Token KW_TABLES439=null;
		Token KW_FROM440=null;
		Token KW_IN441=null;
		Token KW_SHOW442=null;
		Token KW_VIEWS443=null;
		Token KW_FROM444=null;
		Token KW_IN445=null;
		Token KW_LIKE446=null;
		Token KW_SHOW449=null;
		Token KW_MATERIALIZED450=null;
		Token KW_VIEWS451=null;
		Token KW_FROM452=null;
		Token KW_IN453=null;
		Token KW_LIKE454=null;
		Token KW_SHOW457=null;
		Token KW_COLUMNS458=null;
		Token KW_FROM459=null;
		Token KW_IN460=null;
		Token KW_FROM462=null;
		Token KW_IN463=null;
		Token KW_LIKE464=null;
		Token KW_SHOW467=null;
		Token KW_FUNCTIONS468=null;
		Token KW_LIKE469=null;
		Token KW_SHOW471=null;
		Token KW_PARTITIONS472=null;
		Token KW_SHOW474=null;
		Token KW_CREATE475=null;
		Token KW_DATABASE476=null;
		Token KW_SCHEMA477=null;
		Token KW_TABLE478=null;
		Token KW_SHOW479=null;
		Token KW_TABLE480=null;
		Token KW_EXTENDED481=null;
		Token KW_FROM482=null;
		Token KW_IN483=null;
		Token KW_LIKE484=null;
		Token KW_SHOW487=null;
		Token KW_TBLPROPERTIES488=null;
		Token LPAREN490=null;
		Token RPAREN491=null;
		Token KW_SHOW492=null;
		Token KW_LOCKS493=null;
		Token KW_DATABASE494=null;
		Token KW_SCHEMA495=null;
		Token KW_SHOW496=null;
		Token KW_COMPACTIONS497=null;
		Token KW_SHOW498=null;
		Token KW_TRANSACTIONS499=null;
		Token KW_SHOW500=null;
		Token KW_CONF501=null;
		Token StringLiteral502=null;
		Token KW_SHOW503=null;
		Token KW_RESOURCE504=null;
		Token KW_PLAN505=null;
		Token KW_PLANS506=null;
		ParserRuleReturnScope db_name =null;
		ParserRuleReturnScope filter =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope parttype =null;
		ParserRuleReturnScope rp_name =null;
		ParserRuleReturnScope showStmtIdentifier437 =null;
		ParserRuleReturnScope showStmtIdentifier447 =null;
		ParserRuleReturnScope showStmtIdentifier448 =null;
		ParserRuleReturnScope showStmtIdentifier455 =null;
		ParserRuleReturnScope showStmtIdentifier456 =null;
		ParserRuleReturnScope tableName461 =null;
		ParserRuleReturnScope showStmtIdentifier465 =null;
		ParserRuleReturnScope showStmtIdentifier466 =null;
		ParserRuleReturnScope showFunctionIdentifier470 =null;
		ParserRuleReturnScope partitionSpec473 =null;
		ParserRuleReturnScope showStmtIdentifier485 =null;
		ParserRuleReturnScope partitionSpec486 =null;
		ParserRuleReturnScope tableName489 =null;

		ASTNode isExtended_tree=null;
		ASTNode prptyName_tree=null;
		ASTNode KW_SHOW433_tree=null;
		ASTNode KW_DATABASES434_tree=null;
		ASTNode KW_SCHEMAS435_tree=null;
		ASTNode KW_LIKE436_tree=null;
		ASTNode KW_SHOW438_tree=null;
		ASTNode KW_TABLES439_tree=null;
		ASTNode KW_FROM440_tree=null;
		ASTNode KW_IN441_tree=null;
		ASTNode KW_SHOW442_tree=null;
		ASTNode KW_VIEWS443_tree=null;
		ASTNode KW_FROM444_tree=null;
		ASTNode KW_IN445_tree=null;
		ASTNode KW_LIKE446_tree=null;
		ASTNode KW_SHOW449_tree=null;
		ASTNode KW_MATERIALIZED450_tree=null;
		ASTNode KW_VIEWS451_tree=null;
		ASTNode KW_FROM452_tree=null;
		ASTNode KW_IN453_tree=null;
		ASTNode KW_LIKE454_tree=null;
		ASTNode KW_SHOW457_tree=null;
		ASTNode KW_COLUMNS458_tree=null;
		ASTNode KW_FROM459_tree=null;
		ASTNode KW_IN460_tree=null;
		ASTNode KW_FROM462_tree=null;
		ASTNode KW_IN463_tree=null;
		ASTNode KW_LIKE464_tree=null;
		ASTNode KW_SHOW467_tree=null;
		ASTNode KW_FUNCTIONS468_tree=null;
		ASTNode KW_LIKE469_tree=null;
		ASTNode KW_SHOW471_tree=null;
		ASTNode KW_PARTITIONS472_tree=null;
		ASTNode KW_SHOW474_tree=null;
		ASTNode KW_CREATE475_tree=null;
		ASTNode KW_DATABASE476_tree=null;
		ASTNode KW_SCHEMA477_tree=null;
		ASTNode KW_TABLE478_tree=null;
		ASTNode KW_SHOW479_tree=null;
		ASTNode KW_TABLE480_tree=null;
		ASTNode KW_EXTENDED481_tree=null;
		ASTNode KW_FROM482_tree=null;
		ASTNode KW_IN483_tree=null;
		ASTNode KW_LIKE484_tree=null;
		ASTNode KW_SHOW487_tree=null;
		ASTNode KW_TBLPROPERTIES488_tree=null;
		ASTNode LPAREN490_tree=null;
		ASTNode RPAREN491_tree=null;
		ASTNode KW_SHOW492_tree=null;
		ASTNode KW_LOCKS493_tree=null;
		ASTNode KW_DATABASE494_tree=null;
		ASTNode KW_SCHEMA495_tree=null;
		ASTNode KW_SHOW496_tree=null;
		ASTNode KW_COMPACTIONS497_tree=null;
		ASTNode KW_SHOW498_tree=null;
		ASTNode KW_TRANSACTIONS499_tree=null;
		ASTNode KW_SHOW500_tree=null;
		ASTNode KW_CONF501_tree=null;
		ASTNode StringLiteral502_tree=null;
		ASTNode KW_SHOW503_tree=null;
		ASTNode KW_RESOURCE504_tree=null;
		ASTNode KW_PLAN505_tree=null;
		ASTNode KW_PLANS506_tree=null;
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_VIEWS=new RewriteRuleTokenStream(adaptor,"token KW_VIEWS");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_LIKE=new RewriteRuleTokenStream(adaptor,"token KW_LIKE");
		RewriteRuleTokenStream stream_KW_PARTITIONS=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONS");
		RewriteRuleTokenStream stream_KW_IN=new RewriteRuleTokenStream(adaptor,"token KW_IN");
		RewriteRuleTokenStream stream_KW_LOCKS=new RewriteRuleTokenStream(adaptor,"token KW_LOCKS");
		RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
		RewriteRuleTokenStream stream_KW_TABLES=new RewriteRuleTokenStream(adaptor,"token KW_TABLES");
		RewriteRuleTokenStream stream_KW_FUNCTIONS=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTIONS");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_CONF=new RewriteRuleTokenStream(adaptor,"token KW_CONF");
		RewriteRuleTokenStream stream_KW_PLAN=new RewriteRuleTokenStream(adaptor,"token KW_PLAN");
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_KW_TRANSACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTIONS");
		RewriteRuleTokenStream stream_KW_SCHEMAS=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMAS");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_COMPACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_COMPACTIONS");
		RewriteRuleTokenStream stream_KW_PLANS=new RewriteRuleTokenStream(adaptor,"token KW_PLANS");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_RESOURCE=new RewriteRuleTokenStream(adaptor,"token KW_RESOURCE");
		RewriteRuleTokenStream stream_KW_DATABASES=new RewriteRuleTokenStream(adaptor,"token KW_DATABASES");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
		RewriteRuleSubtreeStream stream_showStmtIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showStmtIdentifier");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_showTablesFilterExpr=new RewriteRuleSubtreeStream(adaptor,"rule showTablesFilterExpr");
		RewriteRuleSubtreeStream stream_showFunctionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showFunctionIdentifier");
		RewriteRuleSubtreeStream stream_partTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule partTypeExpr");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("show statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:5: ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW (isExtended= KW_EXTENDED )? KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? (filter= showTablesFilterExpr )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? ) | KW_SHOW KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_MATERIALIZED KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ) | KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) ) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) ) | KW_SHOW KW_COMPACTIONS -> ^( TOK_SHOW_COMPACTIONS ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) | KW_SHOW KW_RESOURCE ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) ) )
			int alt158=15;
			int LA158_0 = input.LA(1);
			if ( (LA158_0==KW_SHOW) ) {
				switch ( input.LA(2) ) {
				case KW_VIEWS:
					{
					alt158=3;
					}
					break;
				case KW_MATERIALIZED:
					{
					alt158=4;
					}
					break;
				case KW_COLUMNS:
					{
					alt158=5;
					}
					break;
				case KW_FUNCTIONS:
					{
					alt158=6;
					}
					break;
				case KW_PARTITIONS:
					{
					alt158=7;
					}
					break;
				case KW_CREATE:
					{
					alt158=8;
					}
					break;
				case KW_TABLE:
					{
					alt158=9;
					}
					break;
				case KW_TBLPROPERTIES:
					{
					alt158=10;
					}
					break;
				case KW_LOCKS:
					{
					alt158=11;
					}
					break;
				case KW_COMPACTIONS:
					{
					alt158=12;
					}
					break;
				case KW_TRANSACTIONS:
					{
					alt158=13;
					}
					break;
				case KW_CONF:
					{
					alt158=14;
					}
					break;
				case KW_RESOURCE:
					{
					alt158=15;
					}
					break;
				case KW_DATABASES:
				case KW_SCHEMAS:
					{
					alt158=1;
					}
					break;
				case KW_EXTENDED:
				case KW_TABLES:
					{
					alt158=2;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 158, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 158, 0, input);
				throw nvae;
			}

			switch (alt158) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:7: KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )?
					{
					KW_SHOW433=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7905); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW433);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:15: ( KW_DATABASES | KW_SCHEMAS )
					int alt128=2;
					int LA128_0 = input.LA(1);
					if ( (LA128_0==KW_DATABASES) ) {
						alt128=1;
					}
					else if ( (LA128_0==KW_SCHEMAS) ) {
						alt128=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 128, 0, input);
						throw nvae;
					}

					switch (alt128) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:16: KW_DATABASES
							{
							KW_DATABASES434=(Token)match(input,KW_DATABASES,FOLLOW_KW_DATABASES_in_showStatement7908); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASES.add(KW_DATABASES434);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:29: KW_SCHEMAS
							{
							KW_SCHEMAS435=(Token)match(input,KW_SCHEMAS,FOLLOW_KW_SCHEMAS_in_showStatement7910); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMAS.add(KW_SCHEMAS435);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:41: ( KW_LIKE showStmtIdentifier )?
					int alt129=2;
					int LA129_0 = input.LA(1);
					if ( (LA129_0==KW_LIKE) ) {
						alt129=1;
					}
					switch (alt129) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:42: KW_LIKE showStmtIdentifier
							{
							KW_LIKE436=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement7914); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE436);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement7916);
							showStmtIdentifier437=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier437.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: showStmtIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1612:71: -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:74: ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWDATABASES, "TOK_SHOWDATABASES"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:94: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:7: KW_SHOW (isExtended= KW_EXTENDED )? KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? (filter= showTablesFilterExpr )?
					{
					KW_SHOW438=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7935); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW438);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:15: (isExtended= KW_EXTENDED )?
					int alt130=2;
					int LA130_0 = input.LA(1);
					if ( (LA130_0==KW_EXTENDED) ) {
						alt130=1;
					}
					switch (alt130) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:16: isExtended= KW_EXTENDED
							{
							isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement7940); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);

							}
							break;

					}

					KW_TABLES439=(Token)match(input,KW_TABLES,FOLLOW_KW_TABLES_in_showStatement7944); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLES.add(KW_TABLES439);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:51: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt132=2;
					int LA132_0 = input.LA(1);
					if ( (LA132_0==KW_FROM||LA132_0==KW_IN) ) {
						alt132=1;
					}
					switch (alt132) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:52: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:52: ( KW_FROM | KW_IN )
							int alt131=2;
							int LA131_0 = input.LA(1);
							if ( (LA131_0==KW_FROM) ) {
								alt131=1;
							}
							else if ( (LA131_0==KW_IN) ) {
								alt131=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 131, 0, input);
								throw nvae;
							}

							switch (alt131) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:53: KW_FROM
									{
									KW_FROM440=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement7948); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM440);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:61: KW_IN
									{
									KW_IN441=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement7950); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN441);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement7955);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:89: (filter= showTablesFilterExpr )?
					int alt133=2;
					int LA133_0 = input.LA(1);
					if ( (LA133_0==Identifier||(LA133_0 >= KW_ABORT && LA133_0 <= KW_AFTER)||LA133_0==KW_ALLOC_FRACTION||LA133_0==KW_ANALYZE||LA133_0==KW_ARCHIVE||LA133_0==KW_ASC||(LA133_0 >= KW_AUTOCOMMIT && LA133_0 <= KW_BEFORE)||(LA133_0 >= KW_BUCKET && LA133_0 <= KW_BUCKETS)||(LA133_0 >= KW_CACHE && LA133_0 <= KW_CASCADE)||(LA133_0 >= KW_CBO && LA133_0 <= KW_CHANGE)||(LA133_0 >= KW_CHECK && LA133_0 <= KW_COLLECTION)||(LA133_0 >= KW_COLUMNS && LA133_0 <= KW_COMMENT)||(LA133_0 >= KW_COMPACT && LA133_0 <= KW_CONCATENATE)||(LA133_0 >= KW_CONTINUE && LA133_0 <= KW_COST)||LA133_0==KW_DATA||LA133_0==KW_DATABASES||(LA133_0 >= KW_DATETIME && LA133_0 <= KW_DEBUG)||(LA133_0 >= KW_DEFAULT && LA133_0 <= KW_DEFINED)||(LA133_0 >= KW_DELIMITED && LA133_0 <= KW_DESC)||(LA133_0 >= KW_DETAIL && LA133_0 <= KW_DISABLE)||(LA133_0 >= KW_DISTRIBUTE && LA133_0 <= KW_DO)||LA133_0==KW_DOW||(LA133_0 >= KW_DUMP && LA133_0 <= KW_ELEM_TYPE)||LA133_0==KW_ENABLE||(LA133_0 >= KW_ENFORCED && LA133_0 <= KW_ESCAPED)||LA133_0==KW_EXCLUSIVE||(LA133_0 >= KW_EXPLAIN && LA133_0 <= KW_EXPRESSION)||(LA133_0 >= KW_FIELDS && LA133_0 <= KW_FIRST)||(LA133_0 >= KW_FORMAT && LA133_0 <= KW_FORMATTED)||LA133_0==KW_FUNCTIONS||(LA133_0 >= KW_HOUR && LA133_0 <= KW_IDXPROPERTIES)||(LA133_0 >= KW_INDEX && LA133_0 <= KW_INDEXES)||(LA133_0 >= KW_INPATH && LA133_0 <= KW_INPUTFORMAT)||(LA133_0 >= KW_ISOLATION && LA133_0 <= KW_JAR)||(LA133_0 >= KW_JOINCOST && LA133_0 <= KW_LAST)||(LA133_0 >= KW_LEVEL && LA133_0 <= KW_LOAD)||(LA133_0 >= KW_LOCATION && LA133_0 <= KW_LONG)||LA133_0==KW_MANAGEMENT||(LA133_0 >= KW_MAPJOIN && LA133_0 <= KW_MATERIALIZED)||LA133_0==KW_METADATA||(LA133_0 >= KW_MINUTE && LA133_0 <= KW_MONTH)||(LA133_0 >= KW_MOVE && LA133_0 <= KW_MSCK)||(LA133_0 >= KW_NORELY && LA133_0 <= KW_NOSCAN)||LA133_0==KW_NOVALIDATE||LA133_0==KW_NULLS||LA133_0==KW_OFFSET||(LA133_0 >= KW_OPERATOR && LA133_0 <= KW_OPTION)||(LA133_0 >= KW_OUTPUTDRIVER && LA133_0 <= KW_OUTPUTFORMAT)||(LA133_0 >= KW_OVERWRITE && LA133_0 <= KW_OWNER)||(LA133_0 >= KW_PARTITIONED && LA133_0 <= KW_PATH)||(LA133_0 >= KW_PLAN && LA133_0 <= KW_POOL)||LA133_0==KW_PRINCIPALS||(LA133_0 >= KW_PURGE && LA133_0 <= KW_QUERY_PARALLELISM)||LA133_0==KW_READ||(LA133_0 >= KW_REBUILD && LA133_0 <= KW_RECORDWRITER)||(LA133_0 >= KW_RELOAD && LA133_0 <= KW_RESTRICT)||LA133_0==KW_REWRITE||(LA133_0 >= KW_ROLE && LA133_0 <= KW_ROLES)||(LA133_0 >= KW_SCHEDULING_POLICY && LA133_0 <= KW_SECOND)||(LA133_0 >= KW_SEMI && LA133_0 <= KW_SERVER)||(LA133_0 >= KW_SETS && LA133_0 <= KW_SKEWED)||(LA133_0 >= KW_SNAPSHOT && LA133_0 <= KW_SSL)||(LA133_0 >= KW_STATISTICS && LA133_0 <= KW_SUMMARY)||LA133_0==KW_TABLES||(LA133_0 >= KW_TBLPROPERTIES && LA133_0 <= KW_TERMINATED)||LA133_0==KW_TINYINT||(LA133_0 >= KW_TOUCH && LA133_0 <= KW_TRANSACTIONS)||LA133_0==KW_UNARCHIVE||LA133_0==KW_UNDO||LA133_0==KW_UNIONTYPE||(LA133_0 >= KW_UNLOCK && LA133_0 <= KW_UNSIGNED)||(LA133_0 >= KW_URI && LA133_0 <= KW_USE)||(LA133_0 >= KW_UTC && LA133_0 <= KW_VALIDATE)||LA133_0==KW_VALUE_TYPE||(LA133_0 >= KW_VECTORIZATION && LA133_0 <= KW_WEEK)||(LA133_0 >= KW_WHERE && LA133_0 <= KW_WHILE)||(LA133_0 >= KW_WORK && LA133_0 <= KW_ZONE)||LA133_0==StringLiteral||LA133_0==KW_BATCH||LA133_0==KW_DAYOFWEEK||LA133_0==KW_HOLD_DDLTIME||LA133_0==KW_IGNORE||LA133_0==KW_NO_DROP||LA133_0==KW_OFFLINE||LA133_0==KW_PROTECTION||LA133_0==KW_READONLY||LA133_0==KW_TIMESTAMPTZ) ) {
						alt133=1;
					}
					switch (alt133) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:90: filter= showTablesFilterExpr
							{
							pushFollow(FOLLOW_showTablesFilterExpr_in_showStatement7962);
							filter=showTablesFilterExpr();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showTablesFilterExpr.add(filter.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: filter, isExtended, db_name
					// token labels: isExtended
					// rule labels: filter, db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
					RewriteRuleSubtreeStream stream_filter=new RewriteRuleSubtreeStream(adaptor,"rule filter",filter!=null?filter.getTree():null);
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1614:5: -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1614:8: ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWTABLES, "TOK_SHOWTABLES"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1614:25: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1614:47: ( $filter)?
						if ( stream_filter.hasNext() ) {
							adaptor.addChild(root_1, stream_filter.nextTree());
						}
						stream_filter.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1614:56: ( $isExtended)?
						if ( stream_isExtended.hasNext() ) {
							adaptor.addChild(root_1, stream_isExtended.nextNode());
						}
						stream_isExtended.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:7: KW_SHOW KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					{
					KW_SHOW442=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7998); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW442);

					KW_VIEWS443=(Token)match(input,KW_VIEWS,FOLLOW_KW_VIEWS_in_showStatement8000); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VIEWS.add(KW_VIEWS443);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:24: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt135=2;
					int LA135_0 = input.LA(1);
					if ( (LA135_0==KW_FROM||LA135_0==KW_IN) ) {
						alt135=1;
					}
					switch (alt135) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:25: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:25: ( KW_FROM | KW_IN )
							int alt134=2;
							int LA134_0 = input.LA(1);
							if ( (LA134_0==KW_FROM) ) {
								alt134=1;
							}
							else if ( (LA134_0==KW_IN) ) {
								alt134=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 134, 0, input);
								throw nvae;
							}

							switch (alt134) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:26: KW_FROM
									{
									KW_FROM444=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8004); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM444);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:34: KW_IN
									{
									KW_IN445=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8006); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN445);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8011);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:62: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					int alt136=3;
					int LA136_0 = input.LA(1);
					if ( (LA136_0==KW_LIKE) ) {
						alt136=1;
					}
					else if ( (LA136_0==Identifier||(LA136_0 >= KW_ABORT && LA136_0 <= KW_AFTER)||LA136_0==KW_ALLOC_FRACTION||LA136_0==KW_ANALYZE||LA136_0==KW_ARCHIVE||LA136_0==KW_ASC||(LA136_0 >= KW_AUTOCOMMIT && LA136_0 <= KW_BEFORE)||(LA136_0 >= KW_BUCKET && LA136_0 <= KW_BUCKETS)||(LA136_0 >= KW_CACHE && LA136_0 <= KW_CASCADE)||(LA136_0 >= KW_CBO && LA136_0 <= KW_CHANGE)||(LA136_0 >= KW_CHECK && LA136_0 <= KW_COLLECTION)||(LA136_0 >= KW_COLUMNS && LA136_0 <= KW_COMMENT)||(LA136_0 >= KW_COMPACT && LA136_0 <= KW_CONCATENATE)||(LA136_0 >= KW_CONTINUE && LA136_0 <= KW_COST)||LA136_0==KW_DATA||LA136_0==KW_DATABASES||(LA136_0 >= KW_DATETIME && LA136_0 <= KW_DEBUG)||(LA136_0 >= KW_DEFAULT && LA136_0 <= KW_DEFINED)||(LA136_0 >= KW_DELIMITED && LA136_0 <= KW_DESC)||(LA136_0 >= KW_DETAIL && LA136_0 <= KW_DISABLE)||(LA136_0 >= KW_DISTRIBUTE && LA136_0 <= KW_DO)||LA136_0==KW_DOW||(LA136_0 >= KW_DUMP && LA136_0 <= KW_ELEM_TYPE)||LA136_0==KW_ENABLE||(LA136_0 >= KW_ENFORCED && LA136_0 <= KW_ESCAPED)||LA136_0==KW_EXCLUSIVE||(LA136_0 >= KW_EXPLAIN && LA136_0 <= KW_EXPRESSION)||(LA136_0 >= KW_FIELDS && LA136_0 <= KW_FIRST)||(LA136_0 >= KW_FORMAT && LA136_0 <= KW_FORMATTED)||LA136_0==KW_FUNCTIONS||(LA136_0 >= KW_HOUR && LA136_0 <= KW_IDXPROPERTIES)||(LA136_0 >= KW_INDEX && LA136_0 <= KW_INDEXES)||(LA136_0 >= KW_INPATH && LA136_0 <= KW_INPUTFORMAT)||(LA136_0 >= KW_ISOLATION && LA136_0 <= KW_JAR)||(LA136_0 >= KW_JOINCOST && LA136_0 <= KW_LAST)||LA136_0==KW_LEVEL||(LA136_0 >= KW_LIMIT && LA136_0 <= KW_LOAD)||(LA136_0 >= KW_LOCATION && LA136_0 <= KW_LONG)||LA136_0==KW_MANAGEMENT||(LA136_0 >= KW_MAPJOIN && LA136_0 <= KW_MATERIALIZED)||LA136_0==KW_METADATA||(LA136_0 >= KW_MINUTE && LA136_0 <= KW_MONTH)||(LA136_0 >= KW_MOVE && LA136_0 <= KW_MSCK)||(LA136_0 >= KW_NORELY && LA136_0 <= KW_NOSCAN)||LA136_0==KW_NOVALIDATE||LA136_0==KW_NULLS||LA136_0==KW_OFFSET||(LA136_0 >= KW_OPERATOR && LA136_0 <= KW_OPTION)||(LA136_0 >= KW_OUTPUTDRIVER && LA136_0 <= KW_OUTPUTFORMAT)||(LA136_0 >= KW_OVERWRITE && LA136_0 <= KW_OWNER)||(LA136_0 >= KW_PARTITIONED && LA136_0 <= KW_PATH)||(LA136_0 >= KW_PLAN && LA136_0 <= KW_POOL)||LA136_0==KW_PRINCIPALS||(LA136_0 >= KW_PURGE && LA136_0 <= KW_QUERY_PARALLELISM)||LA136_0==KW_READ||(LA136_0 >= KW_REBUILD && LA136_0 <= KW_RECORDWRITER)||(LA136_0 >= KW_RELOAD && LA136_0 <= KW_RESTRICT)||LA136_0==KW_REWRITE||(LA136_0 >= KW_ROLE && LA136_0 <= KW_ROLES)||(LA136_0 >= KW_SCHEDULING_POLICY && LA136_0 <= KW_SECOND)||(LA136_0 >= KW_SEMI && LA136_0 <= KW_SERVER)||(LA136_0 >= KW_SETS && LA136_0 <= KW_SKEWED)||(LA136_0 >= KW_SNAPSHOT && LA136_0 <= KW_SSL)||(LA136_0 >= KW_STATISTICS && LA136_0 <= KW_SUMMARY)||LA136_0==KW_TABLES||(LA136_0 >= KW_TBLPROPERTIES && LA136_0 <= KW_TERMINATED)||LA136_0==KW_TINYINT||(LA136_0 >= KW_TOUCH && LA136_0 <= KW_TRANSACTIONS)||LA136_0==KW_UNARCHIVE||LA136_0==KW_UNDO||LA136_0==KW_UNIONTYPE||(LA136_0 >= KW_UNLOCK && LA136_0 <= KW_UNSIGNED)||(LA136_0 >= KW_URI && LA136_0 <= KW_USE)||(LA136_0 >= KW_UTC && LA136_0 <= KW_VALIDATE)||LA136_0==KW_VALUE_TYPE||(LA136_0 >= KW_VECTORIZATION && LA136_0 <= KW_WEEK)||LA136_0==KW_WHILE||(LA136_0 >= KW_WORK && LA136_0 <= KW_ZONE)||LA136_0==StringLiteral||LA136_0==KW_BATCH||LA136_0==KW_DAYOFWEEK||LA136_0==KW_HOLD_DDLTIME||LA136_0==KW_IGNORE||LA136_0==KW_NO_DROP||LA136_0==KW_OFFLINE||LA136_0==KW_PROTECTION||LA136_0==KW_READONLY||LA136_0==KW_TIMESTAMPTZ) ) {
						alt136=2;
					}
					switch (alt136) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:63: KW_LIKE showStmtIdentifier
							{
							KW_LIKE446=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8016); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE446);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8018);
							showStmtIdentifier447=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier447.getTree());
							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:90: showStmtIdentifier
							{
							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8020);
							showStmtIdentifier448=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier448.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: showStmtIdentifier, db_name
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1615:112: -> ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:115: ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWVIEWS, "TOK_SHOWVIEWS"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:131: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:152: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:7: KW_SHOW KW_MATERIALIZED KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					{
					KW_SHOW449=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8048); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW449);

					KW_MATERIALIZED450=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_showStatement8050); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED450);

					KW_VIEWS451=(Token)match(input,KW_VIEWS,FOLLOW_KW_VIEWS_in_showStatement8052); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VIEWS.add(KW_VIEWS451);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:40: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt138=2;
					int LA138_0 = input.LA(1);
					if ( (LA138_0==KW_FROM||LA138_0==KW_IN) ) {
						alt138=1;
					}
					switch (alt138) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:41: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:41: ( KW_FROM | KW_IN )
							int alt137=2;
							int LA137_0 = input.LA(1);
							if ( (LA137_0==KW_FROM) ) {
								alt137=1;
							}
							else if ( (LA137_0==KW_IN) ) {
								alt137=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 137, 0, input);
								throw nvae;
							}

							switch (alt137) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:42: KW_FROM
									{
									KW_FROM452=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8056); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM452);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:50: KW_IN
									{
									KW_IN453=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8058); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN453);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8063);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:78: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					int alt139=3;
					int LA139_0 = input.LA(1);
					if ( (LA139_0==KW_LIKE) ) {
						alt139=1;
					}
					else if ( (LA139_0==Identifier||(LA139_0 >= KW_ABORT && LA139_0 <= KW_AFTER)||LA139_0==KW_ALLOC_FRACTION||LA139_0==KW_ANALYZE||LA139_0==KW_ARCHIVE||LA139_0==KW_ASC||(LA139_0 >= KW_AUTOCOMMIT && LA139_0 <= KW_BEFORE)||(LA139_0 >= KW_BUCKET && LA139_0 <= KW_BUCKETS)||(LA139_0 >= KW_CACHE && LA139_0 <= KW_CASCADE)||(LA139_0 >= KW_CBO && LA139_0 <= KW_CHANGE)||(LA139_0 >= KW_CHECK && LA139_0 <= KW_COLLECTION)||(LA139_0 >= KW_COLUMNS && LA139_0 <= KW_COMMENT)||(LA139_0 >= KW_COMPACT && LA139_0 <= KW_CONCATENATE)||(LA139_0 >= KW_CONTINUE && LA139_0 <= KW_COST)||LA139_0==KW_DATA||LA139_0==KW_DATABASES||(LA139_0 >= KW_DATETIME && LA139_0 <= KW_DEBUG)||(LA139_0 >= KW_DEFAULT && LA139_0 <= KW_DEFINED)||(LA139_0 >= KW_DELIMITED && LA139_0 <= KW_DESC)||(LA139_0 >= KW_DETAIL && LA139_0 <= KW_DISABLE)||(LA139_0 >= KW_DISTRIBUTE && LA139_0 <= KW_DO)||LA139_0==KW_DOW||(LA139_0 >= KW_DUMP && LA139_0 <= KW_ELEM_TYPE)||LA139_0==KW_ENABLE||(LA139_0 >= KW_ENFORCED && LA139_0 <= KW_ESCAPED)||LA139_0==KW_EXCLUSIVE||(LA139_0 >= KW_EXPLAIN && LA139_0 <= KW_EXPRESSION)||(LA139_0 >= KW_FIELDS && LA139_0 <= KW_FIRST)||(LA139_0 >= KW_FORMAT && LA139_0 <= KW_FORMATTED)||LA139_0==KW_FUNCTIONS||(LA139_0 >= KW_HOUR && LA139_0 <= KW_IDXPROPERTIES)||(LA139_0 >= KW_INDEX && LA139_0 <= KW_INDEXES)||(LA139_0 >= KW_INPATH && LA139_0 <= KW_INPUTFORMAT)||(LA139_0 >= KW_ISOLATION && LA139_0 <= KW_JAR)||(LA139_0 >= KW_JOINCOST && LA139_0 <= KW_LAST)||LA139_0==KW_LEVEL||(LA139_0 >= KW_LIMIT && LA139_0 <= KW_LOAD)||(LA139_0 >= KW_LOCATION && LA139_0 <= KW_LONG)||LA139_0==KW_MANAGEMENT||(LA139_0 >= KW_MAPJOIN && LA139_0 <= KW_MATERIALIZED)||LA139_0==KW_METADATA||(LA139_0 >= KW_MINUTE && LA139_0 <= KW_MONTH)||(LA139_0 >= KW_MOVE && LA139_0 <= KW_MSCK)||(LA139_0 >= KW_NORELY && LA139_0 <= KW_NOSCAN)||LA139_0==KW_NOVALIDATE||LA139_0==KW_NULLS||LA139_0==KW_OFFSET||(LA139_0 >= KW_OPERATOR && LA139_0 <= KW_OPTION)||(LA139_0 >= KW_OUTPUTDRIVER && LA139_0 <= KW_OUTPUTFORMAT)||(LA139_0 >= KW_OVERWRITE && LA139_0 <= KW_OWNER)||(LA139_0 >= KW_PARTITIONED && LA139_0 <= KW_PATH)||(LA139_0 >= KW_PLAN && LA139_0 <= KW_POOL)||LA139_0==KW_PRINCIPALS||(LA139_0 >= KW_PURGE && LA139_0 <= KW_QUERY_PARALLELISM)||LA139_0==KW_READ||(LA139_0 >= KW_REBUILD && LA139_0 <= KW_RECORDWRITER)||(LA139_0 >= KW_RELOAD && LA139_0 <= KW_RESTRICT)||LA139_0==KW_REWRITE||(LA139_0 >= KW_ROLE && LA139_0 <= KW_ROLES)||(LA139_0 >= KW_SCHEDULING_POLICY && LA139_0 <= KW_SECOND)||(LA139_0 >= KW_SEMI && LA139_0 <= KW_SERVER)||(LA139_0 >= KW_SETS && LA139_0 <= KW_SKEWED)||(LA139_0 >= KW_SNAPSHOT && LA139_0 <= KW_SSL)||(LA139_0 >= KW_STATISTICS && LA139_0 <= KW_SUMMARY)||LA139_0==KW_TABLES||(LA139_0 >= KW_TBLPROPERTIES && LA139_0 <= KW_TERMINATED)||LA139_0==KW_TINYINT||(LA139_0 >= KW_TOUCH && LA139_0 <= KW_TRANSACTIONS)||LA139_0==KW_UNARCHIVE||LA139_0==KW_UNDO||LA139_0==KW_UNIONTYPE||(LA139_0 >= KW_UNLOCK && LA139_0 <= KW_UNSIGNED)||(LA139_0 >= KW_URI && LA139_0 <= KW_USE)||(LA139_0 >= KW_UTC && LA139_0 <= KW_VALIDATE)||LA139_0==KW_VALUE_TYPE||(LA139_0 >= KW_VECTORIZATION && LA139_0 <= KW_WEEK)||LA139_0==KW_WHILE||(LA139_0 >= KW_WORK && LA139_0 <= KW_ZONE)||LA139_0==StringLiteral||LA139_0==KW_BATCH||LA139_0==KW_DAYOFWEEK||LA139_0==KW_HOLD_DDLTIME||LA139_0==KW_IGNORE||LA139_0==KW_NO_DROP||LA139_0==KW_OFFLINE||LA139_0==KW_PROTECTION||LA139_0==KW_READONLY||LA139_0==KW_TIMESTAMPTZ) ) {
						alt139=2;
					}
					switch (alt139) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:79: KW_LIKE showStmtIdentifier
							{
							KW_LIKE454=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8068); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE454);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8070);
							showStmtIdentifier455=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier455.getTree());
							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:106: showStmtIdentifier
							{
							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8072);
							showStmtIdentifier456=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier456.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: showStmtIdentifier, db_name
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1616:128: -> ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:131: ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWMATERIALIZEDVIEWS, "TOK_SHOWMATERIALIZEDVIEWS"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:159: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:180: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:7: KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					{
					KW_SHOW457=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8100); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW457);

					KW_COLUMNS458=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_showStatement8102); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS458);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:26: ( KW_FROM | KW_IN )
					int alt140=2;
					int LA140_0 = input.LA(1);
					if ( (LA140_0==KW_FROM) ) {
						alt140=1;
					}
					else if ( (LA140_0==KW_IN) ) {
						alt140=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 140, 0, input);
						throw nvae;
					}

					switch (alt140) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:27: KW_FROM
							{
							KW_FROM459=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8105); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM459);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:35: KW_IN
							{
							KW_IN460=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8107); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN460);

							}
							break;

					}

					pushFollow(FOLLOW_tableName_in_showStatement8110);
					tableName461=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName461.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:52: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt142=2;
					int LA142_0 = input.LA(1);
					if ( (LA142_0==KW_FROM||LA142_0==KW_IN) ) {
						alt142=1;
					}
					switch (alt142) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:53: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:53: ( KW_FROM | KW_IN )
							int alt141=2;
							int LA141_0 = input.LA(1);
							if ( (LA141_0==KW_FROM) ) {
								alt141=1;
							}
							else if ( (LA141_0==KW_IN) ) {
								alt141=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 141, 0, input);
								throw nvae;
							}

							switch (alt141) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:54: KW_FROM
									{
									KW_FROM462=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8114); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM462);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:62: KW_IN
									{
									KW_IN463=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8116); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN463);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8121);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:90: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					int alt143=3;
					int LA143_0 = input.LA(1);
					if ( (LA143_0==KW_LIKE) ) {
						alt143=1;
					}
					else if ( (LA143_0==Identifier||(LA143_0 >= KW_ABORT && LA143_0 <= KW_AFTER)||LA143_0==KW_ALLOC_FRACTION||LA143_0==KW_ANALYZE||LA143_0==KW_ARCHIVE||LA143_0==KW_ASC||(LA143_0 >= KW_AUTOCOMMIT && LA143_0 <= KW_BEFORE)||(LA143_0 >= KW_BUCKET && LA143_0 <= KW_BUCKETS)||(LA143_0 >= KW_CACHE && LA143_0 <= KW_CASCADE)||(LA143_0 >= KW_CBO && LA143_0 <= KW_CHANGE)||(LA143_0 >= KW_CHECK && LA143_0 <= KW_COLLECTION)||(LA143_0 >= KW_COLUMNS && LA143_0 <= KW_COMMENT)||(LA143_0 >= KW_COMPACT && LA143_0 <= KW_CONCATENATE)||(LA143_0 >= KW_CONTINUE && LA143_0 <= KW_COST)||LA143_0==KW_DATA||LA143_0==KW_DATABASES||(LA143_0 >= KW_DATETIME && LA143_0 <= KW_DEBUG)||(LA143_0 >= KW_DEFAULT && LA143_0 <= KW_DEFINED)||(LA143_0 >= KW_DELIMITED && LA143_0 <= KW_DESC)||(LA143_0 >= KW_DETAIL && LA143_0 <= KW_DISABLE)||(LA143_0 >= KW_DISTRIBUTE && LA143_0 <= KW_DO)||LA143_0==KW_DOW||(LA143_0 >= KW_DUMP && LA143_0 <= KW_ELEM_TYPE)||LA143_0==KW_ENABLE||(LA143_0 >= KW_ENFORCED && LA143_0 <= KW_ESCAPED)||LA143_0==KW_EXCLUSIVE||(LA143_0 >= KW_EXPLAIN && LA143_0 <= KW_EXPRESSION)||(LA143_0 >= KW_FIELDS && LA143_0 <= KW_FIRST)||(LA143_0 >= KW_FORMAT && LA143_0 <= KW_FORMATTED)||LA143_0==KW_FUNCTIONS||(LA143_0 >= KW_HOUR && LA143_0 <= KW_IDXPROPERTIES)||(LA143_0 >= KW_INDEX && LA143_0 <= KW_INDEXES)||(LA143_0 >= KW_INPATH && LA143_0 <= KW_INPUTFORMAT)||(LA143_0 >= KW_ISOLATION && LA143_0 <= KW_JAR)||(LA143_0 >= KW_JOINCOST && LA143_0 <= KW_LAST)||LA143_0==KW_LEVEL||(LA143_0 >= KW_LIMIT && LA143_0 <= KW_LOAD)||(LA143_0 >= KW_LOCATION && LA143_0 <= KW_LONG)||LA143_0==KW_MANAGEMENT||(LA143_0 >= KW_MAPJOIN && LA143_0 <= KW_MATERIALIZED)||LA143_0==KW_METADATA||(LA143_0 >= KW_MINUTE && LA143_0 <= KW_MONTH)||(LA143_0 >= KW_MOVE && LA143_0 <= KW_MSCK)||(LA143_0 >= KW_NORELY && LA143_0 <= KW_NOSCAN)||LA143_0==KW_NOVALIDATE||LA143_0==KW_NULLS||LA143_0==KW_OFFSET||(LA143_0 >= KW_OPERATOR && LA143_0 <= KW_OPTION)||(LA143_0 >= KW_OUTPUTDRIVER && LA143_0 <= KW_OUTPUTFORMAT)||(LA143_0 >= KW_OVERWRITE && LA143_0 <= KW_OWNER)||(LA143_0 >= KW_PARTITIONED && LA143_0 <= KW_PATH)||(LA143_0 >= KW_PLAN && LA143_0 <= KW_POOL)||LA143_0==KW_PRINCIPALS||(LA143_0 >= KW_PURGE && LA143_0 <= KW_QUERY_PARALLELISM)||LA143_0==KW_READ||(LA143_0 >= KW_REBUILD && LA143_0 <= KW_RECORDWRITER)||(LA143_0 >= KW_RELOAD && LA143_0 <= KW_RESTRICT)||LA143_0==KW_REWRITE||(LA143_0 >= KW_ROLE && LA143_0 <= KW_ROLES)||(LA143_0 >= KW_SCHEDULING_POLICY && LA143_0 <= KW_SECOND)||(LA143_0 >= KW_SEMI && LA143_0 <= KW_SERVER)||(LA143_0 >= KW_SETS && LA143_0 <= KW_SKEWED)||(LA143_0 >= KW_SNAPSHOT && LA143_0 <= KW_SSL)||(LA143_0 >= KW_STATISTICS && LA143_0 <= KW_SUMMARY)||LA143_0==KW_TABLES||(LA143_0 >= KW_TBLPROPERTIES && LA143_0 <= KW_TERMINATED)||LA143_0==KW_TINYINT||(LA143_0 >= KW_TOUCH && LA143_0 <= KW_TRANSACTIONS)||LA143_0==KW_UNARCHIVE||LA143_0==KW_UNDO||LA143_0==KW_UNIONTYPE||(LA143_0 >= KW_UNLOCK && LA143_0 <= KW_UNSIGNED)||(LA143_0 >= KW_URI && LA143_0 <= KW_USE)||(LA143_0 >= KW_UTC && LA143_0 <= KW_VALIDATE)||LA143_0==KW_VALUE_TYPE||(LA143_0 >= KW_VECTORIZATION && LA143_0 <= KW_WEEK)||LA143_0==KW_WHILE||(LA143_0 >= KW_WORK && LA143_0 <= KW_ZONE)||LA143_0==StringLiteral||LA143_0==KW_BATCH||LA143_0==KW_DAYOFWEEK||LA143_0==KW_HOLD_DDLTIME||LA143_0==KW_IGNORE||LA143_0==KW_NO_DROP||LA143_0==KW_OFFLINE||LA143_0==KW_PROTECTION||LA143_0==KW_READONLY||LA143_0==KW_TIMESTAMPTZ) ) {
						alt143=2;
					}
					switch (alt143) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:91: KW_LIKE showStmtIdentifier
							{
							KW_LIKE464=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8126); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE464);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8128);
							showStmtIdentifier465=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier465.getTree());
							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:118: showStmtIdentifier
							{
							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8130);
							showStmtIdentifier466=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier466.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: db_name, showStmtIdentifier, tableName
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1618:5: -> ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1618:8: ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWCOLUMNS, "TOK_SHOWCOLUMNS"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1618:36: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1618:57: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:7: KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier )?
					{
					KW_SHOW467=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8163); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW467);

					KW_FUNCTIONS468=(Token)match(input,KW_FUNCTIONS,FOLLOW_KW_FUNCTIONS_in_showStatement8165); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTIONS.add(KW_FUNCTIONS468);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:28: ( KW_LIKE showFunctionIdentifier )?
					int alt144=2;
					int LA144_0 = input.LA(1);
					if ( (LA144_0==KW_LIKE) ) {
						alt144=1;
					}
					switch (alt144) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:29: KW_LIKE showFunctionIdentifier
							{
							KW_LIKE469=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8168); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE469);

							pushFollow(FOLLOW_showFunctionIdentifier_in_showStatement8170);
							showFunctionIdentifier470=showFunctionIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showFunctionIdentifier.add(showFunctionIdentifier470.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: KW_LIKE, showFunctionIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1619:63: -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:66: ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWFUNCTIONS, "TOK_SHOWFUNCTIONS"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:86: ( KW_LIKE )?
						if ( stream_KW_LIKE.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_LIKE.nextNode());
						}
						stream_KW_LIKE.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:95: ( showFunctionIdentifier )?
						if ( stream_showFunctionIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showFunctionIdentifier.nextTree());
						}
						stream_showFunctionIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1620:7: KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )?
					{
					KW_SHOW471=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8193); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW471);

					KW_PARTITIONS472=(Token)match(input,KW_PARTITIONS,FOLLOW_KW_PARTITIONS_in_showStatement8195); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PARTITIONS.add(KW_PARTITIONS472);

					pushFollow(FOLLOW_tableName_in_showStatement8199);
					tabName=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1620:47: ( partitionSpec )?
					int alt145=2;
					int LA145_0 = input.LA(1);
					if ( (LA145_0==KW_PARTITION) ) {
						alt145=1;
					}
					switch (alt145) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1620:47: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_showStatement8201);
							partitionSpec473=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec473.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: partitionSpec, tabName
					// token labels: 
					// rule labels: tabName, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1620:62: -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1620:65: ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWPARTITIONS, "TOK_SHOWPARTITIONS"), root_1);
						adaptor.addChild(root_1, stream_tabName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1620:95: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1621:7: KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) )
					{
					KW_SHOW474=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8223); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW474);

					KW_CREATE475=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_showStatement8225); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE475);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1621:25: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) )
					int alt147=2;
					int LA147_0 = input.LA(1);
					if ( (LA147_0==KW_DATABASE) && (synpred12_HiveParser())) {
						alt147=1;
					}
					else if ( (LA147_0==KW_SCHEMA) && (synpred12_HiveParser())) {
						alt147=1;
					}
					else if ( (LA147_0==KW_TABLE) ) {
						alt147=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 147, 0, input);
						throw nvae;
					}

					switch (alt147) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:9: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:36: ( KW_DATABASE | KW_SCHEMA )
							int alt146=2;
							int LA146_0 = input.LA(1);
							if ( (LA146_0==KW_DATABASE) ) {
								alt146=1;
							}
							else if ( (LA146_0==KW_SCHEMA) ) {
								alt146=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 146, 0, input);
								throw nvae;
							}

							switch (alt146) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:37: KW_DATABASE
									{
									KW_DATABASE476=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_showStatement8246); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE476);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:49: KW_SCHEMA
									{
									KW_SCHEMA477=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_showStatement8248); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA477);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8253);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							// AST REWRITE
							// elements: db_name
							// token labels: 
							// rule labels: db_name, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1622:79: -> ^( TOK_SHOW_CREATEDATABASE $db_name)
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:82: ^( TOK_SHOW_CREATEDATABASE $db_name)
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_CREATEDATABASE, "TOK_SHOW_CREATEDATABASE"), root_1);
								adaptor.addChild(root_1, stream_db_name.nextTree());
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1624:9: KW_TABLE tabName= tableName
							{
							KW_TABLE478=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_showStatement8282); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE478);

							pushFollow(FOLLOW_tableName_in_showStatement8286);
							tabName=tableName();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
							// AST REWRITE
							// elements: tabName
							// token labels: 
							// rule labels: tabName, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1624:36: -> ^( TOK_SHOW_CREATETABLE $tabName)
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1624:39: ^( TOK_SHOW_CREATETABLE $tabName)
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_CREATETABLE, "TOK_SHOW_CREATETABLE"), root_1);
								adaptor.addChild(root_1, stream_tabName.nextTree());
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;

					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:7: KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )?
					{
					KW_SHOW479=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8311); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW479);

					KW_TABLE480=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_showStatement8313); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE480);

					KW_EXTENDED481=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement8315); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED481);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:36: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt149=2;
					int LA149_0 = input.LA(1);
					if ( (LA149_0==KW_FROM||LA149_0==KW_IN) ) {
						alt149=1;
					}
					switch (alt149) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:37: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:37: ( KW_FROM | KW_IN )
							int alt148=2;
							int LA148_0 = input.LA(1);
							if ( (LA148_0==KW_FROM) ) {
								alt148=1;
							}
							else if ( (LA148_0==KW_IN) ) {
								alt148=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 148, 0, input);
								throw nvae;
							}

							switch (alt148) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:38: KW_FROM
									{
									KW_FROM482=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8319); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM482);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:46: KW_IN
									{
									KW_IN483=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8321); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN483);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8326);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					KW_LIKE484=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8330); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE484);

					pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8332);
					showStmtIdentifier485=showStmtIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier485.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:101: ( partitionSpec )?
					int alt150=2;
					int LA150_0 = input.LA(1);
					if ( (LA150_0==KW_PARTITION) ) {
						alt150=1;
					}
					switch (alt150) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:101: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_showStatement8334);
							partitionSpec486=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec486.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: showStmtIdentifier, db_name, partitionSpec
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1627:5: -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1627:8: ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_TABLESTATUS, "TOK_SHOW_TABLESTATUS"), root_1);
						adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1627:51: ( $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1627:60: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:7: KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )?
					{
					KW_SHOW487=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8362); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW487);

					KW_TBLPROPERTIES488=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_showStatement8364); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES488);

					pushFollow(FOLLOW_tableName_in_showStatement8366);
					tableName489=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName489.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:42: ( LPAREN prptyName= StringLiteral RPAREN )?
					int alt151=2;
					int LA151_0 = input.LA(1);
					if ( (LA151_0==LPAREN) ) {
						alt151=1;
					}
					switch (alt151) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:43: LPAREN prptyName= StringLiteral RPAREN
							{
							LPAREN490=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_showStatement8369); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN490);

							prptyName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStatement8373); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(prptyName);

							RPAREN491=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_showStatement8375); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN491);

							}
							break;

					}

					// AST REWRITE
					// elements: prptyName, tableName
					// token labels: prptyName
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_prptyName=new RewriteRuleTokenStream(adaptor,"token prptyName",prptyName);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1628:83: -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:86: ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_TBLPROPERTIES, "TOK_SHOW_TBLPROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:122: ( $prptyName)?
						if ( stream_prptyName.hasNext() ) {
							adaptor.addChild(root_1, stream_prptyName.nextNode());
						}
						stream_prptyName.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1629:7: KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) )
					{
					KW_SHOW492=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8397); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW492);

					KW_LOCKS493=(Token)match(input,KW_LOCKS,FOLLOW_KW_LOCKS_in_showStatement8399); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCKS.add(KW_LOCKS493);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1630:7: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) )
					int alt156=2;
					int LA156_0 = input.LA(1);
					if ( (LA156_0==KW_DATABASE) && (synpred13_HiveParser())) {
						alt156=1;
					}
					else if ( (LA156_0==KW_SCHEMA) ) {
						switch ( input.LA(2) ) {
						case Identifier:
							{
							int LA156_7 = input.LA(3);
							if ( (synpred13_HiveParser()) ) {
								alt156=1;
							}
							else if ( (true) ) {
								alt156=2;
							}

							}
							break;
						case KW_ABORT:
						case KW_ACTIVATE:
						case KW_ACTIVE:
						case KW_ADD:
						case KW_ADMIN:
						case KW_AFTER:
						case KW_ALLOC_FRACTION:
						case KW_ANALYZE:
						case KW_ARCHIVE:
						case KW_ASC:
						case KW_AUTOCOMMIT:
						case KW_BEFORE:
						case KW_BUCKET:
						case KW_BUCKETS:
						case KW_CACHE:
						case KW_CASCADE:
						case KW_CBO:
						case KW_CHANGE:
						case KW_CHECK:
						case KW_CLUSTER:
						case KW_CLUSTERED:
						case KW_CLUSTERSTATUS:
						case KW_COLLECTION:
						case KW_COLUMNS:
						case KW_COMMENT:
						case KW_COMPACT:
						case KW_COMPACTIONS:
						case KW_COMPUTE:
						case KW_CONCATENATE:
						case KW_CONTINUE:
						case KW_COST:
						case KW_DATA:
						case KW_DATABASES:
						case KW_DATETIME:
						case KW_DAY:
						case KW_DBPROPERTIES:
						case KW_DEBUG:
						case KW_DEFAULT:
						case KW_DEFERRED:
						case KW_DEFINED:
						case KW_DELIMITED:
						case KW_DEPENDENCY:
						case KW_DESC:
						case KW_DETAIL:
						case KW_DIRECTORIES:
						case KW_DIRECTORY:
						case KW_DISABLE:
						case KW_DISTRIBUTE:
						case KW_DISTRIBUTED:
						case KW_DO:
						case KW_DOW:
						case KW_DUMP:
						case KW_ELEM_TYPE:
						case KW_ENABLE:
						case KW_ENFORCED:
						case KW_ESCAPED:
						case KW_EXCLUSIVE:
						case KW_EXPLAIN:
						case KW_EXPORT:
						case KW_EXPRESSION:
						case KW_FIELDS:
						case KW_FILE:
						case KW_FILEFORMAT:
						case KW_FIRST:
						case KW_FORMAT:
						case KW_FORMATTED:
						case KW_FUNCTIONS:
						case KW_HOUR:
						case KW_IDXPROPERTIES:
						case KW_INDEX:
						case KW_INDEXES:
						case KW_INPATH:
						case KW_INPUTDRIVER:
						case KW_INPUTFORMAT:
						case KW_ISOLATION:
						case KW_ITEMS:
						case KW_JAR:
						case KW_JOINCOST:
						case KW_KEY:
						case KW_KEYS:
						case KW_KEY_TYPE:
						case KW_KILL:
						case KW_LAST:
						case KW_LEVEL:
						case KW_LIMIT:
						case KW_LINES:
						case KW_LOAD:
						case KW_LOCATION:
						case KW_LOCK:
						case KW_LOCKS:
						case KW_LOGICAL:
						case KW_LONG:
						case KW_MANAGEMENT:
						case KW_MAPJOIN:
						case KW_MAPPING:
						case KW_MATCHED:
						case KW_MATERIALIZED:
						case KW_METADATA:
						case KW_MINUTE:
						case KW_MONTH:
						case KW_MOVE:
						case KW_MSCK:
						case KW_NORELY:
						case KW_NOSCAN:
						case KW_NOVALIDATE:
						case KW_NULLS:
						case KW_OFFSET:
						case KW_OPERATOR:
						case KW_OPTION:
						case KW_OUTPUTDRIVER:
						case KW_OUTPUTFORMAT:
						case KW_OVERWRITE:
						case KW_OWNER:
						case KW_PARTITIONED:
						case KW_PARTITIONS:
						case KW_PATH:
						case KW_PLAN:
						case KW_PLANS:
						case KW_PLUS:
						case KW_POOL:
						case KW_PRINCIPALS:
						case KW_PURGE:
						case KW_QUARTER:
						case KW_QUERY:
						case KW_QUERY_PARALLELISM:
						case KW_READ:
						case KW_REBUILD:
						case KW_RECORDREADER:
						case KW_RECORDWRITER:
						case KW_RELOAD:
						case KW_RELY:
						case KW_RENAME:
						case KW_REOPTIMIZATION:
						case KW_REPAIR:
						case KW_REPL:
						case KW_REPLACE:
						case KW_REPLICATION:
						case KW_RESOURCE:
						case KW_RESTRICT:
						case KW_REWRITE:
						case KW_ROLE:
						case KW_ROLES:
						case KW_SCHEDULING_POLICY:
						case KW_SCHEMA:
						case KW_SCHEMAS:
						case KW_SECOND:
						case KW_SEMI:
						case KW_SERDE:
						case KW_SERDEPROPERTIES:
						case KW_SERVER:
						case KW_SETS:
						case KW_SHARED:
						case KW_SHOW:
						case KW_SHOW_DATABASE:
						case KW_SKEWED:
						case KW_SNAPSHOT:
						case KW_SORT:
						case KW_SORTED:
						case KW_SSL:
						case KW_STATISTICS:
						case KW_STATUS:
						case KW_STORED:
						case KW_STREAMTABLE:
						case KW_STRING:
						case KW_STRUCT:
						case KW_SUMMARY:
						case KW_TABLES:
						case KW_TBLPROPERTIES:
						case KW_TEMPORARY:
						case KW_TERMINATED:
						case KW_TINYINT:
						case KW_TOUCH:
						case KW_TRANSACTION:
						case KW_TRANSACTIONAL:
						case KW_TRANSACTIONS:
						case KW_UNARCHIVE:
						case KW_UNDO:
						case KW_UNIONTYPE:
						case KW_UNLOCK:
						case KW_UNMANAGED:
						case KW_UNSET:
						case KW_UNSIGNED:
						case KW_URI:
						case KW_USE:
						case KW_UTC:
						case KW_UTCTIMESTAMP:
						case KW_VALIDATE:
						case KW_VALUE_TYPE:
						case KW_VECTORIZATION:
						case KW_VIEW:
						case KW_VIEWS:
						case KW_WAIT:
						case KW_WEEK:
						case KW_WHILE:
						case KW_WORK:
						case KW_WORKLOAD:
						case KW_WRITE:
						case KW_YEAR:
						case KW_ZONE:
						case KW_BATCH:
						case KW_DAYOFWEEK:
						case KW_HOLD_DDLTIME:
						case KW_IGNORE:
						case KW_NO_DROP:
						case KW_OFFLINE:
						case KW_PROTECTION:
						case KW_READONLY:
						case KW_TIMESTAMPTZ:
							{
							int LA156_8 = input.LA(3);
							if ( (synpred13_HiveParser()) ) {
								alt156=1;
							}
							else if ( (true) ) {
								alt156=2;
							}

							}
							break;
						case EOF:
						case DOT:
						case KW_EXTENDED:
						case KW_PARTITION:
							{
							alt156=2;
							}
							break;
						default:
							if (state.backtracking>0) {state.failed=true; return retval;}
							int nvaeMark = input.mark();
							try {
								input.consume();
								NoViableAltException nvae =
									new NoViableAltException("", 156, 2, input);
								throw nvae;
							} finally {
								input.rewind(nvaeMark);
							}
						}
					}
					else if ( (LA156_0==EOF||LA156_0==Identifier||(LA156_0 >= KW_ABORT && LA156_0 <= KW_AFTER)||LA156_0==KW_ALLOC_FRACTION||LA156_0==KW_ANALYZE||LA156_0==KW_ARCHIVE||LA156_0==KW_ASC||(LA156_0 >= KW_AUTOCOMMIT && LA156_0 <= KW_BEFORE)||(LA156_0 >= KW_BUCKET && LA156_0 <= KW_BUCKETS)||(LA156_0 >= KW_CACHE && LA156_0 <= KW_CASCADE)||(LA156_0 >= KW_CBO && LA156_0 <= KW_CHANGE)||(LA156_0 >= KW_CHECK && LA156_0 <= KW_COLLECTION)||(LA156_0 >= KW_COLUMNS && LA156_0 <= KW_COMMENT)||(LA156_0 >= KW_COMPACT && LA156_0 <= KW_CONCATENATE)||(LA156_0 >= KW_CONTINUE && LA156_0 <= KW_COST)||LA156_0==KW_DATA||LA156_0==KW_DATABASES||(LA156_0 >= KW_DATETIME && LA156_0 <= KW_DEBUG)||(LA156_0 >= KW_DEFAULT && LA156_0 <= KW_DEFINED)||(LA156_0 >= KW_DELIMITED && LA156_0 <= KW_DESC)||(LA156_0 >= KW_DETAIL && LA156_0 <= KW_DISABLE)||(LA156_0 >= KW_DISTRIBUTE && LA156_0 <= KW_DO)||LA156_0==KW_DOW||(LA156_0 >= KW_DUMP && LA156_0 <= KW_ELEM_TYPE)||LA156_0==KW_ENABLE||(LA156_0 >= KW_ENFORCED && LA156_0 <= KW_ESCAPED)||LA156_0==KW_EXCLUSIVE||(LA156_0 >= KW_EXPLAIN && LA156_0 <= KW_EXTENDED)||(LA156_0 >= KW_FIELDS && LA156_0 <= KW_FIRST)||(LA156_0 >= KW_FORMAT && LA156_0 <= KW_FORMATTED)||LA156_0==KW_FUNCTIONS||(LA156_0 >= KW_HOUR && LA156_0 <= KW_IDXPROPERTIES)||(LA156_0 >= KW_INDEX && LA156_0 <= KW_INDEXES)||(LA156_0 >= KW_INPATH && LA156_0 <= KW_INPUTFORMAT)||(LA156_0 >= KW_ISOLATION && LA156_0 <= KW_JAR)||(LA156_0 >= KW_JOINCOST && LA156_0 <= KW_LAST)||LA156_0==KW_LEVEL||(LA156_0 >= KW_LIMIT && LA156_0 <= KW_LOAD)||(LA156_0 >= KW_LOCATION && LA156_0 <= KW_LONG)||LA156_0==KW_MANAGEMENT||(LA156_0 >= KW_MAPJOIN && LA156_0 <= KW_MATERIALIZED)||LA156_0==KW_METADATA||(LA156_0 >= KW_MINUTE && LA156_0 <= KW_MONTH)||(LA156_0 >= KW_MOVE && LA156_0 <= KW_MSCK)||(LA156_0 >= KW_NORELY && LA156_0 <= KW_NOSCAN)||LA156_0==KW_NOVALIDATE||LA156_0==KW_NULLS||LA156_0==KW_OFFSET||(LA156_0 >= KW_OPERATOR && LA156_0 <= KW_OPTION)||(LA156_0 >= KW_OUTPUTDRIVER && LA156_0 <= KW_OUTPUTFORMAT)||(LA156_0 >= KW_OVERWRITE && LA156_0 <= KW_OWNER)||(LA156_0 >= KW_PARTITIONED && LA156_0 <= KW_PATH)||(LA156_0 >= KW_PLAN && LA156_0 <= KW_POOL)||LA156_0==KW_PRINCIPALS||(LA156_0 >= KW_PURGE && LA156_0 <= KW_QUERY_PARALLELISM)||LA156_0==KW_READ||(LA156_0 >= KW_REBUILD && LA156_0 <= KW_RECORDWRITER)||(LA156_0 >= KW_RELOAD && LA156_0 <= KW_RESTRICT)||LA156_0==KW_REWRITE||(LA156_0 >= KW_ROLE && LA156_0 <= KW_ROLES)||LA156_0==KW_SCHEDULING_POLICY||(LA156_0 >= KW_SCHEMAS && LA156_0 <= KW_SECOND)||(LA156_0 >= KW_SEMI && LA156_0 <= KW_SERVER)||(LA156_0 >= KW_SETS && LA156_0 <= KW_SKEWED)||(LA156_0 >= KW_SNAPSHOT && LA156_0 <= KW_SSL)||(LA156_0 >= KW_STATISTICS && LA156_0 <= KW_SUMMARY)||LA156_0==KW_TABLES||(LA156_0 >= KW_TBLPROPERTIES && LA156_0 <= KW_TERMINATED)||LA156_0==KW_TINYINT||(LA156_0 >= KW_TOUCH && LA156_0 <= KW_TRANSACTIONS)||LA156_0==KW_UNARCHIVE||LA156_0==KW_UNDO||LA156_0==KW_UNIONTYPE||(LA156_0 >= KW_UNLOCK && LA156_0 <= KW_UNSIGNED)||(LA156_0 >= KW_URI && LA156_0 <= KW_USE)||(LA156_0 >= KW_UTC && LA156_0 <= KW_VALIDATE)||LA156_0==KW_VALUE_TYPE||(LA156_0 >= KW_VECTORIZATION && LA156_0 <= KW_WEEK)||LA156_0==KW_WHILE||(LA156_0 >= KW_WORK && LA156_0 <= KW_ZONE)||LA156_0==KW_BATCH||LA156_0==KW_DAYOFWEEK||LA156_0==KW_HOLD_DDLTIME||LA156_0==KW_IGNORE||LA156_0==KW_NO_DROP||LA156_0==KW_OFFLINE||LA156_0==KW_PROTECTION||LA156_0==KW_READONLY||LA156_0==KW_TIMESTAMPTZ) ) {
						alt156=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 156, 0, input);
						throw nvae;
					}

					switch (alt156) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:7: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )?
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:34: ( KW_DATABASE | KW_SCHEMA )
							int alt152=2;
							int LA152_0 = input.LA(1);
							if ( (LA152_0==KW_DATABASE) ) {
								alt152=1;
							}
							else if ( (LA152_0==KW_SCHEMA) ) {
								alt152=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 152, 0, input);
								throw nvae;
							}

							switch (alt152) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:35: KW_DATABASE
									{
									KW_DATABASE494=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_showStatement8425); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE494);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:47: KW_SCHEMA
									{
									KW_SCHEMA495=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_showStatement8427); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA495);

									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:58: (dbName= identifier )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:59: dbName= identifier
							{
							pushFollow(FOLLOW_identifier_in_showStatement8433);
							dbName=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:78: (isExtended= KW_EXTENDED )?
							int alt153=2;
							int LA153_0 = input.LA(1);
							if ( (LA153_0==KW_EXTENDED) ) {
								alt153=1;
							}
							switch (alt153) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:79: isExtended= KW_EXTENDED
									{
									isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement8439); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);

									}
									break;

							}

							// AST REWRITE
							// elements: isExtended, dbName
							// token labels: isExtended
							// rule labels: dbName, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
							RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1631:104: -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:107: ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWDBLOCKS, "TOK_SHOWDBLOCKS"), root_1);
								adaptor.addChild(root_1, stream_dbName.nextTree());
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:134: ( $isExtended)?
								if ( stream_isExtended.hasNext() ) {
									adaptor.addChild(root_1, stream_isExtended.nextNode());
								}
								stream_isExtended.reset();

								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:7: (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )?
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:7: (parttype= partTypeExpr )?
							int alt154=2;
							int LA154_0 = input.LA(1);
							if ( (LA154_0==Identifier||(LA154_0 >= KW_ABORT && LA154_0 <= KW_AFTER)||LA154_0==KW_ALLOC_FRACTION||LA154_0==KW_ANALYZE||LA154_0==KW_ARCHIVE||LA154_0==KW_ASC||(LA154_0 >= KW_AUTOCOMMIT && LA154_0 <= KW_BEFORE)||(LA154_0 >= KW_BUCKET && LA154_0 <= KW_BUCKETS)||(LA154_0 >= KW_CACHE && LA154_0 <= KW_CASCADE)||(LA154_0 >= KW_CBO && LA154_0 <= KW_CHANGE)||(LA154_0 >= KW_CHECK && LA154_0 <= KW_COLLECTION)||(LA154_0 >= KW_COLUMNS && LA154_0 <= KW_COMMENT)||(LA154_0 >= KW_COMPACT && LA154_0 <= KW_CONCATENATE)||(LA154_0 >= KW_CONTINUE && LA154_0 <= KW_COST)||LA154_0==KW_DATA||LA154_0==KW_DATABASES||(LA154_0 >= KW_DATETIME && LA154_0 <= KW_DEBUG)||(LA154_0 >= KW_DEFAULT && LA154_0 <= KW_DEFINED)||(LA154_0 >= KW_DELIMITED && LA154_0 <= KW_DESC)||(LA154_0 >= KW_DETAIL && LA154_0 <= KW_DISABLE)||(LA154_0 >= KW_DISTRIBUTE && LA154_0 <= KW_DO)||LA154_0==KW_DOW||(LA154_0 >= KW_DUMP && LA154_0 <= KW_ELEM_TYPE)||LA154_0==KW_ENABLE||(LA154_0 >= KW_ENFORCED && LA154_0 <= KW_ESCAPED)||LA154_0==KW_EXCLUSIVE||(LA154_0 >= KW_EXPLAIN && LA154_0 <= KW_EXPRESSION)||(LA154_0 >= KW_FIELDS && LA154_0 <= KW_FIRST)||(LA154_0 >= KW_FORMAT && LA154_0 <= KW_FORMATTED)||LA154_0==KW_FUNCTIONS||(LA154_0 >= KW_HOUR && LA154_0 <= KW_IDXPROPERTIES)||(LA154_0 >= KW_INDEX && LA154_0 <= KW_INDEXES)||(LA154_0 >= KW_INPATH && LA154_0 <= KW_INPUTFORMAT)||(LA154_0 >= KW_ISOLATION && LA154_0 <= KW_JAR)||(LA154_0 >= KW_JOINCOST && LA154_0 <= KW_LAST)||LA154_0==KW_LEVEL||(LA154_0 >= KW_LIMIT && LA154_0 <= KW_LOAD)||(LA154_0 >= KW_LOCATION && LA154_0 <= KW_LONG)||LA154_0==KW_MANAGEMENT||(LA154_0 >= KW_MAPJOIN && LA154_0 <= KW_MATERIALIZED)||LA154_0==KW_METADATA||(LA154_0 >= KW_MINUTE && LA154_0 <= KW_MONTH)||(LA154_0 >= KW_MOVE && LA154_0 <= KW_MSCK)||(LA154_0 >= KW_NORELY && LA154_0 <= KW_NOSCAN)||LA154_0==KW_NOVALIDATE||LA154_0==KW_NULLS||LA154_0==KW_OFFSET||(LA154_0 >= KW_OPERATOR && LA154_0 <= KW_OPTION)||(LA154_0 >= KW_OUTPUTDRIVER && LA154_0 <= KW_OUTPUTFORMAT)||(LA154_0 >= KW_OVERWRITE && LA154_0 <= KW_OWNER)||(LA154_0 >= KW_PARTITIONED && LA154_0 <= KW_PATH)||(LA154_0 >= KW_PLAN && LA154_0 <= KW_POOL)||LA154_0==KW_PRINCIPALS||(LA154_0 >= KW_PURGE && LA154_0 <= KW_QUERY_PARALLELISM)||LA154_0==KW_READ||(LA154_0 >= KW_REBUILD && LA154_0 <= KW_RECORDWRITER)||(LA154_0 >= KW_RELOAD && LA154_0 <= KW_RESTRICT)||LA154_0==KW_REWRITE||(LA154_0 >= KW_ROLE && LA154_0 <= KW_ROLES)||(LA154_0 >= KW_SCHEDULING_POLICY && LA154_0 <= KW_SECOND)||(LA154_0 >= KW_SEMI && LA154_0 <= KW_SERVER)||(LA154_0 >= KW_SETS && LA154_0 <= KW_SKEWED)||(LA154_0 >= KW_SNAPSHOT && LA154_0 <= KW_SSL)||(LA154_0 >= KW_STATISTICS && LA154_0 <= KW_SUMMARY)||LA154_0==KW_TABLES||(LA154_0 >= KW_TBLPROPERTIES && LA154_0 <= KW_TERMINATED)||LA154_0==KW_TINYINT||(LA154_0 >= KW_TOUCH && LA154_0 <= KW_TRANSACTIONS)||LA154_0==KW_UNARCHIVE||LA154_0==KW_UNDO||LA154_0==KW_UNIONTYPE||(LA154_0 >= KW_UNLOCK && LA154_0 <= KW_UNSIGNED)||(LA154_0 >= KW_URI && LA154_0 <= KW_USE)||(LA154_0 >= KW_UTC && LA154_0 <= KW_VALIDATE)||LA154_0==KW_VALUE_TYPE||(LA154_0 >= KW_VECTORIZATION && LA154_0 <= KW_WEEK)||LA154_0==KW_WHILE||(LA154_0 >= KW_WORK && LA154_0 <= KW_ZONE)||LA154_0==KW_BATCH||LA154_0==KW_DAYOFWEEK||LA154_0==KW_HOLD_DDLTIME||LA154_0==KW_IGNORE||LA154_0==KW_NO_DROP||LA154_0==KW_OFFLINE||LA154_0==KW_PROTECTION||LA154_0==KW_READONLY||LA154_0==KW_TIMESTAMPTZ) ) {
								alt154=1;
							}
							switch (alt154) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:8: parttype= partTypeExpr
									{
									pushFollow(FOLLOW_partTypeExpr_in_showStatement8473);
									parttype=partTypeExpr();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_partTypeExpr.add(parttype.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:32: (isExtended= KW_EXTENDED )?
							int alt155=2;
							int LA155_0 = input.LA(1);
							if ( (LA155_0==KW_EXTENDED) ) {
								alt155=1;
							}
							switch (alt155) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:33: isExtended= KW_EXTENDED
									{
									isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement8480); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);

									}
									break;

							}

							// AST REWRITE
							// elements: parttype, isExtended
							// token labels: isExtended
							// rule labels: parttype, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
							RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1633:58: -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:61: ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWLOCKS, "TOK_SHOWLOCKS"), root_1);
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:78: ( $parttype)?
								if ( stream_parttype.hasNext() ) {
									adaptor.addChild(root_1, stream_parttype.nextTree());
								}
								stream_parttype.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:89: ( $isExtended)?
								if ( stream_isExtended.hasNext() ) {
									adaptor.addChild(root_1, stream_isExtended.nextNode());
								}
								stream_isExtended.reset();

								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;

					}

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1635:7: KW_SHOW KW_COMPACTIONS
					{
					KW_SHOW496=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8512); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW496);

					KW_COMPACTIONS497=(Token)match(input,KW_COMPACTIONS,FOLLOW_KW_COMPACTIONS_in_showStatement8514); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMPACTIONS.add(KW_COMPACTIONS497);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1635:30: -> ^( TOK_SHOW_COMPACTIONS )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1635:33: ^( TOK_SHOW_COMPACTIONS )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_COMPACTIONS, "TOK_SHOW_COMPACTIONS"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1636:7: KW_SHOW KW_TRANSACTIONS
					{
					KW_SHOW498=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8528); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW498);

					KW_TRANSACTIONS499=(Token)match(input,KW_TRANSACTIONS,FOLLOW_KW_TRANSACTIONS_in_showStatement8530); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TRANSACTIONS.add(KW_TRANSACTIONS499);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1636:31: -> ^( TOK_SHOW_TRANSACTIONS )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1636:34: ^( TOK_SHOW_TRANSACTIONS )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_TRANSACTIONS, "TOK_SHOW_TRANSACTIONS"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1637:7: KW_SHOW KW_CONF StringLiteral
					{
					KW_SHOW500=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8544); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW500);

					KW_CONF501=(Token)match(input,KW_CONF,FOLLOW_KW_CONF_in_showStatement8546); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONF.add(KW_CONF501);

					StringLiteral502=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStatement8548); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral502);

					// AST REWRITE
					// elements: StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1637:37: -> ^( TOK_SHOWCONF StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1637:40: ^( TOK_SHOWCONF StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWCONF, "TOK_SHOWCONF"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 15 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1638:7: KW_SHOW KW_RESOURCE ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) )
					{
					KW_SHOW503=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8564); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW503);

					KW_RESOURCE504=(Token)match(input,KW_RESOURCE,FOLLOW_KW_RESOURCE_in_showStatement8566); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RESOURCE.add(KW_RESOURCE504);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1639:7: ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) )
					int alt157=2;
					int LA157_0 = input.LA(1);
					if ( (LA157_0==KW_PLAN) ) {
						alt157=1;
					}
					else if ( (LA157_0==KW_PLANS) ) {
						alt157=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 157, 0, input);
						throw nvae;
					}

					switch (alt157) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:9: ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:9: ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:10: KW_PLAN rp_name= identifier
							{
							KW_PLAN505=(Token)match(input,KW_PLAN,FOLLOW_KW_PLAN_in_showStatement8585); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PLAN.add(KW_PLAN505);

							pushFollow(FOLLOW_identifier_in_showStatement8589);
							rp_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(rp_name.getTree());
							// AST REWRITE
							// elements: rp_name
							// token labels: 
							// rule labels: retval, rp_name
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
							RewriteRuleSubtreeStream stream_rp_name=new RewriteRuleSubtreeStream(adaptor,"rule rp_name",rp_name!=null?rp_name.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1640:37: -> ^( TOK_SHOW_RP $rp_name)
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:40: ^( TOK_SHOW_RP $rp_name)
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_RP, "TOK_SHOW_RP"), root_1);
								adaptor.addChild(root_1, stream_rp_name.nextTree());
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:11: ( KW_PLANS -> ^( TOK_SHOW_RP ) )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:11: ( KW_PLANS -> ^( TOK_SHOW_RP ) )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:12: KW_PLANS
							{
							KW_PLANS506=(Token)match(input,KW_PLANS,FOLLOW_KW_PLANS_in_showStatement8612); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PLANS.add(KW_PLANS506);

							// AST REWRITE
							// elements: 
							// token labels: 
							// rule labels: retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1641:21: -> ^( TOK_SHOW_RP )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:24: ^( TOK_SHOW_RP )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_RP, "TOK_SHOW_RP"), root_1);
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}

							}
							break;

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showStatement"


	public static class showTablesFilterExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showTablesFilterExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:1: showTablesFilterExpr : ( KW_WHERE identifier EQUAL StringLiteral -> ^( TOK_TABLE_TYPE identifier StringLiteral ) | KW_LIKE showStmtIdentifier | showStmtIdentifier -> showStmtIdentifier );
	public final HiveParser.showTablesFilterExpr_return showTablesFilterExpr() throws RecognitionException {
		HiveParser.showTablesFilterExpr_return retval = new HiveParser.showTablesFilterExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHERE507=null;
		Token EQUAL509=null;
		Token StringLiteral510=null;
		Token KW_LIKE511=null;
		ParserRuleReturnScope identifier508 =null;
		ParserRuleReturnScope showStmtIdentifier512 =null;
		ParserRuleReturnScope showStmtIdentifier513 =null;

		ASTNode KW_WHERE507_tree=null;
		ASTNode EQUAL509_tree=null;
		ASTNode StringLiteral510_tree=null;
		ASTNode KW_LIKE511_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");
		RewriteRuleTokenStream stream_KW_WHERE=new RewriteRuleTokenStream(adaptor,"token KW_WHERE");
		RewriteRuleSubtreeStream stream_showStmtIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showStmtIdentifier");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("show tables filter expr", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1648:5: ( KW_WHERE identifier EQUAL StringLiteral -> ^( TOK_TABLE_TYPE identifier StringLiteral ) | KW_LIKE showStmtIdentifier | showStmtIdentifier -> showStmtIdentifier )
			int alt159=3;
			switch ( input.LA(1) ) {
			case KW_WHERE:
				{
				alt159=1;
				}
				break;
			case KW_LIKE:
				{
				alt159=2;
				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EXCLUSIVE:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_IDXPROPERTIES:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMA:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SERVER:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URI:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case StringLiteral:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_IGNORE:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt159=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 159, 0, input);
				throw nvae;
			}
			switch (alt159) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1648:7: KW_WHERE identifier EQUAL StringLiteral
					{
					KW_WHERE507=(Token)match(input,KW_WHERE,FOLLOW_KW_WHERE_in_showTablesFilterExpr8654); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WHERE.add(KW_WHERE507);

					pushFollow(FOLLOW_identifier_in_showTablesFilterExpr8656);
					identifier508=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier508.getTree());
					EQUAL509=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_showTablesFilterExpr8658); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL509);

					StringLiteral510=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showTablesFilterExpr8660); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral510);

					// AST REWRITE
					// elements: identifier, StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1649:5: -> ^( TOK_TABLE_TYPE identifier StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1649:8: ^( TOK_TABLE_TYPE identifier StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1650:7: KW_LIKE showStmtIdentifier
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_LIKE511=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showTablesFilterExpr8682); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_LIKE511_tree = (ASTNode)adaptor.create(KW_LIKE511);
					adaptor.addChild(root_0, KW_LIKE511_tree);
					}

					pushFollow(FOLLOW_showStmtIdentifier_in_showTablesFilterExpr8684);
					showStmtIdentifier512=showStmtIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showStmtIdentifier512.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1650:34: showStmtIdentifier
					{
					pushFollow(FOLLOW_showStmtIdentifier_in_showTablesFilterExpr8686);
					showStmtIdentifier513=showStmtIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier513.getTree());
					// AST REWRITE
					// elements: showStmtIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1651:5: -> showStmtIdentifier
					{
						adaptor.addChild(root_0, stream_showStmtIdentifier.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showTablesFilterExpr"


	public static class lockStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "lockStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:1: lockStatement : KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) ;
	public final HiveParser.lockStatement_return lockStatement() throws RecognitionException {
		HiveParser.lockStatement_return retval = new HiveParser.lockStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_LOCK514=null;
		Token KW_TABLE515=null;
		ParserRuleReturnScope tableName516 =null;
		ParserRuleReturnScope partitionSpec517 =null;
		ParserRuleReturnScope lockMode518 =null;

		ASTNode KW_LOCK514_tree=null;
		ASTNode KW_TABLE515_tree=null;
		RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_lockMode=new RewriteRuleSubtreeStream(adaptor,"rule lockMode");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("lock statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:5: ( KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:7: KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode
			{
			KW_LOCK514=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_lockStatement8721); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK514);

			KW_TABLE515=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_lockStatement8723); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE515);

			pushFollow(FOLLOW_tableName_in_lockStatement8725);
			tableName516=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName516.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:34: ( partitionSpec )?
			int alt160=2;
			int LA160_0 = input.LA(1);
			if ( (LA160_0==KW_PARTITION) ) {
				alt160=1;
			}
			switch (alt160) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:34: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_lockStatement8727);
					partitionSpec517=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec517.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_lockMode_in_lockStatement8730);
			lockMode518=lockMode();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_lockMode.add(lockMode518.getTree());
			// AST REWRITE
			// elements: partitionSpec, tableName, lockMode
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1657:58: -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:61: ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LOCKTABLE, "TOK_LOCKTABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				adaptor.addChild(root_1, stream_lockMode.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:96: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "lockStatement"


	public static class lockDatabase_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "lockDatabase"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1660:1: lockDatabase : KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) ;
	public final HiveParser.lockDatabase_return lockDatabase() throws RecognitionException {
		HiveParser.lockDatabase_return retval = new HiveParser.lockDatabase_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_LOCK519=null;
		Token KW_DATABASE520=null;
		Token KW_SCHEMA521=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope lockMode522 =null;

		ASTNode KW_LOCK519_tree=null;
		ASTNode KW_DATABASE520_tree=null;
		ASTNode KW_SCHEMA521_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_lockMode=new RewriteRuleSubtreeStream(adaptor,"rule lockMode");

		 pushMsg("lock database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:5: ( KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:7: KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) lockMode
			{
			KW_LOCK519=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_lockDatabase8770); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK519);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:15: ( KW_DATABASE | KW_SCHEMA )
			int alt161=2;
			int LA161_0 = input.LA(1);
			if ( (LA161_0==KW_DATABASE) ) {
				alt161=1;
			}
			else if ( (LA161_0==KW_SCHEMA) ) {
				alt161=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 161, 0, input);
				throw nvae;
			}

			switch (alt161) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:16: KW_DATABASE
					{
					KW_DATABASE520=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_lockDatabase8773); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE520);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:28: KW_SCHEMA
					{
					KW_SCHEMA521=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_lockDatabase8775); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA521);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:39: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:40: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_lockDatabase8781);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			pushFollow(FOLLOW_lockMode_in_lockDatabase8784);
			lockMode522=lockMode();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_lockMode.add(lockMode522.getTree());
			// AST REWRITE
			// elements: dbName, lockMode
			// token labels: 
			// rule labels: dbName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1663:68: -> ^( TOK_LOCKDB $dbName lockMode )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:71: ^( TOK_LOCKDB $dbName lockMode )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LOCKDB, "TOK_LOCKDB"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				adaptor.addChild(root_1, stream_lockMode.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "lockDatabase"


	public static class lockMode_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "lockMode"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1666:1: lockMode : ( KW_SHARED | KW_EXCLUSIVE );
	public final HiveParser.lockMode_return lockMode() throws RecognitionException {
		HiveParser.lockMode_return retval = new HiveParser.lockMode_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token set523=null;

		ASTNode set523_tree=null;

		 pushMsg("lock mode", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1669:5: ( KW_SHARED | KW_EXCLUSIVE )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:
			{
			root_0 = (ASTNode)adaptor.nil();


			set523=input.LT(1);
			if ( input.LA(1)==KW_EXCLUSIVE||input.LA(1)==KW_SHARED ) {
				input.consume();
				if ( state.backtracking==0 ) adaptor.addChild(root_0, (ASTNode)adaptor.create(set523));
				state.errorRecovery=false;
				state.failed=false;
			}
			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				MismatchedSetException mse = new MismatchedSetException(null,input);
				throw mse;
			}
			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "lockMode"


	public static class unlockStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "unlockStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:1: unlockStatement : KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) ;
	public final HiveParser.unlockStatement_return unlockStatement() throws RecognitionException {
		HiveParser.unlockStatement_return retval = new HiveParser.unlockStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNLOCK524=null;
		Token KW_TABLE525=null;
		ParserRuleReturnScope tableName526 =null;
		ParserRuleReturnScope partitionSpec527 =null;

		ASTNode KW_UNLOCK524_tree=null;
		ASTNode KW_TABLE525_tree=null;
		RewriteRuleTokenStream stream_KW_UNLOCK=new RewriteRuleTokenStream(adaptor,"token KW_UNLOCK");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("unlock statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:5: ( KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:7: KW_UNLOCK KW_TABLE tableName ( partitionSpec )?
			{
			KW_UNLOCK524=(Token)match(input,KW_UNLOCK,FOLLOW_KW_UNLOCK_in_unlockStatement8853); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNLOCK.add(KW_UNLOCK524);

			KW_TABLE525=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_unlockStatement8855); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE525);

			pushFollow(FOLLOW_tableName_in_unlockStatement8857);
			tableName526=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName526.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:36: ( partitionSpec )?
			int alt162=2;
			int LA162_0 = input.LA(1);
			if ( (LA162_0==KW_PARTITION) ) {
				alt162=1;
			}
			switch (alt162) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:36: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_unlockStatement8859);
					partitionSpec527=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec527.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableName, partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1675:52: -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:55: ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNLOCKTABLE, "TOK_UNLOCKTABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:83: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "unlockStatement"


	public static class unlockDatabase_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "unlockDatabase"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1678:1: unlockDatabase : KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) -> ^( TOK_UNLOCKDB $dbName) ;
	public final HiveParser.unlockDatabase_return unlockDatabase() throws RecognitionException {
		HiveParser.unlockDatabase_return retval = new HiveParser.unlockDatabase_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNLOCK528=null;
		Token KW_DATABASE529=null;
		Token KW_SCHEMA530=null;
		ParserRuleReturnScope dbName =null;

		ASTNode KW_UNLOCK528_tree=null;
		ASTNode KW_DATABASE529_tree=null;
		ASTNode KW_SCHEMA530_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_UNLOCK=new RewriteRuleTokenStream(adaptor,"token KW_UNLOCK");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("unlock database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:5: ( KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) -> ^( TOK_UNLOCKDB $dbName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:7: KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier )
			{
			KW_UNLOCK528=(Token)match(input,KW_UNLOCK,FOLLOW_KW_UNLOCK_in_unlockDatabase8899); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNLOCK.add(KW_UNLOCK528);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:17: ( KW_DATABASE | KW_SCHEMA )
			int alt163=2;
			int LA163_0 = input.LA(1);
			if ( (LA163_0==KW_DATABASE) ) {
				alt163=1;
			}
			else if ( (LA163_0==KW_SCHEMA) ) {
				alt163=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 163, 0, input);
				throw nvae;
			}

			switch (alt163) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:18: KW_DATABASE
					{
					KW_DATABASE529=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_unlockDatabase8902); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE529);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:30: KW_SCHEMA
					{
					KW_SCHEMA530=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_unlockDatabase8904); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA530);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:41: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:42: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_unlockDatabase8910);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			// AST REWRITE
			// elements: dbName
			// token labels: 
			// rule labels: dbName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1681:61: -> ^( TOK_UNLOCKDB $dbName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:64: ^( TOK_UNLOCKDB $dbName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNLOCKDB, "TOK_UNLOCKDB"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "unlockDatabase"


	public static class createRoleStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createRoleStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1684:1: createRoleStatement : KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) ;
	public final HiveParser.createRoleStatement_return createRoleStatement() throws RecognitionException {
		HiveParser.createRoleStatement_return retval = new HiveParser.createRoleStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE531=null;
		Token KW_ROLE532=null;
		ParserRuleReturnScope roleName =null;

		ASTNode KW_CREATE531_tree=null;
		ASTNode KW_ROLE532_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("create role", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1687:5: ( KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1687:7: KW_CREATE KW_ROLE roleName= identifier
			{
			KW_CREATE531=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createRoleStatement8947); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE531);

			KW_ROLE532=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_createRoleStatement8949); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE532);

			pushFollow(FOLLOW_identifier_in_createRoleStatement8953);
			roleName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());
			// AST REWRITE
			// elements: roleName
			// token labels: 
			// rule labels: roleName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1688:5: -> ^( TOK_CREATEROLE $roleName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:8: ^( TOK_CREATEROLE $roleName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEROLE, "TOK_CREATEROLE"), root_1);
				adaptor.addChild(root_1, stream_roleName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createRoleStatement"


	public static class dropRoleStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropRoleStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1691:1: dropRoleStatement : KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) ;
	public final HiveParser.dropRoleStatement_return dropRoleStatement() throws RecognitionException {
		HiveParser.dropRoleStatement_return retval = new HiveParser.dropRoleStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP533=null;
		Token KW_ROLE534=null;
		ParserRuleReturnScope roleName =null;

		ASTNode KW_DROP533_tree=null;
		ASTNode KW_ROLE534_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		pushMsg("drop role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1694:5: ( KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1694:7: KW_DROP KW_ROLE roleName= identifier
			{
			KW_DROP533=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropRoleStatement8993); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP533);

			KW_ROLE534=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_dropRoleStatement8995); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE534);

			pushFollow(FOLLOW_identifier_in_dropRoleStatement8999);
			roleName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());
			// AST REWRITE
			// elements: roleName
			// token labels: 
			// rule labels: roleName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1695:5: -> ^( TOK_DROPROLE $roleName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:8: ^( TOK_DROPROLE $roleName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPROLE, "TOK_DROPROLE"), root_1);
				adaptor.addChild(root_1, stream_roleName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropRoleStatement"


	public static class grantPrivileges_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "grantPrivileges"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1698:1: grantPrivileges : KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) ;
	public final HiveParser.grantPrivileges_return grantPrivileges() throws RecognitionException {
		HiveParser.grantPrivileges_return retval = new HiveParser.grantPrivileges_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_GRANT535=null;
		Token KW_TO537=null;
		ParserRuleReturnScope privList =null;
		ParserRuleReturnScope privilegeObject536 =null;
		ParserRuleReturnScope principalSpecification538 =null;
		ParserRuleReturnScope withGrantOption539 =null;

		ASTNode KW_GRANT535_tree=null;
		ASTNode KW_TO537_tree=null;
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleSubtreeStream stream_withGrantOption=new RewriteRuleSubtreeStream(adaptor,"rule withGrantOption");
		RewriteRuleSubtreeStream stream_privilegeList=new RewriteRuleSubtreeStream(adaptor,"rule privilegeList");
		RewriteRuleSubtreeStream stream_privilegeObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeObject");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("grant privileges", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:5: ( KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:7: KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )?
			{
			KW_GRANT535=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantPrivileges9039); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT535);

			pushFollow(FOLLOW_privilegeList_in_grantPrivileges9043);
			privList=privilegeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privilegeList.add(privList.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1702:7: ( privilegeObject )?
			int alt164=2;
			int LA164_0 = input.LA(1);
			if ( (LA164_0==KW_ON) ) {
				alt164=1;
			}
			switch (alt164) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1702:7: privilegeObject
					{
					pushFollow(FOLLOW_privilegeObject_in_grantPrivileges9051);
					privilegeObject536=privilegeObject();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privilegeObject.add(privilegeObject536.getTree());
					}
					break;

			}

			KW_TO537=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_grantPrivileges9060); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO537);

			pushFollow(FOLLOW_principalSpecification_in_grantPrivileges9062);
			principalSpecification538=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification538.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1704:7: ( withGrantOption )?
			int alt165=2;
			int LA165_0 = input.LA(1);
			if ( (LA165_0==KW_WITH) ) {
				alt165=1;
			}
			switch (alt165) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1704:7: withGrantOption
					{
					pushFollow(FOLLOW_withGrantOption_in_grantPrivileges9070);
					withGrantOption539=withGrantOption();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withGrantOption.add(withGrantOption539.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: privilegeObject, withGrantOption, principalSpecification, privList
			// token labels: 
			// rule labels: privList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_privList=new RewriteRuleSubtreeStream(adaptor,"rule privList",privList!=null?privList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1705:5: -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1705:8: ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT, "TOK_GRANT"), root_1);
				adaptor.addChild(root_1, stream_privList.nextTree());
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1705:53: ( privilegeObject )?
				if ( stream_privilegeObject.hasNext() ) {
					adaptor.addChild(root_1, stream_privilegeObject.nextTree());
				}
				stream_privilegeObject.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1705:70: ( withGrantOption )?
				if ( stream_withGrantOption.hasNext() ) {
					adaptor.addChild(root_1, stream_withGrantOption.nextTree());
				}
				stream_withGrantOption.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "grantPrivileges"


	public static class revokePrivileges_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "revokePrivileges"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1708:1: revokePrivileges : KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) ;
	public final HiveParser.revokePrivileges_return revokePrivileges() throws RecognitionException {
		HiveParser.revokePrivileges_return retval = new HiveParser.revokePrivileges_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REVOKE540=null;
		Token KW_FROM544=null;
		ParserRuleReturnScope grantOptionFor541 =null;
		ParserRuleReturnScope privilegeList542 =null;
		ParserRuleReturnScope privilegeObject543 =null;
		ParserRuleReturnScope principalSpecification545 =null;

		ASTNode KW_REVOKE540_tree=null;
		ASTNode KW_FROM544_tree=null;
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_REVOKE=new RewriteRuleTokenStream(adaptor,"token KW_REVOKE");
		RewriteRuleSubtreeStream stream_grantOptionFor=new RewriteRuleSubtreeStream(adaptor,"rule grantOptionFor");
		RewriteRuleSubtreeStream stream_privilegeList=new RewriteRuleSubtreeStream(adaptor,"rule privilegeList");
		RewriteRuleSubtreeStream stream_privilegeObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeObject");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("revoke privileges", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1711:5: ( KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1711:7: KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification
			{
			KW_REVOKE540=(Token)match(input,KW_REVOKE,FOLLOW_KW_REVOKE_in_revokePrivileges9119); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REVOKE.add(KW_REVOKE540);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1711:17: ( grantOptionFor )?
			int alt166=2;
			int LA166_0 = input.LA(1);
			if ( (LA166_0==KW_GRANT) ) {
				alt166=1;
			}
			switch (alt166) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1711:17: grantOptionFor
					{
					pushFollow(FOLLOW_grantOptionFor_in_revokePrivileges9121);
					grantOptionFor541=grantOptionFor();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_grantOptionFor.add(grantOptionFor541.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_privilegeList_in_revokePrivileges9124);
			privilegeList542=privilegeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privilegeList.add(privilegeList542.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1711:47: ( privilegeObject )?
			int alt167=2;
			int LA167_0 = input.LA(1);
			if ( (LA167_0==KW_ON) ) {
				alt167=1;
			}
			switch (alt167) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1711:47: privilegeObject
					{
					pushFollow(FOLLOW_privilegeObject_in_revokePrivileges9126);
					privilegeObject543=privilegeObject();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privilegeObject.add(privilegeObject543.getTree());
					}
					break;

			}

			KW_FROM544=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_revokePrivileges9129); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM544);

			pushFollow(FOLLOW_principalSpecification_in_revokePrivileges9131);
			principalSpecification545=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification545.getTree());
			// AST REWRITE
			// elements: grantOptionFor, privilegeList, privilegeObject, principalSpecification
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1712:5: -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:8: ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REVOKE, "TOK_REVOKE"), root_1);
				adaptor.addChild(root_1, stream_privilegeList.nextTree());
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:58: ( privilegeObject )?
				if ( stream_privilegeObject.hasNext() ) {
					adaptor.addChild(root_1, stream_privilegeObject.nextTree());
				}
				stream_privilegeObject.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:75: ( grantOptionFor )?
				if ( stream_grantOptionFor.hasNext() ) {
					adaptor.addChild(root_1, stream_grantOptionFor.nextTree());
				}
				stream_grantOptionFor.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "revokePrivileges"


	public static class grantRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "grantRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1715:1: grantRole : KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) ;
	public final HiveParser.grantRole_return grantRole() throws RecognitionException {
		HiveParser.grantRole_return retval = new HiveParser.grantRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_GRANT546=null;
		Token KW_ROLE547=null;
		Token COMMA549=null;
		Token KW_TO551=null;
		ParserRuleReturnScope identifier548 =null;
		ParserRuleReturnScope identifier550 =null;
		ParserRuleReturnScope principalSpecification552 =null;
		ParserRuleReturnScope withAdminOption553 =null;

		ASTNode KW_GRANT546_tree=null;
		ASTNode KW_ROLE547_tree=null;
		ASTNode COMMA549_tree=null;
		ASTNode KW_TO551_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_withAdminOption=new RewriteRuleSubtreeStream(adaptor,"rule withAdminOption");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("grant role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:5: ( KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:7: KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )?
			{
			KW_GRANT546=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantRole9178); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT546);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:16: ( KW_ROLE )?
			int alt168=2;
			int LA168_0 = input.LA(1);
			if ( (LA168_0==KW_ROLE) ) {
				int LA168_1 = input.LA(2);
				if ( (LA168_1==Identifier||(LA168_1 >= KW_ABORT && LA168_1 <= KW_AFTER)||LA168_1==KW_ALLOC_FRACTION||LA168_1==KW_ANALYZE||LA168_1==KW_ARCHIVE||LA168_1==KW_ASC||(LA168_1 >= KW_AUTOCOMMIT && LA168_1 <= KW_BEFORE)||(LA168_1 >= KW_BUCKET && LA168_1 <= KW_BUCKETS)||(LA168_1 >= KW_CACHE && LA168_1 <= KW_CASCADE)||(LA168_1 >= KW_CBO && LA168_1 <= KW_CHANGE)||(LA168_1 >= KW_CHECK && LA168_1 <= KW_COLLECTION)||(LA168_1 >= KW_COLUMNS && LA168_1 <= KW_COMMENT)||(LA168_1 >= KW_COMPACT && LA168_1 <= KW_CONCATENATE)||(LA168_1 >= KW_CONTINUE && LA168_1 <= KW_COST)||LA168_1==KW_DATA||LA168_1==KW_DATABASES||(LA168_1 >= KW_DATETIME && LA168_1 <= KW_DEBUG)||(LA168_1 >= KW_DEFAULT && LA168_1 <= KW_DEFINED)||(LA168_1 >= KW_DELIMITED && LA168_1 <= KW_DESC)||(LA168_1 >= KW_DETAIL && LA168_1 <= KW_DISABLE)||(LA168_1 >= KW_DISTRIBUTE && LA168_1 <= KW_DO)||LA168_1==KW_DOW||(LA168_1 >= KW_DUMP && LA168_1 <= KW_ELEM_TYPE)||LA168_1==KW_ENABLE||(LA168_1 >= KW_ENFORCED && LA168_1 <= KW_ESCAPED)||LA168_1==KW_EXCLUSIVE||(LA168_1 >= KW_EXPLAIN && LA168_1 <= KW_EXPRESSION)||(LA168_1 >= KW_FIELDS && LA168_1 <= KW_FIRST)||(LA168_1 >= KW_FORMAT && LA168_1 <= KW_FORMATTED)||LA168_1==KW_FUNCTIONS||(LA168_1 >= KW_HOUR && LA168_1 <= KW_IDXPROPERTIES)||(LA168_1 >= KW_INDEX && LA168_1 <= KW_INDEXES)||(LA168_1 >= KW_INPATH && LA168_1 <= KW_INPUTFORMAT)||(LA168_1 >= KW_ISOLATION && LA168_1 <= KW_JAR)||(LA168_1 >= KW_JOINCOST && LA168_1 <= KW_LAST)||LA168_1==KW_LEVEL||(LA168_1 >= KW_LIMIT && LA168_1 <= KW_LOAD)||(LA168_1 >= KW_LOCATION && LA168_1 <= KW_LONG)||LA168_1==KW_MANAGEMENT||(LA168_1 >= KW_MAPJOIN && LA168_1 <= KW_MATERIALIZED)||LA168_1==KW_METADATA||(LA168_1 >= KW_MINUTE && LA168_1 <= KW_MONTH)||(LA168_1 >= KW_MOVE && LA168_1 <= KW_MSCK)||(LA168_1 >= KW_NORELY && LA168_1 <= KW_NOSCAN)||LA168_1==KW_NOVALIDATE||LA168_1==KW_NULLS||LA168_1==KW_OFFSET||(LA168_1 >= KW_OPERATOR && LA168_1 <= KW_OPTION)||(LA168_1 >= KW_OUTPUTDRIVER && LA168_1 <= KW_OUTPUTFORMAT)||(LA168_1 >= KW_OVERWRITE && LA168_1 <= KW_OWNER)||(LA168_1 >= KW_PARTITIONED && LA168_1 <= KW_PATH)||(LA168_1 >= KW_PLAN && LA168_1 <= KW_POOL)||LA168_1==KW_PRINCIPALS||(LA168_1 >= KW_PURGE && LA168_1 <= KW_QUERY_PARALLELISM)||LA168_1==KW_READ||(LA168_1 >= KW_REBUILD && LA168_1 <= KW_RECORDWRITER)||(LA168_1 >= KW_RELOAD && LA168_1 <= KW_RESTRICT)||LA168_1==KW_REWRITE||(LA168_1 >= KW_ROLE && LA168_1 <= KW_ROLES)||(LA168_1 >= KW_SCHEDULING_POLICY && LA168_1 <= KW_SECOND)||(LA168_1 >= KW_SEMI && LA168_1 <= KW_SERVER)||(LA168_1 >= KW_SETS && LA168_1 <= KW_SKEWED)||(LA168_1 >= KW_SNAPSHOT && LA168_1 <= KW_SSL)||(LA168_1 >= KW_STATISTICS && LA168_1 <= KW_SUMMARY)||LA168_1==KW_TABLES||(LA168_1 >= KW_TBLPROPERTIES && LA168_1 <= KW_TERMINATED)||LA168_1==KW_TINYINT||(LA168_1 >= KW_TOUCH && LA168_1 <= KW_TRANSACTIONS)||LA168_1==KW_UNARCHIVE||LA168_1==KW_UNDO||LA168_1==KW_UNIONTYPE||(LA168_1 >= KW_UNLOCK && LA168_1 <= KW_UNSIGNED)||(LA168_1 >= KW_URI && LA168_1 <= KW_USE)||(LA168_1 >= KW_UTC && LA168_1 <= KW_VALIDATE)||LA168_1==KW_VALUE_TYPE||(LA168_1 >= KW_VECTORIZATION && LA168_1 <= KW_WEEK)||LA168_1==KW_WHILE||(LA168_1 >= KW_WORK && LA168_1 <= KW_ZONE)||LA168_1==KW_BATCH||LA168_1==KW_DAYOFWEEK||LA168_1==KW_HOLD_DDLTIME||LA168_1==KW_IGNORE||LA168_1==KW_NO_DROP||LA168_1==KW_OFFLINE||LA168_1==KW_PROTECTION||LA168_1==KW_READONLY||LA168_1==KW_TIMESTAMPTZ) ) {
					alt168=1;
				}
			}
			switch (alt168) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:16: KW_ROLE
					{
					KW_ROLE547=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_grantRole9180); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE547);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_grantRole9183);
			identifier548=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier548.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:36: ( COMMA identifier )*
			loop169:
			while (true) {
				int alt169=2;
				int LA169_0 = input.LA(1);
				if ( (LA169_0==COMMA) ) {
					alt169=1;
				}

				switch (alt169) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:37: COMMA identifier
					{
					COMMA549=(Token)match(input,COMMA,FOLLOW_COMMA_in_grantRole9186); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA549);

					pushFollow(FOLLOW_identifier_in_grantRole9188);
					identifier550=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier550.getTree());
					}
					break;

				default :
					break loop169;
				}
			}

			KW_TO551=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_grantRole9192); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO551);

			pushFollow(FOLLOW_principalSpecification_in_grantRole9194);
			principalSpecification552=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification552.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:85: ( withAdminOption )?
			int alt170=2;
			int LA170_0 = input.LA(1);
			if ( (LA170_0==KW_WITH) ) {
				alt170=1;
			}
			switch (alt170) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:85: withAdminOption
					{
					pushFollow(FOLLOW_withAdminOption_in_grantRole9196);
					withAdminOption553=withAdminOption();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withAdminOption.add(withAdminOption553.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: principalSpecification, identifier, withAdminOption
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1719:5: -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1719:8: ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_ROLE, "TOK_GRANT_ROLE"), root_1);
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1719:48: ( withAdminOption )?
				if ( stream_withAdminOption.hasNext() ) {
					adaptor.addChild(root_1, stream_withAdminOption.nextTree());
				}
				stream_withAdminOption.reset();

				if ( !(stream_identifier.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_identifier.hasNext() ) {
					adaptor.addChild(root_1, stream_identifier.nextTree());
				}
				stream_identifier.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "grantRole"


	public static class revokeRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "revokeRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1722:1: revokeRole : KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) ;
	public final HiveParser.revokeRole_return revokeRole() throws RecognitionException {
		HiveParser.revokeRole_return retval = new HiveParser.revokeRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REVOKE554=null;
		Token KW_ROLE556=null;
		Token COMMA558=null;
		Token KW_FROM560=null;
		ParserRuleReturnScope adminOptionFor555 =null;
		ParserRuleReturnScope identifier557 =null;
		ParserRuleReturnScope identifier559 =null;
		ParserRuleReturnScope principalSpecification561 =null;

		ASTNode KW_REVOKE554_tree=null;
		ASTNode KW_ROLE556_tree=null;
		ASTNode COMMA558_tree=null;
		ASTNode KW_FROM560_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_REVOKE=new RewriteRuleTokenStream(adaptor,"token KW_REVOKE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_adminOptionFor=new RewriteRuleSubtreeStream(adaptor,"rule adminOptionFor");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("revoke role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1725:5: ( KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1725:7: KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification
			{
			KW_REVOKE554=(Token)match(input,KW_REVOKE,FOLLOW_KW_REVOKE_in_revokeRole9242); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REVOKE.add(KW_REVOKE554);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1725:17: ( adminOptionFor )?
			int alt171=2;
			int LA171_0 = input.LA(1);
			if ( (LA171_0==KW_ADMIN) ) {
				int LA171_1 = input.LA(2);
				if ( (LA171_1==KW_OPTION) ) {
					alt171=1;
				}
			}
			switch (alt171) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1725:17: adminOptionFor
					{
					pushFollow(FOLLOW_adminOptionFor_in_revokeRole9244);
					adminOptionFor555=adminOptionFor();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_adminOptionFor.add(adminOptionFor555.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1725:33: ( KW_ROLE )?
			int alt172=2;
			int LA172_0 = input.LA(1);
			if ( (LA172_0==KW_ROLE) ) {
				int LA172_1 = input.LA(2);
				if ( (LA172_1==Identifier||(LA172_1 >= KW_ABORT && LA172_1 <= KW_AFTER)||LA172_1==KW_ALLOC_FRACTION||LA172_1==KW_ANALYZE||LA172_1==KW_ARCHIVE||LA172_1==KW_ASC||(LA172_1 >= KW_AUTOCOMMIT && LA172_1 <= KW_BEFORE)||(LA172_1 >= KW_BUCKET && LA172_1 <= KW_BUCKETS)||(LA172_1 >= KW_CACHE && LA172_1 <= KW_CASCADE)||(LA172_1 >= KW_CBO && LA172_1 <= KW_CHANGE)||(LA172_1 >= KW_CHECK && LA172_1 <= KW_COLLECTION)||(LA172_1 >= KW_COLUMNS && LA172_1 <= KW_COMMENT)||(LA172_1 >= KW_COMPACT && LA172_1 <= KW_CONCATENATE)||(LA172_1 >= KW_CONTINUE && LA172_1 <= KW_COST)||LA172_1==KW_DATA||LA172_1==KW_DATABASES||(LA172_1 >= KW_DATETIME && LA172_1 <= KW_DEBUG)||(LA172_1 >= KW_DEFAULT && LA172_1 <= KW_DEFINED)||(LA172_1 >= KW_DELIMITED && LA172_1 <= KW_DESC)||(LA172_1 >= KW_DETAIL && LA172_1 <= KW_DISABLE)||(LA172_1 >= KW_DISTRIBUTE && LA172_1 <= KW_DO)||LA172_1==KW_DOW||(LA172_1 >= KW_DUMP && LA172_1 <= KW_ELEM_TYPE)||LA172_1==KW_ENABLE||(LA172_1 >= KW_ENFORCED && LA172_1 <= KW_ESCAPED)||LA172_1==KW_EXCLUSIVE||(LA172_1 >= KW_EXPLAIN && LA172_1 <= KW_EXPRESSION)||(LA172_1 >= KW_FIELDS && LA172_1 <= KW_FIRST)||(LA172_1 >= KW_FORMAT && LA172_1 <= KW_FORMATTED)||LA172_1==KW_FUNCTIONS||(LA172_1 >= KW_HOUR && LA172_1 <= KW_IDXPROPERTIES)||(LA172_1 >= KW_INDEX && LA172_1 <= KW_INDEXES)||(LA172_1 >= KW_INPATH && LA172_1 <= KW_INPUTFORMAT)||(LA172_1 >= KW_ISOLATION && LA172_1 <= KW_JAR)||(LA172_1 >= KW_JOINCOST && LA172_1 <= KW_LAST)||LA172_1==KW_LEVEL||(LA172_1 >= KW_LIMIT && LA172_1 <= KW_LOAD)||(LA172_1 >= KW_LOCATION && LA172_1 <= KW_LONG)||LA172_1==KW_MANAGEMENT||(LA172_1 >= KW_MAPJOIN && LA172_1 <= KW_MATERIALIZED)||LA172_1==KW_METADATA||(LA172_1 >= KW_MINUTE && LA172_1 <= KW_MONTH)||(LA172_1 >= KW_MOVE && LA172_1 <= KW_MSCK)||(LA172_1 >= KW_NORELY && LA172_1 <= KW_NOSCAN)||LA172_1==KW_NOVALIDATE||LA172_1==KW_NULLS||LA172_1==KW_OFFSET||(LA172_1 >= KW_OPERATOR && LA172_1 <= KW_OPTION)||(LA172_1 >= KW_OUTPUTDRIVER && LA172_1 <= KW_OUTPUTFORMAT)||(LA172_1 >= KW_OVERWRITE && LA172_1 <= KW_OWNER)||(LA172_1 >= KW_PARTITIONED && LA172_1 <= KW_PATH)||(LA172_1 >= KW_PLAN && LA172_1 <= KW_POOL)||LA172_1==KW_PRINCIPALS||(LA172_1 >= KW_PURGE && LA172_1 <= KW_QUERY_PARALLELISM)||LA172_1==KW_READ||(LA172_1 >= KW_REBUILD && LA172_1 <= KW_RECORDWRITER)||(LA172_1 >= KW_RELOAD && LA172_1 <= KW_RESTRICT)||LA172_1==KW_REWRITE||(LA172_1 >= KW_ROLE && LA172_1 <= KW_ROLES)||(LA172_1 >= KW_SCHEDULING_POLICY && LA172_1 <= KW_SECOND)||(LA172_1 >= KW_SEMI && LA172_1 <= KW_SERVER)||(LA172_1 >= KW_SETS && LA172_1 <= KW_SKEWED)||(LA172_1 >= KW_SNAPSHOT && LA172_1 <= KW_SSL)||(LA172_1 >= KW_STATISTICS && LA172_1 <= KW_SUMMARY)||LA172_1==KW_TABLES||(LA172_1 >= KW_TBLPROPERTIES && LA172_1 <= KW_TERMINATED)||LA172_1==KW_TINYINT||(LA172_1 >= KW_TOUCH && LA172_1 <= KW_TRANSACTIONS)||LA172_1==KW_UNARCHIVE||LA172_1==KW_UNDO||LA172_1==KW_UNIONTYPE||(LA172_1 >= KW_UNLOCK && LA172_1 <= KW_UNSIGNED)||(LA172_1 >= KW_URI && LA172_1 <= KW_USE)||(LA172_1 >= KW_UTC && LA172_1 <= KW_VALIDATE)||LA172_1==KW_VALUE_TYPE||(LA172_1 >= KW_VECTORIZATION && LA172_1 <= KW_WEEK)||LA172_1==KW_WHILE||(LA172_1 >= KW_WORK && LA172_1 <= KW_ZONE)||LA172_1==KW_BATCH||LA172_1==KW_DAYOFWEEK||LA172_1==KW_HOLD_DDLTIME||LA172_1==KW_IGNORE||LA172_1==KW_NO_DROP||LA172_1==KW_OFFLINE||LA172_1==KW_PROTECTION||LA172_1==KW_READONLY||LA172_1==KW_TIMESTAMPTZ) ) {
					alt172=1;
				}
			}
			switch (alt172) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1725:33: KW_ROLE
					{
					KW_ROLE556=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_revokeRole9247); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE556);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_revokeRole9250);
			identifier557=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier557.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1725:53: ( COMMA identifier )*
			loop173:
			while (true) {
				int alt173=2;
				int LA173_0 = input.LA(1);
				if ( (LA173_0==COMMA) ) {
					alt173=1;
				}

				switch (alt173) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1725:54: COMMA identifier
					{
					COMMA558=(Token)match(input,COMMA,FOLLOW_COMMA_in_revokeRole9253); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA558);

					pushFollow(FOLLOW_identifier_in_revokeRole9255);
					identifier559=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier559.getTree());
					}
					break;

				default :
					break loop173;
				}
			}

			KW_FROM560=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_revokeRole9259); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM560);

			pushFollow(FOLLOW_principalSpecification_in_revokeRole9261);
			principalSpecification561=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification561.getTree());
			// AST REWRITE
			// elements: principalSpecification, adminOptionFor, identifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1726:5: -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1726:8: ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REVOKE_ROLE, "TOK_REVOKE_ROLE"), root_1);
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1726:49: ( adminOptionFor )?
				if ( stream_adminOptionFor.hasNext() ) {
					adaptor.addChild(root_1, stream_adminOptionFor.nextTree());
				}
				stream_adminOptionFor.reset();

				if ( !(stream_identifier.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_identifier.hasNext() ) {
					adaptor.addChild(root_1, stream_identifier.nextTree());
				}
				stream_identifier.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "revokeRole"


	public static class showRoleGrants_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showRoleGrants"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1729:1: showRoleGrants : KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) ;
	public final HiveParser.showRoleGrants_return showRoleGrants() throws RecognitionException {
		HiveParser.showRoleGrants_return retval = new HiveParser.showRoleGrants_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW562=null;
		Token KW_ROLE563=null;
		Token KW_GRANT564=null;
		ParserRuleReturnScope principalName565 =null;

		ASTNode KW_SHOW562_tree=null;
		ASTNode KW_ROLE563_tree=null;
		ASTNode KW_GRANT564_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		pushMsg("show role grants", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1732:5: ( KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1732:7: KW_SHOW KW_ROLE KW_GRANT principalName
			{
			KW_SHOW562=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRoleGrants9306); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW562);

			KW_ROLE563=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_showRoleGrants9308); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE563);

			KW_GRANT564=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_showRoleGrants9310); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT564);

			pushFollow(FOLLOW_principalName_in_showRoleGrants9312);
			principalName565=principalName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalName.add(principalName565.getTree());
			// AST REWRITE
			// elements: principalName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1733:5: -> ^( TOK_SHOW_ROLE_GRANT principalName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1733:8: ^( TOK_SHOW_ROLE_GRANT principalName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_ROLE_GRANT, "TOK_SHOW_ROLE_GRANT"), root_1);
				adaptor.addChild(root_1, stream_principalName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showRoleGrants"


	public static class showRoles_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showRoles"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1737:1: showRoles : KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) ;
	public final HiveParser.showRoles_return showRoles() throws RecognitionException {
		HiveParser.showRoles_return retval = new HiveParser.showRoles_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW566=null;
		Token KW_ROLES567=null;

		ASTNode KW_SHOW566_tree=null;
		ASTNode KW_ROLES567_tree=null;
		RewriteRuleTokenStream stream_KW_ROLES=new RewriteRuleTokenStream(adaptor,"token KW_ROLES");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");

		pushMsg("show roles", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1740:5: ( KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1740:7: KW_SHOW KW_ROLES
			{
			KW_SHOW566=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRoles9352); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW566);

			KW_ROLES567=(Token)match(input,KW_ROLES,FOLLOW_KW_ROLES_in_showRoles9354); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLES.add(KW_ROLES567);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1741:5: -> ^( TOK_SHOW_ROLES )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1741:8: ^( TOK_SHOW_ROLES )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_ROLES, "TOK_SHOW_ROLES"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showRoles"


	public static class showCurrentRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showCurrentRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1744:1: showCurrentRole : KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_SET_ROLE ) ;
	public final HiveParser.showCurrentRole_return showCurrentRole() throws RecognitionException {
		HiveParser.showCurrentRole_return retval = new HiveParser.showCurrentRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW568=null;
		Token KW_CURRENT569=null;
		Token KW_ROLES570=null;

		ASTNode KW_SHOW568_tree=null;
		ASTNode KW_CURRENT569_tree=null;
		ASTNode KW_ROLES570_tree=null;
		RewriteRuleTokenStream stream_KW_ROLES=new RewriteRuleTokenStream(adaptor,"token KW_ROLES");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleTokenStream stream_KW_CURRENT=new RewriteRuleTokenStream(adaptor,"token KW_CURRENT");

		pushMsg("show current role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1747:5: ( KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_SET_ROLE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1747:7: KW_SHOW KW_CURRENT KW_ROLES
			{
			KW_SHOW568=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showCurrentRole9391); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW568);

			KW_CURRENT569=(Token)match(input,KW_CURRENT,FOLLOW_KW_CURRENT_in_showCurrentRole9393); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CURRENT.add(KW_CURRENT569);

			KW_ROLES570=(Token)match(input,KW_ROLES,FOLLOW_KW_ROLES_in_showCurrentRole9395); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLES.add(KW_ROLES570);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1748:5: -> ^( TOK_SHOW_SET_ROLE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1748:8: ^( TOK_SHOW_SET_ROLE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showCurrentRole"


	public static class setRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1751:1: setRole : KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SHOW_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SHOW_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SHOW_SET_ROLE identifier ) ) ;
	public final HiveParser.setRole_return setRole() throws RecognitionException {
		HiveParser.setRole_return retval = new HiveParser.setRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token all=null;
		Token none=null;
		Token KW_SET571=null;
		Token KW_ROLE572=null;
		ParserRuleReturnScope identifier573 =null;

		ASTNode all_tree=null;
		ASTNode none_tree=null;
		ASTNode KW_SET571_tree=null;
		ASTNode KW_ROLE572_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_NONE=new RewriteRuleTokenStream(adaptor,"token KW_NONE");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		pushMsg("set role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1754:5: ( KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SHOW_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SHOW_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SHOW_SET_ROLE identifier ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1754:7: KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SHOW_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SHOW_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SHOW_SET_ROLE identifier ) )
			{
			KW_SET571=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setRole9432); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET571);

			KW_ROLE572=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_setRole9434); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE572);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1755:5: ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SHOW_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SHOW_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SHOW_SET_ROLE identifier ) )
			int alt174=3;
			int LA174_0 = input.LA(1);
			if ( (LA174_0==KW_ALL) && (synpred14_HiveParser())) {
				alt174=1;
			}
			else if ( (LA174_0==KW_NONE) && (synpred15_HiveParser())) {
				alt174=2;
			}
			else if ( (LA174_0==Identifier||(LA174_0 >= KW_ABORT && LA174_0 <= KW_AFTER)||LA174_0==KW_ALLOC_FRACTION||LA174_0==KW_ANALYZE||LA174_0==KW_ARCHIVE||LA174_0==KW_ASC||(LA174_0 >= KW_AUTOCOMMIT && LA174_0 <= KW_BEFORE)||(LA174_0 >= KW_BUCKET && LA174_0 <= KW_BUCKETS)||(LA174_0 >= KW_CACHE && LA174_0 <= KW_CASCADE)||(LA174_0 >= KW_CBO && LA174_0 <= KW_CHANGE)||(LA174_0 >= KW_CHECK && LA174_0 <= KW_COLLECTION)||(LA174_0 >= KW_COLUMNS && LA174_0 <= KW_COMMENT)||(LA174_0 >= KW_COMPACT && LA174_0 <= KW_CONCATENATE)||(LA174_0 >= KW_CONTINUE && LA174_0 <= KW_COST)||LA174_0==KW_DATA||LA174_0==KW_DATABASES||(LA174_0 >= KW_DATETIME && LA174_0 <= KW_DEBUG)||(LA174_0 >= KW_DEFAULT && LA174_0 <= KW_DEFINED)||(LA174_0 >= KW_DELIMITED && LA174_0 <= KW_DESC)||(LA174_0 >= KW_DETAIL && LA174_0 <= KW_DISABLE)||(LA174_0 >= KW_DISTRIBUTE && LA174_0 <= KW_DO)||LA174_0==KW_DOW||(LA174_0 >= KW_DUMP && LA174_0 <= KW_ELEM_TYPE)||LA174_0==KW_ENABLE||(LA174_0 >= KW_ENFORCED && LA174_0 <= KW_ESCAPED)||LA174_0==KW_EXCLUSIVE||(LA174_0 >= KW_EXPLAIN && LA174_0 <= KW_EXPRESSION)||(LA174_0 >= KW_FIELDS && LA174_0 <= KW_FIRST)||(LA174_0 >= KW_FORMAT && LA174_0 <= KW_FORMATTED)||LA174_0==KW_FUNCTIONS||(LA174_0 >= KW_HOUR && LA174_0 <= KW_IDXPROPERTIES)||(LA174_0 >= KW_INDEX && LA174_0 <= KW_INDEXES)||(LA174_0 >= KW_INPATH && LA174_0 <= KW_INPUTFORMAT)||(LA174_0 >= KW_ISOLATION && LA174_0 <= KW_JAR)||(LA174_0 >= KW_JOINCOST && LA174_0 <= KW_LAST)||LA174_0==KW_LEVEL||(LA174_0 >= KW_LIMIT && LA174_0 <= KW_LOAD)||(LA174_0 >= KW_LOCATION && LA174_0 <= KW_LONG)||LA174_0==KW_MANAGEMENT||(LA174_0 >= KW_MAPJOIN && LA174_0 <= KW_MATERIALIZED)||LA174_0==KW_METADATA||(LA174_0 >= KW_MINUTE && LA174_0 <= KW_MONTH)||(LA174_0 >= KW_MOVE && LA174_0 <= KW_MSCK)||(LA174_0 >= KW_NORELY && LA174_0 <= KW_NOSCAN)||LA174_0==KW_NOVALIDATE||LA174_0==KW_NULLS||LA174_0==KW_OFFSET||(LA174_0 >= KW_OPERATOR && LA174_0 <= KW_OPTION)||(LA174_0 >= KW_OUTPUTDRIVER && LA174_0 <= KW_OUTPUTFORMAT)||(LA174_0 >= KW_OVERWRITE && LA174_0 <= KW_OWNER)||(LA174_0 >= KW_PARTITIONED && LA174_0 <= KW_PATH)||(LA174_0 >= KW_PLAN && LA174_0 <= KW_POOL)||LA174_0==KW_PRINCIPALS||(LA174_0 >= KW_PURGE && LA174_0 <= KW_QUERY_PARALLELISM)||LA174_0==KW_READ||(LA174_0 >= KW_REBUILD && LA174_0 <= KW_RECORDWRITER)||(LA174_0 >= KW_RELOAD && LA174_0 <= KW_RESTRICT)||LA174_0==KW_REWRITE||(LA174_0 >= KW_ROLE && LA174_0 <= KW_ROLES)||(LA174_0 >= KW_SCHEDULING_POLICY && LA174_0 <= KW_SECOND)||(LA174_0 >= KW_SEMI && LA174_0 <= KW_SERVER)||(LA174_0 >= KW_SETS && LA174_0 <= KW_SKEWED)||(LA174_0 >= KW_SNAPSHOT && LA174_0 <= KW_SSL)||(LA174_0 >= KW_STATISTICS && LA174_0 <= KW_SUMMARY)||LA174_0==KW_TABLES||(LA174_0 >= KW_TBLPROPERTIES && LA174_0 <= KW_TERMINATED)||LA174_0==KW_TINYINT||(LA174_0 >= KW_TOUCH && LA174_0 <= KW_TRANSACTIONS)||LA174_0==KW_UNARCHIVE||LA174_0==KW_UNDO||LA174_0==KW_UNIONTYPE||(LA174_0 >= KW_UNLOCK && LA174_0 <= KW_UNSIGNED)||(LA174_0 >= KW_URI && LA174_0 <= KW_USE)||(LA174_0 >= KW_UTC && LA174_0 <= KW_VALIDATE)||LA174_0==KW_VALUE_TYPE||(LA174_0 >= KW_VECTORIZATION && LA174_0 <= KW_WEEK)||LA174_0==KW_WHILE||(LA174_0 >= KW_WORK && LA174_0 <= KW_ZONE)||LA174_0==KW_BATCH||LA174_0==KW_DAYOFWEEK||LA174_0==KW_HOLD_DDLTIME||LA174_0==KW_IGNORE||LA174_0==KW_NO_DROP||LA174_0==KW_OFFLINE||LA174_0==KW_PROTECTION||LA174_0==KW_READONLY||LA174_0==KW_TIMESTAMPTZ) ) {
				alt174=3;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 174, 0, input);
				throw nvae;
			}

			switch (alt174) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1756:5: ( KW_ALL )=> (all= KW_ALL )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1756:17: (all= KW_ALL )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1756:18: all= KW_ALL
					{
					all=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setRole9456); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(all);

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1756:30: -> ^( TOK_SHOW_SET_ROLE Identifier[$all.text] )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1756:33: ^( TOK_SHOW_SET_ROLE Identifier[$all.text] )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE"), root_1);
						adaptor.addChild(root_1, (ASTNode)adaptor.create(Identifier, (all!=null?all.getText():null)));
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1758:5: ( KW_NONE )=> (none= KW_NONE )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1758:18: (none= KW_NONE )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1758:19: none= KW_NONE
					{
					none=(Token)match(input,KW_NONE,FOLLOW_KW_NONE_in_setRole9487); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NONE.add(none);

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1758:33: -> ^( TOK_SHOW_SET_ROLE Identifier[$none.text] )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1758:36: ^( TOK_SHOW_SET_ROLE Identifier[$none.text] )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE"), root_1);
						adaptor.addChild(root_1, (ASTNode)adaptor.create(Identifier, (none!=null?none.getText():null)));
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:5: identifier
					{
					pushFollow(FOLLOW_identifier_in_setRole9509);
					identifier573=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier573.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1760:16: -> ^( TOK_SHOW_SET_ROLE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:19: ^( TOK_SHOW_SET_ROLE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setRole"


	public static class showGrants_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showGrants"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1764:1: showGrants : KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) ;
	public final HiveParser.showGrants_return showGrants() throws RecognitionException {
		HiveParser.showGrants_return retval = new HiveParser.showGrants_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW574=null;
		Token KW_GRANT575=null;
		Token KW_ON577=null;
		ParserRuleReturnScope principalName576 =null;
		ParserRuleReturnScope privilegeIncludeColObject578 =null;

		ASTNode KW_SHOW574_tree=null;
		ASTNode KW_GRANT575_tree=null;
		ASTNode KW_ON577_tree=null;
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleSubtreeStream stream_privilegeIncludeColObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeIncludeColObject");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		pushMsg("show grants", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:5: ( KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:7: KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )?
			{
			KW_SHOW574=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showGrants9550); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW574);

			KW_GRANT575=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_showGrants9552); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT575);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:24: ( principalName )?
			int alt175=2;
			int LA175_0 = input.LA(1);
			if ( (LA175_0==KW_GROUP||LA175_0==KW_ROLE||LA175_0==KW_USER) ) {
				alt175=1;
			}
			switch (alt175) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:24: principalName
					{
					pushFollow(FOLLOW_principalName_in_showGrants9554);
					principalName576=principalName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalName.add(principalName576.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:39: ( KW_ON privilegeIncludeColObject )?
			int alt176=2;
			int LA176_0 = input.LA(1);
			if ( (LA176_0==KW_ON) ) {
				alt176=1;
			}
			switch (alt176) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:40: KW_ON privilegeIncludeColObject
					{
					KW_ON577=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_showGrants9558); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON577);

					pushFollow(FOLLOW_privilegeIncludeColObject_in_showGrants9560);
					privilegeIncludeColObject578=privilegeIncludeColObject();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privilegeIncludeColObject.add(privilegeIncludeColObject578.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: privilegeIncludeColObject, principalName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1768:5: -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1768:8: ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_GRANT, "TOK_SHOW_GRANT"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1768:25: ( principalName )?
				if ( stream_principalName.hasNext() ) {
					adaptor.addChild(root_1, stream_principalName.nextTree());
				}
				stream_principalName.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1768:40: ( privilegeIncludeColObject )?
				if ( stream_privilegeIncludeColObject.hasNext() ) {
					adaptor.addChild(root_1, stream_privilegeIncludeColObject.nextTree());
				}
				stream_privilegeIncludeColObject.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showGrants"


	public static class showRolePrincipals_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showRolePrincipals"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1771:1: showRolePrincipals : KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) ;
	public final HiveParser.showRolePrincipals_return showRolePrincipals() throws RecognitionException {
		HiveParser.showRolePrincipals_return retval = new HiveParser.showRolePrincipals_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW579=null;
		Token KW_PRINCIPALS580=null;
		ParserRuleReturnScope roleName =null;

		ASTNode KW_SHOW579_tree=null;
		ASTNode KW_PRINCIPALS580_tree=null;
		RewriteRuleTokenStream stream_KW_PRINCIPALS=new RewriteRuleTokenStream(adaptor,"token KW_PRINCIPALS");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		pushMsg("show role principals", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1774:5: ( KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1774:7: KW_SHOW KW_PRINCIPALS roleName= identifier
			{
			KW_SHOW579=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRolePrincipals9605); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW579);

			KW_PRINCIPALS580=(Token)match(input,KW_PRINCIPALS,FOLLOW_KW_PRINCIPALS_in_showRolePrincipals9607); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_PRINCIPALS.add(KW_PRINCIPALS580);

			pushFollow(FOLLOW_identifier_in_showRolePrincipals9611);
			roleName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());
			// AST REWRITE
			// elements: roleName
			// token labels: 
			// rule labels: roleName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1775:5: -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:8: ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_ROLE_PRINCIPALS, "TOK_SHOW_ROLE_PRINCIPALS"), root_1);
				adaptor.addChild(root_1, stream_roleName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showRolePrincipals"


	public static class privilegeIncludeColObject_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeIncludeColObject"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1779:1: privilegeIncludeColObject : ( ( KW_ALL )=> KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) );
	public final HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject() throws RecognitionException {
		HiveParser.privilegeIncludeColObject_return retval = new HiveParser.privilegeIncludeColObject_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ALL581=null;
		ParserRuleReturnScope privObjectCols582 =null;

		ASTNode KW_ALL581_tree=null;
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
		RewriteRuleSubtreeStream stream_privObjectCols=new RewriteRuleSubtreeStream(adaptor,"rule privObjectCols");

		pushMsg("privilege object including columns", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1782:5: ( ( KW_ALL )=> KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) )
			int alt177=2;
			int LA177_0 = input.LA(1);
			if ( (LA177_0==KW_ALL) && (synpred16_HiveParser())) {
				alt177=1;
			}
			else if ( (LA177_0==Identifier||(LA177_0 >= KW_ABORT && LA177_0 <= KW_AFTER)||LA177_0==KW_ALLOC_FRACTION||LA177_0==KW_ANALYZE||LA177_0==KW_ARCHIVE||LA177_0==KW_ASC||(LA177_0 >= KW_AUTOCOMMIT && LA177_0 <= KW_BEFORE)||(LA177_0 >= KW_BUCKET && LA177_0 <= KW_BUCKETS)||(LA177_0 >= KW_CACHE && LA177_0 <= KW_CASCADE)||(LA177_0 >= KW_CBO && LA177_0 <= KW_CHANGE)||(LA177_0 >= KW_CHECK && LA177_0 <= KW_COLLECTION)||(LA177_0 >= KW_COLUMNS && LA177_0 <= KW_COMMENT)||(LA177_0 >= KW_COMPACT && LA177_0 <= KW_CONCATENATE)||(LA177_0 >= KW_CONTINUE && LA177_0 <= KW_COST)||(LA177_0 >= KW_DATA && LA177_0 <= KW_DATABASES)||(LA177_0 >= KW_DATETIME && LA177_0 <= KW_DEBUG)||(LA177_0 >= KW_DEFAULT && LA177_0 <= KW_DEFINED)||(LA177_0 >= KW_DELIMITED && LA177_0 <= KW_DESC)||(LA177_0 >= KW_DETAIL && LA177_0 <= KW_DISABLE)||(LA177_0 >= KW_DISTRIBUTE && LA177_0 <= KW_DO)||LA177_0==KW_DOW||(LA177_0 >= KW_DUMP && LA177_0 <= KW_ELEM_TYPE)||LA177_0==KW_ENABLE||(LA177_0 >= KW_ENFORCED && LA177_0 <= KW_ESCAPED)||LA177_0==KW_EXCLUSIVE||(LA177_0 >= KW_EXPLAIN && LA177_0 <= KW_EXPRESSION)||(LA177_0 >= KW_FIELDS && LA177_0 <= KW_FIRST)||(LA177_0 >= KW_FORMAT && LA177_0 <= KW_FORMATTED)||LA177_0==KW_FUNCTIONS||(LA177_0 >= KW_HOUR && LA177_0 <= KW_IDXPROPERTIES)||(LA177_0 >= KW_INDEX && LA177_0 <= KW_INDEXES)||(LA177_0 >= KW_INPATH && LA177_0 <= KW_INPUTFORMAT)||(LA177_0 >= KW_ISOLATION && LA177_0 <= KW_JAR)||(LA177_0 >= KW_JOINCOST && LA177_0 <= KW_LAST)||LA177_0==KW_LEVEL||(LA177_0 >= KW_LIMIT && LA177_0 <= KW_LOAD)||(LA177_0 >= KW_LOCATION && LA177_0 <= KW_LONG)||LA177_0==KW_MANAGEMENT||(LA177_0 >= KW_MAPJOIN && LA177_0 <= KW_MATERIALIZED)||LA177_0==KW_METADATA||(LA177_0 >= KW_MINUTE && LA177_0 <= KW_MONTH)||(LA177_0 >= KW_MOVE && LA177_0 <= KW_MSCK)||(LA177_0 >= KW_NORELY && LA177_0 <= KW_NOSCAN)||LA177_0==KW_NOVALIDATE||LA177_0==KW_NULLS||LA177_0==KW_OFFSET||(LA177_0 >= KW_OPERATOR && LA177_0 <= KW_OPTION)||(LA177_0 >= KW_OUTPUTDRIVER && LA177_0 <= KW_OUTPUTFORMAT)||(LA177_0 >= KW_OVERWRITE && LA177_0 <= KW_OWNER)||(LA177_0 >= KW_PARTITIONED && LA177_0 <= KW_PATH)||(LA177_0 >= KW_PLAN && LA177_0 <= KW_POOL)||LA177_0==KW_PRINCIPALS||(LA177_0 >= KW_PURGE && LA177_0 <= KW_QUERY_PARALLELISM)||LA177_0==KW_READ||(LA177_0 >= KW_REBUILD && LA177_0 <= KW_RECORDWRITER)||(LA177_0 >= KW_RELOAD && LA177_0 <= KW_RESTRICT)||LA177_0==KW_REWRITE||(LA177_0 >= KW_ROLE && LA177_0 <= KW_ROLES)||(LA177_0 >= KW_SCHEDULING_POLICY && LA177_0 <= KW_SECOND)||(LA177_0 >= KW_SEMI && LA177_0 <= KW_SERVER)||(LA177_0 >= KW_SETS && LA177_0 <= KW_SKEWED)||(LA177_0 >= KW_SNAPSHOT && LA177_0 <= KW_SSL)||(LA177_0 >= KW_STATISTICS && LA177_0 <= KW_SUMMARY)||(LA177_0 >= KW_TABLE && LA177_0 <= KW_TABLES)||(LA177_0 >= KW_TBLPROPERTIES && LA177_0 <= KW_TERMINATED)||LA177_0==KW_TINYINT||(LA177_0 >= KW_TOUCH && LA177_0 <= KW_TRANSACTIONS)||LA177_0==KW_UNARCHIVE||LA177_0==KW_UNDO||LA177_0==KW_UNIONTYPE||(LA177_0 >= KW_UNLOCK && LA177_0 <= KW_UNSIGNED)||(LA177_0 >= KW_URI && LA177_0 <= KW_USE)||(LA177_0 >= KW_UTC && LA177_0 <= KW_VALIDATE)||LA177_0==KW_VALUE_TYPE||(LA177_0 >= KW_VECTORIZATION && LA177_0 <= KW_WEEK)||LA177_0==KW_WHILE||(LA177_0 >= KW_WORK && LA177_0 <= KW_ZONE)||LA177_0==KW_BATCH||LA177_0==KW_DAYOFWEEK||LA177_0==KW_HOLD_DDLTIME||LA177_0==KW_IGNORE||LA177_0==KW_NO_DROP||LA177_0==KW_OFFLINE||LA177_0==KW_PROTECTION||LA177_0==KW_READONLY||LA177_0==KW_TIMESTAMPTZ) ) {
				alt177=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 177, 0, input);
				throw nvae;
			}

			switch (alt177) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1782:7: ( KW_ALL )=> KW_ALL
					{
					KW_ALL581=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_privilegeIncludeColObject9658); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL581);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1782:26: -> ^( TOK_RESOURCE_ALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1782:29: ^( TOK_RESOURCE_ALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESOURCE_ALL, "TOK_RESOURCE_ALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1783:7: privObjectCols
					{
					pushFollow(FOLLOW_privObjectCols_in_privilegeIncludeColObject9672);
					privObjectCols582=privObjectCols();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privObjectCols.add(privObjectCols582.getTree());
					// AST REWRITE
					// elements: privObjectCols
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1783:22: -> ^( TOK_PRIV_OBJECT_COL privObjectCols )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1783:25: ^( TOK_PRIV_OBJECT_COL privObjectCols )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_OBJECT_COL, "TOK_PRIV_OBJECT_COL"), root_1);
						adaptor.addChild(root_1, stream_privObjectCols.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeIncludeColObject"


	public static class privilegeObject_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeObject"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1786:1: privilegeObject : KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) ;
	public final HiveParser.privilegeObject_return privilegeObject() throws RecognitionException {
		HiveParser.privilegeObject_return retval = new HiveParser.privilegeObject_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ON583=null;
		ParserRuleReturnScope privObject584 =null;

		ASTNode KW_ON583_tree=null;
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleSubtreeStream stream_privObject=new RewriteRuleSubtreeStream(adaptor,"rule privObject");

		pushMsg("privilege object", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1789:5: ( KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1789:7: KW_ON privObject
			{
			KW_ON583=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_privilegeObject9707); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON583);

			pushFollow(FOLLOW_privObject_in_privilegeObject9709);
			privObject584=privObject();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privObject.add(privObject584.getTree());
			// AST REWRITE
			// elements: privObject
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1789:24: -> ^( TOK_PRIV_OBJECT privObject )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1789:27: ^( TOK_PRIV_OBJECT privObject )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_OBJECT, "TOK_PRIV_OBJECT"), root_1);
				adaptor.addChild(root_1, stream_privObject.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeObject"


	public static class privObject_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privObject"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1793:1: privObject : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
	public final HiveParser.privObject_return privObject() throws RecognitionException {
		HiveParser.privObject_return retval = new HiveParser.privObject_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_DATABASE585=null;
		Token KW_SCHEMA586=null;
		Token KW_TABLE588=null;
		Token KW_URI591=null;
		Token KW_SERVER592=null;
		ParserRuleReturnScope identifier587 =null;
		ParserRuleReturnScope tableName589 =null;
		ParserRuleReturnScope partitionSpec590 =null;
		ParserRuleReturnScope identifier593 =null;

		ASTNode path_tree=null;
		ASTNode KW_DATABASE585_tree=null;
		ASTNode KW_SCHEMA586_tree=null;
		ASTNode KW_TABLE588_tree=null;
		ASTNode KW_URI591_tree=null;
		ASTNode KW_SERVER592_tree=null;
		RewriteRuleTokenStream stream_KW_SERVER=new RewriteRuleTokenStream(adaptor,"token KW_SERVER");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_URI=new RewriteRuleTokenStream(adaptor,"token KW_URI");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1794:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
			int alt181=4;
			switch ( input.LA(1) ) {
			case KW_DATABASE:
				{
				alt181=1;
				}
				break;
			case KW_SCHEMA:
				{
				int LA181_2 = input.LA(2);
				if ( (LA181_2==Identifier||(LA181_2 >= KW_ABORT && LA181_2 <= KW_AFTER)||LA181_2==KW_ALLOC_FRACTION||LA181_2==KW_ANALYZE||LA181_2==KW_ARCHIVE||LA181_2==KW_ASC||(LA181_2 >= KW_AUTOCOMMIT && LA181_2 <= KW_BEFORE)||(LA181_2 >= KW_BUCKET && LA181_2 <= KW_BUCKETS)||(LA181_2 >= KW_CACHE && LA181_2 <= KW_CASCADE)||(LA181_2 >= KW_CBO && LA181_2 <= KW_CHANGE)||(LA181_2 >= KW_CHECK && LA181_2 <= KW_COLLECTION)||(LA181_2 >= KW_COLUMNS && LA181_2 <= KW_COMMENT)||(LA181_2 >= KW_COMPACT && LA181_2 <= KW_CONCATENATE)||(LA181_2 >= KW_CONTINUE && LA181_2 <= KW_COST)||LA181_2==KW_DATA||LA181_2==KW_DATABASES||(LA181_2 >= KW_DATETIME && LA181_2 <= KW_DEBUG)||(LA181_2 >= KW_DEFAULT && LA181_2 <= KW_DEFINED)||(LA181_2 >= KW_DELIMITED && LA181_2 <= KW_DESC)||(LA181_2 >= KW_DETAIL && LA181_2 <= KW_DISABLE)||(LA181_2 >= KW_DISTRIBUTE && LA181_2 <= KW_DO)||LA181_2==KW_DOW||(LA181_2 >= KW_DUMP && LA181_2 <= KW_ELEM_TYPE)||LA181_2==KW_ENABLE||(LA181_2 >= KW_ENFORCED && LA181_2 <= KW_ESCAPED)||LA181_2==KW_EXCLUSIVE||(LA181_2 >= KW_EXPLAIN && LA181_2 <= KW_EXPRESSION)||(LA181_2 >= KW_FIELDS && LA181_2 <= KW_FIRST)||(LA181_2 >= KW_FORMAT && LA181_2 <= KW_FORMATTED)||LA181_2==KW_FUNCTIONS||(LA181_2 >= KW_HOUR && LA181_2 <= KW_IDXPROPERTIES)||(LA181_2 >= KW_INDEX && LA181_2 <= KW_INDEXES)||(LA181_2 >= KW_INPATH && LA181_2 <= KW_INPUTFORMAT)||(LA181_2 >= KW_ISOLATION && LA181_2 <= KW_JAR)||(LA181_2 >= KW_JOINCOST && LA181_2 <= KW_LAST)||LA181_2==KW_LEVEL||(LA181_2 >= KW_LIMIT && LA181_2 <= KW_LOAD)||(LA181_2 >= KW_LOCATION && LA181_2 <= KW_LONG)||LA181_2==KW_MANAGEMENT||(LA181_2 >= KW_MAPJOIN && LA181_2 <= KW_MATERIALIZED)||LA181_2==KW_METADATA||(LA181_2 >= KW_MINUTE && LA181_2 <= KW_MONTH)||(LA181_2 >= KW_MOVE && LA181_2 <= KW_MSCK)||(LA181_2 >= KW_NORELY && LA181_2 <= KW_NOSCAN)||LA181_2==KW_NOVALIDATE||LA181_2==KW_NULLS||LA181_2==KW_OFFSET||(LA181_2 >= KW_OPERATOR && LA181_2 <= KW_OPTION)||(LA181_2 >= KW_OUTPUTDRIVER && LA181_2 <= KW_OUTPUTFORMAT)||(LA181_2 >= KW_OVERWRITE && LA181_2 <= KW_OWNER)||(LA181_2 >= KW_PARTITIONED && LA181_2 <= KW_PATH)||(LA181_2 >= KW_PLAN && LA181_2 <= KW_POOL)||LA181_2==KW_PRINCIPALS||(LA181_2 >= KW_PURGE && LA181_2 <= KW_QUERY_PARALLELISM)||LA181_2==KW_READ||(LA181_2 >= KW_REBUILD && LA181_2 <= KW_RECORDWRITER)||(LA181_2 >= KW_RELOAD && LA181_2 <= KW_RESTRICT)||LA181_2==KW_REWRITE||(LA181_2 >= KW_ROLE && LA181_2 <= KW_ROLES)||(LA181_2 >= KW_SCHEDULING_POLICY && LA181_2 <= KW_SECOND)||(LA181_2 >= KW_SEMI && LA181_2 <= KW_SERVER)||(LA181_2 >= KW_SETS && LA181_2 <= KW_SKEWED)||(LA181_2 >= KW_SNAPSHOT && LA181_2 <= KW_SSL)||(LA181_2 >= KW_STATISTICS && LA181_2 <= KW_SUMMARY)||LA181_2==KW_TABLES||(LA181_2 >= KW_TBLPROPERTIES && LA181_2 <= KW_TERMINATED)||LA181_2==KW_TINYINT||(LA181_2 >= KW_TOUCH && LA181_2 <= KW_TRANSACTIONS)||LA181_2==KW_UNARCHIVE||LA181_2==KW_UNDO||LA181_2==KW_UNIONTYPE||(LA181_2 >= KW_UNLOCK && LA181_2 <= KW_UNSIGNED)||(LA181_2 >= KW_URI && LA181_2 <= KW_USE)||(LA181_2 >= KW_UTC && LA181_2 <= KW_VALIDATE)||LA181_2==KW_VALUE_TYPE||(LA181_2 >= KW_VECTORIZATION && LA181_2 <= KW_WEEK)||LA181_2==KW_WHILE||(LA181_2 >= KW_WORK && LA181_2 <= KW_ZONE)||LA181_2==KW_BATCH||LA181_2==KW_DAYOFWEEK||LA181_2==KW_HOLD_DDLTIME||LA181_2==KW_IGNORE||LA181_2==KW_NO_DROP||LA181_2==KW_OFFLINE||LA181_2==KW_PROTECTION||LA181_2==KW_READONLY||LA181_2==KW_TIMESTAMPTZ) ) {
					alt181=1;
				}
				else if ( (LA181_2==DOT||LA181_2==KW_FROM||LA181_2==KW_PARTITION||LA181_2==KW_TO) ) {
					alt181=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 181, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EXCLUSIVE:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_IDXPROPERTIES:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_TABLE:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_IGNORE:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt181=2;
				}
				break;
			case KW_URI:
				{
				int LA181_5 = input.LA(2);
				if ( (LA181_5==DOT||LA181_5==KW_FROM||LA181_5==KW_PARTITION||LA181_5==KW_TO) ) {
					alt181=2;
				}
				else if ( (LA181_5==StringLiteral) ) {
					alt181=3;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 181, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_SERVER:
				{
				int LA181_6 = input.LA(2);
				if ( (LA181_6==DOT||LA181_6==KW_FROM||LA181_6==KW_PARTITION||LA181_6==KW_TO) ) {
					alt181=2;
				}
				else if ( (LA181_6==Identifier||(LA181_6 >= KW_ABORT && LA181_6 <= KW_AFTER)||LA181_6==KW_ALLOC_FRACTION||LA181_6==KW_ANALYZE||LA181_6==KW_ARCHIVE||LA181_6==KW_ASC||(LA181_6 >= KW_AUTOCOMMIT && LA181_6 <= KW_BEFORE)||(LA181_6 >= KW_BUCKET && LA181_6 <= KW_BUCKETS)||(LA181_6 >= KW_CACHE && LA181_6 <= KW_CASCADE)||(LA181_6 >= KW_CBO && LA181_6 <= KW_CHANGE)||(LA181_6 >= KW_CHECK && LA181_6 <= KW_COLLECTION)||(LA181_6 >= KW_COLUMNS && LA181_6 <= KW_COMMENT)||(LA181_6 >= KW_COMPACT && LA181_6 <= KW_CONCATENATE)||(LA181_6 >= KW_CONTINUE && LA181_6 <= KW_COST)||LA181_6==KW_DATA||LA181_6==KW_DATABASES||(LA181_6 >= KW_DATETIME && LA181_6 <= KW_DEBUG)||(LA181_6 >= KW_DEFAULT && LA181_6 <= KW_DEFINED)||(LA181_6 >= KW_DELIMITED && LA181_6 <= KW_DESC)||(LA181_6 >= KW_DETAIL && LA181_6 <= KW_DISABLE)||(LA181_6 >= KW_DISTRIBUTE && LA181_6 <= KW_DO)||LA181_6==KW_DOW||(LA181_6 >= KW_DUMP && LA181_6 <= KW_ELEM_TYPE)||LA181_6==KW_ENABLE||(LA181_6 >= KW_ENFORCED && LA181_6 <= KW_ESCAPED)||LA181_6==KW_EXCLUSIVE||(LA181_6 >= KW_EXPLAIN && LA181_6 <= KW_EXPRESSION)||(LA181_6 >= KW_FIELDS && LA181_6 <= KW_FIRST)||(LA181_6 >= KW_FORMAT && LA181_6 <= KW_FORMATTED)||LA181_6==KW_FUNCTIONS||(LA181_6 >= KW_HOUR && LA181_6 <= KW_IDXPROPERTIES)||(LA181_6 >= KW_INDEX && LA181_6 <= KW_INDEXES)||(LA181_6 >= KW_INPATH && LA181_6 <= KW_INPUTFORMAT)||(LA181_6 >= KW_ISOLATION && LA181_6 <= KW_JAR)||(LA181_6 >= KW_JOINCOST && LA181_6 <= KW_LAST)||LA181_6==KW_LEVEL||(LA181_6 >= KW_LIMIT && LA181_6 <= KW_LOAD)||(LA181_6 >= KW_LOCATION && LA181_6 <= KW_LONG)||LA181_6==KW_MANAGEMENT||(LA181_6 >= KW_MAPJOIN && LA181_6 <= KW_MATERIALIZED)||LA181_6==KW_METADATA||(LA181_6 >= KW_MINUTE && LA181_6 <= KW_MONTH)||(LA181_6 >= KW_MOVE && LA181_6 <= KW_MSCK)||(LA181_6 >= KW_NORELY && LA181_6 <= KW_NOSCAN)||LA181_6==KW_NOVALIDATE||LA181_6==KW_NULLS||LA181_6==KW_OFFSET||(LA181_6 >= KW_OPERATOR && LA181_6 <= KW_OPTION)||(LA181_6 >= KW_OUTPUTDRIVER && LA181_6 <= KW_OUTPUTFORMAT)||(LA181_6 >= KW_OVERWRITE && LA181_6 <= KW_OWNER)||(LA181_6 >= KW_PARTITIONED && LA181_6 <= KW_PATH)||(LA181_6 >= KW_PLAN && LA181_6 <= KW_POOL)||LA181_6==KW_PRINCIPALS||(LA181_6 >= KW_PURGE && LA181_6 <= KW_QUERY_PARALLELISM)||LA181_6==KW_READ||(LA181_6 >= KW_REBUILD && LA181_6 <= KW_RECORDWRITER)||(LA181_6 >= KW_RELOAD && LA181_6 <= KW_RESTRICT)||LA181_6==KW_REWRITE||(LA181_6 >= KW_ROLE && LA181_6 <= KW_ROLES)||(LA181_6 >= KW_SCHEDULING_POLICY && LA181_6 <= KW_SECOND)||(LA181_6 >= KW_SEMI && LA181_6 <= KW_SERVER)||(LA181_6 >= KW_SETS && LA181_6 <= KW_SKEWED)||(LA181_6 >= KW_SNAPSHOT && LA181_6 <= KW_SSL)||(LA181_6 >= KW_STATISTICS && LA181_6 <= KW_SUMMARY)||LA181_6==KW_TABLES||(LA181_6 >= KW_TBLPROPERTIES && LA181_6 <= KW_TERMINATED)||LA181_6==KW_TINYINT||(LA181_6 >= KW_TOUCH && LA181_6 <= KW_TRANSACTIONS)||LA181_6==KW_UNARCHIVE||LA181_6==KW_UNDO||LA181_6==KW_UNIONTYPE||(LA181_6 >= KW_UNLOCK && LA181_6 <= KW_UNSIGNED)||(LA181_6 >= KW_URI && LA181_6 <= KW_USE)||(LA181_6 >= KW_UTC && LA181_6 <= KW_VALIDATE)||LA181_6==KW_VALUE_TYPE||(LA181_6 >= KW_VECTORIZATION && LA181_6 <= KW_WEEK)||LA181_6==KW_WHILE||(LA181_6 >= KW_WORK && LA181_6 <= KW_ZONE)||LA181_6==KW_BATCH||LA181_6==KW_DAYOFWEEK||LA181_6==KW_HOLD_DDLTIME||LA181_6==KW_IGNORE||LA181_6==KW_NO_DROP||LA181_6==KW_OFFLINE||LA181_6==KW_PROTECTION||LA181_6==KW_READONLY||LA181_6==KW_TIMESTAMPTZ) ) {
					alt181=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 181, 6, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 181, 0, input);
				throw nvae;
			}
			switch (alt181) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1794:7: ( KW_DATABASE | KW_SCHEMA ) identifier
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1794:7: ( KW_DATABASE | KW_SCHEMA )
					int alt178=2;
					int LA178_0 = input.LA(1);
					if ( (LA178_0==KW_DATABASE) ) {
						alt178=1;
					}
					else if ( (LA178_0==KW_SCHEMA) ) {
						alt178=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 178, 0, input);
						throw nvae;
					}

					switch (alt178) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1794:8: KW_DATABASE
							{
							KW_DATABASE585=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_privObject9736); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE585);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1794:20: KW_SCHEMA
							{
							KW_SCHEMA586=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_privObject9738); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA586);

							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_privObject9741);
					identifier587=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier587.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1794:42: -> ^( TOK_DB_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1794:45: ^( TOK_DB_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:7: ( KW_TABLE )? tableName ( partitionSpec )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:7: ( KW_TABLE )?
					int alt179=2;
					int LA179_0 = input.LA(1);
					if ( (LA179_0==KW_TABLE) ) {
						alt179=1;
					}
					switch (alt179) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:7: KW_TABLE
							{
							KW_TABLE588=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_privObject9757); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE588);

							}
							break;

					}

					pushFollow(FOLLOW_tableName_in_privObject9760);
					tableName589=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName589.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:27: ( partitionSpec )?
					int alt180=2;
					int LA180_0 = input.LA(1);
					if ( (LA180_0==KW_PARTITION) ) {
						alt180=1;
					}
					switch (alt180) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:27: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_privObject9762);
							partitionSpec590=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec590.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: tableName, partitionSpec
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1795:42: -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:45: ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:72: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1796:7: KW_URI (path= StringLiteral )
					{
					KW_URI591=(Token)match(input,KW_URI,FOLLOW_KW_URI_in_privObject9782); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_URI.add(KW_URI591);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1796:14: (path= StringLiteral )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1796:15: path= StringLiteral
					{
					path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_privObject9787); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(path);

					}

					// AST REWRITE
					// elements: path
					// token labels: path
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1796:35: -> ^( TOK_URI_TYPE $path)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1796:39: ^( TOK_URI_TYPE $path)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE"), root_1);
						adaptor.addChild(root_1, stream_path.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1797:7: KW_SERVER identifier
					{
					KW_SERVER592=(Token)match(input,KW_SERVER,FOLLOW_KW_SERVER_in_privObject9806); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERVER.add(KW_SERVER592);

					pushFollow(FOLLOW_identifier_in_privObject9808);
					identifier593=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier593.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1797:28: -> ^( TOK_SERVER_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1797:31: ^( TOK_SERVER_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privObject"


	public static class privObjectCols_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privObjectCols"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1800:1: privObjectCols : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
	public final HiveParser.privObjectCols_return privObjectCols() throws RecognitionException {
		HiveParser.privObjectCols_return retval = new HiveParser.privObjectCols_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_DATABASE594=null;
		Token KW_SCHEMA595=null;
		Token KW_TABLE597=null;
		Token LPAREN599=null;
		Token RPAREN600=null;
		Token KW_URI602=null;
		Token KW_SERVER603=null;
		ParserRuleReturnScope cols =null;
		ParserRuleReturnScope identifier596 =null;
		ParserRuleReturnScope tableName598 =null;
		ParserRuleReturnScope partitionSpec601 =null;
		ParserRuleReturnScope identifier604 =null;

		ASTNode path_tree=null;
		ASTNode KW_DATABASE594_tree=null;
		ASTNode KW_SCHEMA595_tree=null;
		ASTNode KW_TABLE597_tree=null;
		ASTNode LPAREN599_tree=null;
		ASTNode RPAREN600_tree=null;
		ASTNode KW_URI602_tree=null;
		ASTNode KW_SERVER603_tree=null;
		RewriteRuleTokenStream stream_KW_SERVER=new RewriteRuleTokenStream(adaptor,"token KW_SERVER");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_URI=new RewriteRuleTokenStream(adaptor,"token KW_URI");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1801:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
			int alt186=4;
			switch ( input.LA(1) ) {
			case KW_DATABASE:
				{
				alt186=1;
				}
				break;
			case KW_SCHEMA:
				{
				int LA186_2 = input.LA(2);
				if ( (LA186_2==Identifier||(LA186_2 >= KW_ABORT && LA186_2 <= KW_AFTER)||LA186_2==KW_ALLOC_FRACTION||LA186_2==KW_ANALYZE||LA186_2==KW_ARCHIVE||LA186_2==KW_ASC||(LA186_2 >= KW_AUTOCOMMIT && LA186_2 <= KW_BEFORE)||(LA186_2 >= KW_BUCKET && LA186_2 <= KW_BUCKETS)||(LA186_2 >= KW_CACHE && LA186_2 <= KW_CASCADE)||(LA186_2 >= KW_CBO && LA186_2 <= KW_CHANGE)||(LA186_2 >= KW_CHECK && LA186_2 <= KW_COLLECTION)||(LA186_2 >= KW_COLUMNS && LA186_2 <= KW_COMMENT)||(LA186_2 >= KW_COMPACT && LA186_2 <= KW_CONCATENATE)||(LA186_2 >= KW_CONTINUE && LA186_2 <= KW_COST)||LA186_2==KW_DATA||LA186_2==KW_DATABASES||(LA186_2 >= KW_DATETIME && LA186_2 <= KW_DEBUG)||(LA186_2 >= KW_DEFAULT && LA186_2 <= KW_DEFINED)||(LA186_2 >= KW_DELIMITED && LA186_2 <= KW_DESC)||(LA186_2 >= KW_DETAIL && LA186_2 <= KW_DISABLE)||(LA186_2 >= KW_DISTRIBUTE && LA186_2 <= KW_DO)||LA186_2==KW_DOW||(LA186_2 >= KW_DUMP && LA186_2 <= KW_ELEM_TYPE)||LA186_2==KW_ENABLE||(LA186_2 >= KW_ENFORCED && LA186_2 <= KW_ESCAPED)||LA186_2==KW_EXCLUSIVE||(LA186_2 >= KW_EXPLAIN && LA186_2 <= KW_EXPRESSION)||(LA186_2 >= KW_FIELDS && LA186_2 <= KW_FIRST)||(LA186_2 >= KW_FORMAT && LA186_2 <= KW_FORMATTED)||LA186_2==KW_FUNCTIONS||(LA186_2 >= KW_HOUR && LA186_2 <= KW_IDXPROPERTIES)||(LA186_2 >= KW_INDEX && LA186_2 <= KW_INDEXES)||(LA186_2 >= KW_INPATH && LA186_2 <= KW_INPUTFORMAT)||(LA186_2 >= KW_ISOLATION && LA186_2 <= KW_JAR)||(LA186_2 >= KW_JOINCOST && LA186_2 <= KW_LAST)||LA186_2==KW_LEVEL||(LA186_2 >= KW_LIMIT && LA186_2 <= KW_LOAD)||(LA186_2 >= KW_LOCATION && LA186_2 <= KW_LONG)||LA186_2==KW_MANAGEMENT||(LA186_2 >= KW_MAPJOIN && LA186_2 <= KW_MATERIALIZED)||LA186_2==KW_METADATA||(LA186_2 >= KW_MINUTE && LA186_2 <= KW_MONTH)||(LA186_2 >= KW_MOVE && LA186_2 <= KW_MSCK)||(LA186_2 >= KW_NORELY && LA186_2 <= KW_NOSCAN)||LA186_2==KW_NOVALIDATE||LA186_2==KW_NULLS||LA186_2==KW_OFFSET||(LA186_2 >= KW_OPERATOR && LA186_2 <= KW_OPTION)||(LA186_2 >= KW_OUTPUTDRIVER && LA186_2 <= KW_OUTPUTFORMAT)||(LA186_2 >= KW_OVERWRITE && LA186_2 <= KW_OWNER)||(LA186_2 >= KW_PARTITIONED && LA186_2 <= KW_PATH)||(LA186_2 >= KW_PLAN && LA186_2 <= KW_POOL)||LA186_2==KW_PRINCIPALS||(LA186_2 >= KW_PURGE && LA186_2 <= KW_QUERY_PARALLELISM)||LA186_2==KW_READ||(LA186_2 >= KW_REBUILD && LA186_2 <= KW_RECORDWRITER)||(LA186_2 >= KW_RELOAD && LA186_2 <= KW_RESTRICT)||LA186_2==KW_REWRITE||(LA186_2 >= KW_ROLE && LA186_2 <= KW_ROLES)||(LA186_2 >= KW_SCHEDULING_POLICY && LA186_2 <= KW_SECOND)||(LA186_2 >= KW_SEMI && LA186_2 <= KW_SERVER)||(LA186_2 >= KW_SETS && LA186_2 <= KW_SKEWED)||(LA186_2 >= KW_SNAPSHOT && LA186_2 <= KW_SSL)||(LA186_2 >= KW_STATISTICS && LA186_2 <= KW_SUMMARY)||LA186_2==KW_TABLES||(LA186_2 >= KW_TBLPROPERTIES && LA186_2 <= KW_TERMINATED)||LA186_2==KW_TINYINT||(LA186_2 >= KW_TOUCH && LA186_2 <= KW_TRANSACTIONS)||LA186_2==KW_UNARCHIVE||LA186_2==KW_UNDO||LA186_2==KW_UNIONTYPE||(LA186_2 >= KW_UNLOCK && LA186_2 <= KW_UNSIGNED)||(LA186_2 >= KW_URI && LA186_2 <= KW_USE)||(LA186_2 >= KW_UTC && LA186_2 <= KW_VALIDATE)||LA186_2==KW_VALUE_TYPE||(LA186_2 >= KW_VECTORIZATION && LA186_2 <= KW_WEEK)||LA186_2==KW_WHILE||(LA186_2 >= KW_WORK && LA186_2 <= KW_ZONE)||LA186_2==KW_BATCH||LA186_2==KW_DAYOFWEEK||LA186_2==KW_HOLD_DDLTIME||LA186_2==KW_IGNORE||LA186_2==KW_NO_DROP||LA186_2==KW_OFFLINE||LA186_2==KW_PROTECTION||LA186_2==KW_READONLY||LA186_2==KW_TIMESTAMPTZ) ) {
					alt186=1;
				}
				else if ( (LA186_2==EOF||LA186_2==DOT||LA186_2==KW_PARTITION||LA186_2==LPAREN) ) {
					alt186=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 186, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EXCLUSIVE:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_IDXPROPERTIES:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_TABLE:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_IGNORE:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt186=2;
				}
				break;
			case KW_URI:
				{
				int LA186_5 = input.LA(2);
				if ( (LA186_5==EOF||LA186_5==DOT||LA186_5==KW_PARTITION||LA186_5==LPAREN) ) {
					alt186=2;
				}
				else if ( (LA186_5==StringLiteral) ) {
					alt186=3;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 186, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_SERVER:
				{
				int LA186_6 = input.LA(2);
				if ( (LA186_6==EOF||LA186_6==DOT||LA186_6==KW_PARTITION||LA186_6==LPAREN) ) {
					alt186=2;
				}
				else if ( (LA186_6==Identifier||(LA186_6 >= KW_ABORT && LA186_6 <= KW_AFTER)||LA186_6==KW_ALLOC_FRACTION||LA186_6==KW_ANALYZE||LA186_6==KW_ARCHIVE||LA186_6==KW_ASC||(LA186_6 >= KW_AUTOCOMMIT && LA186_6 <= KW_BEFORE)||(LA186_6 >= KW_BUCKET && LA186_6 <= KW_BUCKETS)||(LA186_6 >= KW_CACHE && LA186_6 <= KW_CASCADE)||(LA186_6 >= KW_CBO && LA186_6 <= KW_CHANGE)||(LA186_6 >= KW_CHECK && LA186_6 <= KW_COLLECTION)||(LA186_6 >= KW_COLUMNS && LA186_6 <= KW_COMMENT)||(LA186_6 >= KW_COMPACT && LA186_6 <= KW_CONCATENATE)||(LA186_6 >= KW_CONTINUE && LA186_6 <= KW_COST)||LA186_6==KW_DATA||LA186_6==KW_DATABASES||(LA186_6 >= KW_DATETIME && LA186_6 <= KW_DEBUG)||(LA186_6 >= KW_DEFAULT && LA186_6 <= KW_DEFINED)||(LA186_6 >= KW_DELIMITED && LA186_6 <= KW_DESC)||(LA186_6 >= KW_DETAIL && LA186_6 <= KW_DISABLE)||(LA186_6 >= KW_DISTRIBUTE && LA186_6 <= KW_DO)||LA186_6==KW_DOW||(LA186_6 >= KW_DUMP && LA186_6 <= KW_ELEM_TYPE)||LA186_6==KW_ENABLE||(LA186_6 >= KW_ENFORCED && LA186_6 <= KW_ESCAPED)||LA186_6==KW_EXCLUSIVE||(LA186_6 >= KW_EXPLAIN && LA186_6 <= KW_EXPRESSION)||(LA186_6 >= KW_FIELDS && LA186_6 <= KW_FIRST)||(LA186_6 >= KW_FORMAT && LA186_6 <= KW_FORMATTED)||LA186_6==KW_FUNCTIONS||(LA186_6 >= KW_HOUR && LA186_6 <= KW_IDXPROPERTIES)||(LA186_6 >= KW_INDEX && LA186_6 <= KW_INDEXES)||(LA186_6 >= KW_INPATH && LA186_6 <= KW_INPUTFORMAT)||(LA186_6 >= KW_ISOLATION && LA186_6 <= KW_JAR)||(LA186_6 >= KW_JOINCOST && LA186_6 <= KW_LAST)||LA186_6==KW_LEVEL||(LA186_6 >= KW_LIMIT && LA186_6 <= KW_LOAD)||(LA186_6 >= KW_LOCATION && LA186_6 <= KW_LONG)||LA186_6==KW_MANAGEMENT||(LA186_6 >= KW_MAPJOIN && LA186_6 <= KW_MATERIALIZED)||LA186_6==KW_METADATA||(LA186_6 >= KW_MINUTE && LA186_6 <= KW_MONTH)||(LA186_6 >= KW_MOVE && LA186_6 <= KW_MSCK)||(LA186_6 >= KW_NORELY && LA186_6 <= KW_NOSCAN)||LA186_6==KW_NOVALIDATE||LA186_6==KW_NULLS||LA186_6==KW_OFFSET||(LA186_6 >= KW_OPERATOR && LA186_6 <= KW_OPTION)||(LA186_6 >= KW_OUTPUTDRIVER && LA186_6 <= KW_OUTPUTFORMAT)||(LA186_6 >= KW_OVERWRITE && LA186_6 <= KW_OWNER)||(LA186_6 >= KW_PARTITIONED && LA186_6 <= KW_PATH)||(LA186_6 >= KW_PLAN && LA186_6 <= KW_POOL)||LA186_6==KW_PRINCIPALS||(LA186_6 >= KW_PURGE && LA186_6 <= KW_QUERY_PARALLELISM)||LA186_6==KW_READ||(LA186_6 >= KW_REBUILD && LA186_6 <= KW_RECORDWRITER)||(LA186_6 >= KW_RELOAD && LA186_6 <= KW_RESTRICT)||LA186_6==KW_REWRITE||(LA186_6 >= KW_ROLE && LA186_6 <= KW_ROLES)||(LA186_6 >= KW_SCHEDULING_POLICY && LA186_6 <= KW_SECOND)||(LA186_6 >= KW_SEMI && LA186_6 <= KW_SERVER)||(LA186_6 >= KW_SETS && LA186_6 <= KW_SKEWED)||(LA186_6 >= KW_SNAPSHOT && LA186_6 <= KW_SSL)||(LA186_6 >= KW_STATISTICS && LA186_6 <= KW_SUMMARY)||LA186_6==KW_TABLES||(LA186_6 >= KW_TBLPROPERTIES && LA186_6 <= KW_TERMINATED)||LA186_6==KW_TINYINT||(LA186_6 >= KW_TOUCH && LA186_6 <= KW_TRANSACTIONS)||LA186_6==KW_UNARCHIVE||LA186_6==KW_UNDO||LA186_6==KW_UNIONTYPE||(LA186_6 >= KW_UNLOCK && LA186_6 <= KW_UNSIGNED)||(LA186_6 >= KW_URI && LA186_6 <= KW_USE)||(LA186_6 >= KW_UTC && LA186_6 <= KW_VALIDATE)||LA186_6==KW_VALUE_TYPE||(LA186_6 >= KW_VECTORIZATION && LA186_6 <= KW_WEEK)||LA186_6==KW_WHILE||(LA186_6 >= KW_WORK && LA186_6 <= KW_ZONE)||LA186_6==KW_BATCH||LA186_6==KW_DAYOFWEEK||LA186_6==KW_HOLD_DDLTIME||LA186_6==KW_IGNORE||LA186_6==KW_NO_DROP||LA186_6==KW_OFFLINE||LA186_6==KW_PROTECTION||LA186_6==KW_READONLY||LA186_6==KW_TIMESTAMPTZ) ) {
					alt186=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 186, 6, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 186, 0, input);
				throw nvae;
			}
			switch (alt186) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1801:7: ( KW_DATABASE | KW_SCHEMA ) identifier
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1801:7: ( KW_DATABASE | KW_SCHEMA )
					int alt182=2;
					int LA182_0 = input.LA(1);
					if ( (LA182_0==KW_DATABASE) ) {
						alt182=1;
					}
					else if ( (LA182_0==KW_SCHEMA) ) {
						alt182=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 182, 0, input);
						throw nvae;
					}

					switch (alt182) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1801:8: KW_DATABASE
							{
							KW_DATABASE594=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_privObjectCols9834); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE594);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1801:20: KW_SCHEMA
							{
							KW_SCHEMA595=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_privObjectCols9836); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA595);

							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_privObjectCols9839);
					identifier596=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier596.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1801:42: -> ^( TOK_DB_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1801:45: ^( TOK_DB_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:7: ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:7: ( KW_TABLE )?
					int alt183=2;
					int LA183_0 = input.LA(1);
					if ( (LA183_0==KW_TABLE) ) {
						alt183=1;
					}
					switch (alt183) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:7: KW_TABLE
							{
							KW_TABLE597=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_privObjectCols9855); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE597);

							}
							break;

					}

					pushFollow(FOLLOW_tableName_in_privObjectCols9858);
					tableName598=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName598.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:27: ( LPAREN cols= columnNameList RPAREN )?
					int alt184=2;
					int LA184_0 = input.LA(1);
					if ( (LA184_0==LPAREN) ) {
						alt184=1;
					}
					switch (alt184) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:28: LPAREN cols= columnNameList RPAREN
							{
							LPAREN599=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_privObjectCols9861); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN599);

							pushFollow(FOLLOW_columnNameList_in_privObjectCols9865);
							cols=columnNameList();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_columnNameList.add(cols.getTree());
							RPAREN600=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_privObjectCols9867); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN600);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:64: ( partitionSpec )?
					int alt185=2;
					int LA185_0 = input.LA(1);
					if ( (LA185_0==KW_PARTITION) ) {
						alt185=1;
					}
					switch (alt185) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:64: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_privObjectCols9871);
							partitionSpec601=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec601.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: cols, partitionSpec, tableName
					// token labels: 
					// rule labels: cols, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_cols=new RewriteRuleSubtreeStream(adaptor,"rule cols",cols!=null?cols.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1802:79: -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:82: ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:110: ( $cols)?
						if ( stream_cols.hasNext() ) {
							adaptor.addChild(root_1, stream_cols.nextTree());
						}
						stream_cols.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:116: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1803:7: KW_URI (path= StringLiteral )
					{
					KW_URI602=(Token)match(input,KW_URI,FOLLOW_KW_URI_in_privObjectCols9895); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_URI.add(KW_URI602);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1803:14: (path= StringLiteral )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1803:15: path= StringLiteral
					{
					path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_privObjectCols9900); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(path);

					}

					// AST REWRITE
					// elements: path
					// token labels: path
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1803:35: -> ^( TOK_URI_TYPE $path)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1803:39: ^( TOK_URI_TYPE $path)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE"), root_1);
						adaptor.addChild(root_1, stream_path.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1804:7: KW_SERVER identifier
					{
					KW_SERVER603=(Token)match(input,KW_SERVER,FOLLOW_KW_SERVER_in_privObjectCols9919); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERVER.add(KW_SERVER603);

					pushFollow(FOLLOW_identifier_in_privObjectCols9921);
					identifier604=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier604.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1804:28: -> ^( TOK_SERVER_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1804:31: ^( TOK_SERVER_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privObjectCols"


	public static class privilegeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:1: privilegeList : privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) ;
	public final HiveParser.privilegeList_return privilegeList() throws RecognitionException {
		HiveParser.privilegeList_return retval = new HiveParser.privilegeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA606=null;
		ParserRuleReturnScope privlegeDef605 =null;
		ParserRuleReturnScope privlegeDef607 =null;

		ASTNode COMMA606_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_privlegeDef=new RewriteRuleSubtreeStream(adaptor,"rule privlegeDef");

		pushMsg("grant privilege list", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1810:5: ( privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1810:7: privlegeDef ( COMMA privlegeDef )*
			{
			pushFollow(FOLLOW_privlegeDef_in_privilegeList9956);
			privlegeDef605=privlegeDef();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privlegeDef.add(privlegeDef605.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1810:19: ( COMMA privlegeDef )*
			loop187:
			while (true) {
				int alt187=2;
				int LA187_0 = input.LA(1);
				if ( (LA187_0==COMMA) ) {
					alt187=1;
				}

				switch (alt187) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1810:20: COMMA privlegeDef
					{
					COMMA606=(Token)match(input,COMMA,FOLLOW_COMMA_in_privilegeList9959); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA606);

					pushFollow(FOLLOW_privlegeDef_in_privilegeList9961);
					privlegeDef607=privlegeDef();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privlegeDef.add(privlegeDef607.getTree());
					}
					break;

				default :
					break loop187;
				}
			}

			// AST REWRITE
			// elements: privlegeDef
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1811:5: -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1811:8: ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIVILEGE_LIST, "TOK_PRIVILEGE_LIST"), root_1);
				if ( !(stream_privlegeDef.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_privlegeDef.hasNext() ) {
					adaptor.addChild(root_1, stream_privlegeDef.nextTree());
				}
				stream_privlegeDef.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeList"


	public static class privlegeDef_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privlegeDef"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1814:1: privlegeDef : privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) ;
	public final HiveParser.privlegeDef_return privlegeDef() throws RecognitionException {
		HiveParser.privlegeDef_return retval = new HiveParser.privlegeDef_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN609=null;
		Token RPAREN610=null;
		ParserRuleReturnScope cols =null;
		ParserRuleReturnScope privilegeType608 =null;

		ASTNode LPAREN609_tree=null;
		ASTNode RPAREN610_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
		RewriteRuleSubtreeStream stream_privilegeType=new RewriteRuleSubtreeStream(adaptor,"rule privilegeType");

		pushMsg("grant privilege", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1817:5: ( privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1817:7: privilegeType ( LPAREN cols= columnNameList RPAREN )?
			{
			pushFollow(FOLLOW_privilegeType_in_privlegeDef10003);
			privilegeType608=privilegeType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privilegeType.add(privilegeType608.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1817:21: ( LPAREN cols= columnNameList RPAREN )?
			int alt188=2;
			int LA188_0 = input.LA(1);
			if ( (LA188_0==LPAREN) ) {
				alt188=1;
			}
			switch (alt188) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1817:22: LPAREN cols= columnNameList RPAREN
					{
					LPAREN609=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_privlegeDef10006); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN609);

					pushFollow(FOLLOW_columnNameList_in_privlegeDef10010);
					cols=columnNameList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameList.add(cols.getTree());
					RPAREN610=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_privlegeDef10012); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN610);

					}
					break;

			}

			// AST REWRITE
			// elements: cols, privilegeType
			// token labels: 
			// rule labels: cols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_cols=new RewriteRuleSubtreeStream(adaptor,"rule cols",cols!=null?cols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1818:5: -> ^( TOK_PRIVILEGE privilegeType ( $cols)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:8: ^( TOK_PRIVILEGE privilegeType ( $cols)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIVILEGE, "TOK_PRIVILEGE"), root_1);
				adaptor.addChild(root_1, stream_privilegeType.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:39: ( $cols)?
				if ( stream_cols.hasNext() ) {
					adaptor.addChild(root_1, stream_cols.nextTree());
				}
				stream_cols.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privlegeDef"


	public static class privilegeType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1821:1: privilegeType : ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) );
	public final HiveParser.privilegeType_return privilegeType() throws RecognitionException {
		HiveParser.privilegeType_return retval = new HiveParser.privilegeType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ALL611=null;
		Token KW_ALTER612=null;
		Token KW_UPDATE613=null;
		Token KW_CREATE614=null;
		Token KW_DROP615=null;
		Token KW_LOCK616=null;
		Token KW_SELECT617=null;
		Token KW_SHOW_DATABASE618=null;
		Token KW_INSERT619=null;
		Token KW_DELETE620=null;

		ASTNode KW_ALL611_tree=null;
		ASTNode KW_ALTER612_tree=null;
		ASTNode KW_UPDATE613_tree=null;
		ASTNode KW_CREATE614_tree=null;
		ASTNode KW_DROP615_tree=null;
		ASTNode KW_LOCK616_tree=null;
		ASTNode KW_SELECT617_tree=null;
		ASTNode KW_SHOW_DATABASE618_tree=null;
		ASTNode KW_INSERT619_tree=null;
		ASTNode KW_DELETE620_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
		RewriteRuleTokenStream stream_KW_SHOW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_SHOW_DATABASE");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_ALTER=new RewriteRuleTokenStream(adaptor,"token KW_ALTER");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
		RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
		RewriteRuleTokenStream stream_KW_SELECT=new RewriteRuleTokenStream(adaptor,"token KW_SELECT");
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");

		pushMsg("privilege type", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1824:5: ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) )
			int alt189=10;
			switch ( input.LA(1) ) {
			case KW_ALL:
				{
				alt189=1;
				}
				break;
			case KW_ALTER:
				{
				alt189=2;
				}
				break;
			case KW_UPDATE:
				{
				alt189=3;
				}
				break;
			case KW_CREATE:
				{
				alt189=4;
				}
				break;
			case KW_DROP:
				{
				alt189=5;
				}
				break;
			case KW_LOCK:
				{
				alt189=6;
				}
				break;
			case KW_SELECT:
				{
				alt189=7;
				}
				break;
			case KW_SHOW_DATABASE:
				{
				alt189=8;
				}
				break;
			case KW_INSERT:
				{
				alt189=9;
				}
				break;
			case KW_DELETE:
				{
				alt189=10;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 189, 0, input);
				throw nvae;
			}
			switch (alt189) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1824:7: KW_ALL
					{
					KW_ALL611=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_privilegeType10057); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL611);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1824:14: -> ^( TOK_PRIV_ALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1824:17: ^( TOK_PRIV_ALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_ALL, "TOK_PRIV_ALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1825:7: KW_ALTER
					{
					KW_ALTER612=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_privilegeType10071); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER612);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1825:16: -> ^( TOK_PRIV_ALTER_METADATA )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1825:19: ^( TOK_PRIV_ALTER_METADATA )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_ALTER_METADATA, "TOK_PRIV_ALTER_METADATA"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1826:7: KW_UPDATE
					{
					KW_UPDATE613=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_privilegeType10085); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE613);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1826:17: -> ^( TOK_PRIV_ALTER_DATA )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1826:20: ^( TOK_PRIV_ALTER_DATA )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_ALTER_DATA, "TOK_PRIV_ALTER_DATA"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1827:7: KW_CREATE
					{
					KW_CREATE614=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_privilegeType10099); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE614);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1827:17: -> ^( TOK_PRIV_CREATE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1827:20: ^( TOK_PRIV_CREATE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_CREATE, "TOK_PRIV_CREATE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1828:7: KW_DROP
					{
					KW_DROP615=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_privilegeType10113); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP615);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1828:15: -> ^( TOK_PRIV_DROP )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1828:18: ^( TOK_PRIV_DROP )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_DROP, "TOK_PRIV_DROP"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1829:7: KW_LOCK
					{
					KW_LOCK616=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_privilegeType10127); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK616);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1829:15: -> ^( TOK_PRIV_LOCK )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1829:18: ^( TOK_PRIV_LOCK )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_LOCK, "TOK_PRIV_LOCK"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:7: KW_SELECT
					{
					KW_SELECT617=(Token)match(input,KW_SELECT,FOLLOW_KW_SELECT_in_privilegeType10141); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SELECT.add(KW_SELECT617);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1830:17: -> ^( TOK_PRIV_SELECT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:20: ^( TOK_PRIV_SELECT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_SELECT, "TOK_PRIV_SELECT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1831:7: KW_SHOW_DATABASE
					{
					KW_SHOW_DATABASE618=(Token)match(input,KW_SHOW_DATABASE,FOLLOW_KW_SHOW_DATABASE_in_privilegeType10155); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW_DATABASE.add(KW_SHOW_DATABASE618);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1831:24: -> ^( TOK_PRIV_SHOW_DATABASE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1831:27: ^( TOK_PRIV_SHOW_DATABASE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_SHOW_DATABASE, "TOK_PRIV_SHOW_DATABASE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1832:7: KW_INSERT
					{
					KW_INSERT619=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_privilegeType10169); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT619);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1832:17: -> ^( TOK_PRIV_INSERT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1832:20: ^( TOK_PRIV_INSERT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_INSERT, "TOK_PRIV_INSERT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1833:7: KW_DELETE
					{
					KW_DELETE620=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_privilegeType10183); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE620);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1833:17: -> ^( TOK_PRIV_DELETE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1833:20: ^( TOK_PRIV_DELETE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_DELETE, "TOK_PRIV_DELETE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeType"


	public static class principalSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "principalSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1836:1: principalSpecification : principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) ;
	public final HiveParser.principalSpecification_return principalSpecification() throws RecognitionException {
		HiveParser.principalSpecification_return retval = new HiveParser.principalSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA622=null;
		ParserRuleReturnScope principalName621 =null;
		ParserRuleReturnScope principalName623 =null;

		ASTNode COMMA622_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		 pushMsg("user/group/role name list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:5: ( principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:7: principalName ( COMMA principalName )*
			{
			pushFollow(FOLLOW_principalName_in_principalSpecification10216);
			principalName621=principalName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalName.add(principalName621.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:21: ( COMMA principalName )*
			loop190:
			while (true) {
				int alt190=2;
				int LA190_0 = input.LA(1);
				if ( (LA190_0==COMMA) ) {
					alt190=1;
				}

				switch (alt190) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:22: COMMA principalName
					{
					COMMA622=(Token)match(input,COMMA,FOLLOW_COMMA_in_principalSpecification10219); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA622);

					pushFollow(FOLLOW_principalName_in_principalSpecification10221);
					principalName623=principalName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalName.add(principalName623.getTree());
					}
					break;

				default :
					break loop190;
				}
			}

			// AST REWRITE
			// elements: principalName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1839:44: -> ^( TOK_PRINCIPAL_NAME ( principalName )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:47: ^( TOK_PRINCIPAL_NAME ( principalName )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRINCIPAL_NAME, "TOK_PRINCIPAL_NAME"), root_1);
				if ( !(stream_principalName.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_principalName.hasNext() ) {
					adaptor.addChild(root_1, stream_principalName.nextTree());
				}
				stream_principalName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "principalSpecification"


	public static class principalName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "principalName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1842:1: principalName : ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) );
	public final HiveParser.principalName_return principalName() throws RecognitionException {
		HiveParser.principalName_return retval = new HiveParser.principalName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_USER624=null;
		Token KW_GROUP626=null;
		Token KW_ROLE628=null;
		ParserRuleReturnScope principalIdentifier625 =null;
		ParserRuleReturnScope principalIdentifier627 =null;
		ParserRuleReturnScope identifier629 =null;

		ASTNode KW_USER624_tree=null;
		ASTNode KW_GROUP626_tree=null;
		ASTNode KW_ROLE628_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_USER=new RewriteRuleTokenStream(adaptor,"token KW_USER");
		RewriteRuleTokenStream stream_KW_GROUP=new RewriteRuleTokenStream(adaptor,"token KW_GROUP");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_principalIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule principalIdentifier");

		pushMsg("user|group|role name", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1845:5: ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) )
			int alt191=3;
			switch ( input.LA(1) ) {
			case KW_USER:
				{
				alt191=1;
				}
				break;
			case KW_GROUP:
				{
				alt191=2;
				}
				break;
			case KW_ROLE:
				{
				alt191=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 191, 0, input);
				throw nvae;
			}
			switch (alt191) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1845:7: KW_USER principalIdentifier
					{
					KW_USER624=(Token)match(input,KW_USER,FOLLOW_KW_USER_in_principalName10259); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_USER.add(KW_USER624);

					pushFollow(FOLLOW_principalIdentifier_in_principalName10261);
					principalIdentifier625=principalIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalIdentifier.add(principalIdentifier625.getTree());
					// AST REWRITE
					// elements: principalIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1845:35: -> ^( TOK_USER principalIdentifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1845:38: ^( TOK_USER principalIdentifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_USER, "TOK_USER"), root_1);
						adaptor.addChild(root_1, stream_principalIdentifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1846:7: KW_GROUP principalIdentifier
					{
					KW_GROUP626=(Token)match(input,KW_GROUP,FOLLOW_KW_GROUP_in_principalName10277); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_GROUP.add(KW_GROUP626);

					pushFollow(FOLLOW_principalIdentifier_in_principalName10279);
					principalIdentifier627=principalIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalIdentifier.add(principalIdentifier627.getTree());
					// AST REWRITE
					// elements: principalIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1846:36: -> ^( TOK_GROUP principalIdentifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1846:39: ^( TOK_GROUP principalIdentifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GROUP, "TOK_GROUP"), root_1);
						adaptor.addChild(root_1, stream_principalIdentifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1847:7: KW_ROLE identifier
					{
					KW_ROLE628=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_principalName10295); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE628);

					pushFollow(FOLLOW_identifier_in_principalName10297);
					identifier629=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier629.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1847:26: -> ^( TOK_ROLE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1847:29: ^( TOK_ROLE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ROLE, "TOK_ROLE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "principalName"


	public static class withGrantOption_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "withGrantOption"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:1: withGrantOption : KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) ;
	public final HiveParser.withGrantOption_return withGrantOption() throws RecognitionException {
		HiveParser.withGrantOption_return retval = new HiveParser.withGrantOption_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WITH630=null;
		Token KW_GRANT631=null;
		Token KW_OPTION632=null;

		ASTNode KW_WITH630_tree=null;
		ASTNode KW_GRANT631_tree=null;
		ASTNode KW_OPTION632_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");

		pushMsg("with grant option", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1853:5: ( KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1853:7: KW_WITH KW_GRANT KW_OPTION
			{
			KW_WITH630=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withGrantOption10332); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH630);

			KW_GRANT631=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_withGrantOption10334); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT631);

			KW_OPTION632=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_withGrantOption10336); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION632);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1854:5: -> ^( TOK_GRANT_WITH_OPTION )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1854:8: ^( TOK_GRANT_WITH_OPTION )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_WITH_OPTION, "TOK_GRANT_WITH_OPTION"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "withGrantOption"


	public static class grantOptionFor_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "grantOptionFor"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:1: grantOptionFor : KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) ;
	public final HiveParser.grantOptionFor_return grantOptionFor() throws RecognitionException {
		HiveParser.grantOptionFor_return retval = new HiveParser.grantOptionFor_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_GRANT633=null;
		Token KW_OPTION634=null;
		Token KW_FOR635=null;

		ASTNode KW_GRANT633_tree=null;
		ASTNode KW_OPTION634_tree=null;
		ASTNode KW_FOR635_tree=null;
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");

		pushMsg("grant option for", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1860:5: ( KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1860:7: KW_GRANT KW_OPTION KW_FOR
			{
			KW_GRANT633=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantOptionFor10373); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT633);

			KW_OPTION634=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_grantOptionFor10375); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION634);

			KW_FOR635=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_grantOptionFor10377); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR635);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1861:5: -> ^( TOK_GRANT_OPTION_FOR )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1861:8: ^( TOK_GRANT_OPTION_FOR )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_OPTION_FOR, "TOK_GRANT_OPTION_FOR"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "grantOptionFor"


	public static class adminOptionFor_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "adminOptionFor"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1864:1: adminOptionFor : KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) ;
	public final HiveParser.adminOptionFor_return adminOptionFor() throws RecognitionException {
		HiveParser.adminOptionFor_return retval = new HiveParser.adminOptionFor_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ADMIN636=null;
		Token KW_OPTION637=null;
		Token KW_FOR638=null;

		ASTNode KW_ADMIN636_tree=null;
		ASTNode KW_OPTION637_tree=null;
		ASTNode KW_FOR638_tree=null;
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");
		RewriteRuleTokenStream stream_KW_ADMIN=new RewriteRuleTokenStream(adaptor,"token KW_ADMIN");

		pushMsg("admin option for", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1867:5: ( KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1867:7: KW_ADMIN KW_OPTION KW_FOR
			{
			KW_ADMIN636=(Token)match(input,KW_ADMIN,FOLLOW_KW_ADMIN_in_adminOptionFor10410); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ADMIN.add(KW_ADMIN636);

			KW_OPTION637=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_adminOptionFor10412); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION637);

			KW_FOR638=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_adminOptionFor10414); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR638);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1868:5: -> ^( TOK_ADMIN_OPTION_FOR )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1868:8: ^( TOK_ADMIN_OPTION_FOR )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ADMIN_OPTION_FOR, "TOK_ADMIN_OPTION_FOR"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "adminOptionFor"


	public static class withAdminOption_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "withAdminOption"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1871:1: withAdminOption : KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) ;
	public final HiveParser.withAdminOption_return withAdminOption() throws RecognitionException {
		HiveParser.withAdminOption_return retval = new HiveParser.withAdminOption_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WITH639=null;
		Token KW_ADMIN640=null;
		Token KW_OPTION641=null;

		ASTNode KW_WITH639_tree=null;
		ASTNode KW_ADMIN640_tree=null;
		ASTNode KW_OPTION641_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");
		RewriteRuleTokenStream stream_KW_ADMIN=new RewriteRuleTokenStream(adaptor,"token KW_ADMIN");

		pushMsg("with admin option", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:5: ( KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:7: KW_WITH KW_ADMIN KW_OPTION
			{
			KW_WITH639=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withAdminOption10447); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH639);

			KW_ADMIN640=(Token)match(input,KW_ADMIN,FOLLOW_KW_ADMIN_in_withAdminOption10449); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ADMIN.add(KW_ADMIN640);

			KW_OPTION641=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_withAdminOption10451); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION641);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1875:5: -> ^( TOK_GRANT_WITH_ADMIN_OPTION )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1875:8: ^( TOK_GRANT_WITH_ADMIN_OPTION )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_WITH_ADMIN_OPTION, "TOK_GRANT_WITH_ADMIN_OPTION"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "withAdminOption"


	public static class metastoreCheck_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "metastoreCheck"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1878:1: metastoreCheck : KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )? | ( partitionSpec )? ) -> ^( TOK_MSCK ( $repair)? ( tableName )? ( $add)? ( $drop)? ( $sync)? ( ( partitionSpec )* )? ) ;
	public final HiveParser.metastoreCheck_return metastoreCheck() throws RecognitionException {
		HiveParser.metastoreCheck_return retval = new HiveParser.metastoreCheck_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token repair=null;
		Token add=null;
		Token drop=null;
		Token sync=null;
		Token parts=null;
		Token KW_MSCK642=null;
		Token KW_TABLE643=null;
		ParserRuleReturnScope tableName644 =null;
		ParserRuleReturnScope partitionSpec645 =null;

		ASTNode repair_tree=null;
		ASTNode add_tree=null;
		ASTNode drop_tree=null;
		ASTNode sync_tree=null;
		ASTNode parts_tree=null;
		ASTNode KW_MSCK642_tree=null;
		ASTNode KW_TABLE643_tree=null;
		RewriteRuleTokenStream stream_KW_REPAIR=new RewriteRuleTokenStream(adaptor,"token KW_REPAIR");
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_SYNC=new RewriteRuleTokenStream(adaptor,"token KW_SYNC");
		RewriteRuleTokenStream stream_KW_MSCK=new RewriteRuleTokenStream(adaptor,"token KW_MSCK");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
		RewriteRuleTokenStream stream_KW_PARTITIONS=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONS");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("metastore check statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:5: ( KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )? | ( partitionSpec )? ) -> ^( TOK_MSCK ( $repair)? ( tableName )? ( $add)? ( $drop)? ( $sync)? ( ( partitionSpec )* )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:7: KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )? | ( partitionSpec )? )
			{
			KW_MSCK642=(Token)match(input,KW_MSCK,FOLLOW_KW_MSCK_in_metastoreCheck10488); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MSCK.add(KW_MSCK642);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:15: (repair= KW_REPAIR )?
			int alt192=2;
			int LA192_0 = input.LA(1);
			if ( (LA192_0==KW_REPAIR) ) {
				alt192=1;
			}
			switch (alt192) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:16: repair= KW_REPAIR
					{
					repair=(Token)match(input,KW_REPAIR,FOLLOW_KW_REPAIR_in_metastoreCheck10493); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REPAIR.add(repair);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:7: ( KW_TABLE tableName ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )? | ( partitionSpec )? )
			int alt196=2;
			int LA196_0 = input.LA(1);
			if ( (LA196_0==KW_TABLE) ) {
				alt196=1;
			}
			else if ( (LA196_0==EOF||LA196_0==KW_PARTITION) ) {
				alt196=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 196, 0, input);
				throw nvae;
			}

			switch (alt196) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:8: KW_TABLE tableName ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )?
					{
					KW_TABLE643=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_metastoreCheck10504); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE643);

					pushFollow(FOLLOW_tableName_in_metastoreCheck10506);
					tableName644=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName644.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:9: ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )?
					int alt194=2;
					int LA194_0 = input.LA(1);
					if ( (LA194_0==KW_ADD||LA194_0==KW_DROP||LA194_0==KW_SYNC) ) {
						alt194=1;
					}
					switch (alt194) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:10: (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:10: (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC )
							int alt193=3;
							switch ( input.LA(1) ) {
							case KW_ADD:
								{
								alt193=1;
								}
								break;
							case KW_DROP:
								{
								alt193=2;
								}
								break;
							case KW_SYNC:
								{
								alt193=3;
								}
								break;
							default:
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 193, 0, input);
								throw nvae;
							}
							switch (alt193) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:11: add= KW_ADD
									{
									add=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_metastoreCheck10520); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_ADD.add(add);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:24: drop= KW_DROP
									{
									drop=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_metastoreCheck10526); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_DROP.add(drop);

									}
									break;
								case 3 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:39: sync= KW_SYNC
									{
									sync=(Token)match(input,KW_SYNC,FOLLOW_KW_SYNC_in_metastoreCheck10532); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_SYNC.add(sync);

									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:53: (parts= KW_PARTITIONS )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:54: parts= KW_PARTITIONS
							{
							parts=(Token)match(input,KW_PARTITIONS,FOLLOW_KW_PARTITIONS_in_metastoreCheck10538); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PARTITIONS.add(parts);

							}

							}
							break;

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1884:9: ( partitionSpec )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1884:9: ( partitionSpec )?
					int alt195=2;
					int LA195_0 = input.LA(1);
					if ( (LA195_0==KW_PARTITION) ) {
						alt195=1;
					}
					switch (alt195) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1884:10: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_metastoreCheck10554);
							partitionSpec645=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec645.getTree());
							}
							break;

					}

					}
					break;

			}

			// AST REWRITE
			// elements: tableName, add, sync, repair, partitionSpec, drop
			// token labels: add, drop, repair, sync
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_add=new RewriteRuleTokenStream(adaptor,"token add",add);
			RewriteRuleTokenStream stream_drop=new RewriteRuleTokenStream(adaptor,"token drop",drop);
			RewriteRuleTokenStream stream_repair=new RewriteRuleTokenStream(adaptor,"token repair",repair);
			RewriteRuleTokenStream stream_sync=new RewriteRuleTokenStream(adaptor,"token sync",sync);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1885:5: -> ^( TOK_MSCK ( $repair)? ( tableName )? ( $add)? ( $drop)? ( $sync)? ( ( partitionSpec )* )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:8: ^( TOK_MSCK ( $repair)? ( tableName )? ( $add)? ( $drop)? ( $sync)? ( ( partitionSpec )* )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MSCK, "TOK_MSCK"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:20: ( $repair)?
				if ( stream_repair.hasNext() ) {
					adaptor.addChild(root_1, stream_repair.nextNode());
				}
				stream_repair.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:28: ( tableName )?
				if ( stream_tableName.hasNext() ) {
					adaptor.addChild(root_1, stream_tableName.nextTree());
				}
				stream_tableName.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:40: ( $add)?
				if ( stream_add.hasNext() ) {
					adaptor.addChild(root_1, stream_add.nextNode());
				}
				stream_add.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:46: ( $drop)?
				if ( stream_drop.hasNext() ) {
					adaptor.addChild(root_1, stream_drop.nextNode());
				}
				stream_drop.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:53: ( $sync)?
				if ( stream_sync.hasNext() ) {
					adaptor.addChild(root_1, stream_sync.nextNode());
				}
				stream_sync.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:59: ( ( partitionSpec )* )?
				if ( stream_partitionSpec.hasNext() ) {
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:60: ( partitionSpec )*
					while ( stream_partitionSpec.hasNext() ) {
						adaptor.addChild(root_1, stream_partitionSpec.nextTree());
					}
					stream_partitionSpec.reset();

				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "metastoreCheck"


	public static class resourceList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "resourceList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1888:1: resourceList : resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) ;
	public final HiveParser.resourceList_return resourceList() throws RecognitionException {
		HiveParser.resourceList_return retval = new HiveParser.resourceList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA647=null;
		ParserRuleReturnScope resource646 =null;
		ParserRuleReturnScope resource648 =null;

		ASTNode COMMA647_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_resource=new RewriteRuleSubtreeStream(adaptor,"rule resource");

		 pushMsg("resource list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1891:3: ( resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1892:3: resource ( COMMA resource )*
			{
			pushFollow(FOLLOW_resource_in_resourceList10619);
			resource646=resource();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_resource.add(resource646.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1892:12: ( COMMA resource )*
			loop197:
			while (true) {
				int alt197=2;
				int LA197_0 = input.LA(1);
				if ( (LA197_0==COMMA) ) {
					alt197=1;
				}

				switch (alt197) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1892:13: COMMA resource
					{
					COMMA647=(Token)match(input,COMMA,FOLLOW_COMMA_in_resourceList10622); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA647);

					pushFollow(FOLLOW_resource_in_resourceList10624);
					resource648=resource();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_resource.add(resource648.getTree());
					}
					break;

				default :
					break loop197;
				}
			}

			// AST REWRITE
			// elements: resource
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1892:30: -> ^( TOK_RESOURCE_LIST ( resource )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1892:33: ^( TOK_RESOURCE_LIST ( resource )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESOURCE_LIST, "TOK_RESOURCE_LIST"), root_1);
				if ( !(stream_resource.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_resource.hasNext() ) {
					adaptor.addChild(root_1, stream_resource.nextTree());
				}
				stream_resource.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "resourceList"


	public static class resource_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "resource"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1895:1: resource : resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) ;
	public final HiveParser.resource_return resource() throws RecognitionException {
		HiveParser.resource_return retval = new HiveParser.resource_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token resPath=null;
		ParserRuleReturnScope resType =null;

		ASTNode resPath_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleSubtreeStream stream_resourceType=new RewriteRuleSubtreeStream(adaptor,"rule resourceType");

		 pushMsg("resource", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1898:3: (resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1899:3: resType= resourceType resPath= StringLiteral
			{
			pushFollow(FOLLOW_resourceType_in_resource10662);
			resType=resourceType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_resourceType.add(resType.getTree());
			resPath=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_resource10666); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(resPath);

			// AST REWRITE
			// elements: resType, resPath
			// token labels: resPath
			// rule labels: resType, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_resPath=new RewriteRuleTokenStream(adaptor,"token resPath",resPath);
			RewriteRuleSubtreeStream stream_resType=new RewriteRuleSubtreeStream(adaptor,"rule resType",resType!=null?resType.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1899:46: -> ^( TOK_RESOURCE_URI $resType $resPath)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1899:49: ^( TOK_RESOURCE_URI $resType $resPath)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESOURCE_URI, "TOK_RESOURCE_URI"), root_1);
				adaptor.addChild(root_1, stream_resType.nextTree());
				adaptor.addChild(root_1, stream_resPath.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "resource"


	public static class resourceType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "resourceType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1902:1: resourceType : ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) );
	public final HiveParser.resourceType_return resourceType() throws RecognitionException {
		HiveParser.resourceType_return retval = new HiveParser.resourceType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_JAR649=null;
		Token KW_FILE650=null;
		Token KW_ARCHIVE651=null;

		ASTNode KW_JAR649_tree=null;
		ASTNode KW_FILE650_tree=null;
		ASTNode KW_ARCHIVE651_tree=null;
		RewriteRuleTokenStream stream_KW_ARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_ARCHIVE");
		RewriteRuleTokenStream stream_KW_JAR=new RewriteRuleTokenStream(adaptor,"token KW_JAR");
		RewriteRuleTokenStream stream_KW_FILE=new RewriteRuleTokenStream(adaptor,"token KW_FILE");

		 pushMsg("resource type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1905:3: ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) )
			int alt198=3;
			switch ( input.LA(1) ) {
			case KW_JAR:
				{
				alt198=1;
				}
				break;
			case KW_FILE:
				{
				alt198=2;
				}
				break;
			case KW_ARCHIVE:
				{
				alt198=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 198, 0, input);
				throw nvae;
			}
			switch (alt198) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:3: KW_JAR
					{
					KW_JAR649=(Token)match(input,KW_JAR,FOLLOW_KW_JAR_in_resourceType10703); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_JAR.add(KW_JAR649);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1906:10: -> ^( TOK_JAR )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:13: ^( TOK_JAR )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_JAR, "TOK_JAR"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:3: KW_FILE
					{
					KW_FILE650=(Token)match(input,KW_FILE,FOLLOW_KW_FILE_in_resourceType10717); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FILE.add(KW_FILE650);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1908:11: -> ^( TOK_FILE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:14: ^( TOK_FILE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FILE, "TOK_FILE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1910:3: KW_ARCHIVE
					{
					KW_ARCHIVE651=(Token)match(input,KW_ARCHIVE,FOLLOW_KW_ARCHIVE_in_resourceType10731); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ARCHIVE.add(KW_ARCHIVE651);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1910:14: -> ^( TOK_ARCHIVE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1910:17: ^( TOK_ARCHIVE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ARCHIVE, "TOK_ARCHIVE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "resourceType"


	public static class createFunctionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createFunctionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1913:1: createFunctionStatement : KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) ;
	public final HiveParser.createFunctionStatement_return createFunctionStatement() throws RecognitionException {
		HiveParser.createFunctionStatement_return retval = new HiveParser.createFunctionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token temp=null;
		Token KW_CREATE652=null;
		Token KW_FUNCTION653=null;
		Token KW_AS655=null;
		Token StringLiteral656=null;
		Token KW_USING657=null;
		ParserRuleReturnScope rList =null;
		ParserRuleReturnScope functionIdentifier654 =null;

		ASTNode temp_tree=null;
		ASTNode KW_CREATE652_tree=null;
		ASTNode KW_FUNCTION653_tree=null;
		ASTNode KW_AS655_tree=null;
		ASTNode StringLiteral656_tree=null;
		ASTNode KW_USING657_tree=null;
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_USING=new RewriteRuleTokenStream(adaptor,"token KW_USING");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_functionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule functionIdentifier");
		RewriteRuleSubtreeStream stream_resourceList=new RewriteRuleSubtreeStream(adaptor,"rule resourceList");

		 pushMsg("create function statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1916:5: ( KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1916:7: KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )?
			{
			KW_CREATE652=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createFunctionStatement10762); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE652);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1916:17: (temp= KW_TEMPORARY )?
			int alt199=2;
			int LA199_0 = input.LA(1);
			if ( (LA199_0==KW_TEMPORARY) ) {
				alt199=1;
			}
			switch (alt199) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1916:18: temp= KW_TEMPORARY
					{
					temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createFunctionStatement10767); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);

					}
					break;

			}

			KW_FUNCTION653=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_createFunctionStatement10771); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION653);

			pushFollow(FOLLOW_functionIdentifier_in_createFunctionStatement10773);
			functionIdentifier654=functionIdentifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_functionIdentifier.add(functionIdentifier654.getTree());
			KW_AS655=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createFunctionStatement10775); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS655);

			StringLiteral656=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_createFunctionStatement10777); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral656);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1917:7: ( KW_USING rList= resourceList )?
			int alt200=2;
			int LA200_0 = input.LA(1);
			if ( (LA200_0==KW_USING) ) {
				alt200=1;
			}
			switch (alt200) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1917:8: KW_USING rList= resourceList
					{
					KW_USING657=(Token)match(input,KW_USING,FOLLOW_KW_USING_in_createFunctionStatement10786); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_USING.add(KW_USING657);

					pushFollow(FOLLOW_resourceList_in_createFunctionStatement10790);
					rList=resourceList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_resourceList.add(rList.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: StringLiteral, rList, rList, functionIdentifier, functionIdentifier, StringLiteral
			// token labels: 
			// rule labels: rList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_rList=new RewriteRuleSubtreeStream(adaptor,"rule rList",rList!=null?rList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1918:5: -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
			if (temp != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1918:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				adaptor.addChild(root_1, stream_StringLiteral.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1918:80: ( $rList)?
				if ( stream_rList.hasNext() ) {
					adaptor.addChild(root_1, stream_rList.nextTree());
				}
				stream_rList.reset();

				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY"));
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1919:5: -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				adaptor.addChild(root_1, stream_StringLiteral.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:80: ( $rList)?
				if ( stream_rList.hasNext() ) {
					adaptor.addChild(root_1, stream_rList.nextTree());
				}
				stream_rList.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createFunctionStatement"


	public static class dropFunctionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropFunctionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1922:1: dropFunctionStatement : KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) ;
	public final HiveParser.dropFunctionStatement_return dropFunctionStatement() throws RecognitionException {
		HiveParser.dropFunctionStatement_return retval = new HiveParser.dropFunctionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token temp=null;
		Token KW_DROP658=null;
		Token KW_FUNCTION659=null;
		ParserRuleReturnScope ifExists660 =null;
		ParserRuleReturnScope functionIdentifier661 =null;

		ASTNode temp_tree=null;
		ASTNode KW_DROP658_tree=null;
		ASTNode KW_FUNCTION659_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_functionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule functionIdentifier");

		 pushMsg("drop function statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1925:5: ( KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1925:7: KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier
			{
			KW_DROP658=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropFunctionStatement10876); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP658);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1925:15: (temp= KW_TEMPORARY )?
			int alt201=2;
			int LA201_0 = input.LA(1);
			if ( (LA201_0==KW_TEMPORARY) ) {
				alt201=1;
			}
			switch (alt201) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1925:16: temp= KW_TEMPORARY
					{
					temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_dropFunctionStatement10881); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);

					}
					break;

			}

			KW_FUNCTION659=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_dropFunctionStatement10885); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION659);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1925:48: ( ifExists )?
			int alt202=2;
			int LA202_0 = input.LA(1);
			if ( (LA202_0==KW_IF) ) {
				alt202=1;
			}
			switch (alt202) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1925:48: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropFunctionStatement10887);
					ifExists660=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists660.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_functionIdentifier_in_dropFunctionStatement10890);
			functionIdentifier661=functionIdentifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_functionIdentifier.add(functionIdentifier661.getTree());
			// AST REWRITE
			// elements: ifExists, functionIdentifier, functionIdentifier, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1926:5: -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
			if (temp != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1926:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1926:63: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY"));
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1927:5: -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1927:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1927:63: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropFunctionStatement"


	public static class reloadFunctionsStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "reloadFunctionsStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1930:1: reloadFunctionsStatement : KW_RELOAD ( KW_FUNCTIONS | KW_FUNCTION ) -> ^( TOK_RELOADFUNCTIONS ) ;
	public final HiveParser.reloadFunctionsStatement_return reloadFunctionsStatement() throws RecognitionException {
		HiveParser.reloadFunctionsStatement_return retval = new HiveParser.reloadFunctionsStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RELOAD662=null;
		Token KW_FUNCTIONS663=null;
		Token KW_FUNCTION664=null;

		ASTNode KW_RELOAD662_tree=null;
		ASTNode KW_FUNCTIONS663_tree=null;
		ASTNode KW_FUNCTION664_tree=null;
		RewriteRuleTokenStream stream_KW_FUNCTIONS=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTIONS");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleTokenStream stream_KW_RELOAD=new RewriteRuleTokenStream(adaptor,"token KW_RELOAD");

		 pushMsg("reload functions statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1933:5: ( KW_RELOAD ( KW_FUNCTIONS | KW_FUNCTION ) -> ^( TOK_RELOADFUNCTIONS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1933:7: KW_RELOAD ( KW_FUNCTIONS | KW_FUNCTION )
			{
			KW_RELOAD662=(Token)match(input,KW_RELOAD,FOLLOW_KW_RELOAD_in_reloadFunctionsStatement10968); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_RELOAD.add(KW_RELOAD662);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1933:17: ( KW_FUNCTIONS | KW_FUNCTION )
			int alt203=2;
			int LA203_0 = input.LA(1);
			if ( (LA203_0==KW_FUNCTIONS) ) {
				alt203=1;
			}
			else if ( (LA203_0==KW_FUNCTION) ) {
				alt203=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 203, 0, input);
				throw nvae;
			}

			switch (alt203) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1933:18: KW_FUNCTIONS
					{
					KW_FUNCTIONS663=(Token)match(input,KW_FUNCTIONS,FOLLOW_KW_FUNCTIONS_in_reloadFunctionsStatement10971); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTIONS.add(KW_FUNCTIONS663);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1933:31: KW_FUNCTION
					{
					KW_FUNCTION664=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_reloadFunctionsStatement10973); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION664);

					}
					break;

			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1933:44: -> ^( TOK_RELOADFUNCTIONS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1933:47: ^( TOK_RELOADFUNCTIONS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RELOADFUNCTIONS, "TOK_RELOADFUNCTIONS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "reloadFunctionsStatement"


	public static class createMacroStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createMacroStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1935:1: createMacroStatement : KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) ;
	public final HiveParser.createMacroStatement_return createMacroStatement() throws RecognitionException {
		HiveParser.createMacroStatement_return retval = new HiveParser.createMacroStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE665=null;
		Token KW_TEMPORARY666=null;
		Token KW_MACRO667=null;
		Token Identifier668=null;
		Token LPAREN669=null;
		Token RPAREN671=null;
		ParserRuleReturnScope columnNameTypeList670 =null;
		ParserRuleReturnScope expression672 =null;

		ASTNode KW_CREATE665_tree=null;
		ASTNode KW_TEMPORARY666_tree=null;
		ASTNode KW_MACRO667_tree=null;
		ASTNode Identifier668_tree=null;
		ASTNode LPAREN669_tree=null;
		ASTNode RPAREN671_tree=null;
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_MACRO=new RewriteRuleTokenStream(adaptor,"token KW_MACRO");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");

		 pushMsg("create macro statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:5: ( KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:7: KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression
			{
			KW_CREATE665=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createMacroStatement11002); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE665);

			KW_TEMPORARY666=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createMacroStatement11004); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(KW_TEMPORARY666);

			KW_MACRO667=(Token)match(input,KW_MACRO,FOLLOW_KW_MACRO_in_createMacroStatement11006); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MACRO.add(KW_MACRO667);

			Identifier668=(Token)match(input,Identifier,FOLLOW_Identifier_in_createMacroStatement11008); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Identifier.add(Identifier668);

			LPAREN669=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createMacroStatement11016); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN669);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1939:14: ( columnNameTypeList )?
			int alt204=2;
			int LA204_0 = input.LA(1);
			if ( (LA204_0==Identifier||(LA204_0 >= KW_ABORT && LA204_0 <= KW_AFTER)||LA204_0==KW_ALLOC_FRACTION||LA204_0==KW_ANALYZE||LA204_0==KW_ARCHIVE||LA204_0==KW_ASC||(LA204_0 >= KW_AUTOCOMMIT && LA204_0 <= KW_BEFORE)||(LA204_0 >= KW_BUCKET && LA204_0 <= KW_BUCKETS)||(LA204_0 >= KW_CACHE && LA204_0 <= KW_CASCADE)||(LA204_0 >= KW_CBO && LA204_0 <= KW_CHANGE)||(LA204_0 >= KW_CHECK && LA204_0 <= KW_COLLECTION)||(LA204_0 >= KW_COLUMNS && LA204_0 <= KW_COMMENT)||(LA204_0 >= KW_COMPACT && LA204_0 <= KW_CONCATENATE)||(LA204_0 >= KW_CONTINUE && LA204_0 <= KW_COST)||LA204_0==KW_DATA||LA204_0==KW_DATABASES||(LA204_0 >= KW_DATETIME && LA204_0 <= KW_DEBUG)||(LA204_0 >= KW_DEFAULT && LA204_0 <= KW_DEFINED)||(LA204_0 >= KW_DELIMITED && LA204_0 <= KW_DESC)||(LA204_0 >= KW_DETAIL && LA204_0 <= KW_DISABLE)||(LA204_0 >= KW_DISTRIBUTE && LA204_0 <= KW_DO)||LA204_0==KW_DOW||(LA204_0 >= KW_DUMP && LA204_0 <= KW_ELEM_TYPE)||LA204_0==KW_ENABLE||(LA204_0 >= KW_ENFORCED && LA204_0 <= KW_ESCAPED)||LA204_0==KW_EXCLUSIVE||(LA204_0 >= KW_EXPLAIN && LA204_0 <= KW_EXPRESSION)||(LA204_0 >= KW_FIELDS && LA204_0 <= KW_FIRST)||(LA204_0 >= KW_FORMAT && LA204_0 <= KW_FORMATTED)||LA204_0==KW_FUNCTIONS||(LA204_0 >= KW_HOUR && LA204_0 <= KW_IDXPROPERTIES)||(LA204_0 >= KW_INDEX && LA204_0 <= KW_INDEXES)||(LA204_0 >= KW_INPATH && LA204_0 <= KW_INPUTFORMAT)||(LA204_0 >= KW_ISOLATION && LA204_0 <= KW_JAR)||(LA204_0 >= KW_JOINCOST && LA204_0 <= KW_LAST)||LA204_0==KW_LEVEL||(LA204_0 >= KW_LIMIT && LA204_0 <= KW_LOAD)||(LA204_0 >= KW_LOCATION && LA204_0 <= KW_LONG)||LA204_0==KW_MANAGEMENT||(LA204_0 >= KW_MAPJOIN && LA204_0 <= KW_MATERIALIZED)||LA204_0==KW_METADATA||(LA204_0 >= KW_MINUTE && LA204_0 <= KW_MONTH)||(LA204_0 >= KW_MOVE && LA204_0 <= KW_MSCK)||(LA204_0 >= KW_NORELY && LA204_0 <= KW_NOSCAN)||LA204_0==KW_NOVALIDATE||LA204_0==KW_NULLS||LA204_0==KW_OFFSET||(LA204_0 >= KW_OPERATOR && LA204_0 <= KW_OPTION)||(LA204_0 >= KW_OUTPUTDRIVER && LA204_0 <= KW_OUTPUTFORMAT)||(LA204_0 >= KW_OVERWRITE && LA204_0 <= KW_OWNER)||(LA204_0 >= KW_PARTITIONED && LA204_0 <= KW_PATH)||(LA204_0 >= KW_PLAN && LA204_0 <= KW_POOL)||LA204_0==KW_PRINCIPALS||(LA204_0 >= KW_PURGE && LA204_0 <= KW_QUERY_PARALLELISM)||LA204_0==KW_READ||(LA204_0 >= KW_REBUILD && LA204_0 <= KW_RECORDWRITER)||(LA204_0 >= KW_RELOAD && LA204_0 <= KW_RESTRICT)||LA204_0==KW_REWRITE||(LA204_0 >= KW_ROLE && LA204_0 <= KW_ROLES)||(LA204_0 >= KW_SCHEDULING_POLICY && LA204_0 <= KW_SECOND)||(LA204_0 >= KW_SEMI && LA204_0 <= KW_SERVER)||(LA204_0 >= KW_SETS && LA204_0 <= KW_SKEWED)||(LA204_0 >= KW_SNAPSHOT && LA204_0 <= KW_SSL)||(LA204_0 >= KW_STATISTICS && LA204_0 <= KW_SUMMARY)||LA204_0==KW_TABLES||(LA204_0 >= KW_TBLPROPERTIES && LA204_0 <= KW_TERMINATED)||LA204_0==KW_TINYINT||(LA204_0 >= KW_TOUCH && LA204_0 <= KW_TRANSACTIONS)||LA204_0==KW_UNARCHIVE||LA204_0==KW_UNDO||LA204_0==KW_UNIONTYPE||(LA204_0 >= KW_UNLOCK && LA204_0 <= KW_UNSIGNED)||(LA204_0 >= KW_URI && LA204_0 <= KW_USE)||(LA204_0 >= KW_UTC && LA204_0 <= KW_VALIDATE)||LA204_0==KW_VALUE_TYPE||(LA204_0 >= KW_VECTORIZATION && LA204_0 <= KW_WEEK)||LA204_0==KW_WHILE||(LA204_0 >= KW_WORK && LA204_0 <= KW_ZONE)||LA204_0==KW_BATCH||LA204_0==KW_DAYOFWEEK||LA204_0==KW_HOLD_DDLTIME||LA204_0==KW_IGNORE||LA204_0==KW_NO_DROP||LA204_0==KW_OFFLINE||LA204_0==KW_PROTECTION||LA204_0==KW_READONLY||LA204_0==KW_TIMESTAMPTZ) ) {
				alt204=1;
			}
			switch (alt204) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1939:14: columnNameTypeList
					{
					pushFollow(FOLLOW_columnNameTypeList_in_createMacroStatement11018);
					columnNameTypeList670=columnNameTypeList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameTypeList.add(columnNameTypeList670.getTree());
					}
					break;

			}

			RPAREN671=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createMacroStatement11021); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN671);

			pushFollow(FOLLOW_expression_in_createMacroStatement11023);
			expression672=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression672.getTree());
			// AST REWRITE
			// elements: columnNameTypeList, Identifier, expression
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1940:5: -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:8: ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEMACRO, "TOK_CREATEMACRO"), root_1);
				adaptor.addChild(root_1, stream_Identifier.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:37: ( columnNameTypeList )?
				if ( stream_columnNameTypeList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
				}
				stream_columnNameTypeList.reset();

				adaptor.addChild(root_1, stream_expression.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createMacroStatement"


	public static class dropMacroStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropMacroStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1943:1: dropMacroStatement : KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) ;
	public final HiveParser.dropMacroStatement_return dropMacroStatement() throws RecognitionException {
		HiveParser.dropMacroStatement_return retval = new HiveParser.dropMacroStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP673=null;
		Token KW_TEMPORARY674=null;
		Token KW_MACRO675=null;
		Token Identifier677=null;
		ParserRuleReturnScope ifExists676 =null;

		ASTNode KW_DROP673_tree=null;
		ASTNode KW_TEMPORARY674_tree=null;
		ASTNode KW_MACRO675_tree=null;
		ASTNode Identifier677_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
		RewriteRuleTokenStream stream_KW_MACRO=new RewriteRuleTokenStream(adaptor,"token KW_MACRO");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("drop macro statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1946:5: ( KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1946:7: KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier
			{
			KW_DROP673=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropMacroStatement11067); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP673);

			KW_TEMPORARY674=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_dropMacroStatement11069); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(KW_TEMPORARY674);

			KW_MACRO675=(Token)match(input,KW_MACRO,FOLLOW_KW_MACRO_in_dropMacroStatement11071); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MACRO.add(KW_MACRO675);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1946:37: ( ifExists )?
			int alt205=2;
			int LA205_0 = input.LA(1);
			if ( (LA205_0==KW_IF) ) {
				alt205=1;
			}
			switch (alt205) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1946:37: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropMacroStatement11073);
					ifExists676=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists676.getTree());
					}
					break;

			}

			Identifier677=(Token)match(input,Identifier,FOLLOW_Identifier_in_dropMacroStatement11076); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Identifier.add(Identifier677);

			// AST REWRITE
			// elements: Identifier, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1947:5: -> ^( TOK_DROPMACRO Identifier ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1947:8: ^( TOK_DROPMACRO Identifier ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPMACRO, "TOK_DROPMACRO"), root_1);
				adaptor.addChild(root_1, stream_Identifier.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1947:35: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropMacroStatement"


	public static class createViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1950:1: createViewStatement : KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) ;
	public final HiveParser.createViewStatement_return createViewStatement() throws RecognitionException {
		HiveParser.createViewStatement_return retval = new HiveParser.createViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE678=null;
		Token KW_VIEW680=null;
		Token LPAREN682=null;
		Token RPAREN684=null;
		Token KW_AS688=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope orReplace679 =null;
		ParserRuleReturnScope ifNotExists681 =null;
		ParserRuleReturnScope columnNameCommentList683 =null;
		ParserRuleReturnScope tableComment685 =null;
		ParserRuleReturnScope viewPartition686 =null;
		ParserRuleReturnScope tablePropertiesPrefixed687 =null;
		ParserRuleReturnScope selectStatementWithCTE689 =null;

		ASTNode KW_CREATE678_tree=null;
		ASTNode KW_VIEW680_tree=null;
		ASTNode LPAREN682_tree=null;
		ASTNode RPAREN684_tree=null;
		ASTNode KW_AS688_tree=null;
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_columnNameCommentList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameCommentList");
		RewriteRuleSubtreeStream stream_selectStatementWithCTE=new RewriteRuleSubtreeStream(adaptor,"rule selectStatementWithCTE");
		RewriteRuleSubtreeStream stream_orReplace=new RewriteRuleSubtreeStream(adaptor,"rule orReplace");
		RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
		RewriteRuleSubtreeStream stream_viewPartition=new RewriteRuleSubtreeStream(adaptor,"rule viewPartition");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");


		    pushMsg("create view statement", state);

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:5: ( KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:7: KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE
			{
			KW_CREATE678=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createViewStatement11118); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE678);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:17: ( orReplace )?
			int alt206=2;
			int LA206_0 = input.LA(1);
			if ( (LA206_0==KW_OR) ) {
				alt206=1;
			}
			switch (alt206) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:18: orReplace
					{
					pushFollow(FOLLOW_orReplace_in_createViewStatement11121);
					orReplace679=orReplace();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orReplace.add(orReplace679.getTree());
					}
					break;

			}

			KW_VIEW680=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_createViewStatement11125); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW680);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:38: ( ifNotExists )?
			int alt207=2;
			int LA207_0 = input.LA(1);
			if ( (LA207_0==KW_IF) ) {
				alt207=1;
			}
			switch (alt207) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:39: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_createViewStatement11128);
					ifNotExists681=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists681.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_createViewStatement11134);
			name=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(name.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1956:9: ( LPAREN columnNameCommentList RPAREN )?
			int alt208=2;
			int LA208_0 = input.LA(1);
			if ( (LA208_0==LPAREN) ) {
				alt208=1;
			}
			switch (alt208) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1956:10: LPAREN columnNameCommentList RPAREN
					{
					LPAREN682=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createViewStatement11145); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN682);

					pushFollow(FOLLOW_columnNameCommentList_in_createViewStatement11147);
					columnNameCommentList683=columnNameCommentList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameCommentList.add(columnNameCommentList683.getTree());
					RPAREN684=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createViewStatement11149); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN684);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1956:48: ( tableComment )?
			int alt209=2;
			int LA209_0 = input.LA(1);
			if ( (LA209_0==KW_COMMENT) ) {
				alt209=1;
			}
			switch (alt209) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1956:48: tableComment
					{
					pushFollow(FOLLOW_tableComment_in_createViewStatement11153);
					tableComment685=tableComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableComment.add(tableComment685.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1956:62: ( viewPartition )?
			int alt210=2;
			int LA210_0 = input.LA(1);
			if ( (LA210_0==KW_PARTITIONED) ) {
				alt210=1;
			}
			switch (alt210) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1956:62: viewPartition
					{
					pushFollow(FOLLOW_viewPartition_in_createViewStatement11156);
					viewPartition686=viewPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_viewPartition.add(viewPartition686.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1957:9: ( tablePropertiesPrefixed )?
			int alt211=2;
			int LA211_0 = input.LA(1);
			if ( (LA211_0==KW_TBLPROPERTIES) ) {
				alt211=1;
			}
			switch (alt211) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1957:9: tablePropertiesPrefixed
					{
					pushFollow(FOLLOW_tablePropertiesPrefixed_in_createViewStatement11167);
					tablePropertiesPrefixed687=tablePropertiesPrefixed();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed687.getTree());
					}
					break;

			}

			KW_AS688=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createViewStatement11178); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS688);

			pushFollow(FOLLOW_selectStatementWithCTE_in_createViewStatement11188);
			selectStatementWithCTE689=selectStatementWithCTE();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_selectStatementWithCTE.add(selectStatementWithCTE689.getTree());
			// AST REWRITE
			// elements: name, viewPartition, tablePropertiesPrefixed, selectStatementWithCTE, tableComment, columnNameCommentList, orReplace, ifNotExists
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1960:5: -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1960:8: ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEVIEW, "TOK_CREATEVIEW"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1960:31: ( orReplace )?
				if ( stream_orReplace.hasNext() ) {
					adaptor.addChild(root_1, stream_orReplace.nextTree());
				}
				stream_orReplace.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1961:10: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1962:10: ( columnNameCommentList )?
				if ( stream_columnNameCommentList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameCommentList.nextTree());
				}
				stream_columnNameCommentList.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:10: ( tableComment )?
				if ( stream_tableComment.hasNext() ) {
					adaptor.addChild(root_1, stream_tableComment.nextTree());
				}
				stream_tableComment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1964:10: ( viewPartition )?
				if ( stream_viewPartition.hasNext() ) {
					adaptor.addChild(root_1, stream_viewPartition.nextTree());
				}
				stream_viewPartition.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1965:10: ( tablePropertiesPrefixed )?
				if ( stream_tablePropertiesPrefixed.hasNext() ) {
					adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
				}
				stream_tablePropertiesPrefixed.reset();

				adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createViewStatement"


	public static class viewPartition_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewPartition"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1970:1: viewPartition : KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) ;
	public final HiveParser.viewPartition_return viewPartition() throws RecognitionException {
		HiveParser.viewPartition_return retval = new HiveParser.viewPartition_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PARTITIONED690=null;
		Token KW_ON691=null;
		Token LPAREN692=null;
		Token RPAREN694=null;
		ParserRuleReturnScope columnNameList693 =null;

		ASTNode KW_PARTITIONED690_tree=null;
		ASTNode KW_ON691_tree=null;
		ASTNode LPAREN692_tree=null;
		ASTNode RPAREN694_tree=null;
		RewriteRuleTokenStream stream_KW_PARTITIONED=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONED");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1973:5: ( KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1973:7: KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN
			{
			KW_PARTITIONED690=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_viewPartition11311); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_PARTITIONED.add(KW_PARTITIONED690);

			KW_ON691=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewPartition11313); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON691);

			LPAREN692=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewPartition11315); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN692);

			pushFollow(FOLLOW_columnNameList_in_viewPartition11317);
			columnNameList693=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList693.getTree());
			RPAREN694=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewPartition11319); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN694);

			// AST REWRITE
			// elements: columnNameList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1974:5: -> ^( TOK_VIEWPARTCOLS columnNameList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1974:8: ^( TOK_VIEWPARTCOLS columnNameList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWPARTCOLS, "TOK_VIEWPARTCOLS"), root_1);
				adaptor.addChild(root_1, stream_columnNameList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewPartition"


	public static class viewOrganization_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewOrganization"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1977:1: viewOrganization : ( viewClusterSpec | viewComplexSpec );
	public final HiveParser.viewOrganization_return viewOrganization() throws RecognitionException {
		HiveParser.viewOrganization_return retval = new HiveParser.viewOrganization_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope viewClusterSpec695 =null;
		ParserRuleReturnScope viewComplexSpec696 =null;


		 pushMsg("view organization specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1980:5: ( viewClusterSpec | viewComplexSpec )
			int alt212=2;
			int LA212_0 = input.LA(1);
			if ( (LA212_0==KW_CLUSTERED) ) {
				alt212=1;
			}
			else if ( (LA212_0==KW_DISTRIBUTED) ) {
				alt212=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 212, 0, input);
				throw nvae;
			}

			switch (alt212) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1980:7: viewClusterSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_viewClusterSpec_in_viewOrganization11358);
					viewClusterSpec695=viewClusterSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, viewClusterSpec695.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1981:7: viewComplexSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_viewComplexSpec_in_viewOrganization11366);
					viewComplexSpec696=viewComplexSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, viewComplexSpec696.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewOrganization"


	public static class viewClusterSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewClusterSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1984:1: viewClusterSpec : KW_CLUSTERED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWCLUSTERCOLS columnNameList ) ;
	public final HiveParser.viewClusterSpec_return viewClusterSpec() throws RecognitionException {
		HiveParser.viewClusterSpec_return retval = new HiveParser.viewClusterSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CLUSTERED697=null;
		Token KW_ON698=null;
		Token LPAREN699=null;
		Token RPAREN701=null;
		ParserRuleReturnScope columnNameList700 =null;

		ASTNode KW_CLUSTERED697_tree=null;
		ASTNode KW_ON698_tree=null;
		ASTNode LPAREN699_tree=null;
		ASTNode RPAREN701_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view cluster specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1987:5: ( KW_CLUSTERED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWCLUSTERCOLS columnNameList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1987:7: KW_CLUSTERED KW_ON LPAREN columnNameList RPAREN
			{
			KW_CLUSTERED697=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_viewClusterSpec11393); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CLUSTERED.add(KW_CLUSTERED697);

			KW_ON698=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewClusterSpec11395); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON698);

			LPAREN699=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewClusterSpec11397); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN699);

			pushFollow(FOLLOW_columnNameList_in_viewClusterSpec11399);
			columnNameList700=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList700.getTree());
			RPAREN701=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewClusterSpec11401); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN701);

			// AST REWRITE
			// elements: columnNameList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1988:5: -> ^( TOK_VIEWCLUSTERCOLS columnNameList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1988:8: ^( TOK_VIEWCLUSTERCOLS columnNameList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWCLUSTERCOLS, "TOK_VIEWCLUSTERCOLS"), root_1);
				adaptor.addChild(root_1, stream_columnNameList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewClusterSpec"


	public static class viewComplexSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewComplexSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1991:1: viewComplexSpec : viewDistSpec viewSortSpec ;
	public final HiveParser.viewComplexSpec_return viewComplexSpec() throws RecognitionException {
		HiveParser.viewComplexSpec_return retval = new HiveParser.viewComplexSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope viewDistSpec702 =null;
		ParserRuleReturnScope viewSortSpec703 =null;


		 pushMsg("view complex specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1994:5: ( viewDistSpec viewSortSpec )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1994:7: viewDistSpec viewSortSpec
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_viewDistSpec_in_viewComplexSpec11440);
			viewDistSpec702=viewDistSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, viewDistSpec702.getTree());

			pushFollow(FOLLOW_viewSortSpec_in_viewComplexSpec11442);
			viewSortSpec703=viewSortSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, viewSortSpec703.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewComplexSpec"


	public static class viewDistSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewDistSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1997:1: viewDistSpec : KW_DISTRIBUTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWDISTRIBUTECOLS $colList) ;
	public final HiveParser.viewDistSpec_return viewDistSpec() throws RecognitionException {
		HiveParser.viewDistSpec_return retval = new HiveParser.viewDistSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DISTRIBUTED704=null;
		Token KW_ON705=null;
		Token LPAREN706=null;
		Token RPAREN707=null;
		ParserRuleReturnScope colList =null;

		ASTNode KW_DISTRIBUTED704_tree=null;
		ASTNode KW_ON705_tree=null;
		ASTNode LPAREN706_tree=null;
		ASTNode RPAREN707_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_DISTRIBUTED=new RewriteRuleTokenStream(adaptor,"token KW_DISTRIBUTED");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view distribute specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2000:5: ( KW_DISTRIBUTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWDISTRIBUTECOLS $colList) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2000:7: KW_DISTRIBUTED KW_ON LPAREN colList= columnNameList RPAREN
			{
			KW_DISTRIBUTED704=(Token)match(input,KW_DISTRIBUTED,FOLLOW_KW_DISTRIBUTED_in_viewDistSpec11469); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DISTRIBUTED.add(KW_DISTRIBUTED704);

			KW_ON705=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewDistSpec11471); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON705);

			LPAREN706=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewDistSpec11473); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN706);

			pushFollow(FOLLOW_columnNameList_in_viewDistSpec11477);
			colList=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(colList.getTree());
			RPAREN707=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewDistSpec11479); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN707);

			// AST REWRITE
			// elements: colList
			// token labels: 
			// rule labels: colList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colList=new RewriteRuleSubtreeStream(adaptor,"rule colList",colList!=null?colList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2001:5: -> ^( TOK_VIEWDISTRIBUTECOLS $colList)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2001:8: ^( TOK_VIEWDISTRIBUTECOLS $colList)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWDISTRIBUTECOLS, "TOK_VIEWDISTRIBUTECOLS"), root_1);
				adaptor.addChild(root_1, stream_colList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewDistSpec"


	public static class viewSortSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewSortSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2004:1: viewSortSpec : KW_SORTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWSORTCOLS $colList) ;
	public final HiveParser.viewSortSpec_return viewSortSpec() throws RecognitionException {
		HiveParser.viewSortSpec_return retval = new HiveParser.viewSortSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SORTED708=null;
		Token KW_ON709=null;
		Token LPAREN710=null;
		Token RPAREN711=null;
		ParserRuleReturnScope colList =null;

		ASTNode KW_SORTED708_tree=null;
		ASTNode KW_ON709_tree=null;
		ASTNode LPAREN710_tree=null;
		ASTNode RPAREN711_tree=null;
		RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view sort specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2007:5: ( KW_SORTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWSORTCOLS $colList) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2007:7: KW_SORTED KW_ON LPAREN colList= columnNameList RPAREN
			{
			KW_SORTED708=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_viewSortSpec11519); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED708);

			KW_ON709=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewSortSpec11521); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON709);

			LPAREN710=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewSortSpec11523); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN710);

			pushFollow(FOLLOW_columnNameList_in_viewSortSpec11527);
			colList=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(colList.getTree());
			RPAREN711=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewSortSpec11529); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN711);

			// AST REWRITE
			// elements: colList
			// token labels: 
			// rule labels: colList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colList=new RewriteRuleSubtreeStream(adaptor,"rule colList",colList!=null?colList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2008:5: -> ^( TOK_VIEWSORTCOLS $colList)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2008:8: ^( TOK_VIEWSORTCOLS $colList)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWSORTCOLS, "TOK_VIEWSORTCOLS"), root_1);
				adaptor.addChild(root_1, stream_colList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewSortSpec"


	public static class dropViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2011:1: dropViewStatement : KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) ;
	public final HiveParser.dropViewStatement_return dropViewStatement() throws RecognitionException {
		HiveParser.dropViewStatement_return retval = new HiveParser.dropViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP712=null;
		Token KW_VIEW713=null;
		ParserRuleReturnScope ifExists714 =null;
		ParserRuleReturnScope viewName715 =null;

		ASTNode KW_DROP712_tree=null;
		ASTNode KW_VIEW713_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleSubtreeStream stream_viewName=new RewriteRuleSubtreeStream(adaptor,"rule viewName");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("drop view statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:5: ( KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:7: KW_DROP KW_VIEW ( ifExists )? viewName
			{
			KW_DROP712=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropViewStatement11569); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP712);

			KW_VIEW713=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_dropViewStatement11571); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW713);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:23: ( ifExists )?
			int alt213=2;
			int LA213_0 = input.LA(1);
			if ( (LA213_0==KW_IF) ) {
				alt213=1;
			}
			switch (alt213) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:23: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropViewStatement11573);
					ifExists714=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists714.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_viewName_in_dropViewStatement11576);
			viewName715=viewName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_viewName.add(viewName715.getTree());
			// AST REWRITE
			// elements: viewName, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2014:42: -> ^( TOK_DROPVIEW viewName ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:45: ^( TOK_DROPVIEW viewName ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPVIEW, "TOK_DROPVIEW"), root_1);
				adaptor.addChild(root_1, stream_viewName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:69: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropViewStatement"


	public static class createMaterializedViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createMaterializedViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2017:1: createMaterializedViewStatement : KW_CREATE KW_MATERIALIZED KW_VIEW ( ifNotExists )? name= tableName ( rewriteDisabled )? ( tableComment )? ( viewPartition )? ( viewOrganization )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) ;
	public final HiveParser.createMaterializedViewStatement_return createMaterializedViewStatement() throws RecognitionException {
		HiveParser.createMaterializedViewStatement_return retval = new HiveParser.createMaterializedViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE716=null;
		Token KW_MATERIALIZED717=null;
		Token KW_VIEW718=null;
		Token KW_AS728=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope ifNotExists719 =null;
		ParserRuleReturnScope rewriteDisabled720 =null;
		ParserRuleReturnScope tableComment721 =null;
		ParserRuleReturnScope viewPartition722 =null;
		ParserRuleReturnScope viewOrganization723 =null;
		ParserRuleReturnScope tableRowFormat724 =null;
		ParserRuleReturnScope tableFileFormat725 =null;
		ParserRuleReturnScope tableLocation726 =null;
		ParserRuleReturnScope tablePropertiesPrefixed727 =null;
		ParserRuleReturnScope selectStatementWithCTE729 =null;

		ASTNode KW_CREATE716_tree=null;
		ASTNode KW_MATERIALIZED717_tree=null;
		ASTNode KW_VIEW718_tree=null;
		ASTNode KW_AS728_tree=null;
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
		RewriteRuleSubtreeStream stream_selectStatementWithCTE=new RewriteRuleSubtreeStream(adaptor,"rule selectStatementWithCTE");
		RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
		RewriteRuleSubtreeStream stream_rewriteDisabled=new RewriteRuleSubtreeStream(adaptor,"rule rewriteDisabled");
		RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
		RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
		RewriteRuleSubtreeStream stream_viewOrganization=new RewriteRuleSubtreeStream(adaptor,"rule viewOrganization");
		RewriteRuleSubtreeStream stream_viewPartition=new RewriteRuleSubtreeStream(adaptor,"rule viewPartition");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");


		    pushMsg("create materialized view statement", state);

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2022:5: ( KW_CREATE KW_MATERIALIZED KW_VIEW ( ifNotExists )? name= tableName ( rewriteDisabled )? ( tableComment )? ( viewPartition )? ( viewOrganization )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2022:7: KW_CREATE KW_MATERIALIZED KW_VIEW ( ifNotExists )? name= tableName ( rewriteDisabled )? ( tableComment )? ( viewPartition )? ( viewOrganization )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE
			{
			KW_CREATE716=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createMaterializedViewStatement11614); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE716);

			KW_MATERIALIZED717=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_createMaterializedViewStatement11616); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED717);

			KW_VIEW718=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_createMaterializedViewStatement11618); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW718);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2022:41: ( ifNotExists )?
			int alt214=2;
			int LA214_0 = input.LA(1);
			if ( (LA214_0==KW_IF) ) {
				alt214=1;
			}
			switch (alt214) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2022:42: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_createMaterializedViewStatement11621);
					ifNotExists719=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists719.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_createMaterializedViewStatement11627);
			name=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(name.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:9: ( rewriteDisabled )?
			int alt215=2;
			int LA215_0 = input.LA(1);
			if ( (LA215_0==KW_DISABLE) ) {
				alt215=1;
			}
			switch (alt215) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:9: rewriteDisabled
					{
					pushFollow(FOLLOW_rewriteDisabled_in_createMaterializedViewStatement11637);
					rewriteDisabled720=rewriteDisabled();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rewriteDisabled.add(rewriteDisabled720.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:26: ( tableComment )?
			int alt216=2;
			int LA216_0 = input.LA(1);
			if ( (LA216_0==KW_COMMENT) ) {
				alt216=1;
			}
			switch (alt216) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:26: tableComment
					{
					pushFollow(FOLLOW_tableComment_in_createMaterializedViewStatement11640);
					tableComment721=tableComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableComment.add(tableComment721.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:40: ( viewPartition )?
			int alt217=2;
			int LA217_0 = input.LA(1);
			if ( (LA217_0==KW_PARTITIONED) ) {
				alt217=1;
			}
			switch (alt217) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:40: viewPartition
					{
					pushFollow(FOLLOW_viewPartition_in_createMaterializedViewStatement11643);
					viewPartition722=viewPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_viewPartition.add(viewPartition722.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:55: ( viewOrganization )?
			int alt218=2;
			int LA218_0 = input.LA(1);
			if ( (LA218_0==KW_CLUSTERED||LA218_0==KW_DISTRIBUTED) ) {
				alt218=1;
			}
			switch (alt218) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:55: viewOrganization
					{
					pushFollow(FOLLOW_viewOrganization_in_createMaterializedViewStatement11646);
					viewOrganization723=viewOrganization();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_viewOrganization.add(viewOrganization723.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2024:9: ( tableRowFormat )?
			int alt219=2;
			int LA219_0 = input.LA(1);
			if ( (LA219_0==KW_ROW) ) {
				alt219=1;
			}
			switch (alt219) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2024:9: tableRowFormat
					{
					pushFollow(FOLLOW_tableRowFormat_in_createMaterializedViewStatement11657);
					tableRowFormat724=tableRowFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat724.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2024:25: ( tableFileFormat )?
			int alt220=2;
			int LA220_0 = input.LA(1);
			if ( (LA220_0==KW_STORED) ) {
				alt220=1;
			}
			switch (alt220) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2024:25: tableFileFormat
					{
					pushFollow(FOLLOW_tableFileFormat_in_createMaterializedViewStatement11660);
					tableFileFormat725=tableFileFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat725.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2024:42: ( tableLocation )?
			int alt221=2;
			int LA221_0 = input.LA(1);
			if ( (LA221_0==KW_LOCATION) ) {
				alt221=1;
			}
			switch (alt221) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2024:42: tableLocation
					{
					pushFollow(FOLLOW_tableLocation_in_createMaterializedViewStatement11663);
					tableLocation726=tableLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation726.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2025:9: ( tablePropertiesPrefixed )?
			int alt222=2;
			int LA222_0 = input.LA(1);
			if ( (LA222_0==KW_TBLPROPERTIES) ) {
				alt222=1;
			}
			switch (alt222) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2025:9: tablePropertiesPrefixed
					{
					pushFollow(FOLLOW_tablePropertiesPrefixed_in_createMaterializedViewStatement11674);
					tablePropertiesPrefixed727=tablePropertiesPrefixed();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed727.getTree());
					}
					break;

			}

			KW_AS728=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createMaterializedViewStatement11677); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS728);

			pushFollow(FOLLOW_selectStatementWithCTE_in_createMaterializedViewStatement11679);
			selectStatementWithCTE729=selectStatementWithCTE();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_selectStatementWithCTE.add(selectStatementWithCTE729.getTree());
			// AST REWRITE
			// elements: name, rewriteDisabled, selectStatementWithCTE, ifNotExists, tableRowFormat, tableComment, viewPartition, tableFileFormat, tableLocation, tablePropertiesPrefixed, viewOrganization
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2026:5: -> ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2026:8: ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATE_MATERIALIZED_VIEW, "TOK_CREATE_MATERIALIZED_VIEW"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2027:10: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2028:10: ( rewriteDisabled )?
				if ( stream_rewriteDisabled.hasNext() ) {
					adaptor.addChild(root_1, stream_rewriteDisabled.nextTree());
				}
				stream_rewriteDisabled.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2029:10: ( tableComment )?
				if ( stream_tableComment.hasNext() ) {
					adaptor.addChild(root_1, stream_tableComment.nextTree());
				}
				stream_tableComment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2030:10: ( tableRowFormat )?
				if ( stream_tableRowFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
				}
				stream_tableRowFormat.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:10: ( tableFileFormat )?
				if ( stream_tableFileFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
				}
				stream_tableFileFormat.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:10: ( tableLocation )?
				if ( stream_tableLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_tableLocation.nextTree());
				}
				stream_tableLocation.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2033:10: ( viewPartition )?
				if ( stream_viewPartition.hasNext() ) {
					adaptor.addChild(root_1, stream_viewPartition.nextTree());
				}
				stream_viewPartition.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2034:10: ( viewOrganization )?
				if ( stream_viewOrganization.hasNext() ) {
					adaptor.addChild(root_1, stream_viewOrganization.nextTree());
				}
				stream_viewOrganization.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2035:10: ( tablePropertiesPrefixed )?
				if ( stream_tablePropertiesPrefixed.hasNext() ) {
					adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
				}
				stream_tablePropertiesPrefixed.reset();

				adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createMaterializedViewStatement"


	public static class dropMaterializedViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropMaterializedViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2040:1: dropMaterializedViewStatement : KW_DROP KW_MATERIALIZED KW_VIEW ( ifExists )? viewName -> ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? ) ;
	public final HiveParser.dropMaterializedViewStatement_return dropMaterializedViewStatement() throws RecognitionException {
		HiveParser.dropMaterializedViewStatement_return retval = new HiveParser.dropMaterializedViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP730=null;
		Token KW_MATERIALIZED731=null;
		Token KW_VIEW732=null;
		ParserRuleReturnScope ifExists733 =null;
		ParserRuleReturnScope viewName734 =null;

		ASTNode KW_DROP730_tree=null;
		ASTNode KW_MATERIALIZED731_tree=null;
		ASTNode KW_VIEW732_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleSubtreeStream stream_viewName=new RewriteRuleSubtreeStream(adaptor,"rule viewName");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("drop materialized view statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:5: ( KW_DROP KW_MATERIALIZED KW_VIEW ( ifExists )? viewName -> ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:7: KW_DROP KW_MATERIALIZED KW_VIEW ( ifExists )? viewName
			{
			KW_DROP730=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropMaterializedViewStatement11847); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP730);

			KW_MATERIALIZED731=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_dropMaterializedViewStatement11849); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED731);

			KW_VIEW732=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_dropMaterializedViewStatement11851); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW732);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:39: ( ifExists )?
			int alt223=2;
			int LA223_0 = input.LA(1);
			if ( (LA223_0==KW_IF) ) {
				alt223=1;
			}
			switch (alt223) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:39: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropMaterializedViewStatement11853);
					ifExists733=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists733.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_viewName_in_dropMaterializedViewStatement11856);
			viewName734=viewName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_viewName.add(viewName734.getTree());
			// AST REWRITE
			// elements: viewName, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2043:58: -> ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:61: ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROP_MATERIALIZED_VIEW, "TOK_DROP_MATERIALIZED_VIEW"), root_1);
				adaptor.addChild(root_1, stream_viewName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:99: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropMaterializedViewStatement"


	public static class showFunctionIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showFunctionIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2046:1: showFunctionIdentifier : ( functionIdentifier | StringLiteral );
	public final HiveParser.showFunctionIdentifier_return showFunctionIdentifier() throws RecognitionException {
		HiveParser.showFunctionIdentifier_return retval = new HiveParser.showFunctionIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token StringLiteral736=null;
		ParserRuleReturnScope functionIdentifier735 =null;

		ASTNode StringLiteral736_tree=null;

		 pushMsg("identifier for show function statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2049:5: ( functionIdentifier | StringLiteral )
			int alt224=2;
			int LA224_0 = input.LA(1);
			if ( (LA224_0==Identifier||(LA224_0 >= KW_ABORT && LA224_0 <= KW_AFTER)||LA224_0==KW_ALLOC_FRACTION||LA224_0==KW_ANALYZE||LA224_0==KW_ARCHIVE||LA224_0==KW_ASC||(LA224_0 >= KW_AUTOCOMMIT && LA224_0 <= KW_BEFORE)||(LA224_0 >= KW_BUCKET && LA224_0 <= KW_BUCKETS)||(LA224_0 >= KW_CACHE && LA224_0 <= KW_CASCADE)||(LA224_0 >= KW_CBO && LA224_0 <= KW_CHANGE)||(LA224_0 >= KW_CHECK && LA224_0 <= KW_COLLECTION)||(LA224_0 >= KW_COLUMNS && LA224_0 <= KW_COMMENT)||(LA224_0 >= KW_COMPACT && LA224_0 <= KW_CONCATENATE)||(LA224_0 >= KW_CONTINUE && LA224_0 <= KW_COST)||LA224_0==KW_DATA||LA224_0==KW_DATABASES||(LA224_0 >= KW_DATETIME && LA224_0 <= KW_DEBUG)||(LA224_0 >= KW_DEFAULT && LA224_0 <= KW_DEFINED)||(LA224_0 >= KW_DELIMITED && LA224_0 <= KW_DESC)||(LA224_0 >= KW_DETAIL && LA224_0 <= KW_DISABLE)||(LA224_0 >= KW_DISTRIBUTE && LA224_0 <= KW_DO)||LA224_0==KW_DOW||(LA224_0 >= KW_DUMP && LA224_0 <= KW_ELEM_TYPE)||LA224_0==KW_ENABLE||(LA224_0 >= KW_ENFORCED && LA224_0 <= KW_ESCAPED)||LA224_0==KW_EXCLUSIVE||(LA224_0 >= KW_EXPLAIN && LA224_0 <= KW_EXPRESSION)||(LA224_0 >= KW_FIELDS && LA224_0 <= KW_FIRST)||(LA224_0 >= KW_FORMAT && LA224_0 <= KW_FORMATTED)||LA224_0==KW_FUNCTIONS||(LA224_0 >= KW_HOUR && LA224_0 <= KW_IDXPROPERTIES)||(LA224_0 >= KW_INDEX && LA224_0 <= KW_INDEXES)||(LA224_0 >= KW_INPATH && LA224_0 <= KW_INPUTFORMAT)||(LA224_0 >= KW_ISOLATION && LA224_0 <= KW_JAR)||(LA224_0 >= KW_JOINCOST && LA224_0 <= KW_LAST)||LA224_0==KW_LEVEL||(LA224_0 >= KW_LIMIT && LA224_0 <= KW_LOAD)||(LA224_0 >= KW_LOCATION && LA224_0 <= KW_LONG)||LA224_0==KW_MANAGEMENT||(LA224_0 >= KW_MAPJOIN && LA224_0 <= KW_MATERIALIZED)||LA224_0==KW_METADATA||(LA224_0 >= KW_MINUTE && LA224_0 <= KW_MONTH)||(LA224_0 >= KW_MOVE && LA224_0 <= KW_MSCK)||(LA224_0 >= KW_NORELY && LA224_0 <= KW_NOSCAN)||LA224_0==KW_NOVALIDATE||LA224_0==KW_NULLS||LA224_0==KW_OFFSET||(LA224_0 >= KW_OPERATOR && LA224_0 <= KW_OPTION)||(LA224_0 >= KW_OUTPUTDRIVER && LA224_0 <= KW_OUTPUTFORMAT)||(LA224_0 >= KW_OVERWRITE && LA224_0 <= KW_OWNER)||(LA224_0 >= KW_PARTITIONED && LA224_0 <= KW_PATH)||(LA224_0 >= KW_PLAN && LA224_0 <= KW_POOL)||LA224_0==KW_PRINCIPALS||(LA224_0 >= KW_PURGE && LA224_0 <= KW_QUERY_PARALLELISM)||LA224_0==KW_READ||(LA224_0 >= KW_REBUILD && LA224_0 <= KW_RECORDWRITER)||(LA224_0 >= KW_RELOAD && LA224_0 <= KW_RESTRICT)||LA224_0==KW_REWRITE||(LA224_0 >= KW_ROLE && LA224_0 <= KW_ROLES)||(LA224_0 >= KW_SCHEDULING_POLICY && LA224_0 <= KW_SECOND)||(LA224_0 >= KW_SEMI && LA224_0 <= KW_SERVER)||(LA224_0 >= KW_SETS && LA224_0 <= KW_SKEWED)||(LA224_0 >= KW_SNAPSHOT && LA224_0 <= KW_SSL)||(LA224_0 >= KW_STATISTICS && LA224_0 <= KW_SUMMARY)||LA224_0==KW_TABLES||(LA224_0 >= KW_TBLPROPERTIES && LA224_0 <= KW_TERMINATED)||LA224_0==KW_TINYINT||(LA224_0 >= KW_TOUCH && LA224_0 <= KW_TRANSACTIONS)||LA224_0==KW_UNARCHIVE||LA224_0==KW_UNDO||LA224_0==KW_UNIONTYPE||(LA224_0 >= KW_UNLOCK && LA224_0 <= KW_UNSIGNED)||(LA224_0 >= KW_URI && LA224_0 <= KW_USE)||(LA224_0 >= KW_UTC && LA224_0 <= KW_VALIDATE)||LA224_0==KW_VALUE_TYPE||(LA224_0 >= KW_VECTORIZATION && LA224_0 <= KW_WEEK)||LA224_0==KW_WHILE||(LA224_0 >= KW_WORK && LA224_0 <= KW_ZONE)||LA224_0==KW_BATCH||LA224_0==KW_DAYOFWEEK||LA224_0==KW_HOLD_DDLTIME||LA224_0==KW_IGNORE||LA224_0==KW_NO_DROP||LA224_0==KW_OFFLINE||LA224_0==KW_PROTECTION||LA224_0==KW_READONLY||LA224_0==KW_TIMESTAMPTZ) ) {
				alt224=1;
			}
			else if ( (LA224_0==StringLiteral) ) {
				alt224=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 224, 0, input);
				throw nvae;
			}

			switch (alt224) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2049:7: functionIdentifier
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_functionIdentifier_in_showFunctionIdentifier11894);
					functionIdentifier735=functionIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, functionIdentifier735.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2050:7: StringLiteral
					{
					root_0 = (ASTNode)adaptor.nil();


					StringLiteral736=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showFunctionIdentifier11902); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					StringLiteral736_tree = (ASTNode)adaptor.create(StringLiteral736);
					adaptor.addChild(root_0, StringLiteral736_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showFunctionIdentifier"


	public static class showStmtIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showStmtIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2053:1: showStmtIdentifier : ( identifier | StringLiteral );
	public final HiveParser.showStmtIdentifier_return showStmtIdentifier() throws RecognitionException {
		HiveParser.showStmtIdentifier_return retval = new HiveParser.showStmtIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token StringLiteral738=null;
		ParserRuleReturnScope identifier737 =null;

		ASTNode StringLiteral738_tree=null;

		 pushMsg("identifier for show statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2056:5: ( identifier | StringLiteral )
			int alt225=2;
			int LA225_0 = input.LA(1);
			if ( (LA225_0==Identifier||(LA225_0 >= KW_ABORT && LA225_0 <= KW_AFTER)||LA225_0==KW_ALLOC_FRACTION||LA225_0==KW_ANALYZE||LA225_0==KW_ARCHIVE||LA225_0==KW_ASC||(LA225_0 >= KW_AUTOCOMMIT && LA225_0 <= KW_BEFORE)||(LA225_0 >= KW_BUCKET && LA225_0 <= KW_BUCKETS)||(LA225_0 >= KW_CACHE && LA225_0 <= KW_CASCADE)||(LA225_0 >= KW_CBO && LA225_0 <= KW_CHANGE)||(LA225_0 >= KW_CHECK && LA225_0 <= KW_COLLECTION)||(LA225_0 >= KW_COLUMNS && LA225_0 <= KW_COMMENT)||(LA225_0 >= KW_COMPACT && LA225_0 <= KW_CONCATENATE)||(LA225_0 >= KW_CONTINUE && LA225_0 <= KW_COST)||LA225_0==KW_DATA||LA225_0==KW_DATABASES||(LA225_0 >= KW_DATETIME && LA225_0 <= KW_DEBUG)||(LA225_0 >= KW_DEFAULT && LA225_0 <= KW_DEFINED)||(LA225_0 >= KW_DELIMITED && LA225_0 <= KW_DESC)||(LA225_0 >= KW_DETAIL && LA225_0 <= KW_DISABLE)||(LA225_0 >= KW_DISTRIBUTE && LA225_0 <= KW_DO)||LA225_0==KW_DOW||(LA225_0 >= KW_DUMP && LA225_0 <= KW_ELEM_TYPE)||LA225_0==KW_ENABLE||(LA225_0 >= KW_ENFORCED && LA225_0 <= KW_ESCAPED)||LA225_0==KW_EXCLUSIVE||(LA225_0 >= KW_EXPLAIN && LA225_0 <= KW_EXPRESSION)||(LA225_0 >= KW_FIELDS && LA225_0 <= KW_FIRST)||(LA225_0 >= KW_FORMAT && LA225_0 <= KW_FORMATTED)||LA225_0==KW_FUNCTIONS||(LA225_0 >= KW_HOUR && LA225_0 <= KW_IDXPROPERTIES)||(LA225_0 >= KW_INDEX && LA225_0 <= KW_INDEXES)||(LA225_0 >= KW_INPATH && LA225_0 <= KW_INPUTFORMAT)||(LA225_0 >= KW_ISOLATION && LA225_0 <= KW_JAR)||(LA225_0 >= KW_JOINCOST && LA225_0 <= KW_LAST)||LA225_0==KW_LEVEL||(LA225_0 >= KW_LIMIT && LA225_0 <= KW_LOAD)||(LA225_0 >= KW_LOCATION && LA225_0 <= KW_LONG)||LA225_0==KW_MANAGEMENT||(LA225_0 >= KW_MAPJOIN && LA225_0 <= KW_MATERIALIZED)||LA225_0==KW_METADATA||(LA225_0 >= KW_MINUTE && LA225_0 <= KW_MONTH)||(LA225_0 >= KW_MOVE && LA225_0 <= KW_MSCK)||(LA225_0 >= KW_NORELY && LA225_0 <= KW_NOSCAN)||LA225_0==KW_NOVALIDATE||LA225_0==KW_NULLS||LA225_0==KW_OFFSET||(LA225_0 >= KW_OPERATOR && LA225_0 <= KW_OPTION)||(LA225_0 >= KW_OUTPUTDRIVER && LA225_0 <= KW_OUTPUTFORMAT)||(LA225_0 >= KW_OVERWRITE && LA225_0 <= KW_OWNER)||(LA225_0 >= KW_PARTITIONED && LA225_0 <= KW_PATH)||(LA225_0 >= KW_PLAN && LA225_0 <= KW_POOL)||LA225_0==KW_PRINCIPALS||(LA225_0 >= KW_PURGE && LA225_0 <= KW_QUERY_PARALLELISM)||LA225_0==KW_READ||(LA225_0 >= KW_REBUILD && LA225_0 <= KW_RECORDWRITER)||(LA225_0 >= KW_RELOAD && LA225_0 <= KW_RESTRICT)||LA225_0==KW_REWRITE||(LA225_0 >= KW_ROLE && LA225_0 <= KW_ROLES)||(LA225_0 >= KW_SCHEDULING_POLICY && LA225_0 <= KW_SECOND)||(LA225_0 >= KW_SEMI && LA225_0 <= KW_SERVER)||(LA225_0 >= KW_SETS && LA225_0 <= KW_SKEWED)||(LA225_0 >= KW_SNAPSHOT && LA225_0 <= KW_SSL)||(LA225_0 >= KW_STATISTICS && LA225_0 <= KW_SUMMARY)||LA225_0==KW_TABLES||(LA225_0 >= KW_TBLPROPERTIES && LA225_0 <= KW_TERMINATED)||LA225_0==KW_TINYINT||(LA225_0 >= KW_TOUCH && LA225_0 <= KW_TRANSACTIONS)||LA225_0==KW_UNARCHIVE||LA225_0==KW_UNDO||LA225_0==KW_UNIONTYPE||(LA225_0 >= KW_UNLOCK && LA225_0 <= KW_UNSIGNED)||(LA225_0 >= KW_URI && LA225_0 <= KW_USE)||(LA225_0 >= KW_UTC && LA225_0 <= KW_VALIDATE)||LA225_0==KW_VALUE_TYPE||(LA225_0 >= KW_VECTORIZATION && LA225_0 <= KW_WEEK)||LA225_0==KW_WHILE||(LA225_0 >= KW_WORK && LA225_0 <= KW_ZONE)||LA225_0==KW_BATCH||LA225_0==KW_DAYOFWEEK||LA225_0==KW_HOLD_DDLTIME||LA225_0==KW_IGNORE||LA225_0==KW_NO_DROP||LA225_0==KW_OFFLINE||LA225_0==KW_PROTECTION||LA225_0==KW_READONLY||LA225_0==KW_TIMESTAMPTZ) ) {
				alt225=1;
			}
			else if ( (LA225_0==StringLiteral) ) {
				alt225=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 225, 0, input);
				throw nvae;
			}

			switch (alt225) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2056:7: identifier
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_identifier_in_showStmtIdentifier11929);
					identifier737=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier737.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2057:7: StringLiteral
					{
					root_0 = (ASTNode)adaptor.nil();


					StringLiteral738=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStmtIdentifier11937); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					StringLiteral738_tree = (ASTNode)adaptor.create(StringLiteral738);
					adaptor.addChild(root_0, StringLiteral738_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showStmtIdentifier"


	public static class tableComment_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableComment"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2060:1: tableComment : KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) ;
	public final HiveParser.tableComment_return tableComment() throws RecognitionException {
		HiveParser.tableComment_return retval = new HiveParser.tableComment_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT739=null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT739_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

		 pushMsg("table's comment", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2064:7: KW_COMMENT comment= StringLiteral
			{
			KW_COMMENT739=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_tableComment11970); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT739);

			comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableComment11974); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

			// AST REWRITE
			// elements: comment
			// token labels: comment
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2064:41: -> ^( TOK_TABLECOMMENT $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2064:44: ^( TOK_TABLECOMMENT $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLECOMMENT, "TOK_TABLECOMMENT"), root_1);
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableComment"


	public static class createTablePartitionSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTablePartitionSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2067:1: createTablePartitionSpec : KW_PARTITIONED KW_BY LPAREN (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec ) RPAREN -> {$opt1.tree != null}? $opt1 -> $opt2;
	public final HiveParser.createTablePartitionSpec_return createTablePartitionSpec() throws RecognitionException {
		HiveParser.createTablePartitionSpec_return retval = new HiveParser.createTablePartitionSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PARTITIONED740=null;
		Token KW_BY741=null;
		Token LPAREN742=null;
		Token RPAREN743=null;
		ParserRuleReturnScope opt1 =null;
		ParserRuleReturnScope opt2 =null;

		ASTNode KW_PARTITIONED740_tree=null;
		ASTNode KW_BY741_tree=null;
		ASTNode LPAREN742_tree=null;
		ASTNode RPAREN743_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_KW_PARTITIONED=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONED");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_createTablePartitionColumnSpec=new RewriteRuleSubtreeStream(adaptor,"rule createTablePartitionColumnSpec");
		RewriteRuleSubtreeStream stream_createTablePartitionColumnTypeSpec=new RewriteRuleSubtreeStream(adaptor,"rule createTablePartitionColumnTypeSpec");

		 pushMsg("create table partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2070:5: ( KW_PARTITIONED KW_BY LPAREN (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec ) RPAREN -> {$opt1.tree != null}? $opt1 -> $opt2)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2070:7: KW_PARTITIONED KW_BY LPAREN (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec ) RPAREN
			{
			KW_PARTITIONED740=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_createTablePartitionSpec12011); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_PARTITIONED.add(KW_PARTITIONED740);

			KW_BY741=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_createTablePartitionSpec12013); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY741);

			LPAREN742=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createTablePartitionSpec12015); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN742);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2070:35: (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec )
			int alt226=2;
			int LA226_0 = input.LA(1);
			if ( (LA226_0==Identifier) ) {
				int LA226_1 = input.LA(2);
				if ( (LA226_1==KW_ARRAY||(LA226_1 >= KW_BIGINT && LA226_1 <= KW_BOOLEAN)||LA226_1==KW_CHAR||(LA226_1 >= KW_DATE && LA226_1 <= KW_DATETIME)||LA226_1==KW_DECIMAL||LA226_1==KW_DOUBLE||LA226_1==KW_FLOAT||LA226_1==KW_INT||LA226_1==KW_MAP||LA226_1==KW_SMALLINT||(LA226_1 >= KW_STRING && LA226_1 <= KW_STRUCT)||(LA226_1 >= KW_TIMESTAMP && LA226_1 <= KW_TINYINT)||LA226_1==KW_UNIONTYPE||LA226_1==KW_VARCHAR) ) {
					alt226=1;
				}
				else if ( (LA226_1==COMMA||LA226_1==RPAREN) ) {
					alt226=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 226, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( ((LA226_0 >= KW_ABORT && LA226_0 <= KW_AFTER)||LA226_0==KW_ALLOC_FRACTION||LA226_0==KW_ANALYZE||LA226_0==KW_ARCHIVE||LA226_0==KW_ASC||(LA226_0 >= KW_AUTOCOMMIT && LA226_0 <= KW_BEFORE)||(LA226_0 >= KW_BUCKET && LA226_0 <= KW_BUCKETS)||(LA226_0 >= KW_CACHE && LA226_0 <= KW_CASCADE)||(LA226_0 >= KW_CBO && LA226_0 <= KW_CHANGE)||(LA226_0 >= KW_CHECK && LA226_0 <= KW_COLLECTION)||(LA226_0 >= KW_COLUMNS && LA226_0 <= KW_COMMENT)||(LA226_0 >= KW_COMPACT && LA226_0 <= KW_CONCATENATE)||(LA226_0 >= KW_CONTINUE && LA226_0 <= KW_COST)||LA226_0==KW_DATA||LA226_0==KW_DATABASES||(LA226_0 >= KW_DATETIME && LA226_0 <= KW_DEBUG)||(LA226_0 >= KW_DEFAULT && LA226_0 <= KW_DEFINED)||(LA226_0 >= KW_DELIMITED && LA226_0 <= KW_DESC)||(LA226_0 >= KW_DETAIL && LA226_0 <= KW_DISABLE)||(LA226_0 >= KW_DISTRIBUTE && LA226_0 <= KW_DO)||LA226_0==KW_DOW||(LA226_0 >= KW_DUMP && LA226_0 <= KW_ELEM_TYPE)||LA226_0==KW_ENABLE||(LA226_0 >= KW_ENFORCED && LA226_0 <= KW_ESCAPED)||LA226_0==KW_EXCLUSIVE||(LA226_0 >= KW_EXPLAIN && LA226_0 <= KW_EXPRESSION)||(LA226_0 >= KW_FIELDS && LA226_0 <= KW_FIRST)||(LA226_0 >= KW_FORMAT && LA226_0 <= KW_FORMATTED)||LA226_0==KW_FUNCTIONS||(LA226_0 >= KW_HOUR && LA226_0 <= KW_IDXPROPERTIES)||(LA226_0 >= KW_INDEX && LA226_0 <= KW_INDEXES)||(LA226_0 >= KW_INPATH && LA226_0 <= KW_INPUTFORMAT)||(LA226_0 >= KW_ISOLATION && LA226_0 <= KW_JAR)||(LA226_0 >= KW_JOINCOST && LA226_0 <= KW_LAST)||LA226_0==KW_LEVEL||(LA226_0 >= KW_LIMIT && LA226_0 <= KW_LOAD)||(LA226_0 >= KW_LOCATION && LA226_0 <= KW_LONG)||LA226_0==KW_MANAGEMENT||(LA226_0 >= KW_MAPJOIN && LA226_0 <= KW_MATERIALIZED)||LA226_0==KW_METADATA||(LA226_0 >= KW_MINUTE && LA226_0 <= KW_MONTH)||(LA226_0 >= KW_MOVE && LA226_0 <= KW_MSCK)||(LA226_0 >= KW_NORELY && LA226_0 <= KW_NOSCAN)||LA226_0==KW_NOVALIDATE||LA226_0==KW_NULLS||LA226_0==KW_OFFSET||(LA226_0 >= KW_OPERATOR && LA226_0 <= KW_OPTION)||(LA226_0 >= KW_OUTPUTDRIVER && LA226_0 <= KW_OUTPUTFORMAT)||(LA226_0 >= KW_OVERWRITE && LA226_0 <= KW_OWNER)||(LA226_0 >= KW_PARTITIONED && LA226_0 <= KW_PATH)||(LA226_0 >= KW_PLAN && LA226_0 <= KW_POOL)||LA226_0==KW_PRINCIPALS||(LA226_0 >= KW_PURGE && LA226_0 <= KW_QUERY_PARALLELISM)||LA226_0==KW_READ||(LA226_0 >= KW_REBUILD && LA226_0 <= KW_RECORDWRITER)||(LA226_0 >= KW_RELOAD && LA226_0 <= KW_RESTRICT)||LA226_0==KW_REWRITE||(LA226_0 >= KW_ROLE && LA226_0 <= KW_ROLES)||(LA226_0 >= KW_SCHEDULING_POLICY && LA226_0 <= KW_SECOND)||(LA226_0 >= KW_SEMI && LA226_0 <= KW_SERVER)||(LA226_0 >= KW_SETS && LA226_0 <= KW_SKEWED)||(LA226_0 >= KW_SNAPSHOT && LA226_0 <= KW_SSL)||(LA226_0 >= KW_STATISTICS && LA226_0 <= KW_SUMMARY)||LA226_0==KW_TABLES||(LA226_0 >= KW_TBLPROPERTIES && LA226_0 <= KW_TERMINATED)||LA226_0==KW_TINYINT||(LA226_0 >= KW_TOUCH && LA226_0 <= KW_TRANSACTIONS)||LA226_0==KW_UNARCHIVE||LA226_0==KW_UNDO||LA226_0==KW_UNIONTYPE||(LA226_0 >= KW_UNLOCK && LA226_0 <= KW_UNSIGNED)||(LA226_0 >= KW_URI && LA226_0 <= KW_USE)||(LA226_0 >= KW_UTC && LA226_0 <= KW_VALIDATE)||LA226_0==KW_VALUE_TYPE||(LA226_0 >= KW_VECTORIZATION && LA226_0 <= KW_WEEK)||LA226_0==KW_WHILE||(LA226_0 >= KW_WORK && LA226_0 <= KW_ZONE)||LA226_0==KW_BATCH||LA226_0==KW_DAYOFWEEK||LA226_0==KW_HOLD_DDLTIME||LA226_0==KW_IGNORE||LA226_0==KW_NO_DROP||LA226_0==KW_OFFLINE||LA226_0==KW_PROTECTION||LA226_0==KW_READONLY||LA226_0==KW_TIMESTAMPTZ) ) {
				int LA226_2 = input.LA(2);
				if ( (LA226_2==KW_ARRAY||(LA226_2 >= KW_BIGINT && LA226_2 <= KW_BOOLEAN)||LA226_2==KW_CHAR||(LA226_2 >= KW_DATE && LA226_2 <= KW_DATETIME)||LA226_2==KW_DECIMAL||LA226_2==KW_DOUBLE||LA226_2==KW_FLOAT||LA226_2==KW_INT||LA226_2==KW_MAP||LA226_2==KW_SMALLINT||(LA226_2 >= KW_STRING && LA226_2 <= KW_STRUCT)||(LA226_2 >= KW_TIMESTAMP && LA226_2 <= KW_TINYINT)||LA226_2==KW_UNIONTYPE||LA226_2==KW_VARCHAR) ) {
					alt226=1;
				}
				else if ( (LA226_2==COMMA||LA226_2==RPAREN) ) {
					alt226=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 226, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 226, 0, input);
				throw nvae;
			}

			switch (alt226) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2070:36: opt1= createTablePartitionColumnTypeSpec
					{
					pushFollow(FOLLOW_createTablePartitionColumnTypeSpec_in_createTablePartitionSpec12022);
					opt1=createTablePartitionColumnTypeSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_createTablePartitionColumnTypeSpec.add(opt1.getTree());
					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2070:80: opt2= createTablePartitionColumnSpec
					{
					pushFollow(FOLLOW_createTablePartitionColumnSpec_in_createTablePartitionSpec12030);
					opt2=createTablePartitionColumnSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_createTablePartitionColumnSpec.add(opt2.getTree());
					}
					break;

			}

			RPAREN743=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createTablePartitionSpec12033); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN743);

			// AST REWRITE
			// elements: opt2, opt1
			// token labels: 
			// rule labels: opt1, opt2, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_opt1=new RewriteRuleSubtreeStream(adaptor,"rule opt1",opt1!=null?opt1.getTree():null);
			RewriteRuleSubtreeStream stream_opt2=new RewriteRuleSubtreeStream(adaptor,"rule opt2",opt2!=null?opt2.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2071:5: -> {$opt1.tree != null}? $opt1
			if ((opt1!=null?((ASTNode)opt1.getTree()):null) != null) {
				adaptor.addChild(root_0, stream_opt1.nextTree());
			}

			else // 2072:5: -> $opt2
			{
				adaptor.addChild(root_0, stream_opt2.nextTree());
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTablePartitionSpec"


	public static class createTablePartitionColumnTypeSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTablePartitionColumnTypeSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2075:1: createTablePartitionColumnTypeSpec : columnNameTypeConstraint ( COMMA columnNameTypeConstraint )* -> ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ ) ;
	public final HiveParser.createTablePartitionColumnTypeSpec_return createTablePartitionColumnTypeSpec() throws RecognitionException {
		HiveParser.createTablePartitionColumnTypeSpec_return retval = new HiveParser.createTablePartitionColumnTypeSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA745=null;
		ParserRuleReturnScope columnNameTypeConstraint744 =null;
		ParserRuleReturnScope columnNameTypeConstraint746 =null;

		ASTNode COMMA745_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameTypeConstraint=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeConstraint");

		 pushMsg("create table partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:5: ( columnNameTypeConstraint ( COMMA columnNameTypeConstraint )* -> ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:7: columnNameTypeConstraint ( COMMA columnNameTypeConstraint )*
			{
			pushFollow(FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec12080);
			columnNameTypeConstraint744=columnNameTypeConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameTypeConstraint.add(columnNameTypeConstraint744.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:32: ( COMMA columnNameTypeConstraint )*
			loop227:
			while (true) {
				int alt227=2;
				int LA227_0 = input.LA(1);
				if ( (LA227_0==COMMA) ) {
					alt227=1;
				}

				switch (alt227) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:33: COMMA columnNameTypeConstraint
					{
					COMMA745=(Token)match(input,COMMA,FOLLOW_COMMA_in_createTablePartitionColumnTypeSpec12083); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA745);

					pushFollow(FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec12085);
					columnNameTypeConstraint746=columnNameTypeConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameTypeConstraint.add(columnNameTypeConstraint746.getTree());
					}
					break;

				default :
					break loop227;
				}
			}

			// AST REWRITE
			// elements: columnNameTypeConstraint
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2079:5: -> ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2079:8: ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPARTCOLS, "TOK_TABLEPARTCOLS"), root_1);
				if ( !(stream_columnNameTypeConstraint.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameTypeConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeConstraint.nextTree());
				}
				stream_columnNameTypeConstraint.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTablePartitionColumnTypeSpec"


	public static class createTablePartitionColumnSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTablePartitionColumnSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2082:1: createTablePartitionColumnSpec : columnName ( COMMA columnName )* -> ^( TOK_TABLEPARTCOLNAMES ( columnName )+ ) ;
	public final HiveParser.createTablePartitionColumnSpec_return createTablePartitionColumnSpec() throws RecognitionException {
		HiveParser.createTablePartitionColumnSpec_return retval = new HiveParser.createTablePartitionColumnSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA748=null;
		ParserRuleReturnScope columnName747 =null;
		ParserRuleReturnScope columnName749 =null;

		ASTNode COMMA748_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("create table partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:5: ( columnName ( COMMA columnName )* -> ^( TOK_TABLEPARTCOLNAMES ( columnName )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:7: columnName ( COMMA columnName )*
			{
			pushFollow(FOLLOW_columnName_in_createTablePartitionColumnSpec12127);
			columnName747=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(columnName747.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:18: ( COMMA columnName )*
			loop228:
			while (true) {
				int alt228=2;
				int LA228_0 = input.LA(1);
				if ( (LA228_0==COMMA) ) {
					alt228=1;
				}

				switch (alt228) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:19: COMMA columnName
					{
					COMMA748=(Token)match(input,COMMA,FOLLOW_COMMA_in_createTablePartitionColumnSpec12130); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA748);

					pushFollow(FOLLOW_columnName_in_createTablePartitionColumnSpec12132);
					columnName749=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName749.getTree());
					}
					break;

				default :
					break loop228;
				}
			}

			// AST REWRITE
			// elements: columnName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2086:5: -> ^( TOK_TABLEPARTCOLNAMES ( columnName )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2086:8: ^( TOK_TABLEPARTCOLNAMES ( columnName )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPARTCOLNAMES, "TOK_TABLEPARTCOLNAMES"), root_1);
				if ( !(stream_columnName.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnName.hasNext() ) {
					adaptor.addChild(root_1, stream_columnName.nextTree());
				}
				stream_columnName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTablePartitionColumnSpec"


	public static class tableBuckets_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableBuckets"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2089:1: tableBuckets : KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) ;
	public final HiveParser.tableBuckets_return tableBuckets() throws RecognitionException {
		HiveParser.tableBuckets_return retval = new HiveParser.tableBuckets_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token num=null;
		Token KW_CLUSTERED750=null;
		Token KW_BY751=null;
		Token LPAREN752=null;
		Token RPAREN753=null;
		Token KW_SORTED754=null;
		Token KW_BY755=null;
		Token LPAREN756=null;
		Token RPAREN757=null;
		Token KW_INTO758=null;
		Token KW_BUCKETS759=null;
		ParserRuleReturnScope bucketCols =null;
		ParserRuleReturnScope sortCols =null;

		ASTNode num_tree=null;
		ASTNode KW_CLUSTERED750_tree=null;
		ASTNode KW_BY751_tree=null;
		ASTNode LPAREN752_tree=null;
		ASTNode RPAREN753_tree=null;
		ASTNode KW_SORTED754_tree=null;
		ASTNode KW_BY755_tree=null;
		ASTNode LPAREN756_tree=null;
		ASTNode RPAREN757_tree=null;
		ASTNode KW_INTO758_tree=null;
		ASTNode KW_BUCKETS759_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_BUCKETS=new RewriteRuleTokenStream(adaptor,"token KW_BUCKETS");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
		RewriteRuleSubtreeStream stream_columnNameOrderList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameOrderList");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("table buckets specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2092:5: ( KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2093:7: KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS
			{
			KW_CLUSTERED750=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_tableBuckets12180); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CLUSTERED.add(KW_CLUSTERED750);

			KW_BY751=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableBuckets12182); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY751);

			LPAREN752=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableBuckets12184); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN752);

			pushFollow(FOLLOW_columnNameList_in_tableBuckets12188);
			bucketCols=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(bucketCols.getTree());
			RPAREN753=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableBuckets12190); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN753);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2093:66: ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )?
			int alt229=2;
			int LA229_0 = input.LA(1);
			if ( (LA229_0==KW_SORTED) ) {
				alt229=1;
			}
			switch (alt229) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2093:67: KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN
					{
					KW_SORTED754=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_tableBuckets12193); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED754);

					KW_BY755=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableBuckets12195); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY755);

					LPAREN756=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableBuckets12197); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN756);

					pushFollow(FOLLOW_columnNameOrderList_in_tableBuckets12201);
					sortCols=columnNameOrderList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameOrderList.add(sortCols.getTree());
					RPAREN757=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableBuckets12203); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN757);

					}
					break;

			}

			KW_INTO758=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_tableBuckets12207); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO758);

			num=(Token)match(input,Number,FOLLOW_Number_in_tableBuckets12211); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Number.add(num);

			KW_BUCKETS759=(Token)match(input,KW_BUCKETS,FOLLOW_KW_BUCKETS_in_tableBuckets12213); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BUCKETS.add(KW_BUCKETS759);

			// AST REWRITE
			// elements: bucketCols, sortCols, num
			// token labels: num
			// rule labels: bucketCols, sortCols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
			RewriteRuleSubtreeStream stream_bucketCols=new RewriteRuleSubtreeStream(adaptor,"rule bucketCols",bucketCols!=null?bucketCols.getTree():null);
			RewriteRuleSubtreeStream stream_sortCols=new RewriteRuleSubtreeStream(adaptor,"rule sortCols",sortCols!=null?sortCols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2094:5: -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2094:8: ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS"), root_1);
				adaptor.addChild(root_1, stream_bucketCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2094:46: ( $sortCols)?
				if ( stream_sortCols.hasNext() ) {
					adaptor.addChild(root_1, stream_sortCols.nextTree());
				}
				stream_sortCols.reset();

				adaptor.addChild(root_1, stream_num.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableBuckets"


	public static class tableSkewed_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableSkewed"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2097:1: tableSkewed : KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) ;
	public final HiveParser.tableSkewed_return tableSkewed() throws RecognitionException {
		HiveParser.tableSkewed_return retval = new HiveParser.tableSkewed_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SKEWED760=null;
		Token KW_BY761=null;
		Token LPAREN762=null;
		Token RPAREN763=null;
		Token KW_ON764=null;
		Token LPAREN765=null;
		Token RPAREN766=null;
		ParserRuleReturnScope skewedCols =null;
		ParserRuleReturnScope skewedValues =null;
		ParserRuleReturnScope storedAsDirs767 =null;

		ASTNode KW_SKEWED760_tree=null;
		ASTNode KW_BY761_tree=null;
		ASTNode LPAREN762_tree=null;
		ASTNode RPAREN763_tree=null;
		ASTNode KW_ON764_tree=null;
		ASTNode LPAREN765_tree=null;
		ASTNode RPAREN766_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleSubtreeStream stream_skewedValueElement=new RewriteRuleSubtreeStream(adaptor,"rule skewedValueElement");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
		RewriteRuleSubtreeStream stream_storedAsDirs=new RewriteRuleSubtreeStream(adaptor,"rule storedAsDirs");

		 pushMsg("table skewed specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2100:5: ( KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:6: KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )?
			{
			KW_SKEWED760=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_tableSkewed12265); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SKEWED.add(KW_SKEWED760);

			KW_BY761=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableSkewed12267); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY761);

			LPAREN762=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableSkewed12269); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN762);

			pushFollow(FOLLOW_columnNameList_in_tableSkewed12273);
			skewedCols=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(skewedCols.getTree());
			RPAREN763=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableSkewed12275); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN763);

			KW_ON764=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_tableSkewed12277); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON764);

			LPAREN765=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableSkewed12279); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN765);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:75: (skewedValues= skewedValueElement )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:76: skewedValues= skewedValueElement
			{
			pushFollow(FOLLOW_skewedValueElement_in_tableSkewed12284);
			skewedValues=skewedValueElement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedValueElement.add(skewedValues.getTree());
			}

			RPAREN766=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableSkewed12287); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN766);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:116: ( ( storedAsDirs )=> storedAsDirs )?
			int alt230=2;
			int LA230_0 = input.LA(1);
			if ( (LA230_0==KW_STORED) ) {
				int LA230_1 = input.LA(2);
				if ( (LA230_1==KW_AS) ) {
					int LA230_7 = input.LA(3);
					if ( (LA230_7==KW_DIRECTORIES) ) {
						int LA230_9 = input.LA(4);
						if ( (synpred17_HiveParser()) ) {
							alt230=1;
						}
					}
				}
			}
			switch (alt230) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:117: ( storedAsDirs )=> storedAsDirs
					{
					pushFollow(FOLLOW_storedAsDirs_in_tableSkewed12296);
					storedAsDirs767=storedAsDirs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_storedAsDirs.add(storedAsDirs767.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: skewedCols, storedAsDirs, skewedValues
			// token labels: 
			// rule labels: skewedCols, skewedValues, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_skewedCols=new RewriteRuleSubtreeStream(adaptor,"rule skewedCols",skewedCols!=null?skewedCols.getTree():null);
			RewriteRuleSubtreeStream stream_skewedValues=new RewriteRuleSubtreeStream(adaptor,"rule skewedValues",skewedValues!=null?skewedValues.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2102:5: -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2102:8: ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLESKEWED, "TOK_TABLESKEWED"), root_1);
				adaptor.addChild(root_1, stream_skewedCols.nextTree());
				adaptor.addChild(root_1, stream_skewedValues.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2102:52: ( storedAsDirs )?
				if ( stream_storedAsDirs.hasNext() ) {
					adaptor.addChild(root_1, stream_storedAsDirs.nextTree());
				}
				stream_storedAsDirs.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableSkewed"


	public static class rowFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rowFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2105:1: rowFormat : ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) );
	public final HiveParser.rowFormat_return rowFormat() throws RecognitionException {
		HiveParser.rowFormat_return retval = new HiveParser.rowFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope rowFormatSerde768 =null;
		ParserRuleReturnScope rowFormatDelimited769 =null;

		RewriteRuleSubtreeStream stream_rowFormatSerde=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatSerde");
		RewriteRuleSubtreeStream stream_rowFormatDelimited=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatDelimited");

		 pushMsg("serde specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2108:5: ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) )
			int alt231=3;
			int LA231_0 = input.LA(1);
			if ( (LA231_0==KW_ROW) ) {
				int LA231_1 = input.LA(2);
				if ( (LA231_1==KW_FORMAT) ) {
					int LA231_27 = input.LA(3);
					if ( (LA231_27==KW_SERDE) ) {
						alt231=1;
					}
					else if ( (LA231_27==KW_DELIMITED) ) {
						alt231=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 231, 27, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 231, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( (LA231_0==EOF||LA231_0==COMMA||LA231_0==KW_CLUSTER||LA231_0==KW_DISTRIBUTE||LA231_0==KW_EXCEPT||LA231_0==KW_FROM||LA231_0==KW_GROUP||LA231_0==KW_HAVING||LA231_0==KW_INSERT||LA231_0==KW_INTERSECT||LA231_0==KW_LATERAL||LA231_0==KW_LIMIT||LA231_0==KW_MAP||LA231_0==KW_MINUS||LA231_0==KW_ORDER||(LA231_0 >= KW_RECORDREADER && LA231_0 <= KW_REDUCE)||LA231_0==KW_SELECT||LA231_0==KW_SORT||LA231_0==KW_UNION||LA231_0==KW_USING||LA231_0==KW_WHERE||LA231_0==KW_WINDOW||LA231_0==RPAREN) ) {
				alt231=3;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 231, 0, input);
				throw nvae;
			}

			switch (alt231) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2108:7: rowFormatSerde
					{
					pushFollow(FOLLOW_rowFormatSerde_in_rowFormat12344);
					rowFormatSerde768=rowFormatSerde();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatSerde.add(rowFormatSerde768.getTree());
					// AST REWRITE
					// elements: rowFormatSerde
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2108:22: -> ^( TOK_SERDE rowFormatSerde )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2108:25: ^( TOK_SERDE rowFormatSerde )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);
						adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2109:7: rowFormatDelimited
					{
					pushFollow(FOLLOW_rowFormatDelimited_in_rowFormat12360);
					rowFormatDelimited769=rowFormatDelimited();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatDelimited.add(rowFormatDelimited769.getTree());
					// AST REWRITE
					// elements: rowFormatDelimited
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2109:26: -> ^( TOK_SERDE rowFormatDelimited )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2109:29: ^( TOK_SERDE rowFormatDelimited )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);
						adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2110:9: 
					{
					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2110:9: -> ^( TOK_SERDE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2110:12: ^( TOK_SERDE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rowFormat"


	public static class recordReader_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "recordReader"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2113:1: recordReader : ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) );
	public final HiveParser.recordReader_return recordReader() throws RecognitionException {
		HiveParser.recordReader_return retval = new HiveParser.recordReader_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RECORDREADER770=null;
		Token StringLiteral771=null;

		ASTNode KW_RECORDREADER770_tree=null;
		ASTNode StringLiteral771_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_RECORDREADER=new RewriteRuleTokenStream(adaptor,"token KW_RECORDREADER");

		 pushMsg("record reader specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2116:5: ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) )
			int alt232=2;
			int LA232_0 = input.LA(1);
			if ( (LA232_0==KW_RECORDREADER) ) {
				alt232=1;
			}
			else if ( (LA232_0==EOF||LA232_0==COMMA||LA232_0==KW_CLUSTER||LA232_0==KW_DISTRIBUTE||LA232_0==KW_EXCEPT||LA232_0==KW_FROM||LA232_0==KW_GROUP||LA232_0==KW_HAVING||LA232_0==KW_INSERT||LA232_0==KW_INTERSECT||LA232_0==KW_LATERAL||LA232_0==KW_LIMIT||LA232_0==KW_MAP||LA232_0==KW_MINUS||LA232_0==KW_ORDER||LA232_0==KW_REDUCE||LA232_0==KW_SELECT||LA232_0==KW_SORT||LA232_0==KW_UNION||LA232_0==KW_WHERE||LA232_0==KW_WINDOW||LA232_0==RPAREN) ) {
				alt232=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 232, 0, input);
				throw nvae;
			}

			switch (alt232) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2116:7: KW_RECORDREADER StringLiteral
					{
					KW_RECORDREADER770=(Token)match(input,KW_RECORDREADER,FOLLOW_KW_RECORDREADER_in_recordReader12409); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RECORDREADER.add(KW_RECORDREADER770);

					StringLiteral771=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_recordReader12411); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral771);

					// AST REWRITE
					// elements: StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2116:37: -> ^( TOK_RECORDREADER StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2116:40: ^( TOK_RECORDREADER StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:9: 
					{
					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2117:9: -> ^( TOK_RECORDREADER )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:12: ^( TOK_RECORDREADER )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "recordReader"


	public static class recordWriter_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "recordWriter"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2120:1: recordWriter : ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) );
	public final HiveParser.recordWriter_return recordWriter() throws RecognitionException {
		HiveParser.recordWriter_return retval = new HiveParser.recordWriter_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RECORDWRITER772=null;
		Token StringLiteral773=null;

		ASTNode KW_RECORDWRITER772_tree=null;
		ASTNode StringLiteral773_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_RECORDWRITER=new RewriteRuleTokenStream(adaptor,"token KW_RECORDWRITER");

		 pushMsg("record writer specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:5: ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) )
			int alt233=2;
			int LA233_0 = input.LA(1);
			if ( (LA233_0==KW_RECORDWRITER) ) {
				alt233=1;
			}
			else if ( (LA233_0==KW_USING) ) {
				alt233=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 233, 0, input);
				throw nvae;
			}

			switch (alt233) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:7: KW_RECORDWRITER StringLiteral
					{
					KW_RECORDWRITER772=(Token)match(input,KW_RECORDWRITER,FOLLOW_KW_RECORDWRITER_in_recordWriter12460); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RECORDWRITER.add(KW_RECORDWRITER772);

					StringLiteral773=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_recordWriter12462); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral773);

					// AST REWRITE
					// elements: StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2123:37: -> ^( TOK_RECORDWRITER StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:40: ^( TOK_RECORDWRITER StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2124:9: 
					{
					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2124:9: -> ^( TOK_RECORDWRITER )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2124:12: ^( TOK_RECORDWRITER )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "recordWriter"


	public static class rowFormatSerde_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rowFormatSerde"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2127:1: rowFormatSerde : KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) ;
	public final HiveParser.rowFormatSerde_return rowFormatSerde() throws RecognitionException {
		HiveParser.rowFormatSerde_return retval = new HiveParser.rowFormatSerde_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token name=null;
		Token KW_ROW774=null;
		Token KW_FORMAT775=null;
		Token KW_SERDE776=null;
		Token KW_WITH777=null;
		Token KW_SERDEPROPERTIES778=null;
		ParserRuleReturnScope serdeprops =null;

		ASTNode name_tree=null;
		ASTNode KW_ROW774_tree=null;
		ASTNode KW_FORMAT775_tree=null;
		ASTNode KW_SERDE776_tree=null;
		ASTNode KW_WITH777_tree=null;
		ASTNode KW_SERDEPROPERTIES778_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_ROW=new RewriteRuleTokenStream(adaptor,"token KW_ROW");
		RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
		RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
		RewriteRuleTokenStream stream_KW_FORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FORMAT");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("serde format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2130:5: ( KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2130:7: KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
			{
			KW_ROW774=(Token)match(input,KW_ROW,FOLLOW_KW_ROW_in_rowFormatSerde12511); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROW.add(KW_ROW774);

			KW_FORMAT775=(Token)match(input,KW_FORMAT,FOLLOW_KW_FORMAT_in_rowFormatSerde12513); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FORMAT.add(KW_FORMAT775);

			KW_SERDE776=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_rowFormatSerde12515); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE776);

			name=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_rowFormatSerde12519); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(name);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2130:52: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
			int alt234=2;
			int LA234_0 = input.LA(1);
			if ( (LA234_0==KW_WITH) ) {
				alt234=1;
			}
			switch (alt234) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2130:53: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
					{
					KW_WITH777=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_rowFormatSerde12522); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH777);

					KW_SERDEPROPERTIES778=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde12524); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES778);

					pushFollow(FOLLOW_tableProperties_in_rowFormatSerde12528);
					serdeprops=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(serdeprops.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: name, serdeprops
			// token labels: name
			// rule labels: serdeprops, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_name=new RewriteRuleTokenStream(adaptor,"token name",name);
			RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2131:5: -> ^( TOK_SERDENAME $name ( $serdeprops)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2131:8: ^( TOK_SERDENAME $name ( $serdeprops)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDENAME, "TOK_SERDENAME"), root_1);
				adaptor.addChild(root_1, stream_name.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2131:31: ( $serdeprops)?
				if ( stream_serdeprops.hasNext() ) {
					adaptor.addChild(root_1, stream_serdeprops.nextTree());
				}
				stream_serdeprops.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rowFormatSerde"


	public static class rowFormatDelimited_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rowFormatDelimited"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2134:1: rowFormatDelimited : KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) ;
	public final HiveParser.rowFormatDelimited_return rowFormatDelimited() throws RecognitionException {
		HiveParser.rowFormatDelimited_return retval = new HiveParser.rowFormatDelimited_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ROW779=null;
		Token KW_FORMAT780=null;
		Token KW_DELIMITED781=null;
		ParserRuleReturnScope tableRowFormatFieldIdentifier782 =null;
		ParserRuleReturnScope tableRowFormatCollItemsIdentifier783 =null;
		ParserRuleReturnScope tableRowFormatMapKeysIdentifier784 =null;
		ParserRuleReturnScope tableRowFormatLinesIdentifier785 =null;
		ParserRuleReturnScope tableRowNullFormat786 =null;

		ASTNode KW_ROW779_tree=null;
		ASTNode KW_FORMAT780_tree=null;
		ASTNode KW_DELIMITED781_tree=null;
		RewriteRuleTokenStream stream_KW_ROW=new RewriteRuleTokenStream(adaptor,"token KW_ROW");
		RewriteRuleTokenStream stream_KW_DELIMITED=new RewriteRuleTokenStream(adaptor,"token KW_DELIMITED");
		RewriteRuleTokenStream stream_KW_FORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FORMAT");
		RewriteRuleSubtreeStream stream_tableRowNullFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowNullFormat");
		RewriteRuleSubtreeStream stream_tableRowFormatFieldIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatFieldIdentifier");
		RewriteRuleSubtreeStream stream_tableRowFormatCollItemsIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatCollItemsIdentifier");
		RewriteRuleSubtreeStream stream_tableRowFormatMapKeysIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatMapKeysIdentifier");
		RewriteRuleSubtreeStream stream_tableRowFormatLinesIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatLinesIdentifier");

		 pushMsg("serde properties specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2137:5: ( KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:7: KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )?
			{
			KW_ROW779=(Token)match(input,KW_ROW,FOLLOW_KW_ROW_in_rowFormatDelimited12580); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROW.add(KW_ROW779);

			KW_FORMAT780=(Token)match(input,KW_FORMAT,FOLLOW_KW_FORMAT_in_rowFormatDelimited12582); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FORMAT.add(KW_FORMAT780);

			KW_DELIMITED781=(Token)match(input,KW_DELIMITED,FOLLOW_KW_DELIMITED_in_rowFormatDelimited12584); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DELIMITED.add(KW_DELIMITED781);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:37: ( tableRowFormatFieldIdentifier )?
			int alt235=2;
			int LA235_0 = input.LA(1);
			if ( (LA235_0==KW_FIELDS) ) {
				alt235=1;
			}
			switch (alt235) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:37: tableRowFormatFieldIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited12586);
					tableRowFormatFieldIdentifier782=tableRowFormatFieldIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatFieldIdentifier.add(tableRowFormatFieldIdentifier782.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:68: ( tableRowFormatCollItemsIdentifier )?
			int alt236=2;
			int LA236_0 = input.LA(1);
			if ( (LA236_0==KW_COLLECTION) ) {
				alt236=1;
			}
			switch (alt236) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:68: tableRowFormatCollItemsIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited12589);
					tableRowFormatCollItemsIdentifier783=tableRowFormatCollItemsIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatCollItemsIdentifier.add(tableRowFormatCollItemsIdentifier783.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:103: ( tableRowFormatMapKeysIdentifier )?
			int alt237=2;
			alt237 = dfa237.predict(input);
			switch (alt237) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:103: tableRowFormatMapKeysIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited12592);
					tableRowFormatMapKeysIdentifier784=tableRowFormatMapKeysIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatMapKeysIdentifier.add(tableRowFormatMapKeysIdentifier784.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:136: ( tableRowFormatLinesIdentifier )?
			int alt238=2;
			int LA238_0 = input.LA(1);
			if ( (LA238_0==KW_LINES) ) {
				alt238=1;
			}
			switch (alt238) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:136: tableRowFormatLinesIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited12595);
					tableRowFormatLinesIdentifier785=tableRowFormatLinesIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatLinesIdentifier.add(tableRowFormatLinesIdentifier785.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:167: ( tableRowNullFormat )?
			int alt239=2;
			int LA239_0 = input.LA(1);
			if ( (LA239_0==KW_NULL) ) {
				alt239=1;
			}
			switch (alt239) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:167: tableRowNullFormat
					{
					pushFollow(FOLLOW_tableRowNullFormat_in_rowFormatDelimited12598);
					tableRowNullFormat786=tableRowNullFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowNullFormat.add(tableRowNullFormat786.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableRowFormatCollItemsIdentifier, tableRowFormatFieldIdentifier, tableRowFormatMapKeysIdentifier, tableRowFormatLinesIdentifier, tableRowNullFormat
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2139:5: -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2139:8: ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDEPROPS, "TOK_SERDEPROPS"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2139:25: ( tableRowFormatFieldIdentifier )?
				if ( stream_tableRowFormatFieldIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatFieldIdentifier.nextTree());
				}
				stream_tableRowFormatFieldIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2139:56: ( tableRowFormatCollItemsIdentifier )?
				if ( stream_tableRowFormatCollItemsIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatCollItemsIdentifier.nextTree());
				}
				stream_tableRowFormatCollItemsIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2139:91: ( tableRowFormatMapKeysIdentifier )?
				if ( stream_tableRowFormatMapKeysIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatMapKeysIdentifier.nextTree());
				}
				stream_tableRowFormatMapKeysIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2139:124: ( tableRowFormatLinesIdentifier )?
				if ( stream_tableRowFormatLinesIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatLinesIdentifier.nextTree());
				}
				stream_tableRowFormatLinesIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2139:155: ( tableRowNullFormat )?
				if ( stream_tableRowNullFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowNullFormat.nextTree());
				}
				stream_tableRowNullFormat.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rowFormatDelimited"


	public static class tableRowFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2142:1: tableRowFormat : ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) );
	public final HiveParser.tableRowFormat_return tableRowFormat() throws RecognitionException {
		HiveParser.tableRowFormat_return retval = new HiveParser.tableRowFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope rowFormatDelimited787 =null;
		ParserRuleReturnScope rowFormatSerde788 =null;

		RewriteRuleSubtreeStream stream_rowFormatSerde=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatSerde");
		RewriteRuleSubtreeStream stream_rowFormatDelimited=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatDelimited");

		 pushMsg("table row format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2145:5: ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) )
			int alt240=2;
			int LA240_0 = input.LA(1);
			if ( (LA240_0==KW_ROW) ) {
				int LA240_1 = input.LA(2);
				if ( (LA240_1==KW_FORMAT) ) {
					int LA240_2 = input.LA(3);
					if ( (LA240_2==KW_DELIMITED) ) {
						alt240=1;
					}
					else if ( (LA240_2==KW_SERDE) ) {
						alt240=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 240, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 240, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 240, 0, input);
				throw nvae;
			}

			switch (alt240) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2146:7: rowFormatDelimited
					{
					pushFollow(FOLLOW_rowFormatDelimited_in_tableRowFormat12657);
					rowFormatDelimited787=rowFormatDelimited();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatDelimited.add(rowFormatDelimited787.getTree());
					// AST REWRITE
					// elements: rowFormatDelimited
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2147:5: -> ^( TOK_TABLEROWFORMAT rowFormatDelimited )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2147:8: ^( TOK_TABLEROWFORMAT rowFormatDelimited )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMAT, "TOK_TABLEROWFORMAT"), root_1);
						adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2148:7: rowFormatSerde
					{
					pushFollow(FOLLOW_rowFormatSerde_in_tableRowFormat12677);
					rowFormatSerde788=rowFormatSerde();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatSerde.add(rowFormatSerde788.getTree());
					// AST REWRITE
					// elements: rowFormatSerde
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2149:5: -> ^( TOK_TABLESERIALIZER rowFormatSerde )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2149:8: ^( TOK_TABLESERIALIZER rowFormatSerde )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLESERIALIZER, "TOK_TABLESERIALIZER"), root_1);
						adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormat"


	public static class tablePropertiesPrefixed_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tablePropertiesPrefixed"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:1: tablePropertiesPrefixed : KW_TBLPROPERTIES ! tableProperties ;
	public final HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed() throws RecognitionException {
		HiveParser.tablePropertiesPrefixed_return retval = new HiveParser.tablePropertiesPrefixed_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_TBLPROPERTIES789=null;
		ParserRuleReturnScope tableProperties790 =null;

		ASTNode KW_TBLPROPERTIES789_tree=null;

		 pushMsg("table properties with prefix", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2155:5: ( KW_TBLPROPERTIES ! tableProperties )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2156:9: KW_TBLPROPERTIES ! tableProperties
			{
			root_0 = (ASTNode)adaptor.nil();


			KW_TBLPROPERTIES789=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed12724); if (state.failed) return retval;
			pushFollow(FOLLOW_tableProperties_in_tablePropertiesPrefixed12727);
			tableProperties790=tableProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, tableProperties790.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tablePropertiesPrefixed"


	public static class tableProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2159:1: tableProperties : LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) ;
	public final HiveParser.tableProperties_return tableProperties() throws RecognitionException {
		HiveParser.tableProperties_return retval = new HiveParser.tableProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN791=null;
		Token RPAREN793=null;
		ParserRuleReturnScope tablePropertiesList792 =null;

		ASTNode LPAREN791_tree=null;
		ASTNode RPAREN793_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_tablePropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesList");

		 pushMsg("table properties", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2162:5: ( LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2163:7: LPAREN tablePropertiesList RPAREN
			{
			LPAREN791=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableProperties12760); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN791);

			pushFollow(FOLLOW_tablePropertiesList_in_tableProperties12762);
			tablePropertiesList792=tablePropertiesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tablePropertiesList.add(tablePropertiesList792.getTree());
			RPAREN793=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableProperties12764); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN793);

			// AST REWRITE
			// elements: tablePropertiesList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2163:41: -> ^( TOK_TABLEPROPERTIES tablePropertiesList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2163:44: ^( TOK_TABLEPROPERTIES tablePropertiesList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPERTIES, "TOK_TABLEPROPERTIES"), root_1);
				adaptor.addChild(root_1, stream_tablePropertiesList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableProperties"


	public static class tablePropertiesList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tablePropertiesList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:1: tablePropertiesList : ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) );
	public final HiveParser.tablePropertiesList_return tablePropertiesList() throws RecognitionException {
		HiveParser.tablePropertiesList_return retval = new HiveParser.tablePropertiesList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA795=null;
		Token COMMA798=null;
		ParserRuleReturnScope keyValueProperty794 =null;
		ParserRuleReturnScope keyValueProperty796 =null;
		ParserRuleReturnScope keyProperty797 =null;
		ParserRuleReturnScope keyProperty799 =null;

		ASTNode COMMA795_tree=null;
		ASTNode COMMA798_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");
		RewriteRuleSubtreeStream stream_keyProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyProperty");

		 pushMsg("table properties list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2169:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) )
			int alt243=2;
			int LA243_0 = input.LA(1);
			if ( (LA243_0==StringLiteral) ) {
				int LA243_1 = input.LA(2);
				if ( (LA243_1==EQUAL) ) {
					alt243=1;
				}
				else if ( (LA243_1==COMMA||LA243_1==RPAREN) ) {
					alt243=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 243, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 243, 0, input);
				throw nvae;
			}

			switch (alt243) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:7: keyValueProperty ( COMMA keyValueProperty )*
					{
					pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList12805);
					keyValueProperty794=keyValueProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty794.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:24: ( COMMA keyValueProperty )*
					loop241:
					while (true) {
						int alt241=2;
						int LA241_0 = input.LA(1);
						if ( (LA241_0==COMMA) ) {
							alt241=1;
						}

						switch (alt241) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:25: COMMA keyValueProperty
							{
							COMMA795=(Token)match(input,COMMA,FOLLOW_COMMA_in_tablePropertiesList12808); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA795);

							pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList12810);
							keyValueProperty796=keyValueProperty();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty796.getTree());
							}
							break;

						default :
							break loop241;
						}
					}

					// AST REWRITE
					// elements: keyValueProperty
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2170:50: -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:53: ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST"), root_1);
						if ( !(stream_keyValueProperty.hasNext()) ) {
							throw new RewriteEarlyExitException();
						}
						while ( stream_keyValueProperty.hasNext() ) {
							adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
						}
						stream_keyValueProperty.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:7: keyProperty ( COMMA keyProperty )*
					{
					pushFollow(FOLLOW_keyProperty_in_tablePropertiesList12835);
					keyProperty797=keyProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyProperty.add(keyProperty797.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:19: ( COMMA keyProperty )*
					loop242:
					while (true) {
						int alt242=2;
						int LA242_0 = input.LA(1);
						if ( (LA242_0==COMMA) ) {
							alt242=1;
						}

						switch (alt242) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:20: COMMA keyProperty
							{
							COMMA798=(Token)match(input,COMMA,FOLLOW_COMMA_in_tablePropertiesList12838); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA798);

							pushFollow(FOLLOW_keyProperty_in_tablePropertiesList12840);
							keyProperty799=keyProperty();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_keyProperty.add(keyProperty799.getTree());
							}
							break;

						default :
							break loop242;
						}
					}

					// AST REWRITE
					// elements: keyProperty
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2172:40: -> ^( TOK_TABLEPROPLIST ( keyProperty )+ )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:43: ^( TOK_TABLEPROPLIST ( keyProperty )+ )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST"), root_1);
						if ( !(stream_keyProperty.hasNext()) ) {
							throw new RewriteEarlyExitException();
						}
						while ( stream_keyProperty.hasNext() ) {
							adaptor.addChild(root_1, stream_keyProperty.nextTree());
						}
						stream_keyProperty.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tablePropertiesList"


	public static class keyValueProperty_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "keyValueProperty"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2175:1: keyValueProperty : key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) ;
	public final HiveParser.keyValueProperty_return keyValueProperty() throws RecognitionException {
		HiveParser.keyValueProperty_return retval = new HiveParser.keyValueProperty_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token key=null;
		Token value=null;
		Token EQUAL800=null;

		ASTNode key_tree=null;
		ASTNode value_tree=null;
		ASTNode EQUAL800_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");

		 pushMsg("specifying key/value property", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2178:5: (key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:7: key= StringLiteral EQUAL value= StringLiteral
			{
			key=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyValueProperty12886); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(key);

			EQUAL800=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_keyValueProperty12888); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL800);

			value=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyValueProperty12892); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(value);

			// AST REWRITE
			// elements: key, value
			// token labels: value, key
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
			RewriteRuleTokenStream stream_key=new RewriteRuleTokenStream(adaptor,"token key",key);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2179:51: -> ^( TOK_TABLEPROPERTY $key $value)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:54: ^( TOK_TABLEPROPERTY $key $value)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY"), root_1);
				adaptor.addChild(root_1, stream_key.nextNode());
				adaptor.addChild(root_1, stream_value.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "keyValueProperty"


	public static class keyProperty_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "keyProperty"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2182:1: keyProperty : key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) ;
	public final HiveParser.keyProperty_return keyProperty() throws RecognitionException {
		HiveParser.keyProperty_return retval = new HiveParser.keyProperty_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token key=null;

		ASTNode key_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");

		 pushMsg("specifying key property", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:5: (key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:7: key= StringLiteral
			{
			key=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyProperty12939); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(key);

			// AST REWRITE
			// elements: key
			// token labels: key
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_key=new RewriteRuleTokenStream(adaptor,"token key",key);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2186:25: -> ^( TOK_TABLEPROPERTY $key TOK_NULL )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:28: ^( TOK_TABLEPROPERTY $key TOK_NULL )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY"), root_1);
				adaptor.addChild(root_1, stream_key.nextNode());
				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_NULL, "TOK_NULL"));
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "keyProperty"


	public static class tableRowFormatFieldIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatFieldIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2189:1: tableRowFormatFieldIdentifier : KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) ;
	public final HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatFieldIdentifier_return retval = new HiveParser.tableRowFormatFieldIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token fldIdnt=null;
		Token fldEscape=null;
		Token KW_FIELDS801=null;
		Token KW_TERMINATED802=null;
		Token KW_BY803=null;
		Token KW_ESCAPED804=null;
		Token KW_BY805=null;

		ASTNode fldIdnt_tree=null;
		ASTNode fldEscape_tree=null;
		ASTNode KW_FIELDS801_tree=null;
		ASTNode KW_TERMINATED802_tree=null;
		ASTNode KW_BY803_tree=null;
		ASTNode KW_ESCAPED804_tree=null;
		ASTNode KW_BY805_tree=null;
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_ESCAPED=new RewriteRuleTokenStream(adaptor,"token KW_ESCAPED");
		RewriteRuleTokenStream stream_KW_FIELDS=new RewriteRuleTokenStream(adaptor,"token KW_FIELDS");

		 pushMsg("table row format's field separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2192:5: ( KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2193:7: KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
			{
			KW_FIELDS801=(Token)match(input,KW_FIELDS,FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier12983); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FIELDS.add(KW_FIELDS801);

			KW_TERMINATED802=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier12985); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED802);

			KW_BY803=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier12987); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY803);

			fldIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier12991); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(fldIdnt);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2193:59: ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
			int alt244=2;
			int LA244_0 = input.LA(1);
			if ( (LA244_0==KW_ESCAPED) ) {
				alt244=1;
			}
			switch (alt244) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2193:60: KW_ESCAPED KW_BY fldEscape= StringLiteral
					{
					KW_ESCAPED804=(Token)match(input,KW_ESCAPED,FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier12994); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ESCAPED.add(KW_ESCAPED804);

					KW_BY805=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier12996); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY805);

					fldEscape=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier13000); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(fldEscape);

					}
					break;

			}

			// AST REWRITE
			// elements: fldEscape, fldIdnt
			// token labels: fldIdnt, fldEscape
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_fldIdnt=new RewriteRuleTokenStream(adaptor,"token fldIdnt",fldIdnt);
			RewriteRuleTokenStream stream_fldEscape=new RewriteRuleTokenStream(adaptor,"token fldEscape",fldEscape);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2194:5: -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2194:8: ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATFIELD, "TOK_TABLEROWFORMATFIELD"), root_1);
				adaptor.addChild(root_1, stream_fldIdnt.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2194:44: ( $fldEscape)?
				if ( stream_fldEscape.hasNext() ) {
					adaptor.addChild(root_1, stream_fldEscape.nextNode());
				}
				stream_fldEscape.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatFieldIdentifier"


	public static class tableRowFormatCollItemsIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatCollItemsIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2197:1: tableRowFormatCollItemsIdentifier : KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) ;
	public final HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatCollItemsIdentifier_return retval = new HiveParser.tableRowFormatCollItemsIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token collIdnt=null;
		Token KW_COLLECTION806=null;
		Token KW_ITEMS807=null;
		Token KW_TERMINATED808=null;
		Token KW_BY809=null;

		ASTNode collIdnt_tree=null;
		ASTNode KW_COLLECTION806_tree=null;
		ASTNode KW_ITEMS807_tree=null;
		ASTNode KW_TERMINATED808_tree=null;
		ASTNode KW_BY809_tree=null;
		RewriteRuleTokenStream stream_KW_COLLECTION=new RewriteRuleTokenStream(adaptor,"token KW_COLLECTION");
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_ITEMS=new RewriteRuleTokenStream(adaptor,"token KW_ITEMS");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");

		 pushMsg("table row format's column separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2200:5: ( KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2201:7: KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral
			{
			KW_COLLECTION806=(Token)match(input,KW_COLLECTION,FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier13052); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COLLECTION.add(KW_COLLECTION806);

			KW_ITEMS807=(Token)match(input,KW_ITEMS,FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier13054); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ITEMS.add(KW_ITEMS807);

			KW_TERMINATED808=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier13056); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED808);

			KW_BY809=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier13058); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY809);

			collIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier13062); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(collIdnt);

			// AST REWRITE
			// elements: collIdnt
			// token labels: collIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_collIdnt=new RewriteRuleTokenStream(adaptor,"token collIdnt",collIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2202:5: -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2202:8: ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATCOLLITEMS, "TOK_TABLEROWFORMATCOLLITEMS"), root_1);
				adaptor.addChild(root_1, stream_collIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatCollItemsIdentifier"


	public static class tableRowFormatMapKeysIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatMapKeysIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:1: tableRowFormatMapKeysIdentifier : KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) ;
	public final HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatMapKeysIdentifier_return retval = new HiveParser.tableRowFormatMapKeysIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token mapKeysIdnt=null;
		Token KW_MAP810=null;
		Token KW_KEYS811=null;
		Token KW_TERMINATED812=null;
		Token KW_BY813=null;

		ASTNode mapKeysIdnt_tree=null;
		ASTNode KW_MAP810_tree=null;
		ASTNode KW_KEYS811_tree=null;
		ASTNode KW_TERMINATED812_tree=null;
		ASTNode KW_BY813_tree=null;
		RewriteRuleTokenStream stream_KW_KEYS=new RewriteRuleTokenStream(adaptor,"token KW_KEYS");
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_MAP=new RewriteRuleTokenStream(adaptor,"token KW_MAP");

		 pushMsg("table row format's map key separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:5: ( KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2209:7: KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral
			{
			KW_MAP810=(Token)match(input,KW_MAP,FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier13108); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MAP.add(KW_MAP810);

			KW_KEYS811=(Token)match(input,KW_KEYS,FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier13110); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KEYS.add(KW_KEYS811);

			KW_TERMINATED812=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier13112); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED812);

			KW_BY813=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier13114); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY813);

			mapKeysIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier13118); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(mapKeysIdnt);

			// AST REWRITE
			// elements: mapKeysIdnt
			// token labels: mapKeysIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_mapKeysIdnt=new RewriteRuleTokenStream(adaptor,"token mapKeysIdnt",mapKeysIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2210:5: -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2210:8: ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATMAPKEYS, "TOK_TABLEROWFORMATMAPKEYS"), root_1);
				adaptor.addChild(root_1, stream_mapKeysIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatMapKeysIdentifier"


	public static class tableRowFormatLinesIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatLinesIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2213:1: tableRowFormatLinesIdentifier : KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) ;
	public final HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatLinesIdentifier_return retval = new HiveParser.tableRowFormatLinesIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token linesIdnt=null;
		Token KW_LINES814=null;
		Token KW_TERMINATED815=null;
		Token KW_BY816=null;

		ASTNode linesIdnt_tree=null;
		ASTNode KW_LINES814_tree=null;
		ASTNode KW_TERMINATED815_tree=null;
		ASTNode KW_BY816_tree=null;
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LINES=new RewriteRuleTokenStream(adaptor,"token KW_LINES");

		 pushMsg("table row format's line separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2216:5: ( KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2217:7: KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral
			{
			KW_LINES814=(Token)match(input,KW_LINES,FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier13164); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LINES.add(KW_LINES814);

			KW_TERMINATED815=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier13166); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED815);

			KW_BY816=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier13168); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY816);

			linesIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier13172); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(linesIdnt);

			// AST REWRITE
			// elements: linesIdnt
			// token labels: linesIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_linesIdnt=new RewriteRuleTokenStream(adaptor,"token linesIdnt",linesIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2218:5: -> ^( TOK_TABLEROWFORMATLINES $linesIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2218:8: ^( TOK_TABLEROWFORMATLINES $linesIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATLINES, "TOK_TABLEROWFORMATLINES"), root_1);
				adaptor.addChild(root_1, stream_linesIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatLinesIdentifier"


	public static class tableRowNullFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowNullFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2221:1: tableRowNullFormat : KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) ;
	public final HiveParser.tableRowNullFormat_return tableRowNullFormat() throws RecognitionException {
		HiveParser.tableRowNullFormat_return retval = new HiveParser.tableRowNullFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token nullIdnt=null;
		Token KW_NULL817=null;
		Token KW_DEFINED818=null;
		Token KW_AS819=null;

		ASTNode nullIdnt_tree=null;
		ASTNode KW_NULL817_tree=null;
		ASTNode KW_DEFINED818_tree=null;
		ASTNode KW_AS819_tree=null;
		RewriteRuleTokenStream stream_KW_NULL=new RewriteRuleTokenStream(adaptor,"token KW_NULL");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_DEFINED=new RewriteRuleTokenStream(adaptor,"token KW_DEFINED");

		 pushMsg("table row format's null specifier", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:5: ( KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2225:7: KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral
			{
			KW_NULL817=(Token)match(input,KW_NULL,FOLLOW_KW_NULL_in_tableRowNullFormat13218); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_NULL.add(KW_NULL817);

			KW_DEFINED818=(Token)match(input,KW_DEFINED,FOLLOW_KW_DEFINED_in_tableRowNullFormat13220); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DEFINED.add(KW_DEFINED818);

			KW_AS819=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableRowNullFormat13222); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS819);

			nullIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowNullFormat13226); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(nullIdnt);

			// AST REWRITE
			// elements: nullIdnt
			// token labels: nullIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_nullIdnt=new RewriteRuleTokenStream(adaptor,"token nullIdnt",nullIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2226:5: -> ^( TOK_TABLEROWFORMATNULL $nullIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2226:8: ^( TOK_TABLEROWFORMATNULL $nullIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATNULL, "TOK_TABLEROWFORMATNULL"), root_1);
				adaptor.addChild(root_1, stream_nullIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowNullFormat"


	public static class tableFileFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableFileFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:1: tableFileFormat : ( ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
	public final HiveParser.tableFileFormat_return tableFileFormat() throws RecognitionException {
		HiveParser.tableFileFormat_return retval = new HiveParser.tableFileFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token inFmt=null;
		Token outFmt=null;
		Token inDriver=null;
		Token outDriver=null;
		Token storageHandler=null;
		Token KW_STORED820=null;
		Token KW_AS821=null;
		Token KW_INPUTFORMAT822=null;
		Token KW_OUTPUTFORMAT823=null;
		Token KW_INPUTDRIVER824=null;
		Token KW_OUTPUTDRIVER825=null;
		Token KW_STORED826=null;
		Token KW_BY827=null;
		Token KW_WITH828=null;
		Token KW_SERDEPROPERTIES829=null;
		Token KW_STORED830=null;
		Token KW_AS831=null;
		ParserRuleReturnScope serdeprops =null;
		ParserRuleReturnScope genericSpec =null;

		ASTNode inFmt_tree=null;
		ASTNode outFmt_tree=null;
		ASTNode inDriver_tree=null;
		ASTNode outDriver_tree=null;
		ASTNode storageHandler_tree=null;
		ASTNode KW_STORED820_tree=null;
		ASTNode KW_AS821_tree=null;
		ASTNode KW_INPUTFORMAT822_tree=null;
		ASTNode KW_OUTPUTFORMAT823_tree=null;
		ASTNode KW_INPUTDRIVER824_tree=null;
		ASTNode KW_OUTPUTDRIVER825_tree=null;
		ASTNode KW_STORED826_tree=null;
		ASTNode KW_BY827_tree=null;
		ASTNode KW_WITH828_tree=null;
		ASTNode KW_SERDEPROPERTIES829_tree=null;
		ASTNode KW_STORED830_tree=null;
		ASTNode KW_AS831_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
		RewriteRuleTokenStream stream_KW_INPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_INPUTDRIVER");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_OUTPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTFORMAT");
		RewriteRuleTokenStream stream_KW_STORED=new RewriteRuleTokenStream(adaptor,"token KW_STORED");
		RewriteRuleTokenStream stream_KW_OUTPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTDRIVER");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("table file format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2231:5: ( ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
			int alt247=3;
			int LA247_0 = input.LA(1);
			if ( (LA247_0==KW_STORED) ) {
				int LA247_1 = input.LA(2);
				if ( (LA247_1==KW_AS) ) {
					int LA247_2 = input.LA(3);
					if ( (LA247_2==KW_INPUTFORMAT) ) {
						int LA247_4 = input.LA(4);
						if ( (synpred18_HiveParser()) ) {
							alt247=1;
						}
						else if ( (true) ) {
							alt247=3;
						}

					}
					else if ( (LA247_2==Identifier||(LA247_2 >= KW_ABORT && LA247_2 <= KW_AFTER)||LA247_2==KW_ALLOC_FRACTION||LA247_2==KW_ANALYZE||LA247_2==KW_ARCHIVE||LA247_2==KW_ASC||(LA247_2 >= KW_AUTOCOMMIT && LA247_2 <= KW_BEFORE)||(LA247_2 >= KW_BUCKET && LA247_2 <= KW_BUCKETS)||(LA247_2 >= KW_CACHE && LA247_2 <= KW_CASCADE)||(LA247_2 >= KW_CBO && LA247_2 <= KW_CHANGE)||(LA247_2 >= KW_CHECK && LA247_2 <= KW_COLLECTION)||(LA247_2 >= KW_COLUMNS && LA247_2 <= KW_COMMENT)||(LA247_2 >= KW_COMPACT && LA247_2 <= KW_CONCATENATE)||(LA247_2 >= KW_CONTINUE && LA247_2 <= KW_COST)||LA247_2==KW_DATA||LA247_2==KW_DATABASES||(LA247_2 >= KW_DATETIME && LA247_2 <= KW_DEBUG)||(LA247_2 >= KW_DEFAULT && LA247_2 <= KW_DEFINED)||(LA247_2 >= KW_DELIMITED && LA247_2 <= KW_DESC)||(LA247_2 >= KW_DETAIL && LA247_2 <= KW_DISABLE)||(LA247_2 >= KW_DISTRIBUTE && LA247_2 <= KW_DO)||LA247_2==KW_DOW||(LA247_2 >= KW_DUMP && LA247_2 <= KW_ELEM_TYPE)||LA247_2==KW_ENABLE||(LA247_2 >= KW_ENFORCED && LA247_2 <= KW_ESCAPED)||LA247_2==KW_EXCLUSIVE||(LA247_2 >= KW_EXPLAIN && LA247_2 <= KW_EXPRESSION)||(LA247_2 >= KW_FIELDS && LA247_2 <= KW_FIRST)||(LA247_2 >= KW_FORMAT && LA247_2 <= KW_FORMATTED)||LA247_2==KW_FUNCTIONS||(LA247_2 >= KW_HOUR && LA247_2 <= KW_IDXPROPERTIES)||(LA247_2 >= KW_INDEX && LA247_2 <= KW_INDEXES)||(LA247_2 >= KW_INPATH && LA247_2 <= KW_INPUTDRIVER)||(LA247_2 >= KW_ISOLATION && LA247_2 <= KW_JAR)||(LA247_2 >= KW_JOINCOST && LA247_2 <= KW_LAST)||LA247_2==KW_LEVEL||(LA247_2 >= KW_LIMIT && LA247_2 <= KW_LOAD)||(LA247_2 >= KW_LOCATION && LA247_2 <= KW_LONG)||LA247_2==KW_MANAGEMENT||(LA247_2 >= KW_MAPJOIN && LA247_2 <= KW_MATERIALIZED)||LA247_2==KW_METADATA||(LA247_2 >= KW_MINUTE && LA247_2 <= KW_MONTH)||(LA247_2 >= KW_MOVE && LA247_2 <= KW_MSCK)||(LA247_2 >= KW_NORELY && LA247_2 <= KW_NOSCAN)||LA247_2==KW_NOVALIDATE||LA247_2==KW_NULLS||LA247_2==KW_OFFSET||(LA247_2 >= KW_OPERATOR && LA247_2 <= KW_OPTION)||(LA247_2 >= KW_OUTPUTDRIVER && LA247_2 <= KW_OUTPUTFORMAT)||(LA247_2 >= KW_OVERWRITE && LA247_2 <= KW_OWNER)||(LA247_2 >= KW_PARTITIONED && LA247_2 <= KW_PATH)||(LA247_2 >= KW_PLAN && LA247_2 <= KW_POOL)||LA247_2==KW_PRINCIPALS||(LA247_2 >= KW_PURGE && LA247_2 <= KW_QUERY_PARALLELISM)||LA247_2==KW_READ||(LA247_2 >= KW_REBUILD && LA247_2 <= KW_RECORDWRITER)||(LA247_2 >= KW_RELOAD && LA247_2 <= KW_RESTRICT)||LA247_2==KW_REWRITE||(LA247_2 >= KW_ROLE && LA247_2 <= KW_ROLES)||(LA247_2 >= KW_SCHEDULING_POLICY && LA247_2 <= KW_SECOND)||(LA247_2 >= KW_SEMI && LA247_2 <= KW_SERVER)||(LA247_2 >= KW_SETS && LA247_2 <= KW_SKEWED)||(LA247_2 >= KW_SNAPSHOT && LA247_2 <= KW_SSL)||(LA247_2 >= KW_STATISTICS && LA247_2 <= KW_SUMMARY)||LA247_2==KW_TABLES||(LA247_2 >= KW_TBLPROPERTIES && LA247_2 <= KW_TERMINATED)||LA247_2==KW_TINYINT||(LA247_2 >= KW_TOUCH && LA247_2 <= KW_TRANSACTIONS)||LA247_2==KW_UNARCHIVE||LA247_2==KW_UNDO||LA247_2==KW_UNIONTYPE||(LA247_2 >= KW_UNLOCK && LA247_2 <= KW_UNSIGNED)||(LA247_2 >= KW_URI && LA247_2 <= KW_USE)||(LA247_2 >= KW_UTC && LA247_2 <= KW_VALIDATE)||LA247_2==KW_VALUE_TYPE||(LA247_2 >= KW_VECTORIZATION && LA247_2 <= KW_WEEK)||LA247_2==KW_WHILE||(LA247_2 >= KW_WORK && LA247_2 <= KW_ZONE)||LA247_2==KW_BATCH||LA247_2==KW_DAYOFWEEK||LA247_2==KW_HOLD_DDLTIME||LA247_2==KW_IGNORE||LA247_2==KW_NO_DROP||LA247_2==KW_OFFLINE||LA247_2==KW_PROTECTION||LA247_2==KW_READONLY||LA247_2==KW_TIMESTAMPTZ) ) {
						alt247=3;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 247, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( (LA247_1==KW_BY) ) {
					alt247=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 247, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 247, 0, input);
				throw nvae;
			}

			switch (alt247) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:7: ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
					{
					KW_STORED820=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat13281); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED820);

					KW_AS821=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat13283); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS821);

					KW_INPUTFORMAT822=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_tableFileFormat13285); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT822);

					inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat13289); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(inFmt);

					KW_OUTPUTFORMAT823=(Token)match(input,KW_OUTPUTFORMAT,FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat13291); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT823);

					outFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat13295); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(outFmt);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:131: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
					int alt245=2;
					int LA245_0 = input.LA(1);
					if ( (LA245_0==KW_INPUTDRIVER) ) {
						alt245=1;
					}
					switch (alt245) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:132: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
							{
							KW_INPUTDRIVER824=(Token)match(input,KW_INPUTDRIVER,FOLLOW_KW_INPUTDRIVER_in_tableFileFormat13298); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER824);

							inDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat13302); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(inDriver);

							KW_OUTPUTDRIVER825=(Token)match(input,KW_OUTPUTDRIVER,FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat13304); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER825);

							outDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat13308); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(outDriver);

							}
							break;

					}

					// AST REWRITE
					// elements: inDriver, inFmt, outDriver, outFmt
					// token labels: inFmt, inDriver, outDriver, outFmt
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
					RewriteRuleTokenStream stream_inDriver=new RewriteRuleTokenStream(adaptor,"token inDriver",inDriver);
					RewriteRuleTokenStream stream_outDriver=new RewriteRuleTokenStream(adaptor,"token outDriver",outDriver);
					RewriteRuleTokenStream stream_outFmt=new RewriteRuleTokenStream(adaptor,"token outFmt",outFmt);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2233:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2233:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT"), root_1);
						adaptor.addChild(root_1, stream_inFmt.nextNode());
						adaptor.addChild(root_1, stream_outFmt.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2233:48: ( $inDriver)?
						if ( stream_inDriver.hasNext() ) {
							adaptor.addChild(root_1, stream_inDriver.nextNode());
						}
						stream_inDriver.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2233:59: ( $outDriver)?
						if ( stream_outDriver.hasNext() ) {
							adaptor.addChild(root_1, stream_outDriver.nextNode());
						}
						stream_outDriver.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2234:9: KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
					{
					KW_STORED826=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat13346); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED826);

					KW_BY827=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableFileFormat13348); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY827);

					storageHandler=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat13352); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(storageHandler);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2235:10: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
					int alt246=2;
					int LA246_0 = input.LA(1);
					if ( (LA246_0==KW_WITH) ) {
						alt246=1;
					}
					switch (alt246) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2235:11: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
							{
							KW_WITH828=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_tableFileFormat13364); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH828);

							KW_SERDEPROPERTIES829=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat13366); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES829);

							pushFollow(FOLLOW_tableProperties_in_tableFileFormat13370);
							serdeprops=tableProperties();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableProperties.add(serdeprops.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: storageHandler, serdeprops
					// token labels: storageHandler
					// rule labels: serdeprops, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_storageHandler=new RewriteRuleTokenStream(adaptor,"token storageHandler",storageHandler);
					RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2236:7: -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:10: ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_STORAGEHANDLER, "TOK_STORAGEHANDLER"), root_1);
						adaptor.addChild(root_1, stream_storageHandler.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:48: ( $serdeprops)?
						if ( stream_serdeprops.hasNext() ) {
							adaptor.addChild(root_1, stream_serdeprops.nextTree());
						}
						stream_serdeprops.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2237:9: KW_STORED KW_AS genericSpec= identifier
					{
					KW_STORED830=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat13401); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED830);

					KW_AS831=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat13403); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS831);

					pushFollow(FOLLOW_identifier_in_tableFileFormat13407);
					genericSpec=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(genericSpec.getTree());
					// AST REWRITE
					// elements: genericSpec
					// token labels: 
					// rule labels: genericSpec, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_genericSpec=new RewriteRuleSubtreeStream(adaptor,"rule genericSpec",genericSpec!=null?genericSpec.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2238:7: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2238:10: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_1);
						adaptor.addChild(root_1, stream_genericSpec.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableFileFormat"


	public static class tableLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2241:1: tableLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_TABLELOCATION $locn) ;
	public final HiveParser.tableLocation_return tableLocation() throws RecognitionException {
		HiveParser.tableLocation_return retval = new HiveParser.tableLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token locn=null;
		Token KW_LOCATION832=null;

		ASTNode locn_tree=null;
		ASTNode KW_LOCATION832_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

		 pushMsg("table location specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2244:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_TABLELOCATION $locn) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:7: KW_LOCATION locn= StringLiteral
			{
			KW_LOCATION832=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_tableLocation13455); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION832);

			locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableLocation13459); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(locn);

			// AST REWRITE
			// elements: locn
			// token labels: locn
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2245:38: -> ^( TOK_TABLELOCATION $locn)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:41: ^( TOK_TABLELOCATION $locn)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLELOCATION, "TOK_TABLELOCATION"), root_1);
				adaptor.addChild(root_1, stream_locn.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableLocation"


	public static class columnNameTypeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2248:1: columnNameTypeList : columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) ;
	public final HiveParser.columnNameTypeList_return columnNameTypeList() throws RecognitionException {
		HiveParser.columnNameTypeList_return retval = new HiveParser.columnNameTypeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA834=null;
		ParserRuleReturnScope columnNameType833 =null;
		ParserRuleReturnScope columnNameType835 =null;

		ASTNode COMMA834_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameType");

		 pushMsg("column name type list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2251:5: ( columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2251:7: columnNameType ( COMMA columnNameType )*
			{
			pushFollow(FOLLOW_columnNameType_in_columnNameTypeList13495);
			columnNameType833=columnNameType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType833.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2251:22: ( COMMA columnNameType )*
			loop248:
			while (true) {
				int alt248=2;
				int LA248_0 = input.LA(1);
				if ( (LA248_0==COMMA) ) {
					int LA248_20 = input.LA(2);
					if ( (LA248_20==Identifier||(LA248_20 >= KW_ABORT && LA248_20 <= KW_AFTER)||LA248_20==KW_ALLOC_FRACTION||LA248_20==KW_ANALYZE||LA248_20==KW_ARCHIVE||LA248_20==KW_ASC||(LA248_20 >= KW_AUTOCOMMIT && LA248_20 <= KW_BEFORE)||(LA248_20 >= KW_BUCKET && LA248_20 <= KW_BUCKETS)||(LA248_20 >= KW_CACHE && LA248_20 <= KW_CASCADE)||(LA248_20 >= KW_CBO && LA248_20 <= KW_CHANGE)||(LA248_20 >= KW_CHECK && LA248_20 <= KW_COLLECTION)||(LA248_20 >= KW_COLUMNS && LA248_20 <= KW_COMMENT)||(LA248_20 >= KW_COMPACT && LA248_20 <= KW_CONCATENATE)||(LA248_20 >= KW_CONTINUE && LA248_20 <= KW_COST)||LA248_20==KW_DATA||LA248_20==KW_DATABASES||(LA248_20 >= KW_DATETIME && LA248_20 <= KW_DEBUG)||(LA248_20 >= KW_DEFAULT && LA248_20 <= KW_DEFINED)||(LA248_20 >= KW_DELIMITED && LA248_20 <= KW_DESC)||(LA248_20 >= KW_DETAIL && LA248_20 <= KW_DISABLE)||(LA248_20 >= KW_DISTRIBUTE && LA248_20 <= KW_DO)||LA248_20==KW_DOW||(LA248_20 >= KW_DUMP && LA248_20 <= KW_ELEM_TYPE)||LA248_20==KW_ENABLE||(LA248_20 >= KW_ENFORCED && LA248_20 <= KW_ESCAPED)||LA248_20==KW_EXCLUSIVE||(LA248_20 >= KW_EXPLAIN && LA248_20 <= KW_EXPRESSION)||(LA248_20 >= KW_FIELDS && LA248_20 <= KW_FIRST)||(LA248_20 >= KW_FORMAT && LA248_20 <= KW_FORMATTED)||LA248_20==KW_FUNCTIONS||(LA248_20 >= KW_HOUR && LA248_20 <= KW_IDXPROPERTIES)||(LA248_20 >= KW_INDEX && LA248_20 <= KW_INDEXES)||(LA248_20 >= KW_INPATH && LA248_20 <= KW_INPUTFORMAT)||(LA248_20 >= KW_ISOLATION && LA248_20 <= KW_JAR)||(LA248_20 >= KW_JOINCOST && LA248_20 <= KW_LAST)||LA248_20==KW_LEVEL||(LA248_20 >= KW_LIMIT && LA248_20 <= KW_LOAD)||(LA248_20 >= KW_LOCATION && LA248_20 <= KW_LONG)||LA248_20==KW_MANAGEMENT||(LA248_20 >= KW_MAPJOIN && LA248_20 <= KW_MATERIALIZED)||LA248_20==KW_METADATA||(LA248_20 >= KW_MINUTE && LA248_20 <= KW_MONTH)||(LA248_20 >= KW_MOVE && LA248_20 <= KW_MSCK)||(LA248_20 >= KW_NORELY && LA248_20 <= KW_NOSCAN)||LA248_20==KW_NOVALIDATE||LA248_20==KW_NULLS||LA248_20==KW_OFFSET||(LA248_20 >= KW_OPERATOR && LA248_20 <= KW_OPTION)||(LA248_20 >= KW_OUTPUTDRIVER && LA248_20 <= KW_OUTPUTFORMAT)||(LA248_20 >= KW_OVERWRITE && LA248_20 <= KW_OWNER)||(LA248_20 >= KW_PARTITIONED && LA248_20 <= KW_PATH)||(LA248_20 >= KW_PLAN && LA248_20 <= KW_POOL)||LA248_20==KW_PRINCIPALS||(LA248_20 >= KW_PURGE && LA248_20 <= KW_QUERY_PARALLELISM)||LA248_20==KW_READ||(LA248_20 >= KW_REBUILD && LA248_20 <= KW_RECORDWRITER)||(LA248_20 >= KW_RELOAD && LA248_20 <= KW_RESTRICT)||LA248_20==KW_REWRITE||(LA248_20 >= KW_ROLE && LA248_20 <= KW_ROLES)||(LA248_20 >= KW_SCHEDULING_POLICY && LA248_20 <= KW_SECOND)||(LA248_20 >= KW_SEMI && LA248_20 <= KW_SERVER)||(LA248_20 >= KW_SETS && LA248_20 <= KW_SKEWED)||(LA248_20 >= KW_SNAPSHOT && LA248_20 <= KW_SSL)||(LA248_20 >= KW_STATISTICS && LA248_20 <= KW_SUMMARY)||LA248_20==KW_TABLES||(LA248_20 >= KW_TBLPROPERTIES && LA248_20 <= KW_TERMINATED)||LA248_20==KW_TINYINT||(LA248_20 >= KW_TOUCH && LA248_20 <= KW_TRANSACTIONS)||LA248_20==KW_UNARCHIVE||LA248_20==KW_UNDO||LA248_20==KW_UNIONTYPE||(LA248_20 >= KW_UNLOCK && LA248_20 <= KW_UNSIGNED)||(LA248_20 >= KW_URI && LA248_20 <= KW_USE)||(LA248_20 >= KW_UTC && LA248_20 <= KW_VALIDATE)||LA248_20==KW_VALUE_TYPE||(LA248_20 >= KW_VECTORIZATION && LA248_20 <= KW_WEEK)||LA248_20==KW_WHILE||(LA248_20 >= KW_WORK && LA248_20 <= KW_ZONE)||LA248_20==KW_BATCH||LA248_20==KW_DAYOFWEEK||LA248_20==KW_HOLD_DDLTIME||LA248_20==KW_IGNORE||LA248_20==KW_NO_DROP||LA248_20==KW_OFFLINE||LA248_20==KW_PROTECTION||LA248_20==KW_READONLY||LA248_20==KW_TIMESTAMPTZ) ) {
						alt248=1;
					}

				}

				switch (alt248) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2251:23: COMMA columnNameType
					{
					COMMA834=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameTypeList13498); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA834);

					pushFollow(FOLLOW_columnNameType_in_columnNameTypeList13500);
					columnNameType835=columnNameType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType835.getTree());
					}
					break;

				default :
					break loop248;
				}
			}

			// AST REWRITE
			// elements: columnNameType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2251:46: -> ^( TOK_TABCOLLIST ( columnNameType )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2251:49: ^( TOK_TABCOLLIST ( columnNameType )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);
				if ( !(stream_columnNameType.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameType.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameType.nextTree());
				}
				stream_columnNameType.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeList"


	public static class columnNameTypeOrConstraintList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeOrConstraintList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2254:1: columnNameTypeOrConstraintList : columnNameTypeOrConstraint ( COMMA columnNameTypeOrConstraint )* -> ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ ) ;
	public final HiveParser.columnNameTypeOrConstraintList_return columnNameTypeOrConstraintList() throws RecognitionException {
		HiveParser.columnNameTypeOrConstraintList_return retval = new HiveParser.columnNameTypeOrConstraintList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA837=null;
		ParserRuleReturnScope columnNameTypeOrConstraint836 =null;
		ParserRuleReturnScope columnNameTypeOrConstraint838 =null;

		ASTNode COMMA837_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameTypeOrConstraint=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeOrConstraint");

		 pushMsg("column name type and constraints list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2257:5: ( columnNameTypeOrConstraint ( COMMA columnNameTypeOrConstraint )* -> ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2257:7: columnNameTypeOrConstraint ( COMMA columnNameTypeOrConstraint )*
			{
			pushFollow(FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList13538);
			columnNameTypeOrConstraint836=columnNameTypeOrConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameTypeOrConstraint.add(columnNameTypeOrConstraint836.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2257:34: ( COMMA columnNameTypeOrConstraint )*
			loop249:
			while (true) {
				int alt249=2;
				int LA249_0 = input.LA(1);
				if ( (LA249_0==COMMA) ) {
					alt249=1;
				}

				switch (alt249) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2257:35: COMMA columnNameTypeOrConstraint
					{
					COMMA837=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameTypeOrConstraintList13541); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA837);

					pushFollow(FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList13543);
					columnNameTypeOrConstraint838=columnNameTypeOrConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameTypeOrConstraint.add(columnNameTypeOrConstraint838.getTree());
					}
					break;

				default :
					break loop249;
				}
			}

			// AST REWRITE
			// elements: columnNameTypeOrConstraint
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2257:70: -> ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2257:73: ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);
				if ( !(stream_columnNameTypeOrConstraint.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameTypeOrConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeOrConstraint.nextTree());
				}
				stream_columnNameTypeOrConstraint.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeOrConstraintList"


	public static class columnNameColonTypeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameColonTypeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2260:1: columnNameColonTypeList : columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) ;
	public final HiveParser.columnNameColonTypeList_return columnNameColonTypeList() throws RecognitionException {
		HiveParser.columnNameColonTypeList_return retval = new HiveParser.columnNameColonTypeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA840=null;
		ParserRuleReturnScope columnNameColonType839 =null;
		ParserRuleReturnScope columnNameColonType841 =null;

		ASTNode COMMA840_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameColonType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameColonType");

		 pushMsg("column name type list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2263:5: ( columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2263:7: columnNameColonType ( COMMA columnNameColonType )*
			{
			pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList13581);
			columnNameColonType839=columnNameColonType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameColonType.add(columnNameColonType839.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2263:27: ( COMMA columnNameColonType )*
			loop250:
			while (true) {
				int alt250=2;
				int LA250_0 = input.LA(1);
				if ( (LA250_0==COMMA) ) {
					alt250=1;
				}

				switch (alt250) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2263:28: COMMA columnNameColonType
					{
					COMMA840=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameColonTypeList13584); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA840);

					pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList13586);
					columnNameColonType841=columnNameColonType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameColonType.add(columnNameColonType841.getTree());
					}
					break;

				default :
					break loop250;
				}
			}

			// AST REWRITE
			// elements: columnNameColonType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2263:56: -> ^( TOK_TABCOLLIST ( columnNameColonType )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2263:59: ^( TOK_TABCOLLIST ( columnNameColonType )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);
				if ( !(stream_columnNameColonType.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameColonType.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameColonType.nextTree());
				}
				stream_columnNameColonType.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameColonTypeList"


	public static class columnNameList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2266:1: columnNameList : columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) ;
	public final HiveParser.columnNameList_return columnNameList() throws RecognitionException {
		HiveParser.columnNameList_return retval = new HiveParser.columnNameList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA843=null;
		ParserRuleReturnScope columnName842 =null;
		ParserRuleReturnScope columnName844 =null;

		ASTNode COMMA843_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("column name list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:5: ( columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:7: columnName ( COMMA columnName )*
			{
			pushFollow(FOLLOW_columnName_in_columnNameList13624);
			columnName842=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(columnName842.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:18: ( COMMA columnName )*
			loop251:
			while (true) {
				int alt251=2;
				int LA251_0 = input.LA(1);
				if ( (LA251_0==COMMA) ) {
					alt251=1;
				}

				switch (alt251) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:19: COMMA columnName
					{
					COMMA843=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameList13627); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA843);

					pushFollow(FOLLOW_columnName_in_columnNameList13629);
					columnName844=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName844.getTree());
					}
					break;

				default :
					break loop251;
				}
			}

			// AST REWRITE
			// elements: columnName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2269:38: -> ^( TOK_TABCOLNAME ( columnName )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:41: ^( TOK_TABCOLNAME ( columnName )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);
				if ( !(stream_columnName.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnName.hasNext() ) {
					adaptor.addChild(root_1, stream_columnName.nextTree());
				}
				stream_columnName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameList"


	public static class columnName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2272:1: columnName : identifier ;
	public final HiveParser.columnName_return columnName() throws RecognitionException {
		HiveParser.columnName_return retval = new HiveParser.columnName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope identifier845 =null;


		 pushMsg("column name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2275:5: ( identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2276:7: identifier
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_identifier_in_columnName13673);
			identifier845=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier845.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnName"


	public static class extColumnName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "extColumnName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2279:1: extColumnName : identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* ;
	public final HiveParser.extColumnName_return extColumnName() throws RecognitionException {
		HiveParser.extColumnName_return retval = new HiveParser.extColumnName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token DOT847=null;
		Token KW_ELEM_TYPE848=null;
		Token KW_KEY_TYPE849=null;
		Token KW_VALUE_TYPE850=null;
		ParserRuleReturnScope identifier846 =null;
		ParserRuleReturnScope identifier851 =null;

		ASTNode DOT847_tree=null;
		ASTNode KW_ELEM_TYPE848_tree=null;
		ASTNode KW_KEY_TYPE849_tree=null;
		ASTNode KW_VALUE_TYPE850_tree=null;

		 pushMsg("column name for complex types", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2282:5: ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:7: identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_identifier_in_extColumnName13706);
			identifier846=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier846.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:18: ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
			loop253:
			while (true) {
				int alt253=2;
				int LA253_0 = input.LA(1);
				if ( (LA253_0==DOT) ) {
					alt253=1;
				}

				switch (alt253) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:19: DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
					{
					DOT847=(Token)match(input,DOT,FOLLOW_DOT_in_extColumnName13709); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					DOT847_tree = (ASTNode)adaptor.create(DOT847);
					root_0 = (ASTNode)adaptor.becomeRoot(DOT847_tree, root_0);
					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:24: ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
					int alt252=4;
					switch ( input.LA(1) ) {
					case KW_ELEM_TYPE:
						{
						int LA252_1 = input.LA(2);
						if ( (synpred19_HiveParser()) ) {
							alt252=1;
						}
						else if ( (true) ) {
							alt252=4;
						}

						}
						break;
					case KW_KEY_TYPE:
						{
						int LA252_2 = input.LA(2);
						if ( (synpred20_HiveParser()) ) {
							alt252=2;
						}
						else if ( (true) ) {
							alt252=4;
						}

						}
						break;
					case KW_VALUE_TYPE:
						{
						int LA252_3 = input.LA(2);
						if ( (synpred21_HiveParser()) ) {
							alt252=3;
						}
						else if ( (true) ) {
							alt252=4;
						}

						}
						break;
					case Identifier:
					case KW_ABORT:
					case KW_ACTIVATE:
					case KW_ACTIVE:
					case KW_ADD:
					case KW_ADMIN:
					case KW_AFTER:
					case KW_ALLOC_FRACTION:
					case KW_ANALYZE:
					case KW_ARCHIVE:
					case KW_ASC:
					case KW_AUTOCOMMIT:
					case KW_BEFORE:
					case KW_BUCKET:
					case KW_BUCKETS:
					case KW_CACHE:
					case KW_CASCADE:
					case KW_CBO:
					case KW_CHANGE:
					case KW_CHECK:
					case KW_CLUSTER:
					case KW_CLUSTERED:
					case KW_CLUSTERSTATUS:
					case KW_COLLECTION:
					case KW_COLUMNS:
					case KW_COMMENT:
					case KW_COMPACT:
					case KW_COMPACTIONS:
					case KW_COMPUTE:
					case KW_CONCATENATE:
					case KW_CONTINUE:
					case KW_COST:
					case KW_DATA:
					case KW_DATABASES:
					case KW_DATETIME:
					case KW_DAY:
					case KW_DBPROPERTIES:
					case KW_DEBUG:
					case KW_DEFAULT:
					case KW_DEFERRED:
					case KW_DEFINED:
					case KW_DELIMITED:
					case KW_DEPENDENCY:
					case KW_DESC:
					case KW_DETAIL:
					case KW_DIRECTORIES:
					case KW_DIRECTORY:
					case KW_DISABLE:
					case KW_DISTRIBUTE:
					case KW_DISTRIBUTED:
					case KW_DO:
					case KW_DOW:
					case KW_DUMP:
					case KW_ENABLE:
					case KW_ENFORCED:
					case KW_ESCAPED:
					case KW_EXCLUSIVE:
					case KW_EXPLAIN:
					case KW_EXPORT:
					case KW_EXPRESSION:
					case KW_FIELDS:
					case KW_FILE:
					case KW_FILEFORMAT:
					case KW_FIRST:
					case KW_FORMAT:
					case KW_FORMATTED:
					case KW_FUNCTIONS:
					case KW_HOUR:
					case KW_IDXPROPERTIES:
					case KW_INDEX:
					case KW_INDEXES:
					case KW_INPATH:
					case KW_INPUTDRIVER:
					case KW_INPUTFORMAT:
					case KW_ISOLATION:
					case KW_ITEMS:
					case KW_JAR:
					case KW_JOINCOST:
					case KW_KEY:
					case KW_KEYS:
					case KW_KILL:
					case KW_LAST:
					case KW_LEVEL:
					case KW_LIMIT:
					case KW_LINES:
					case KW_LOAD:
					case KW_LOCATION:
					case KW_LOCK:
					case KW_LOCKS:
					case KW_LOGICAL:
					case KW_LONG:
					case KW_MANAGEMENT:
					case KW_MAPJOIN:
					case KW_MAPPING:
					case KW_MATCHED:
					case KW_MATERIALIZED:
					case KW_METADATA:
					case KW_MINUTE:
					case KW_MONTH:
					case KW_MOVE:
					case KW_MSCK:
					case KW_NORELY:
					case KW_NOSCAN:
					case KW_NOVALIDATE:
					case KW_NULLS:
					case KW_OFFSET:
					case KW_OPERATOR:
					case KW_OPTION:
					case KW_OUTPUTDRIVER:
					case KW_OUTPUTFORMAT:
					case KW_OVERWRITE:
					case KW_OWNER:
					case KW_PARTITIONED:
					case KW_PARTITIONS:
					case KW_PATH:
					case KW_PLAN:
					case KW_PLANS:
					case KW_PLUS:
					case KW_POOL:
					case KW_PRINCIPALS:
					case KW_PURGE:
					case KW_QUARTER:
					case KW_QUERY:
					case KW_QUERY_PARALLELISM:
					case KW_READ:
					case KW_REBUILD:
					case KW_RECORDREADER:
					case KW_RECORDWRITER:
					case KW_RELOAD:
					case KW_RELY:
					case KW_RENAME:
					case KW_REOPTIMIZATION:
					case KW_REPAIR:
					case KW_REPL:
					case KW_REPLACE:
					case KW_REPLICATION:
					case KW_RESOURCE:
					case KW_RESTRICT:
					case KW_REWRITE:
					case KW_ROLE:
					case KW_ROLES:
					case KW_SCHEDULING_POLICY:
					case KW_SCHEMA:
					case KW_SCHEMAS:
					case KW_SECOND:
					case KW_SEMI:
					case KW_SERDE:
					case KW_SERDEPROPERTIES:
					case KW_SERVER:
					case KW_SETS:
					case KW_SHARED:
					case KW_SHOW:
					case KW_SHOW_DATABASE:
					case KW_SKEWED:
					case KW_SNAPSHOT:
					case KW_SORT:
					case KW_SORTED:
					case KW_SSL:
					case KW_STATISTICS:
					case KW_STATUS:
					case KW_STORED:
					case KW_STREAMTABLE:
					case KW_STRING:
					case KW_STRUCT:
					case KW_SUMMARY:
					case KW_TABLES:
					case KW_TBLPROPERTIES:
					case KW_TEMPORARY:
					case KW_TERMINATED:
					case KW_TINYINT:
					case KW_TOUCH:
					case KW_TRANSACTION:
					case KW_TRANSACTIONAL:
					case KW_TRANSACTIONS:
					case KW_UNARCHIVE:
					case KW_UNDO:
					case KW_UNIONTYPE:
					case KW_UNLOCK:
					case KW_UNMANAGED:
					case KW_UNSET:
					case KW_UNSIGNED:
					case KW_URI:
					case KW_USE:
					case KW_UTC:
					case KW_UTCTIMESTAMP:
					case KW_VALIDATE:
					case KW_VECTORIZATION:
					case KW_VIEW:
					case KW_VIEWS:
					case KW_WAIT:
					case KW_WEEK:
					case KW_WHILE:
					case KW_WORK:
					case KW_WORKLOAD:
					case KW_WRITE:
					case KW_YEAR:
					case KW_ZONE:
					case KW_BATCH:
					case KW_DAYOFWEEK:
					case KW_HOLD_DDLTIME:
					case KW_IGNORE:
					case KW_NO_DROP:
					case KW_OFFLINE:
					case KW_PROTECTION:
					case KW_READONLY:
					case KW_TIMESTAMPTZ:
						{
						alt252=4;
						}
						break;
					default:
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 252, 0, input);
						throw nvae;
					}
					switch (alt252) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:25: ( KW_ELEM_TYPE )=> KW_ELEM_TYPE
							{
							KW_ELEM_TYPE848=(Token)match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_extColumnName13719); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							KW_ELEM_TYPE848_tree = (ASTNode)adaptor.create(KW_ELEM_TYPE848);
							adaptor.addChild(root_0, KW_ELEM_TYPE848_tree);
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:58: ( KW_KEY_TYPE )=> KW_KEY_TYPE
							{
							KW_KEY_TYPE849=(Token)match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_extColumnName13729); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							KW_KEY_TYPE849_tree = (ASTNode)adaptor.create(KW_KEY_TYPE849);
							adaptor.addChild(root_0, KW_KEY_TYPE849_tree);
							}

							}
							break;
						case 3 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:89: ( KW_VALUE_TYPE )=> KW_VALUE_TYPE
							{
							KW_VALUE_TYPE850=(Token)match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_extColumnName13739); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							KW_VALUE_TYPE850_tree = (ASTNode)adaptor.create(KW_VALUE_TYPE850);
							adaptor.addChild(root_0, KW_VALUE_TYPE850_tree);
							}

							}
							break;
						case 4 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:124: identifier
							{
							pushFollow(FOLLOW_identifier_in_extColumnName13743);
							identifier851=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier851.getTree());

							}
							break;

					}

					}
					break;

				default :
					break loop253;
				}
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "extColumnName"


	public static class columnNameOrderList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameOrderList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2286:1: columnNameOrderList : columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) ;
	public final HiveParser.columnNameOrderList_return columnNameOrderList() throws RecognitionException {
		HiveParser.columnNameOrderList_return retval = new HiveParser.columnNameOrderList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA853=null;
		ParserRuleReturnScope columnNameOrder852 =null;
		ParserRuleReturnScope columnNameOrder854 =null;

		ASTNode COMMA853_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameOrder=new RewriteRuleSubtreeStream(adaptor,"rule columnNameOrder");

		 pushMsg("column name order list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2289:5: ( columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2289:7: columnNameOrder ( COMMA columnNameOrder )*
			{
			pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList13773);
			columnNameOrder852=columnNameOrder();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameOrder.add(columnNameOrder852.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2289:23: ( COMMA columnNameOrder )*
			loop254:
			while (true) {
				int alt254=2;
				int LA254_0 = input.LA(1);
				if ( (LA254_0==COMMA) ) {
					alt254=1;
				}

				switch (alt254) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2289:24: COMMA columnNameOrder
					{
					COMMA853=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameOrderList13776); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA853);

					pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList13778);
					columnNameOrder854=columnNameOrder();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameOrder.add(columnNameOrder854.getTree());
					}
					break;

				default :
					break loop254;
				}
			}

			// AST REWRITE
			// elements: columnNameOrder
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2289:48: -> ^( TOK_TABCOLNAME ( columnNameOrder )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2289:51: ^( TOK_TABCOLNAME ( columnNameOrder )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);
				if ( !(stream_columnNameOrder.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameOrder.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameOrder.nextTree());
				}
				stream_columnNameOrder.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameOrderList"


	public static class columnParenthesesList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnParenthesesList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2292:1: columnParenthesesList : LPAREN ! columnNameList RPAREN !;
	public final HiveParser.columnParenthesesList_return columnParenthesesList() throws RecognitionException {
		HiveParser.columnParenthesesList_return retval = new HiveParser.columnParenthesesList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN855=null;
		Token RPAREN857=null;
		ParserRuleReturnScope columnNameList856 =null;

		ASTNode LPAREN855_tree=null;
		ASTNode RPAREN857_tree=null;

		 pushMsg("column parentheses list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2295:5: ( LPAREN ! columnNameList RPAREN !)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2295:7: LPAREN ! columnNameList RPAREN !
			{
			root_0 = (ASTNode)adaptor.nil();


			LPAREN855=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_columnParenthesesList13816); if (state.failed) return retval;
			pushFollow(FOLLOW_columnNameList_in_columnParenthesesList13819);
			columnNameList856=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, columnNameList856.getTree());

			RPAREN857=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_columnParenthesesList13821); if (state.failed) return retval;
			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnParenthesesList"


	public static class enableValidateSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "enableValidateSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2298:1: enableValidateSpecification : ( enableSpecification ( validateSpecification )? | enforcedSpecification );
	public final HiveParser.enableValidateSpecification_return enableValidateSpecification() throws RecognitionException {
		HiveParser.enableValidateSpecification_return retval = new HiveParser.enableValidateSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope enableSpecification858 =null;
		ParserRuleReturnScope validateSpecification859 =null;
		ParserRuleReturnScope enforcedSpecification860 =null;


		 pushMsg("enable specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2301:5: ( enableSpecification ( validateSpecification )? | enforcedSpecification )
			int alt256=2;
			int LA256_0 = input.LA(1);
			if ( (LA256_0==KW_DISABLE||LA256_0==KW_ENABLE) ) {
				alt256=1;
			}
			else if ( (LA256_0==KW_ENFORCED||LA256_0==KW_NOT) ) {
				alt256=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 256, 0, input);
				throw nvae;
			}

			switch (alt256) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2301:7: enableSpecification ( validateSpecification )?
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_enableSpecification_in_enableValidateSpecification13849);
					enableSpecification858=enableSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, enableSpecification858.getTree());

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2301:27: ( validateSpecification )?
					int alt255=2;
					int LA255_0 = input.LA(1);
					if ( (LA255_0==KW_NOVALIDATE||LA255_0==KW_VALIDATE) ) {
						alt255=1;
					}
					switch (alt255) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2301:27: validateSpecification
							{
							pushFollow(FOLLOW_validateSpecification_in_enableValidateSpecification13851);
							validateSpecification859=validateSpecification();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, validateSpecification859.getTree());

							}
							break;

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2302:7: enforcedSpecification
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_enforcedSpecification_in_enableValidateSpecification13860);
					enforcedSpecification860=enforcedSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, enforcedSpecification860.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "enableValidateSpecification"


	public static class enableSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "enableSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2305:1: enableSpecification : ( KW_ENABLE -> ^( TOK_ENABLE ) | KW_DISABLE -> ^( TOK_DISABLE ) );
	public final HiveParser.enableSpecification_return enableSpecification() throws RecognitionException {
		HiveParser.enableSpecification_return retval = new HiveParser.enableSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ENABLE861=null;
		Token KW_DISABLE862=null;

		ASTNode KW_ENABLE861_tree=null;
		ASTNode KW_DISABLE862_tree=null;
		RewriteRuleTokenStream stream_KW_DISABLE=new RewriteRuleTokenStream(adaptor,"token KW_DISABLE");
		RewriteRuleTokenStream stream_KW_ENABLE=new RewriteRuleTokenStream(adaptor,"token KW_ENABLE");

		 pushMsg("enable specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2308:5: ( KW_ENABLE -> ^( TOK_ENABLE ) | KW_DISABLE -> ^( TOK_DISABLE ) )
			int alt257=2;
			int LA257_0 = input.LA(1);
			if ( (LA257_0==KW_ENABLE) ) {
				alt257=1;
			}
			else if ( (LA257_0==KW_DISABLE) ) {
				alt257=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 257, 0, input);
				throw nvae;
			}

			switch (alt257) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2308:7: KW_ENABLE
					{
					KW_ENABLE861=(Token)match(input,KW_ENABLE,FOLLOW_KW_ENABLE_in_enableSpecification13887); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ENABLE.add(KW_ENABLE861);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2308:17: -> ^( TOK_ENABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2308:20: ^( TOK_ENABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ENABLE, "TOK_ENABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2309:7: KW_DISABLE
					{
					KW_DISABLE862=(Token)match(input,KW_DISABLE,FOLLOW_KW_DISABLE_in_enableSpecification13901); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DISABLE.add(KW_DISABLE862);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2309:18: -> ^( TOK_DISABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2309:21: ^( TOK_DISABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DISABLE, "TOK_DISABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "enableSpecification"


	public static class validateSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "validateSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2312:1: validateSpecification : ( KW_VALIDATE -> ^( TOK_VALIDATE ) | KW_NOVALIDATE -> ^( TOK_NOVALIDATE ) );
	public final HiveParser.validateSpecification_return validateSpecification() throws RecognitionException {
		HiveParser.validateSpecification_return retval = new HiveParser.validateSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_VALIDATE863=null;
		Token KW_NOVALIDATE864=null;

		ASTNode KW_VALIDATE863_tree=null;
		ASTNode KW_NOVALIDATE864_tree=null;
		RewriteRuleTokenStream stream_KW_VALIDATE=new RewriteRuleTokenStream(adaptor,"token KW_VALIDATE");
		RewriteRuleTokenStream stream_KW_NOVALIDATE=new RewriteRuleTokenStream(adaptor,"token KW_NOVALIDATE");

		 pushMsg("validate specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2315:5: ( KW_VALIDATE -> ^( TOK_VALIDATE ) | KW_NOVALIDATE -> ^( TOK_NOVALIDATE ) )
			int alt258=2;
			int LA258_0 = input.LA(1);
			if ( (LA258_0==KW_VALIDATE) ) {
				alt258=1;
			}
			else if ( (LA258_0==KW_NOVALIDATE) ) {
				alt258=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 258, 0, input);
				throw nvae;
			}

			switch (alt258) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2315:7: KW_VALIDATE
					{
					KW_VALIDATE863=(Token)match(input,KW_VALIDATE,FOLLOW_KW_VALIDATE_in_validateSpecification13934); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VALIDATE.add(KW_VALIDATE863);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2315:19: -> ^( TOK_VALIDATE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2315:22: ^( TOK_VALIDATE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VALIDATE, "TOK_VALIDATE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2316:7: KW_NOVALIDATE
					{
					KW_NOVALIDATE864=(Token)match(input,KW_NOVALIDATE,FOLLOW_KW_NOVALIDATE_in_validateSpecification13948); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOVALIDATE.add(KW_NOVALIDATE864);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2316:21: -> ^( TOK_NOVALIDATE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2316:24: ^( TOK_NOVALIDATE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NOVALIDATE, "TOK_NOVALIDATE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "validateSpecification"


	public static class enforcedSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "enforcedSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2319:1: enforcedSpecification : ( KW_ENFORCED -> ^( TOK_ENABLE ) | KW_NOT KW_ENFORCED -> ^( TOK_DISABLE ) );
	public final HiveParser.enforcedSpecification_return enforcedSpecification() throws RecognitionException {
		HiveParser.enforcedSpecification_return retval = new HiveParser.enforcedSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ENFORCED865=null;
		Token KW_NOT866=null;
		Token KW_ENFORCED867=null;

		ASTNode KW_ENFORCED865_tree=null;
		ASTNode KW_NOT866_tree=null;
		ASTNode KW_ENFORCED867_tree=null;
		RewriteRuleTokenStream stream_KW_ENFORCED=new RewriteRuleTokenStream(adaptor,"token KW_ENFORCED");
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");

		 pushMsg("enforced specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2322:5: ( KW_ENFORCED -> ^( TOK_ENABLE ) | KW_NOT KW_ENFORCED -> ^( TOK_DISABLE ) )
			int alt259=2;
			int LA259_0 = input.LA(1);
			if ( (LA259_0==KW_ENFORCED) ) {
				alt259=1;
			}
			else if ( (LA259_0==KW_NOT) ) {
				alt259=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 259, 0, input);
				throw nvae;
			}

			switch (alt259) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2322:7: KW_ENFORCED
					{
					KW_ENFORCED865=(Token)match(input,KW_ENFORCED,FOLLOW_KW_ENFORCED_in_enforcedSpecification13981); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ENFORCED.add(KW_ENFORCED865);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2322:19: -> ^( TOK_ENABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2322:22: ^( TOK_ENABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ENABLE, "TOK_ENABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2323:7: KW_NOT KW_ENFORCED
					{
					KW_NOT866=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_enforcedSpecification13995); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT866);

					KW_ENFORCED867=(Token)match(input,KW_ENFORCED,FOLLOW_KW_ENFORCED_in_enforcedSpecification13997); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ENFORCED.add(KW_ENFORCED867);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2323:26: -> ^( TOK_DISABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2323:29: ^( TOK_DISABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DISABLE, "TOK_DISABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "enforcedSpecification"


	public static class relySpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "relySpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2326:1: relySpecification : ( KW_RELY -> ^( TOK_RELY ) | KW_NORELY -> ^( TOK_NORELY ) );
	public final HiveParser.relySpecification_return relySpecification() throws RecognitionException {
		HiveParser.relySpecification_return retval = new HiveParser.relySpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RELY868=null;
		Token KW_NORELY869=null;

		ASTNode KW_RELY868_tree=null;
		ASTNode KW_NORELY869_tree=null;
		RewriteRuleTokenStream stream_KW_NORELY=new RewriteRuleTokenStream(adaptor,"token KW_NORELY");
		RewriteRuleTokenStream stream_KW_RELY=new RewriteRuleTokenStream(adaptor,"token KW_RELY");

		 pushMsg("rely specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2329:5: ( KW_RELY -> ^( TOK_RELY ) | KW_NORELY -> ^( TOK_NORELY ) )
			int alt260=2;
			int LA260_0 = input.LA(1);
			if ( (LA260_0==KW_RELY) ) {
				alt260=1;
			}
			else if ( (LA260_0==KW_NORELY) ) {
				alt260=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 260, 0, input);
				throw nvae;
			}

			switch (alt260) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2329:8: KW_RELY
					{
					KW_RELY868=(Token)match(input,KW_RELY,FOLLOW_KW_RELY_in_relySpecification14031); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RELY.add(KW_RELY868);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2329:16: -> ^( TOK_RELY )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2329:19: ^( TOK_RELY )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RELY, "TOK_RELY"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2330:8: KW_NORELY
					{
					KW_NORELY869=(Token)match(input,KW_NORELY,FOLLOW_KW_NORELY_in_relySpecification14046); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NORELY.add(KW_NORELY869);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2330:18: -> ^( TOK_NORELY )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2330:21: ^( TOK_NORELY )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NORELY, "TOK_NORELY"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "relySpecification"


	public static class createConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2333:1: createConstraint : ( KW_CONSTRAINT constraintName= identifier )? tableLevelConstraint ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) ;
	public final HiveParser.createConstraint_return createConstraint() throws RecognitionException {
		HiveParser.createConstraint_return retval = new HiveParser.createConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT870=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tableLevelConstraint871 =null;
		ParserRuleReturnScope constraintOptsCreate872 =null;

		ASTNode KW_CONSTRAINT870_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableLevelConstraint=new RewriteRuleSubtreeStream(adaptor,"rule tableLevelConstraint");

		 pushMsg("pk or uk or nn constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2336:5: ( ( KW_CONSTRAINT constraintName= identifier )? tableLevelConstraint ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2336:7: ( KW_CONSTRAINT constraintName= identifier )? tableLevelConstraint ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2336:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt261=2;
			int LA261_0 = input.LA(1);
			if ( (LA261_0==KW_CONSTRAINT) ) {
				alt261=1;
			}
			switch (alt261) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2336:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT870=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_createConstraint14080); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT870);

					pushFollow(FOLLOW_identifier_in_createConstraint14084);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableLevelConstraint_in_createConstraint14088);
			tableLevelConstraint871=tableLevelConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableLevelConstraint.add(tableLevelConstraint871.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2336:71: ( constraintOptsCreate )?
			int alt262=2;
			int LA262_0 = input.LA(1);
			if ( (LA262_0==KW_DISABLE||LA262_0==KW_ENABLE||LA262_0==KW_ENFORCED||LA262_0==KW_NOT) ) {
				alt262=1;
			}
			switch (alt262) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2336:71: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_createConstraint14090);
					constraintOptsCreate872=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate872.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsCreate, constraintOptsCreate, constraintName
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2337:5: -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2338:13: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((tableLevelConstraint871!=null?((ASTNode)tableLevelConstraint871.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2338:44: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2338:83: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2339:5: -> ^( ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2339:8: ^( ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((tableLevelConstraint871!=null?((ASTNode)tableLevelConstraint871.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2339:39: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createConstraint"


	public static class alterConstraintWithName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterConstraintWithName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2342:1: alterConstraintWithName : KW_CONSTRAINT constraintName= identifier tableLevelConstraint ( constraintOptsAlter )? -> ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) ;
	public final HiveParser.alterConstraintWithName_return alterConstraintWithName() throws RecognitionException {
		HiveParser.alterConstraintWithName_return retval = new HiveParser.alterConstraintWithName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT873=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tableLevelConstraint874 =null;
		ParserRuleReturnScope constraintOptsAlter875 =null;

		ASTNode KW_CONSTRAINT873_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableLevelConstraint=new RewriteRuleSubtreeStream(adaptor,"rule tableLevelConstraint");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");

		 pushMsg("pk or uk or nn constraint with name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2345:5: ( KW_CONSTRAINT constraintName= identifier tableLevelConstraint ( constraintOptsAlter )? -> ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2345:7: KW_CONSTRAINT constraintName= identifier tableLevelConstraint ( constraintOptsAlter )?
			{
			KW_CONSTRAINT873=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterConstraintWithName14165); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT873);

			pushFollow(FOLLOW_identifier_in_alterConstraintWithName14169);
			constraintName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
			pushFollow(FOLLOW_tableLevelConstraint_in_alterConstraintWithName14171);
			tableLevelConstraint874=tableLevelConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableLevelConstraint.add(tableLevelConstraint874.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2345:68: ( constraintOptsAlter )?
			int alt263=2;
			int LA263_0 = input.LA(1);
			if ( (LA263_0==KW_DISABLE||LA263_0==KW_ENABLE||LA263_0==KW_ENFORCED||LA263_0==KW_NOT) ) {
				alt263=1;
			}
			switch (alt263) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2345:68: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterConstraintWithName14173);
					constraintOptsAlter875=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter875.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintName, constraintOptsAlter
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2346:5: -> ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2346:7: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((tableLevelConstraint874!=null?((ASTNode)tableLevelConstraint874.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2346:38: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2346:77: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterConstraintWithName"


	public static class tableLevelConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableLevelConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2349:1: tableLevelConstraint : ( pkUkConstraint | checkConstraint );
	public final HiveParser.tableLevelConstraint_return tableLevelConstraint() throws RecognitionException {
		HiveParser.tableLevelConstraint_return retval = new HiveParser.tableLevelConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope pkUkConstraint876 =null;
		ParserRuleReturnScope checkConstraint877 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2350:5: ( pkUkConstraint | checkConstraint )
			int alt264=2;
			int LA264_0 = input.LA(1);
			if ( (LA264_0==KW_PRIMARY||LA264_0==KW_UNIQUE) ) {
				alt264=1;
			}
			else if ( (LA264_0==KW_CHECK) ) {
				alt264=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 264, 0, input);
				throw nvae;
			}

			switch (alt264) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2350:7: pkUkConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_pkUkConstraint_in_tableLevelConstraint14210);
					pkUkConstraint876=pkUkConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, pkUkConstraint876.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2351:7: checkConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_checkConstraint_in_tableLevelConstraint14218);
					checkConstraint877=checkConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, checkConstraint877.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableLevelConstraint"


	public static class pkUkConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "pkUkConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2354:1: pkUkConstraint : tableConstraintType pkCols= columnParenthesesList -> ^( tableConstraintType $pkCols) ;
	public final HiveParser.pkUkConstraint_return pkUkConstraint() throws RecognitionException {
		HiveParser.pkUkConstraint_return retval = new HiveParser.pkUkConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope pkCols =null;
		ParserRuleReturnScope tableConstraintType878 =null;

		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_tableConstraintType=new RewriteRuleSubtreeStream(adaptor,"rule tableConstraintType");

		 pushMsg("pk or uk table level constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2357:5: ( tableConstraintType pkCols= columnParenthesesList -> ^( tableConstraintType $pkCols) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2357:7: tableConstraintType pkCols= columnParenthesesList
			{
			pushFollow(FOLLOW_tableConstraintType_in_pkUkConstraint14245);
			tableConstraintType878=tableConstraintType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableConstraintType.add(tableConstraintType878.getTree());
			pushFollow(FOLLOW_columnParenthesesList_in_pkUkConstraint14249);
			pkCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(pkCols.getTree());
			// AST REWRITE
			// elements: tableConstraintType, pkCols
			// token labels: 
			// rule labels: pkCols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_pkCols=new RewriteRuleSubtreeStream(adaptor,"rule pkCols",pkCols!=null?pkCols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2358:5: -> ^( tableConstraintType $pkCols)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2358:8: ^( tableConstraintType $pkCols)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_tableConstraintType.nextNode(), root_1);
				adaptor.addChild(root_1, stream_pkCols.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "pkUkConstraint"


	public static class checkConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "checkConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2361:1: checkConstraint : KW_CHECK LPAREN expression RPAREN -> ^( TOK_CHECK_CONSTRAINT expression ) ;
	public final HiveParser.checkConstraint_return checkConstraint() throws RecognitionException {
		HiveParser.checkConstraint_return retval = new HiveParser.checkConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CHECK879=null;
		Token LPAREN880=null;
		Token RPAREN882=null;
		ParserRuleReturnScope expression881 =null;

		ASTNode KW_CHECK879_tree=null;
		ASTNode LPAREN880_tree=null;
		ASTNode RPAREN882_tree=null;
		RewriteRuleTokenStream stream_KW_CHECK=new RewriteRuleTokenStream(adaptor,"token KW_CHECK");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");

		 pushMsg("CHECK constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2364:5: ( KW_CHECK LPAREN expression RPAREN -> ^( TOK_CHECK_CONSTRAINT expression ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2364:7: KW_CHECK LPAREN expression RPAREN
			{
			KW_CHECK879=(Token)match(input,KW_CHECK,FOLLOW_KW_CHECK_in_checkConstraint14289); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CHECK.add(KW_CHECK879);

			LPAREN880=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_checkConstraint14291); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN880);

			pushFollow(FOLLOW_expression_in_checkConstraint14293);
			expression881=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression881.getTree());
			RPAREN882=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_checkConstraint14295); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN882);

			// AST REWRITE
			// elements: expression
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2365:5: -> ^( TOK_CHECK_CONSTRAINT expression )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2365:8: ^( TOK_CHECK_CONSTRAINT expression )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CHECK_CONSTRAINT, "TOK_CHECK_CONSTRAINT"), root_1);
				adaptor.addChild(root_1, stream_expression.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "checkConstraint"


	public static class createForeignKey_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createForeignKey"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2368:1: createForeignKey : ( KW_CONSTRAINT constraintName= identifier )? KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? ) ;
	public final HiveParser.createForeignKey_return createForeignKey() throws RecognitionException {
		HiveParser.createForeignKey_return retval = new HiveParser.createForeignKey_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT883=null;
		Token KW_FOREIGN884=null;
		Token KW_KEY885=null;
		Token KW_REFERENCES886=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope fkCols =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope parCols =null;
		ParserRuleReturnScope constraintOptsCreate887 =null;

		ASTNode KW_CONSTRAINT883_tree=null;
		ASTNode KW_FOREIGN884_tree=null;
		ASTNode KW_KEY885_tree=null;
		ASTNode KW_REFERENCES886_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleTokenStream stream_KW_FOREIGN=new RewriteRuleTokenStream(adaptor,"token KW_FOREIGN");
		RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("foreign key", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2371:5: ( ( KW_CONSTRAINT constraintName= identifier )? KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2371:7: ( KW_CONSTRAINT constraintName= identifier )? KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2371:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt265=2;
			int LA265_0 = input.LA(1);
			if ( (LA265_0==KW_CONSTRAINT) ) {
				alt265=1;
			}
			switch (alt265) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2371:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT883=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_createForeignKey14335); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT883);

					pushFollow(FOLLOW_identifier_in_createForeignKey14339);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			KW_FOREIGN884=(Token)match(input,KW_FOREIGN,FOLLOW_KW_FOREIGN_in_createForeignKey14343); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOREIGN.add(KW_FOREIGN884);

			KW_KEY885=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_createForeignKey14345); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY885);

			pushFollow(FOLLOW_columnParenthesesList_in_createForeignKey14349);
			fkCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(fkCols.getTree());
			KW_REFERENCES886=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_createForeignKey14352); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES886);

			pushFollow(FOLLOW_tableName_in_createForeignKey14356);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			pushFollow(FOLLOW_columnParenthesesList_in_createForeignKey14360);
			parCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(parCols.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2371:160: ( constraintOptsCreate )?
			int alt266=2;
			int LA266_0 = input.LA(1);
			if ( (LA266_0==KW_DISABLE||LA266_0==KW_ENABLE||LA266_0==KW_ENFORCED||LA266_0==KW_NOT) ) {
				alt266=1;
			}
			switch (alt266) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2371:160: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_createForeignKey14362);
					constraintOptsCreate887=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate887.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsCreate, parCols, tabName, fkCols, fkCols, tabName, constraintOptsCreate, constraintName, parCols
			// token labels: 
			// rule labels: parCols, tabName, fkCols, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_parCols=new RewriteRuleSubtreeStream(adaptor,"rule parCols",parCols!=null?parCols.getTree():null);
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_fkCols=new RewriteRuleSubtreeStream(adaptor,"rule fkCols",fkCols!=null?fkCols.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2372:5: -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2373:13: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2373:31: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_fkCols.nextTree());
				adaptor.addChild(root_1, stream_tabName.nextTree());
				adaptor.addChild(root_1, stream_parCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2373:96: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2374:5: -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:8: ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				adaptor.addChild(root_1, stream_fkCols.nextTree());
				adaptor.addChild(root_1, stream_tabName.nextTree());
				adaptor.addChild(root_1, stream_parCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:52: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createForeignKey"


	public static class alterForeignKeyWithName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterForeignKeyWithName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2377:1: alterForeignKeyWithName : KW_CONSTRAINT constraintName= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsAlter )? -> ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? ) ;
	public final HiveParser.alterForeignKeyWithName_return alterForeignKeyWithName() throws RecognitionException {
		HiveParser.alterForeignKeyWithName_return retval = new HiveParser.alterForeignKeyWithName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT888=null;
		Token KW_FOREIGN889=null;
		Token KW_KEY890=null;
		Token KW_REFERENCES891=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope fkCols =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope parCols =null;
		ParserRuleReturnScope constraintOptsAlter892 =null;

		ASTNode KW_CONSTRAINT888_tree=null;
		ASTNode KW_FOREIGN889_tree=null;
		ASTNode KW_KEY890_tree=null;
		ASTNode KW_REFERENCES891_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleTokenStream stream_KW_FOREIGN=new RewriteRuleTokenStream(adaptor,"token KW_FOREIGN");
		RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");
		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("foreign key with key name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:5: ( KW_CONSTRAINT constraintName= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsAlter )? -> ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:7: KW_CONSTRAINT constraintName= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsAlter )?
			{
			KW_CONSTRAINT888=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterForeignKeyWithName14455); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT888);

			pushFollow(FOLLOW_identifier_in_alterForeignKeyWithName14459);
			constraintName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
			KW_FOREIGN889=(Token)match(input,KW_FOREIGN,FOLLOW_KW_FOREIGN_in_alterForeignKeyWithName14461); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOREIGN.add(KW_FOREIGN889);

			KW_KEY890=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_alterForeignKeyWithName14463); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY890);

			pushFollow(FOLLOW_columnParenthesesList_in_alterForeignKeyWithName14467);
			fkCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(fkCols.getTree());
			KW_REFERENCES891=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_alterForeignKeyWithName14470); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES891);

			pushFollow(FOLLOW_tableName_in_alterForeignKeyWithName14474);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			pushFollow(FOLLOW_columnParenthesesList_in_alterForeignKeyWithName14478);
			parCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(parCols.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:157: ( constraintOptsAlter )?
			int alt267=2;
			int LA267_0 = input.LA(1);
			if ( (LA267_0==KW_DISABLE||LA267_0==KW_ENABLE||LA267_0==KW_ENFORCED||LA267_0==KW_NOT) ) {
				alt267=1;
			}
			switch (alt267) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:157: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterForeignKeyWithName14480);
					constraintOptsAlter892=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter892.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: parCols, fkCols, constraintName, tabName, constraintOptsAlter
			// token labels: 
			// rule labels: parCols, tabName, fkCols, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_parCols=new RewriteRuleSubtreeStream(adaptor,"rule parCols",parCols!=null?parCols.getTree():null);
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_fkCols=new RewriteRuleSubtreeStream(adaptor,"rule fkCols",fkCols!=null?fkCols.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2381:5: -> ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2381:8: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2381:26: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_fkCols.nextTree());
				adaptor.addChild(root_1, stream_tabName.nextTree());
				adaptor.addChild(root_1, stream_parCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2381:91: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterForeignKeyWithName"


	public static class skewedValueElement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedValueElement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2384:1: skewedValueElement : ( skewedColumnValues | skewedColumnValuePairList );
	public final HiveParser.skewedValueElement_return skewedValueElement() throws RecognitionException {
		HiveParser.skewedValueElement_return retval = new HiveParser.skewedValueElement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope skewedColumnValues893 =null;
		ParserRuleReturnScope skewedColumnValuePairList894 =null;


		 pushMsg("skewed value element", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2387:5: ( skewedColumnValues | skewedColumnValuePairList )
			int alt268=2;
			int LA268_0 = input.LA(1);
			if ( (LA268_0==CharSetName||LA268_0==IntegralLiteral||(LA268_0 >= KW_CURRENT_DATE && LA268_0 <= KW_CURRENT_TIMESTAMP)||LA268_0==KW_DATE||LA268_0==KW_FALSE||LA268_0==KW_NULL||(LA268_0 >= KW_TIMESTAMP && LA268_0 <= KW_TIMESTAMPLOCALTZ)||LA268_0==KW_TRUE||(LA268_0 >= Number && LA268_0 <= NumberLiteral)||LA268_0==StringLiteral) ) {
				alt268=1;
			}
			else if ( (LA268_0==LPAREN) ) {
				alt268=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 268, 0, input);
				throw nvae;
			}

			switch (alt268) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2388:7: skewedColumnValues
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValues_in_skewedValueElement14544);
					skewedColumnValues893=skewedColumnValues();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValues893.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2389:8: skewedColumnValuePairList
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValuePairList_in_skewedValueElement14553);
					skewedColumnValuePairList894=skewedColumnValuePairList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValuePairList894.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedValueElement"


	public static class skewedColumnValuePairList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValuePairList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:1: skewedColumnValuePairList : skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) ;
	public final HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList() throws RecognitionException {
		HiveParser.skewedColumnValuePairList_return retval = new HiveParser.skewedColumnValuePairList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA896=null;
		ParserRuleReturnScope skewedColumnValuePair895 =null;
		ParserRuleReturnScope skewedColumnValuePair897 =null;

		ASTNode COMMA896_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_skewedColumnValuePair=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValuePair");

		 pushMsg("column value pair list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2395:5: ( skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2395:7: skewedColumnValuePair ( COMMA skewedColumnValuePair )*
			{
			pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList14580);
			skewedColumnValuePair895=skewedColumnValuePair();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedColumnValuePair.add(skewedColumnValuePair895.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2395:29: ( COMMA skewedColumnValuePair )*
			loop269:
			while (true) {
				int alt269=2;
				int LA269_0 = input.LA(1);
				if ( (LA269_0==COMMA) ) {
					alt269=1;
				}

				switch (alt269) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2395:30: COMMA skewedColumnValuePair
					{
					COMMA896=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedColumnValuePairList14583); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA896);

					pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList14585);
					skewedColumnValuePair897=skewedColumnValuePair();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_skewedColumnValuePair.add(skewedColumnValuePair897.getTree());
					}
					break;

				default :
					break loop269;
				}
			}

			// AST REWRITE
			// elements: skewedColumnValuePair
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2395:60: -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2395:63: ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLVALUE_PAIR, "TOK_TABCOLVALUE_PAIR"), root_1);
				if ( !(stream_skewedColumnValuePair.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_skewedColumnValuePair.hasNext() ) {
					adaptor.addChild(root_1, stream_skewedColumnValuePair.nextTree());
				}
				stream_skewedColumnValuePair.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValuePairList"


	public static class skewedColumnValuePair_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValuePair"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2398:1: skewedColumnValuePair : LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) ;
	public final HiveParser.skewedColumnValuePair_return skewedColumnValuePair() throws RecognitionException {
		HiveParser.skewedColumnValuePair_return retval = new HiveParser.skewedColumnValuePair_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN898=null;
		Token RPAREN899=null;
		ParserRuleReturnScope colValues =null;

		ASTNode LPAREN898_tree=null;
		ASTNode RPAREN899_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_skewedColumnValues=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValues");

		 pushMsg("column value pair", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2401:5: ( LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2402:7: LPAREN colValues= skewedColumnValues RPAREN
			{
			LPAREN898=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_skewedColumnValuePair14630); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN898);

			pushFollow(FOLLOW_skewedColumnValues_in_skewedColumnValuePair14634);
			colValues=skewedColumnValues();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedColumnValues.add(colValues.getTree());
			RPAREN899=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_skewedColumnValuePair14636); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN899);

			// AST REWRITE
			// elements: colValues
			// token labels: 
			// rule labels: colValues, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colValues=new RewriteRuleSubtreeStream(adaptor,"rule colValues",colValues!=null?colValues.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2403:7: -> ^( TOK_TABCOLVALUES $colValues)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2403:10: ^( TOK_TABCOLVALUES $colValues)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLVALUES, "TOK_TABCOLVALUES"), root_1);
				adaptor.addChild(root_1, stream_colValues.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValuePair"


	public static class skewedColumnValues_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValues"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:1: skewedColumnValues : skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) ;
	public final HiveParser.skewedColumnValues_return skewedColumnValues() throws RecognitionException {
		HiveParser.skewedColumnValues_return retval = new HiveParser.skewedColumnValues_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA901=null;
		ParserRuleReturnScope skewedColumnValue900 =null;
		ParserRuleReturnScope skewedColumnValue902 =null;

		ASTNode COMMA901_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_skewedColumnValue=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValue");

		 pushMsg("column values", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2409:5: ( skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2409:7: skewedColumnValue ( COMMA skewedColumnValue )*
			{
			pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues14679);
			skewedColumnValue900=skewedColumnValue();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedColumnValue.add(skewedColumnValue900.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2409:25: ( COMMA skewedColumnValue )*
			loop270:
			while (true) {
				int alt270=2;
				int LA270_0 = input.LA(1);
				if ( (LA270_0==COMMA) ) {
					alt270=1;
				}

				switch (alt270) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2409:26: COMMA skewedColumnValue
					{
					COMMA901=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedColumnValues14682); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA901);

					pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues14684);
					skewedColumnValue902=skewedColumnValue();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_skewedColumnValue.add(skewedColumnValue902.getTree());
					}
					break;

				default :
					break loop270;
				}
			}

			// AST REWRITE
			// elements: skewedColumnValue
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2409:52: -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2409:55: ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLVALUE, "TOK_TABCOLVALUE"), root_1);
				if ( !(stream_skewedColumnValue.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_skewedColumnValue.hasNext() ) {
					adaptor.addChild(root_1, stream_skewedColumnValue.nextTree());
				}
				stream_skewedColumnValue.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValues"


	public static class skewedColumnValue_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValue"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2412:1: skewedColumnValue : constant ;
	public final HiveParser.skewedColumnValue_return skewedColumnValue() throws RecognitionException {
		HiveParser.skewedColumnValue_return retval = new HiveParser.skewedColumnValue_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope constant903 =null;


		 pushMsg("column value", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2415:5: ( constant )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2416:7: constant
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_constant_in_skewedColumnValue14728);
			constant903=constant();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, constant903.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValue"


	public static class skewedValueLocationElement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedValueLocationElement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2419:1: skewedValueLocationElement : ( skewedColumnValue | skewedColumnValuePair );
	public final HiveParser.skewedValueLocationElement_return skewedValueLocationElement() throws RecognitionException {
		HiveParser.skewedValueLocationElement_return retval = new HiveParser.skewedValueLocationElement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope skewedColumnValue904 =null;
		ParserRuleReturnScope skewedColumnValuePair905 =null;


		 pushMsg("skewed value location element", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2422:5: ( skewedColumnValue | skewedColumnValuePair )
			int alt271=2;
			int LA271_0 = input.LA(1);
			if ( (LA271_0==CharSetName||LA271_0==IntegralLiteral||(LA271_0 >= KW_CURRENT_DATE && LA271_0 <= KW_CURRENT_TIMESTAMP)||LA271_0==KW_DATE||LA271_0==KW_FALSE||LA271_0==KW_NULL||(LA271_0 >= KW_TIMESTAMP && LA271_0 <= KW_TIMESTAMPLOCALTZ)||LA271_0==KW_TRUE||(LA271_0 >= Number && LA271_0 <= NumberLiteral)||LA271_0==StringLiteral) ) {
				alt271=1;
			}
			else if ( (LA271_0==LPAREN) ) {
				alt271=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 271, 0, input);
				throw nvae;
			}

			switch (alt271) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2423:7: skewedColumnValue
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValue_in_skewedValueLocationElement14762);
					skewedColumnValue904=skewedColumnValue();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValue904.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2424:8: skewedColumnValuePair
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement14771);
					skewedColumnValuePair905=skewedColumnValuePair();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValuePair905.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedValueLocationElement"


	public static class orderSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "orderSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2427:1: orderSpecification : ( KW_ASC | KW_DESC );
	public final HiveParser.orderSpecification_return orderSpecification() throws RecognitionException {
		HiveParser.orderSpecification_return retval = new HiveParser.orderSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token set906=null;

		ASTNode set906_tree=null;

		 pushMsg("order specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2430:5: ( KW_ASC | KW_DESC )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:
			{
			root_0 = (ASTNode)adaptor.nil();


			set906=input.LT(1);
			if ( input.LA(1)==KW_ASC||input.LA(1)==KW_DESC ) {
				input.consume();
				if ( state.backtracking==0 ) adaptor.addChild(root_0, (ASTNode)adaptor.create(set906));
				state.errorRecovery=false;
				state.failed=false;
			}
			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				MismatchedSetException mse = new MismatchedSetException(null,input);
				throw mse;
			}
			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "orderSpecification"


	public static class nullOrdering_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "nullOrdering"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2432:1: nullOrdering : ( KW_NULLS KW_FIRST -> ^( TOK_NULLS_FIRST ) | KW_NULLS KW_LAST -> ^( TOK_NULLS_LAST ) );
	public final HiveParser.nullOrdering_return nullOrdering() throws RecognitionException {
		HiveParser.nullOrdering_return retval = new HiveParser.nullOrdering_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_NULLS907=null;
		Token KW_FIRST908=null;
		Token KW_NULLS909=null;
		Token KW_LAST910=null;

		ASTNode KW_NULLS907_tree=null;
		ASTNode KW_FIRST908_tree=null;
		ASTNode KW_NULLS909_tree=null;
		ASTNode KW_LAST910_tree=null;
		RewriteRuleTokenStream stream_KW_FIRST=new RewriteRuleTokenStream(adaptor,"token KW_FIRST");
		RewriteRuleTokenStream stream_KW_NULLS=new RewriteRuleTokenStream(adaptor,"token KW_NULLS");
		RewriteRuleTokenStream stream_KW_LAST=new RewriteRuleTokenStream(adaptor,"token KW_LAST");

		 pushMsg("nulls ordering", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2435:5: ( KW_NULLS KW_FIRST -> ^( TOK_NULLS_FIRST ) | KW_NULLS KW_LAST -> ^( TOK_NULLS_LAST ) )
			int alt272=2;
			int LA272_0 = input.LA(1);
			if ( (LA272_0==KW_NULLS) ) {
				int LA272_1 = input.LA(2);
				if ( (LA272_1==KW_FIRST) ) {
					alt272=1;
				}
				else if ( (LA272_1==KW_LAST) ) {
					alt272=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 272, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 272, 0, input);
				throw nvae;
			}

			switch (alt272) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2435:7: KW_NULLS KW_FIRST
					{
					KW_NULLS907=(Token)match(input,KW_NULLS,FOLLOW_KW_NULLS_in_nullOrdering14825); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NULLS.add(KW_NULLS907);

					KW_FIRST908=(Token)match(input,KW_FIRST,FOLLOW_KW_FIRST_in_nullOrdering14827); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FIRST.add(KW_FIRST908);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2435:25: -> ^( TOK_NULLS_FIRST )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2435:28: ^( TOK_NULLS_FIRST )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2436:7: KW_NULLS KW_LAST
					{
					KW_NULLS909=(Token)match(input,KW_NULLS,FOLLOW_KW_NULLS_in_nullOrdering14841); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NULLS.add(KW_NULLS909);

					KW_LAST910=(Token)match(input,KW_LAST,FOLLOW_KW_LAST_in_nullOrdering14843); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LAST.add(KW_LAST910);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2436:24: -> ^( TOK_NULLS_LAST )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2436:27: ^( TOK_NULLS_LAST )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "nullOrdering"


	public static class columnNameOrder_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameOrder"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2439:1: columnNameOrder : identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) ) -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) ) ;
	public final HiveParser.columnNameOrder_return columnNameOrder() throws RecognitionException {
		HiveParser.columnNameOrder_return retval = new HiveParser.columnNameOrder_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope orderSpec =null;
		ParserRuleReturnScope nullSpec =null;
		ParserRuleReturnScope identifier911 =null;

		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_nullOrdering=new RewriteRuleSubtreeStream(adaptor,"rule nullOrdering");
		RewriteRuleSubtreeStream stream_orderSpecification=new RewriteRuleSubtreeStream(adaptor,"rule orderSpecification");

		 pushMsg("column name order", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2442:5: ( identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) ) -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2442:7: identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameOrder14876);
			identifier911=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier911.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2442:27: (orderSpec= orderSpecification )?
			int alt273=2;
			int LA273_0 = input.LA(1);
			if ( (LA273_0==KW_ASC||LA273_0==KW_DESC) ) {
				alt273=1;
			}
			switch (alt273) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2442:27: orderSpec= orderSpecification
					{
					pushFollow(FOLLOW_orderSpecification_in_columnNameOrder14880);
					orderSpec=orderSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orderSpecification.add(orderSpec.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2442:56: (nullSpec= nullOrdering )?
			int alt274=2;
			int LA274_0 = input.LA(1);
			if ( (LA274_0==KW_NULLS) ) {
				alt274=1;
			}
			switch (alt274) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2442:56: nullSpec= nullOrdering
					{
					pushFollow(FOLLOW_nullOrdering_in_columnNameOrder14885);
					nullSpec=nullOrdering();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_nullOrdering.add(nullSpec.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: identifier, identifier, nullSpec, nullSpec, identifier, identifier, identifier, identifier, nullSpec
			// token labels: 
			// rule labels: nullSpec, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_nullSpec=new RewriteRuleSubtreeStream(adaptor,"rule nullSpec",nullSpec!=null?nullSpec.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2443:5: -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null && (nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2444:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2444:37: ^( TOK_NULLS_FIRST identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2445:5: -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2446:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2446:37: ^( $nullSpec identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2447:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && (orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType()==HiveParser.KW_ASC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2448:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2448:37: ^( TOK_NULLS_FIRST identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2449:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && (orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType()==HiveParser.KW_DESC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2450:13: ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2450:38: ^( TOK_NULLS_LAST identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2451:5: -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType()==HiveParser.KW_ASC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2452:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2452:37: ^( $nullSpec identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2453:5: -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2453:8: ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2453:33: ^( $nullSpec identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameOrder"


	public static class columnNameCommentList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameCommentList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2456:1: columnNameCommentList : columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) ;
	public final HiveParser.columnNameCommentList_return columnNameCommentList() throws RecognitionException {
		HiveParser.columnNameCommentList_return retval = new HiveParser.columnNameCommentList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA913=null;
		ParserRuleReturnScope columnNameComment912 =null;
		ParserRuleReturnScope columnNameComment914 =null;

		ASTNode COMMA913_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameComment=new RewriteRuleSubtreeStream(adaptor,"rule columnNameComment");

		 pushMsg("column name comment list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:5: ( columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:7: columnNameComment ( COMMA columnNameComment )*
			{
			pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList15082);
			columnNameComment912=columnNameComment();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameComment.add(columnNameComment912.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:25: ( COMMA columnNameComment )*
			loop275:
			while (true) {
				int alt275=2;
				int LA275_0 = input.LA(1);
				if ( (LA275_0==COMMA) ) {
					alt275=1;
				}

				switch (alt275) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:26: COMMA columnNameComment
					{
					COMMA913=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameCommentList15085); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA913);

					pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList15087);
					columnNameComment914=columnNameComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameComment.add(columnNameComment914.getTree());
					}
					break;

				default :
					break loop275;
				}
			}

			// AST REWRITE
			// elements: columnNameComment
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2459:52: -> ^( TOK_TABCOLNAME ( columnNameComment )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:55: ^( TOK_TABCOLNAME ( columnNameComment )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);
				if ( !(stream_columnNameComment.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameComment.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameComment.nextTree());
				}
				stream_columnNameComment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameCommentList"


	public static class columnNameComment_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameComment"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2462:1: columnNameComment : colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) ;
	public final HiveParser.columnNameComment_return columnNameComment() throws RecognitionException {
		HiveParser.columnNameComment_return retval = new HiveParser.columnNameComment_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT915=null;
		ParserRuleReturnScope colName =null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT915_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("column name comment", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2465:5: (colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2465:7: colName= identifier ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameComment15127);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2465:26: ( KW_COMMENT comment= StringLiteral )?
			int alt276=2;
			int LA276_0 = input.LA(1);
			if ( (LA276_0==KW_COMMENT) ) {
				alt276=1;
			}
			switch (alt276) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2465:27: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT915=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameComment15130); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT915);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameComment15134); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: comment, colName
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2466:5: -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2466:8: ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_NULL, "TOK_NULL"));
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2466:40: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameComment"


	public static class orderSpecificationRewrite_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "orderSpecificationRewrite"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2469:1: orderSpecificationRewrite : ( KW_ASC -> ^( TOK_TABSORTCOLNAMEASC ) | KW_DESC -> ^( TOK_TABSORTCOLNAMEDESC ) );
	public final HiveParser.orderSpecificationRewrite_return orderSpecificationRewrite() throws RecognitionException {
		HiveParser.orderSpecificationRewrite_return retval = new HiveParser.orderSpecificationRewrite_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ASC916=null;
		Token KW_DESC917=null;

		ASTNode KW_ASC916_tree=null;
		ASTNode KW_DESC917_tree=null;
		RewriteRuleTokenStream stream_KW_DESC=new RewriteRuleTokenStream(adaptor,"token KW_DESC");
		RewriteRuleTokenStream stream_KW_ASC=new RewriteRuleTokenStream(adaptor,"token KW_ASC");

		 pushMsg("order specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2472:5: ( KW_ASC -> ^( TOK_TABSORTCOLNAMEASC ) | KW_DESC -> ^( TOK_TABSORTCOLNAMEDESC ) )
			int alt277=2;
			int LA277_0 = input.LA(1);
			if ( (LA277_0==KW_ASC) ) {
				alt277=1;
			}
			else if ( (LA277_0==KW_DESC) ) {
				alt277=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 277, 0, input);
				throw nvae;
			}

			switch (alt277) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2472:7: KW_ASC
					{
					KW_ASC916=(Token)match(input,KW_ASC,FOLLOW_KW_ASC_in_orderSpecificationRewrite15182); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ASC.add(KW_ASC916);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2472:14: -> ^( TOK_TABSORTCOLNAMEASC )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2472:17: ^( TOK_TABSORTCOLNAMEASC )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2473:7: KW_DESC
					{
					KW_DESC917=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_orderSpecificationRewrite15196); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DESC.add(KW_DESC917);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2473:15: -> ^( TOK_TABSORTCOLNAMEDESC )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2473:18: ^( TOK_TABSORTCOLNAMEDESC )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "orderSpecificationRewrite"


	public static class columnRefOrder_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnRefOrder"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2476:1: columnRefOrder : expression (orderSpec= orderSpecificationRewrite )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null && nullsLast()}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) ) -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) ) -> {$nullSpec.tree == null && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) ) -> {$nullSpec.tree == null}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) ) -> ^( $orderSpec ^( $nullSpec expression ) ) ;
	public final HiveParser.columnRefOrder_return columnRefOrder() throws RecognitionException {
		HiveParser.columnRefOrder_return retval = new HiveParser.columnRefOrder_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope orderSpec =null;
		ParserRuleReturnScope nullSpec =null;
		ParserRuleReturnScope expression918 =null;

		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_orderSpecificationRewrite=new RewriteRuleSubtreeStream(adaptor,"rule orderSpecificationRewrite");
		RewriteRuleSubtreeStream stream_nullOrdering=new RewriteRuleSubtreeStream(adaptor,"rule nullOrdering");

		 pushMsg("column order", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2479:5: ( expression (orderSpec= orderSpecificationRewrite )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null && nullsLast()}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) ) -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) ) -> {$nullSpec.tree == null && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) ) -> {$nullSpec.tree == null}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) ) -> ^( $orderSpec ^( $nullSpec expression ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2479:7: expression (orderSpec= orderSpecificationRewrite )? (nullSpec= nullOrdering )?
			{
			pushFollow(FOLLOW_expression_in_columnRefOrder15229);
			expression918=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression918.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2479:27: (orderSpec= orderSpecificationRewrite )?
			int alt278=2;
			int LA278_0 = input.LA(1);
			if ( (LA278_0==KW_ASC||LA278_0==KW_DESC) ) {
				alt278=1;
			}
			switch (alt278) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2479:27: orderSpec= orderSpecificationRewrite
					{
					pushFollow(FOLLOW_orderSpecificationRewrite_in_columnRefOrder15233);
					orderSpec=orderSpecificationRewrite();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orderSpecificationRewrite.add(orderSpec.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2479:63: (nullSpec= nullOrdering )?
			int alt279=2;
			int LA279_0 = input.LA(1);
			if ( (LA279_0==KW_NULLS) ) {
				alt279=1;
			}
			switch (alt279) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2479:63: nullSpec= nullOrdering
					{
					pushFollow(FOLLOW_nullOrdering_in_columnRefOrder15238);
					nullSpec=nullOrdering();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_nullOrdering.add(nullSpec.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: orderSpec, orderSpec, orderSpec, nullSpec, expression, expression, expression, expression, expression, nullSpec, expression
			// token labels: 
			// rule labels: orderSpec, nullSpec, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_orderSpec=new RewriteRuleSubtreeStream(adaptor,"rule orderSpec",orderSpec!=null?orderSpec.getTree():null);
			RewriteRuleSubtreeStream stream_nullSpec=new RewriteRuleSubtreeStream(adaptor,"rule nullSpec",nullSpec!=null?nullSpec.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2481:5: -> {$orderSpec.tree == null && $nullSpec.tree == null && nullsLast()}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null && (nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && nullsLast()) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2482:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2482:37: ^( TOK_NULLS_LAST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2484:5: -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null && (nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2485:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2485:37: ^( TOK_NULLS_FIRST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2487:5: -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2488:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2488:37: ^( $nullSpec expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2490:5: -> {$nullSpec.tree == null && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && nullsLast()) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2491:13: ^( $orderSpec ^( TOK_NULLS_LAST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2491:26: ^( TOK_NULLS_LAST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2493:5: -> {$nullSpec.tree == null}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2494:13: ^( $orderSpec ^( TOK_NULLS_FIRST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2494:26: ^( TOK_NULLS_FIRST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2496:5: -> ^( $orderSpec ^( $nullSpec expression ) )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:8: ^( $orderSpec ^( $nullSpec expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:21: ^( $nullSpec expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnRefOrder"


	public static class columnNameType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2499:1: columnNameType : colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
	public final HiveParser.columnNameType_return columnNameType() throws RecognitionException {
		HiveParser.columnNameType_return retval = new HiveParser.columnNameType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT920=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope colType919 =null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT920_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2502:5: (colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2502:7: colName= identifier colType ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameType15469);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			pushFollow(FOLLOW_colType_in_columnNameType15471);
			colType919=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType919.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2502:34: ( KW_COMMENT comment= StringLiteral )?
			int alt280=2;
			int LA280_0 = input.LA(1);
			if ( (LA280_0==KW_COMMENT) ) {
				alt280=1;
			}
			switch (alt280) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2502:35: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT920=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameType15474); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT920);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameType15478); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: colName, comment, colType, colName, colType
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2503:5: -> {containExcludedCharForCreateTableColumnName($colName.text)}?
			if (containExcludedCharForCreateTableColumnName((colName!=null?input.toString(colName.start,colName.stop):null))) {
				adaptor.addChild(root_0, throwColumnNameException());
			}

			else // 2504:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
			if (comment == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2504:28: ^( TOK_TABCOL $colName colType )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2505:5: -> ^( TOK_TABCOL $colName colType $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2505:28: ^( TOK_TABCOL $colName colType $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameType"


	public static class columnNameTypeOrConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeOrConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2508:1: columnNameTypeOrConstraint : ( ( tableConstraint ) | ( columnNameTypeConstraint ) );
	public final HiveParser.columnNameTypeOrConstraint_return columnNameTypeOrConstraint() throws RecognitionException {
		HiveParser.columnNameTypeOrConstraint_return retval = new HiveParser.columnNameTypeOrConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tableConstraint921 =null;
		ParserRuleReturnScope columnNameTypeConstraint922 =null;


		 pushMsg("column name or constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2511:5: ( ( tableConstraint ) | ( columnNameTypeConstraint ) )
			int alt281=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
			case KW_FOREIGN:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt281=1;
				}
				break;
			case KW_CHECK:
				{
				int LA281_5 = input.LA(2);
				if ( (LA281_5==LPAREN) ) {
					alt281=1;
				}
				else if ( (LA281_5==KW_ARRAY||(LA281_5 >= KW_BIGINT && LA281_5 <= KW_BOOLEAN)||LA281_5==KW_CHAR||(LA281_5 >= KW_DATE && LA281_5 <= KW_DATETIME)||LA281_5==KW_DECIMAL||LA281_5==KW_DOUBLE||LA281_5==KW_FLOAT||LA281_5==KW_INT||LA281_5==KW_MAP||LA281_5==KW_SMALLINT||(LA281_5 >= KW_STRING && LA281_5 <= KW_STRUCT)||(LA281_5 >= KW_TIMESTAMP && LA281_5 <= KW_TINYINT)||LA281_5==KW_UNIONTYPE||LA281_5==KW_VARCHAR) ) {
					alt281=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 281, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EXCLUSIVE:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_IDXPROPERTIES:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMA:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SERVER:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URI:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_IGNORE:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt281=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 281, 0, input);
				throw nvae;
			}
			switch (alt281) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2511:7: ( tableConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2511:7: ( tableConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2511:9: tableConstraint
					{
					pushFollow(FOLLOW_tableConstraint_in_columnNameTypeOrConstraint15574);
					tableConstraint921=tableConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, tableConstraint921.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2512:7: ( columnNameTypeConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2512:7: ( columnNameTypeConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2512:9: columnNameTypeConstraint
					{
					pushFollow(FOLLOW_columnNameTypeConstraint_in_columnNameTypeOrConstraint15586);
					columnNameTypeConstraint922=columnNameTypeConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, columnNameTypeConstraint922.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeOrConstraint"


	public static class tableConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2515:1: tableConstraint : ( ( createForeignKey ) | ( createConstraint ) );
	public final HiveParser.tableConstraint_return tableConstraint() throws RecognitionException {
		HiveParser.tableConstraint_return retval = new HiveParser.tableConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope createForeignKey923 =null;
		ParserRuleReturnScope createConstraint924 =null;


		 pushMsg("table constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:5: ( ( createForeignKey ) | ( createConstraint ) )
			int alt282=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
				{
				int LA282_1 = input.LA(2);
				if ( (LA282_1==Identifier) ) {
					int LA282_6 = input.LA(3);
					if ( (LA282_6==KW_FOREIGN) ) {
						alt282=1;
					}
					else if ( (LA282_6==KW_CHECK||LA282_6==KW_PRIMARY||LA282_6==KW_UNIQUE) ) {
						alt282=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 282, 6, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA282_1 >= KW_ABORT && LA282_1 <= KW_AFTER)||LA282_1==KW_ALLOC_FRACTION||LA282_1==KW_ANALYZE||LA282_1==KW_ARCHIVE||LA282_1==KW_ASC||(LA282_1 >= KW_AUTOCOMMIT && LA282_1 <= KW_BEFORE)||(LA282_1 >= KW_BUCKET && LA282_1 <= KW_BUCKETS)||(LA282_1 >= KW_CACHE && LA282_1 <= KW_CASCADE)||(LA282_1 >= KW_CBO && LA282_1 <= KW_CHANGE)||(LA282_1 >= KW_CHECK && LA282_1 <= KW_COLLECTION)||(LA282_1 >= KW_COLUMNS && LA282_1 <= KW_COMMENT)||(LA282_1 >= KW_COMPACT && LA282_1 <= KW_CONCATENATE)||(LA282_1 >= KW_CONTINUE && LA282_1 <= KW_COST)||LA282_1==KW_DATA||LA282_1==KW_DATABASES||(LA282_1 >= KW_DATETIME && LA282_1 <= KW_DEBUG)||(LA282_1 >= KW_DEFAULT && LA282_1 <= KW_DEFINED)||(LA282_1 >= KW_DELIMITED && LA282_1 <= KW_DESC)||(LA282_1 >= KW_DETAIL && LA282_1 <= KW_DISABLE)||(LA282_1 >= KW_DISTRIBUTE && LA282_1 <= KW_DO)||LA282_1==KW_DOW||(LA282_1 >= KW_DUMP && LA282_1 <= KW_ELEM_TYPE)||LA282_1==KW_ENABLE||(LA282_1 >= KW_ENFORCED && LA282_1 <= KW_ESCAPED)||LA282_1==KW_EXCLUSIVE||(LA282_1 >= KW_EXPLAIN && LA282_1 <= KW_EXPRESSION)||(LA282_1 >= KW_FIELDS && LA282_1 <= KW_FIRST)||(LA282_1 >= KW_FORMAT && LA282_1 <= KW_FORMATTED)||LA282_1==KW_FUNCTIONS||(LA282_1 >= KW_HOUR && LA282_1 <= KW_IDXPROPERTIES)||(LA282_1 >= KW_INDEX && LA282_1 <= KW_INDEXES)||(LA282_1 >= KW_INPATH && LA282_1 <= KW_INPUTFORMAT)||(LA282_1 >= KW_ISOLATION && LA282_1 <= KW_JAR)||(LA282_1 >= KW_JOINCOST && LA282_1 <= KW_LAST)||LA282_1==KW_LEVEL||(LA282_1 >= KW_LIMIT && LA282_1 <= KW_LOAD)||(LA282_1 >= KW_LOCATION && LA282_1 <= KW_LONG)||LA282_1==KW_MANAGEMENT||(LA282_1 >= KW_MAPJOIN && LA282_1 <= KW_MATERIALIZED)||LA282_1==KW_METADATA||(LA282_1 >= KW_MINUTE && LA282_1 <= KW_MONTH)||(LA282_1 >= KW_MOVE && LA282_1 <= KW_MSCK)||(LA282_1 >= KW_NORELY && LA282_1 <= KW_NOSCAN)||LA282_1==KW_NOVALIDATE||LA282_1==KW_NULLS||LA282_1==KW_OFFSET||(LA282_1 >= KW_OPERATOR && LA282_1 <= KW_OPTION)||(LA282_1 >= KW_OUTPUTDRIVER && LA282_1 <= KW_OUTPUTFORMAT)||(LA282_1 >= KW_OVERWRITE && LA282_1 <= KW_OWNER)||(LA282_1 >= KW_PARTITIONED && LA282_1 <= KW_PATH)||(LA282_1 >= KW_PLAN && LA282_1 <= KW_POOL)||LA282_1==KW_PRINCIPALS||(LA282_1 >= KW_PURGE && LA282_1 <= KW_QUERY_PARALLELISM)||LA282_1==KW_READ||(LA282_1 >= KW_REBUILD && LA282_1 <= KW_RECORDWRITER)||(LA282_1 >= KW_RELOAD && LA282_1 <= KW_RESTRICT)||LA282_1==KW_REWRITE||(LA282_1 >= KW_ROLE && LA282_1 <= KW_ROLES)||(LA282_1 >= KW_SCHEDULING_POLICY && LA282_1 <= KW_SECOND)||(LA282_1 >= KW_SEMI && LA282_1 <= KW_SERVER)||(LA282_1 >= KW_SETS && LA282_1 <= KW_SKEWED)||(LA282_1 >= KW_SNAPSHOT && LA282_1 <= KW_SSL)||(LA282_1 >= KW_STATISTICS && LA282_1 <= KW_SUMMARY)||LA282_1==KW_TABLES||(LA282_1 >= KW_TBLPROPERTIES && LA282_1 <= KW_TERMINATED)||LA282_1==KW_TINYINT||(LA282_1 >= KW_TOUCH && LA282_1 <= KW_TRANSACTIONS)||LA282_1==KW_UNARCHIVE||LA282_1==KW_UNDO||LA282_1==KW_UNIONTYPE||(LA282_1 >= KW_UNLOCK && LA282_1 <= KW_UNSIGNED)||(LA282_1 >= KW_URI && LA282_1 <= KW_USE)||(LA282_1 >= KW_UTC && LA282_1 <= KW_VALIDATE)||LA282_1==KW_VALUE_TYPE||(LA282_1 >= KW_VECTORIZATION && LA282_1 <= KW_WEEK)||LA282_1==KW_WHILE||(LA282_1 >= KW_WORK && LA282_1 <= KW_ZONE)||LA282_1==KW_BATCH||LA282_1==KW_DAYOFWEEK||LA282_1==KW_HOLD_DDLTIME||LA282_1==KW_IGNORE||LA282_1==KW_NO_DROP||LA282_1==KW_OFFLINE||LA282_1==KW_PROTECTION||LA282_1==KW_READONLY||LA282_1==KW_TIMESTAMPTZ) ) {
					int LA282_7 = input.LA(3);
					if ( (LA282_7==KW_FOREIGN) ) {
						alt282=1;
					}
					else if ( (LA282_7==KW_CHECK||LA282_7==KW_PRIMARY||LA282_7==KW_UNIQUE) ) {
						alt282=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 282, 7, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 282, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_FOREIGN:
				{
				alt282=1;
				}
				break;
			case KW_CHECK:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt282=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 282, 0, input);
				throw nvae;
			}
			switch (alt282) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:7: ( createForeignKey )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:7: ( createForeignKey )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:9: createForeignKey
					{
					pushFollow(FOLLOW_createForeignKey_in_tableConstraint15617);
					createForeignKey923=createForeignKey();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createForeignKey923.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2519:7: ( createConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2519:7: ( createConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2519:9: createConstraint
					{
					pushFollow(FOLLOW_createConstraint_in_tableConstraint15629);
					createConstraint924=createConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createConstraint924.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableConstraint"


	public static class columnNameTypeConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2522:1: columnNameTypeConstraint : colName= identifier colType ( columnConstraint[$colName.tree] )? ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? ) ;
	public final HiveParser.columnNameTypeConstraint_return columnNameTypeConstraint() throws RecognitionException {
		HiveParser.columnNameTypeConstraint_return retval = new HiveParser.columnNameTypeConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT927=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope colType925 =null;
		ParserRuleReturnScope columnConstraint926 =null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT927_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnConstraint=new RewriteRuleSubtreeStream(adaptor,"rule columnConstraint");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2525:5: (colName= identifier colType ( columnConstraint[$colName.tree] )? ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2525:7: colName= identifier colType ( columnConstraint[$colName.tree] )? ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameTypeConstraint15660);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			pushFollow(FOLLOW_colType_in_columnNameTypeConstraint15662);
			colType925=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType925.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2525:34: ( columnConstraint[$colName.tree] )?
			int alt283=2;
			int LA283_0 = input.LA(1);
			if ( (LA283_0==KW_CHECK||LA283_0==KW_CONSTRAINT||LA283_0==KW_DEFAULT||LA283_0==KW_NOT||LA283_0==KW_PRIMARY||LA283_0==KW_REFERENCES||LA283_0==KW_UNIQUE) ) {
				alt283=1;
			}
			switch (alt283) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2525:34: columnConstraint[$colName.tree]
					{
					pushFollow(FOLLOW_columnConstraint_in_columnNameTypeConstraint15664);
					columnConstraint926=columnConstraint((colName!=null?((ASTNode)colName.getTree()):null));
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnConstraint.add(columnConstraint926.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2525:67: ( KW_COMMENT comment= StringLiteral )?
			int alt284=2;
			int LA284_0 = input.LA(1);
			if ( (LA284_0==KW_COMMENT) ) {
				alt284=1;
			}
			switch (alt284) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2525:68: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT927=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameTypeConstraint15669); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT927);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameTypeConstraint15673); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: colName, columnConstraint, comment, colType
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2526:5: -> {containExcludedCharForCreateTableColumnName($colName.text)}?
			if (containExcludedCharForCreateTableColumnName((colName!=null?input.toString(colName.start,colName.stop):null))) {
				adaptor.addChild(root_0, throwColumnNameException());
			}

			else // 2527:5: -> ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2527:8: ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2527:39: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2527:48: ( columnConstraint )?
				if ( stream_columnConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_columnConstraint.nextTree());
				}
				stream_columnConstraint.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeConstraint"


	public static class columnConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2530:1: columnConstraint[CommonTree fkColName] : ( ( foreignKeyConstraint[$fkColName] ) | ( colConstraint ) );
	public final HiveParser.columnConstraint_return columnConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.columnConstraint_return retval = new HiveParser.columnConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope foreignKeyConstraint928 =null;
		ParserRuleReturnScope colConstraint929 =null;


		 pushMsg("column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2533:5: ( ( foreignKeyConstraint[$fkColName] ) | ( colConstraint ) )
			int alt285=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
				{
				int LA285_1 = input.LA(2);
				if ( (LA285_1==Identifier) ) {
					int LA285_8 = input.LA(3);
					if ( (LA285_8==KW_REFERENCES) ) {
						alt285=1;
					}
					else if ( (LA285_8==KW_CHECK||LA285_8==KW_DEFAULT||LA285_8==KW_NOT||LA285_8==KW_PRIMARY||LA285_8==KW_UNIQUE) ) {
						alt285=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 285, 8, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA285_1 >= KW_ABORT && LA285_1 <= KW_AFTER)||LA285_1==KW_ALLOC_FRACTION||LA285_1==KW_ANALYZE||LA285_1==KW_ARCHIVE||LA285_1==KW_ASC||(LA285_1 >= KW_AUTOCOMMIT && LA285_1 <= KW_BEFORE)||(LA285_1 >= KW_BUCKET && LA285_1 <= KW_BUCKETS)||(LA285_1 >= KW_CACHE && LA285_1 <= KW_CASCADE)||(LA285_1 >= KW_CBO && LA285_1 <= KW_CHANGE)||(LA285_1 >= KW_CHECK && LA285_1 <= KW_COLLECTION)||(LA285_1 >= KW_COLUMNS && LA285_1 <= KW_COMMENT)||(LA285_1 >= KW_COMPACT && LA285_1 <= KW_CONCATENATE)||(LA285_1 >= KW_CONTINUE && LA285_1 <= KW_COST)||LA285_1==KW_DATA||LA285_1==KW_DATABASES||(LA285_1 >= KW_DATETIME && LA285_1 <= KW_DEBUG)||(LA285_1 >= KW_DEFAULT && LA285_1 <= KW_DEFINED)||(LA285_1 >= KW_DELIMITED && LA285_1 <= KW_DESC)||(LA285_1 >= KW_DETAIL && LA285_1 <= KW_DISABLE)||(LA285_1 >= KW_DISTRIBUTE && LA285_1 <= KW_DO)||LA285_1==KW_DOW||(LA285_1 >= KW_DUMP && LA285_1 <= KW_ELEM_TYPE)||LA285_1==KW_ENABLE||(LA285_1 >= KW_ENFORCED && LA285_1 <= KW_ESCAPED)||LA285_1==KW_EXCLUSIVE||(LA285_1 >= KW_EXPLAIN && LA285_1 <= KW_EXPRESSION)||(LA285_1 >= KW_FIELDS && LA285_1 <= KW_FIRST)||(LA285_1 >= KW_FORMAT && LA285_1 <= KW_FORMATTED)||LA285_1==KW_FUNCTIONS||(LA285_1 >= KW_HOUR && LA285_1 <= KW_IDXPROPERTIES)||(LA285_1 >= KW_INDEX && LA285_1 <= KW_INDEXES)||(LA285_1 >= KW_INPATH && LA285_1 <= KW_INPUTFORMAT)||(LA285_1 >= KW_ISOLATION && LA285_1 <= KW_JAR)||(LA285_1 >= KW_JOINCOST && LA285_1 <= KW_LAST)||LA285_1==KW_LEVEL||(LA285_1 >= KW_LIMIT && LA285_1 <= KW_LOAD)||(LA285_1 >= KW_LOCATION && LA285_1 <= KW_LONG)||LA285_1==KW_MANAGEMENT||(LA285_1 >= KW_MAPJOIN && LA285_1 <= KW_MATERIALIZED)||LA285_1==KW_METADATA||(LA285_1 >= KW_MINUTE && LA285_1 <= KW_MONTH)||(LA285_1 >= KW_MOVE && LA285_1 <= KW_MSCK)||(LA285_1 >= KW_NORELY && LA285_1 <= KW_NOSCAN)||LA285_1==KW_NOVALIDATE||LA285_1==KW_NULLS||LA285_1==KW_OFFSET||(LA285_1 >= KW_OPERATOR && LA285_1 <= KW_OPTION)||(LA285_1 >= KW_OUTPUTDRIVER && LA285_1 <= KW_OUTPUTFORMAT)||(LA285_1 >= KW_OVERWRITE && LA285_1 <= KW_OWNER)||(LA285_1 >= KW_PARTITIONED && LA285_1 <= KW_PATH)||(LA285_1 >= KW_PLAN && LA285_1 <= KW_POOL)||LA285_1==KW_PRINCIPALS||(LA285_1 >= KW_PURGE && LA285_1 <= KW_QUERY_PARALLELISM)||LA285_1==KW_READ||(LA285_1 >= KW_REBUILD && LA285_1 <= KW_RECORDWRITER)||(LA285_1 >= KW_RELOAD && LA285_1 <= KW_RESTRICT)||LA285_1==KW_REWRITE||(LA285_1 >= KW_ROLE && LA285_1 <= KW_ROLES)||(LA285_1 >= KW_SCHEDULING_POLICY && LA285_1 <= KW_SECOND)||(LA285_1 >= KW_SEMI && LA285_1 <= KW_SERVER)||(LA285_1 >= KW_SETS && LA285_1 <= KW_SKEWED)||(LA285_1 >= KW_SNAPSHOT && LA285_1 <= KW_SSL)||(LA285_1 >= KW_STATISTICS && LA285_1 <= KW_SUMMARY)||LA285_1==KW_TABLES||(LA285_1 >= KW_TBLPROPERTIES && LA285_1 <= KW_TERMINATED)||LA285_1==KW_TINYINT||(LA285_1 >= KW_TOUCH && LA285_1 <= KW_TRANSACTIONS)||LA285_1==KW_UNARCHIVE||LA285_1==KW_UNDO||LA285_1==KW_UNIONTYPE||(LA285_1 >= KW_UNLOCK && LA285_1 <= KW_UNSIGNED)||(LA285_1 >= KW_URI && LA285_1 <= KW_USE)||(LA285_1 >= KW_UTC && LA285_1 <= KW_VALIDATE)||LA285_1==KW_VALUE_TYPE||(LA285_1 >= KW_VECTORIZATION && LA285_1 <= KW_WEEK)||LA285_1==KW_WHILE||(LA285_1 >= KW_WORK && LA285_1 <= KW_ZONE)||LA285_1==KW_BATCH||LA285_1==KW_DAYOFWEEK||LA285_1==KW_HOLD_DDLTIME||LA285_1==KW_IGNORE||LA285_1==KW_NO_DROP||LA285_1==KW_OFFLINE||LA285_1==KW_PROTECTION||LA285_1==KW_READONLY||LA285_1==KW_TIMESTAMPTZ) ) {
					int LA285_9 = input.LA(3);
					if ( (LA285_9==KW_REFERENCES) ) {
						alt285=1;
					}
					else if ( (LA285_9==KW_CHECK||LA285_9==KW_DEFAULT||LA285_9==KW_NOT||LA285_9==KW_PRIMARY||LA285_9==KW_UNIQUE) ) {
						alt285=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 285, 9, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 285, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_REFERENCES:
				{
				alt285=1;
				}
				break;
			case KW_CHECK:
			case KW_DEFAULT:
			case KW_NOT:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt285=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 285, 0, input);
				throw nvae;
			}
			switch (alt285) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2533:7: ( foreignKeyConstraint[$fkColName] )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2533:7: ( foreignKeyConstraint[$fkColName] )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2533:9: foreignKeyConstraint[$fkColName]
					{
					pushFollow(FOLLOW_foreignKeyConstraint_in_columnConstraint15737);
					foreignKeyConstraint928=foreignKeyConstraint(fkColName);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, foreignKeyConstraint928.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2534:7: ( colConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2534:7: ( colConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2534:9: colConstraint
					{
					pushFollow(FOLLOW_colConstraint_in_columnConstraint15750);
					colConstraint929=colConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, colConstraint929.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnConstraint"


	public static class foreignKeyConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "foreignKeyConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2537:1: foreignKeyConstraint[CommonTree fkColName] : ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) ;
	public final HiveParser.foreignKeyConstraint_return foreignKeyConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.foreignKeyConstraint_return retval = new HiveParser.foreignKeyConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT930=null;
		Token KW_REFERENCES931=null;
		Token LPAREN932=null;
		Token RPAREN933=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope constraintOptsCreate934 =null;

		ASTNode KW_CONSTRAINT930_tree=null;
		ASTNode KW_REFERENCES931_tree=null;
		ASTNode LPAREN932_tree=null;
		ASTNode RPAREN933_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2540:5: ( ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2540:7: ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2540:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt286=2;
			int LA286_0 = input.LA(1);
			if ( (LA286_0==KW_CONSTRAINT) ) {
				alt286=1;
			}
			switch (alt286) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2540:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT930=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_foreignKeyConstraint15781); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT930);

					pushFollow(FOLLOW_identifier_in_foreignKeyConstraint15785);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			KW_REFERENCES931=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_foreignKeyConstraint15789); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES931);

			pushFollow(FOLLOW_tableName_in_foreignKeyConstraint15793);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			LPAREN932=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_foreignKeyConstraint15795); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN932);

			pushFollow(FOLLOW_columnName_in_foreignKeyConstraint15799);
			colName=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(colName.getTree());
			RPAREN933=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_foreignKeyConstraint15801); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN933);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2540:115: ( constraintOptsCreate )?
			int alt287=2;
			int LA287_0 = input.LA(1);
			if ( (LA287_0==KW_DISABLE||LA287_0==KW_ENABLE||LA287_0==KW_ENFORCED||LA287_0==KW_NOT) ) {
				alt287=1;
			}
			switch (alt287) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2540:115: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_foreignKeyConstraint15803);
					constraintOptsCreate934=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate934.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsCreate, constraintName, colName, constraintOptsCreate, colName, tabName, tabName
			// token labels: 
			// rule labels: colName, tabName, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2541:5: -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2542:13: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2542:31: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2542:70: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2542:110: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2542:137: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2543:5: -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2543:8: ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2543:26: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2543:66: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2543:93: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "foreignKeyConstraint"


	public static class colConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "colConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2546:1: colConstraint : ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) ;
	public final HiveParser.colConstraint_return colConstraint() throws RecognitionException {
		HiveParser.colConstraint_return retval = new HiveParser.colConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT935=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope columnConstraintType936 =null;
		ParserRuleReturnScope constraintOptsCreate937 =null;

		ASTNode KW_CONSTRAINT935_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnConstraintType=new RewriteRuleSubtreeStream(adaptor,"rule columnConstraintType");

		 pushMsg("column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2549:5: ( ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2549:7: ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2549:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt288=2;
			int LA288_0 = input.LA(1);
			if ( (LA288_0==KW_CONSTRAINT) ) {
				alt288=1;
			}
			switch (alt288) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2549:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT935=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_colConstraint15911); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT935);

					pushFollow(FOLLOW_identifier_in_colConstraint15915);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_columnConstraintType_in_colConstraint15919);
			columnConstraintType936=columnConstraintType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnConstraintType.add(columnConstraintType936.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2549:71: ( constraintOptsCreate )?
			int alt289=2;
			int LA289_0 = input.LA(1);
			if ( (LA289_0==KW_DISABLE||LA289_0==KW_ENABLE||LA289_0==KW_ENFORCED||LA289_0==KW_NOT) ) {
				alt289=1;
			}
			switch (alt289) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2549:71: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_colConstraint15921);
					constraintOptsCreate937=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate937.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsCreate, constraintName, constraintOptsCreate
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2550:5: -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2551:13: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType936!=null?((ASTNode)columnConstraintType936.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2551:44: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2551:83: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2552:5: -> ^( ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2552:8: ^( ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType936!=null?((ASTNode)columnConstraintType936.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2552:39: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "colConstraint"


	public static class alterColumnConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterColumnConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2555:1: alterColumnConstraint[CommonTree fkColName] : ( ( alterForeignKeyConstraint[$fkColName] ) | ( alterColConstraint ) );
	public final HiveParser.alterColumnConstraint_return alterColumnConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.alterColumnConstraint_return retval = new HiveParser.alterColumnConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterForeignKeyConstraint938 =null;
		ParserRuleReturnScope alterColConstraint939 =null;


		 pushMsg("alter column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2558:5: ( ( alterForeignKeyConstraint[$fkColName] ) | ( alterColConstraint ) )
			int alt290=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
				{
				int LA290_1 = input.LA(2);
				if ( (LA290_1==Identifier) ) {
					int LA290_8 = input.LA(3);
					if ( (LA290_8==KW_REFERENCES) ) {
						alt290=1;
					}
					else if ( (LA290_8==KW_CHECK||LA290_8==KW_DEFAULT||LA290_8==KW_NOT||LA290_8==KW_PRIMARY||LA290_8==KW_UNIQUE) ) {
						alt290=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 290, 8, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA290_1 >= KW_ABORT && LA290_1 <= KW_AFTER)||LA290_1==KW_ALLOC_FRACTION||LA290_1==KW_ANALYZE||LA290_1==KW_ARCHIVE||LA290_1==KW_ASC||(LA290_1 >= KW_AUTOCOMMIT && LA290_1 <= KW_BEFORE)||(LA290_1 >= KW_BUCKET && LA290_1 <= KW_BUCKETS)||(LA290_1 >= KW_CACHE && LA290_1 <= KW_CASCADE)||(LA290_1 >= KW_CBO && LA290_1 <= KW_CHANGE)||(LA290_1 >= KW_CHECK && LA290_1 <= KW_COLLECTION)||(LA290_1 >= KW_COLUMNS && LA290_1 <= KW_COMMENT)||(LA290_1 >= KW_COMPACT && LA290_1 <= KW_CONCATENATE)||(LA290_1 >= KW_CONTINUE && LA290_1 <= KW_COST)||LA290_1==KW_DATA||LA290_1==KW_DATABASES||(LA290_1 >= KW_DATETIME && LA290_1 <= KW_DEBUG)||(LA290_1 >= KW_DEFAULT && LA290_1 <= KW_DEFINED)||(LA290_1 >= KW_DELIMITED && LA290_1 <= KW_DESC)||(LA290_1 >= KW_DETAIL && LA290_1 <= KW_DISABLE)||(LA290_1 >= KW_DISTRIBUTE && LA290_1 <= KW_DO)||LA290_1==KW_DOW||(LA290_1 >= KW_DUMP && LA290_1 <= KW_ELEM_TYPE)||LA290_1==KW_ENABLE||(LA290_1 >= KW_ENFORCED && LA290_1 <= KW_ESCAPED)||LA290_1==KW_EXCLUSIVE||(LA290_1 >= KW_EXPLAIN && LA290_1 <= KW_EXPRESSION)||(LA290_1 >= KW_FIELDS && LA290_1 <= KW_FIRST)||(LA290_1 >= KW_FORMAT && LA290_1 <= KW_FORMATTED)||LA290_1==KW_FUNCTIONS||(LA290_1 >= KW_HOUR && LA290_1 <= KW_IDXPROPERTIES)||(LA290_1 >= KW_INDEX && LA290_1 <= KW_INDEXES)||(LA290_1 >= KW_INPATH && LA290_1 <= KW_INPUTFORMAT)||(LA290_1 >= KW_ISOLATION && LA290_1 <= KW_JAR)||(LA290_1 >= KW_JOINCOST && LA290_1 <= KW_LAST)||LA290_1==KW_LEVEL||(LA290_1 >= KW_LIMIT && LA290_1 <= KW_LOAD)||(LA290_1 >= KW_LOCATION && LA290_1 <= KW_LONG)||LA290_1==KW_MANAGEMENT||(LA290_1 >= KW_MAPJOIN && LA290_1 <= KW_MATERIALIZED)||LA290_1==KW_METADATA||(LA290_1 >= KW_MINUTE && LA290_1 <= KW_MONTH)||(LA290_1 >= KW_MOVE && LA290_1 <= KW_MSCK)||(LA290_1 >= KW_NORELY && LA290_1 <= KW_NOSCAN)||LA290_1==KW_NOVALIDATE||LA290_1==KW_NULLS||LA290_1==KW_OFFSET||(LA290_1 >= KW_OPERATOR && LA290_1 <= KW_OPTION)||(LA290_1 >= KW_OUTPUTDRIVER && LA290_1 <= KW_OUTPUTFORMAT)||(LA290_1 >= KW_OVERWRITE && LA290_1 <= KW_OWNER)||(LA290_1 >= KW_PARTITIONED && LA290_1 <= KW_PATH)||(LA290_1 >= KW_PLAN && LA290_1 <= KW_POOL)||LA290_1==KW_PRINCIPALS||(LA290_1 >= KW_PURGE && LA290_1 <= KW_QUERY_PARALLELISM)||LA290_1==KW_READ||(LA290_1 >= KW_REBUILD && LA290_1 <= KW_RECORDWRITER)||(LA290_1 >= KW_RELOAD && LA290_1 <= KW_RESTRICT)||LA290_1==KW_REWRITE||(LA290_1 >= KW_ROLE && LA290_1 <= KW_ROLES)||(LA290_1 >= KW_SCHEDULING_POLICY && LA290_1 <= KW_SECOND)||(LA290_1 >= KW_SEMI && LA290_1 <= KW_SERVER)||(LA290_1 >= KW_SETS && LA290_1 <= KW_SKEWED)||(LA290_1 >= KW_SNAPSHOT && LA290_1 <= KW_SSL)||(LA290_1 >= KW_STATISTICS && LA290_1 <= KW_SUMMARY)||LA290_1==KW_TABLES||(LA290_1 >= KW_TBLPROPERTIES && LA290_1 <= KW_TERMINATED)||LA290_1==KW_TINYINT||(LA290_1 >= KW_TOUCH && LA290_1 <= KW_TRANSACTIONS)||LA290_1==KW_UNARCHIVE||LA290_1==KW_UNDO||LA290_1==KW_UNIONTYPE||(LA290_1 >= KW_UNLOCK && LA290_1 <= KW_UNSIGNED)||(LA290_1 >= KW_URI && LA290_1 <= KW_USE)||(LA290_1 >= KW_UTC && LA290_1 <= KW_VALIDATE)||LA290_1==KW_VALUE_TYPE||(LA290_1 >= KW_VECTORIZATION && LA290_1 <= KW_WEEK)||LA290_1==KW_WHILE||(LA290_1 >= KW_WORK && LA290_1 <= KW_ZONE)||LA290_1==KW_BATCH||LA290_1==KW_DAYOFWEEK||LA290_1==KW_HOLD_DDLTIME||LA290_1==KW_IGNORE||LA290_1==KW_NO_DROP||LA290_1==KW_OFFLINE||LA290_1==KW_PROTECTION||LA290_1==KW_READONLY||LA290_1==KW_TIMESTAMPTZ) ) {
					int LA290_9 = input.LA(3);
					if ( (LA290_9==KW_REFERENCES) ) {
						alt290=1;
					}
					else if ( (LA290_9==KW_CHECK||LA290_9==KW_DEFAULT||LA290_9==KW_NOT||LA290_9==KW_PRIMARY||LA290_9==KW_UNIQUE) ) {
						alt290=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 290, 9, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 290, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_REFERENCES:
				{
				alt290=1;
				}
				break;
			case KW_CHECK:
			case KW_DEFAULT:
			case KW_NOT:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt290=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 290, 0, input);
				throw nvae;
			}
			switch (alt290) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2558:7: ( alterForeignKeyConstraint[$fkColName] )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2558:7: ( alterForeignKeyConstraint[$fkColName] )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2558:9: alterForeignKeyConstraint[$fkColName]
					{
					pushFollow(FOLLOW_alterForeignKeyConstraint_in_alterColumnConstraint15999);
					alterForeignKeyConstraint938=alterForeignKeyConstraint(fkColName);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterForeignKeyConstraint938.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2559:7: ( alterColConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2559:7: ( alterColConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2559:9: alterColConstraint
					{
					pushFollow(FOLLOW_alterColConstraint_in_alterColumnConstraint16012);
					alterColConstraint939=alterColConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterColConstraint939.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterColumnConstraint"


	public static class alterForeignKeyConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterForeignKeyConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2562:1: alterForeignKeyConstraint[CommonTree fkColName] : ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) ;
	public final HiveParser.alterForeignKeyConstraint_return alterForeignKeyConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.alterForeignKeyConstraint_return retval = new HiveParser.alterForeignKeyConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT940=null;
		Token KW_REFERENCES941=null;
		Token LPAREN942=null;
		Token RPAREN943=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope constraintOptsAlter944 =null;

		ASTNode KW_CONSTRAINT940_tree=null;
		ASTNode KW_REFERENCES941_tree=null;
		ASTNode LPAREN942_tree=null;
		ASTNode RPAREN943_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("alter column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:5: ( ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:7: ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsAlter )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt291=2;
			int LA291_0 = input.LA(1);
			if ( (LA291_0==KW_CONSTRAINT) ) {
				alt291=1;
			}
			switch (alt291) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT940=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterForeignKeyConstraint16043); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT940);

					pushFollow(FOLLOW_identifier_in_alterForeignKeyConstraint16047);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			KW_REFERENCES941=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_alterForeignKeyConstraint16051); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES941);

			pushFollow(FOLLOW_tableName_in_alterForeignKeyConstraint16055);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			LPAREN942=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterForeignKeyConstraint16057); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN942);

			pushFollow(FOLLOW_columnName_in_alterForeignKeyConstraint16061);
			colName=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(colName.getTree());
			RPAREN943=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterForeignKeyConstraint16063); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN943);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:115: ( constraintOptsAlter )?
			int alt292=2;
			int LA292_0 = input.LA(1);
			if ( (LA292_0==KW_DISABLE||LA292_0==KW_ENABLE||LA292_0==KW_ENFORCED||LA292_0==KW_NOT) ) {
				alt292=1;
			}
			switch (alt292) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:115: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterForeignKeyConstraint16065);
					constraintOptsAlter944=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter944.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: colName, constraintOptsAlter, tabName, constraintOptsAlter, constraintName, tabName, colName
			// token labels: 
			// rule labels: colName, tabName, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2566:5: -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2567:13: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2567:31: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2567:70: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2567:110: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2567:137: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2568:5: -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2568:8: ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2568:26: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2568:66: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2568:93: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterForeignKeyConstraint"


	public static class alterColConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterColConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2571:1: alterColConstraint : ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) -> ^( ( constraintOptsAlter )? ) ;
	public final HiveParser.alterColConstraint_return alterColConstraint() throws RecognitionException {
		HiveParser.alterColConstraint_return retval = new HiveParser.alterColConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT945=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope columnConstraintType946 =null;
		ParserRuleReturnScope constraintOptsAlter947 =null;

		ASTNode KW_CONSTRAINT945_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnConstraintType=new RewriteRuleSubtreeStream(adaptor,"rule columnConstraintType");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");

		 pushMsg("alter column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2574:5: ( ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) -> ^( ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2574:7: ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsAlter )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2574:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt293=2;
			int LA293_0 = input.LA(1);
			if ( (LA293_0==KW_CONSTRAINT) ) {
				alt293=1;
			}
			switch (alt293) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2574:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT945=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterColConstraint16173); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT945);

					pushFollow(FOLLOW_identifier_in_alterColConstraint16177);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_columnConstraintType_in_alterColConstraint16181);
			columnConstraintType946=columnConstraintType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnConstraintType.add(columnConstraintType946.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2574:71: ( constraintOptsAlter )?
			int alt294=2;
			int LA294_0 = input.LA(1);
			if ( (LA294_0==KW_DISABLE||LA294_0==KW_ENABLE||LA294_0==KW_ENFORCED||LA294_0==KW_NOT) ) {
				alt294=1;
			}
			switch (alt294) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2574:71: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterColConstraint16183);
					constraintOptsAlter947=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter947.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsAlter, constraintName, constraintOptsAlter
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2575:5: -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2576:13: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType946!=null?((ASTNode)columnConstraintType946.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2576:44: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2576:83: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2577:5: -> ^( ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2577:8: ^( ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType946!=null?((ASTNode)columnConstraintType946.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2577:39: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterColConstraint"


	public static class columnConstraintType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnConstraintType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2580:1: columnConstraintType : ( KW_NOT KW_NULL -> TOK_NOT_NULL | KW_DEFAULT defaultVal -> ^( TOK_DEFAULT_VALUE defaultVal ) | checkConstraint | tableConstraintType );
	public final HiveParser.columnConstraintType_return columnConstraintType() throws RecognitionException {
		HiveParser.columnConstraintType_return retval = new HiveParser.columnConstraintType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_NOT948=null;
		Token KW_NULL949=null;
		Token KW_DEFAULT950=null;
		ParserRuleReturnScope defaultVal951 =null;
		ParserRuleReturnScope checkConstraint952 =null;
		ParserRuleReturnScope tableConstraintType953 =null;

		ASTNode KW_NOT948_tree=null;
		ASTNode KW_NULL949_tree=null;
		ASTNode KW_DEFAULT950_tree=null;
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_NULL=new RewriteRuleTokenStream(adaptor,"token KW_NULL");
		RewriteRuleTokenStream stream_KW_DEFAULT=new RewriteRuleTokenStream(adaptor,"token KW_DEFAULT");
		RewriteRuleSubtreeStream stream_defaultVal=new RewriteRuleSubtreeStream(adaptor,"rule defaultVal");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2581:5: ( KW_NOT KW_NULL -> TOK_NOT_NULL | KW_DEFAULT defaultVal -> ^( TOK_DEFAULT_VALUE defaultVal ) | checkConstraint | tableConstraintType )
			int alt295=4;
			switch ( input.LA(1) ) {
			case KW_NOT:
				{
				alt295=1;
				}
				break;
			case KW_DEFAULT:
				{
				alt295=2;
				}
				break;
			case KW_CHECK:
				{
				alt295=3;
				}
				break;
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt295=4;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 295, 0, input);
				throw nvae;
			}
			switch (alt295) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2581:7: KW_NOT KW_NULL
					{
					KW_NOT948=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_columnConstraintType16248); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT948);

					KW_NULL949=(Token)match(input,KW_NULL,FOLLOW_KW_NULL_in_columnConstraintType16250); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NULL.add(KW_NULL949);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2581:28: -> TOK_NOT_NULL
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_NOT_NULL, "TOK_NOT_NULL"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:7: KW_DEFAULT defaultVal
					{
					KW_DEFAULT950=(Token)match(input,KW_DEFAULT,FOLLOW_KW_DEFAULT_in_columnConstraintType16271); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DEFAULT.add(KW_DEFAULT950);

					pushFollow(FOLLOW_defaultVal_in_columnConstraintType16273);
					defaultVal951=defaultVal();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_defaultVal.add(defaultVal951.getTree());
					// AST REWRITE
					// elements: defaultVal
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2582:28: -> ^( TOK_DEFAULT_VALUE defaultVal )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:34: ^( TOK_DEFAULT_VALUE defaultVal )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DEFAULT_VALUE, "TOK_DEFAULT_VALUE"), root_1);
						adaptor.addChild(root_1, stream_defaultVal.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2583:7: checkConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_checkConstraint_in_columnConstraintType16291);
					checkConstraint952=checkConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, checkConstraint952.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2584:7: tableConstraintType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_tableConstraintType_in_columnConstraintType16299);
					tableConstraintType953=tableConstraintType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, tableConstraintType953.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnConstraintType"


	public static class defaultVal_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "defaultVal"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2587:1: defaultVal : ( constant | function | castExpression );
	public final HiveParser.defaultVal_return defaultVal() throws RecognitionException {
		HiveParser.defaultVal_return retval = new HiveParser.defaultVal_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope constant954 =null;
		ParserRuleReturnScope function955 =null;
		ParserRuleReturnScope castExpression956 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2588:5: ( constant | function | castExpression )
			int alt296=3;
			switch ( input.LA(1) ) {
			case CharSetName:
			case IntegralLiteral:
			case KW_FALSE:
			case KW_NULL:
			case KW_TIMESTAMPLOCALTZ:
			case KW_TRUE:
			case Number:
			case NumberLiteral:
			case StringLiteral:
				{
				alt296=1;
				}
				break;
			case KW_DATE:
				{
				int LA296_3 = input.LA(2);
				if ( (LA296_3==StringLiteral) ) {
					alt296=1;
				}
				else if ( (LA296_3==LPAREN) ) {
					alt296=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 296, 3, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_CURRENT_DATE:
				{
				int LA296_4 = input.LA(2);
				if ( (LA296_4==EOF||LA296_4==COMMA||LA296_4==KW_AFTER||LA296_4==KW_CASCADE||LA296_4==KW_COMMENT||LA296_4==KW_DISABLE||LA296_4==KW_ENABLE||LA296_4==KW_ENFORCED||LA296_4==KW_FIRST||LA296_4==KW_NOT||LA296_4==KW_RESTRICT||LA296_4==RPAREN) ) {
					alt296=1;
				}
				else if ( (LA296_4==LPAREN) ) {
					alt296=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 296, 4, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_TIMESTAMP:
				{
				int LA296_5 = input.LA(2);
				if ( (LA296_5==StringLiteral) ) {
					alt296=1;
				}
				else if ( (LA296_5==LPAREN) ) {
					alt296=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 296, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_CURRENT_TIMESTAMP:
				{
				int LA296_6 = input.LA(2);
				if ( (LA296_6==EOF||LA296_6==COMMA||LA296_6==KW_AFTER||LA296_6==KW_CASCADE||LA296_6==KW_COMMENT||LA296_6==KW_DISABLE||LA296_6==KW_ENABLE||LA296_6==KW_ENFORCED||LA296_6==KW_FIRST||LA296_6==KW_NOT||LA296_6==KW_RESTRICT||LA296_6==RPAREN) ) {
					alt296=1;
				}
				else if ( (LA296_6==LPAREN) ) {
					alt296=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 296, 6, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ARRAY:
			case KW_ASC:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BIGINT:
			case KW_BINARY:
			case KW_BOOLEAN:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOUBLE:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EXCLUSIVE:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FLOAT:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_GROUPING:
			case KW_HOUR:
			case KW_IDXPROPERTIES:
			case KW_IF:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_INT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGEMENT:
			case KW_MAP:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMA:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SERVER:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SMALLINT:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URI:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_IGNORE:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt296=2;
				}
				break;
			case KW_CAST:
				{
				alt296=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 296, 0, input);
				throw nvae;
			}
			switch (alt296) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2588:7: constant
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_constant_in_defaultVal16316);
					constant954=constant();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, constant954.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2589:7: function
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_function_in_defaultVal16324);
					function955=function();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, function955.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2590:7: castExpression
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_castExpression_in_defaultVal16332);
					castExpression956=castExpression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, castExpression956.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "defaultVal"


	public static class tableConstraintType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableConstraintType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2593:1: tableConstraintType : ( KW_PRIMARY KW_KEY -> TOK_PRIMARY_KEY | KW_UNIQUE -> TOK_UNIQUE );
	public final HiveParser.tableConstraintType_return tableConstraintType() throws RecognitionException {
		HiveParser.tableConstraintType_return retval = new HiveParser.tableConstraintType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PRIMARY957=null;
		Token KW_KEY958=null;
		Token KW_UNIQUE959=null;

		ASTNode KW_PRIMARY957_tree=null;
		ASTNode KW_KEY958_tree=null;
		ASTNode KW_UNIQUE959_tree=null;
		RewriteRuleTokenStream stream_KW_PRIMARY=new RewriteRuleTokenStream(adaptor,"token KW_PRIMARY");
		RewriteRuleTokenStream stream_KW_UNIQUE=new RewriteRuleTokenStream(adaptor,"token KW_UNIQUE");
		RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2594:5: ( KW_PRIMARY KW_KEY -> TOK_PRIMARY_KEY | KW_UNIQUE -> TOK_UNIQUE )
			int alt297=2;
			int LA297_0 = input.LA(1);
			if ( (LA297_0==KW_PRIMARY) ) {
				alt297=1;
			}
			else if ( (LA297_0==KW_UNIQUE) ) {
				alt297=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 297, 0, input);
				throw nvae;
			}

			switch (alt297) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2594:7: KW_PRIMARY KW_KEY
					{
					KW_PRIMARY957=(Token)match(input,KW_PRIMARY,FOLLOW_KW_PRIMARY_in_tableConstraintType16349); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PRIMARY.add(KW_PRIMARY957);

					KW_KEY958=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_tableConstraintType16351); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY958);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2594:28: -> TOK_PRIMARY_KEY
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_PRIMARY_KEY, "TOK_PRIMARY_KEY"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2595:7: KW_UNIQUE
					{
					KW_UNIQUE959=(Token)match(input,KW_UNIQUE,FOLLOW_KW_UNIQUE_in_tableConstraintType16369); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNIQUE.add(KW_UNIQUE959);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2595:28: -> TOK_UNIQUE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_UNIQUE, "TOK_UNIQUE"));
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableConstraintType"


	public static class constraintOptsCreate_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "constraintOptsCreate"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2598:1: constraintOptsCreate : enableValidateSpecification ( relySpecification )? ;
	public final HiveParser.constraintOptsCreate_return constraintOptsCreate() throws RecognitionException {
		HiveParser.constraintOptsCreate_return retval = new HiveParser.constraintOptsCreate_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope enableValidateSpecification960 =null;
		ParserRuleReturnScope relySpecification961 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2599:5: ( enableValidateSpecification ( relySpecification )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2599:7: enableValidateSpecification ( relySpecification )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_enableValidateSpecification_in_constraintOptsCreate16404);
			enableValidateSpecification960=enableValidateSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, enableValidateSpecification960.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2599:35: ( relySpecification )?
			int alt298=2;
			int LA298_0 = input.LA(1);
			if ( (LA298_0==KW_NORELY||LA298_0==KW_RELY) ) {
				alt298=1;
			}
			switch (alt298) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2599:35: relySpecification
					{
					pushFollow(FOLLOW_relySpecification_in_constraintOptsCreate16406);
					relySpecification961=relySpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, relySpecification961.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "constraintOptsCreate"


	public static class constraintOptsAlter_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "constraintOptsAlter"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2602:1: constraintOptsAlter : enableValidateSpecification ( relySpecification )? ;
	public final HiveParser.constraintOptsAlter_return constraintOptsAlter() throws RecognitionException {
		HiveParser.constraintOptsAlter_return retval = new HiveParser.constraintOptsAlter_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope enableValidateSpecification962 =null;
		ParserRuleReturnScope relySpecification963 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2603:5: ( enableValidateSpecification ( relySpecification )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2603:7: enableValidateSpecification ( relySpecification )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_enableValidateSpecification_in_constraintOptsAlter16424);
			enableValidateSpecification962=enableValidateSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, enableValidateSpecification962.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2603:35: ( relySpecification )?
			int alt299=2;
			int LA299_0 = input.LA(1);
			if ( (LA299_0==KW_NORELY||LA299_0==KW_RELY) ) {
				alt299=1;
			}
			switch (alt299) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2603:35: relySpecification
					{
					pushFollow(FOLLOW_relySpecification_in_constraintOptsAlter16426);
					relySpecification963=relySpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, relySpecification963.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "constraintOptsAlter"


	public static class columnNameColonType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameColonType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2606:1: columnNameColonType : colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
	public final HiveParser.columnNameColonType_return columnNameColonType() throws RecognitionException {
		HiveParser.columnNameColonType_return retval = new HiveParser.columnNameColonType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token COLON964=null;
		Token KW_COMMENT966=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope colType965 =null;

		ASTNode comment_tree=null;
		ASTNode COLON964_tree=null;
		ASTNode KW_COMMENT966_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_COLON=new RewriteRuleTokenStream(adaptor,"token COLON");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2609:5: (colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2609:7: colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameColonType16456);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			COLON964=(Token)match(input,COLON,FOLLOW_COLON_in_columnNameColonType16458); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_COLON.add(COLON964);

			pushFollow(FOLLOW_colType_in_columnNameColonType16460);
			colType965=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType965.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2609:40: ( KW_COMMENT comment= StringLiteral )?
			int alt300=2;
			int LA300_0 = input.LA(1);
			if ( (LA300_0==KW_COMMENT) ) {
				alt300=1;
			}
			switch (alt300) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2609:41: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT966=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameColonType16463); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT966);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameColonType16467); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: colType, comment, colName, colName, colType
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2610:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
			if (comment == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2610:28: ^( TOK_TABCOL $colName colType )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2611:5: -> ^( TOK_TABCOL $colName colType $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2611:28: ^( TOK_TABCOL $colName colType $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameColonType"


	public static class colType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "colType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2614:1: colType : type ;
	public final HiveParser.colType_return colType() throws RecognitionException {
		HiveParser.colType_return retval = new HiveParser.colType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope type967 =null;


		 pushMsg("column type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2617:5: ( type )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2617:7: type
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_type_in_colType16551);
			type967=type();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, type967.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "colType"


	public static class colTypeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "colTypeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2620:1: colTypeList : colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) ;
	public final HiveParser.colTypeList_return colTypeList() throws RecognitionException {
		HiveParser.colTypeList_return retval = new HiveParser.colTypeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA969=null;
		ParserRuleReturnScope colType968 =null;
		ParserRuleReturnScope colType970 =null;

		ASTNode COMMA969_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column type list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2623:5: ( colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2623:7: colType ( COMMA colType )*
			{
			pushFollow(FOLLOW_colType_in_colTypeList16578);
			colType968=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType968.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2623:15: ( COMMA colType )*
			loop301:
			while (true) {
				int alt301=2;
				int LA301_0 = input.LA(1);
				if ( (LA301_0==COMMA) ) {
					alt301=1;
				}

				switch (alt301) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2623:16: COMMA colType
					{
					COMMA969=(Token)match(input,COMMA,FOLLOW_COMMA_in_colTypeList16581); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA969);

					pushFollow(FOLLOW_colType_in_colTypeList16583);
					colType970=colType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_colType.add(colType970.getTree());
					}
					break;

				default :
					break loop301;
				}
			}

			// AST REWRITE
			// elements: colType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2623:32: -> ^( TOK_COLTYPELIST ( colType )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2623:35: ^( TOK_COLTYPELIST ( colType )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_COLTYPELIST, "TOK_COLTYPELIST"), root_1);
				if ( !(stream_colType.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_colType.hasNext() ) {
					adaptor.addChild(root_1, stream_colType.nextTree());
				}
				stream_colType.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "colTypeList"


	public static class type_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "type"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2626:1: type : ( primitiveType | listType | structType | mapType | unionType );
	public final HiveParser.type_return type() throws RecognitionException {
		HiveParser.type_return retval = new HiveParser.type_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope primitiveType971 =null;
		ParserRuleReturnScope listType972 =null;
		ParserRuleReturnScope structType973 =null;
		ParserRuleReturnScope mapType974 =null;
		ParserRuleReturnScope unionType975 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2627:5: ( primitiveType | listType | structType | mapType | unionType )
			int alt302=5;
			switch ( input.LA(1) ) {
			case KW_BIGINT:
			case KW_BINARY:
			case KW_BOOLEAN:
			case KW_CHAR:
			case KW_DATE:
			case KW_DATETIME:
			case KW_DECIMAL:
			case KW_DOUBLE:
			case KW_FLOAT:
			case KW_INT:
			case KW_SMALLINT:
			case KW_STRING:
			case KW_TIMESTAMP:
			case KW_TIMESTAMPLOCALTZ:
			case KW_TINYINT:
			case KW_VARCHAR:
				{
				alt302=1;
				}
				break;
			case KW_ARRAY:
				{
				alt302=2;
				}
				break;
			case KW_STRUCT:
				{
				alt302=3;
				}
				break;
			case KW_MAP:
				{
				alt302=4;
				}
				break;
			case KW_UNIONTYPE:
				{
				alt302=5;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 302, 0, input);
				throw nvae;
			}
			switch (alt302) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2627:7: primitiveType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_primitiveType_in_type16611);
					primitiveType971=primitiveType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, primitiveType971.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2628:7: listType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_listType_in_type16619);
					listType972=listType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, listType972.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2629:7: structType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_structType_in_type16627);
					structType973=structType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, structType973.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2630:7: mapType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_mapType_in_type16635);
					mapType974=mapType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, mapType974.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2631:7: unionType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_unionType_in_type16643);
					unionType975=unionType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, unionType975.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "type"


	public static class primitiveType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "primitiveType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2633:1: primitiveType : ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE ( KW_PRECISION )? -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_TIMESTAMPLOCALTZ -> TOK_TIMESTAMPLOCALTZ | KW_TIMESTAMP KW_WITH KW_LOCAL KW_TIME KW_ZONE -> TOK_TIMESTAMPLOCALTZ | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) );
	public final HiveParser.primitiveType_return primitiveType() throws RecognitionException {
		HiveParser.primitiveType_return retval = new HiveParser.primitiveType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token prec=null;
		Token scale=null;
		Token length=null;
		Token KW_TINYINT976=null;
		Token KW_SMALLINT977=null;
		Token KW_INT978=null;
		Token KW_BIGINT979=null;
		Token KW_BOOLEAN980=null;
		Token KW_FLOAT981=null;
		Token KW_DOUBLE982=null;
		Token KW_PRECISION983=null;
		Token KW_DATE984=null;
		Token KW_DATETIME985=null;
		Token KW_TIMESTAMP986=null;
		Token KW_TIMESTAMPLOCALTZ987=null;
		Token KW_TIMESTAMP988=null;
		Token KW_WITH989=null;
		Token KW_LOCAL990=null;
		Token KW_TIME991=null;
		Token KW_ZONE992=null;
		Token KW_STRING993=null;
		Token KW_BINARY994=null;
		Token KW_DECIMAL995=null;
		Token LPAREN996=null;
		Token COMMA997=null;
		Token RPAREN998=null;
		Token KW_VARCHAR999=null;
		Token LPAREN1000=null;
		Token RPAREN1001=null;
		Token KW_CHAR1002=null;
		Token LPAREN1003=null;
		Token RPAREN1004=null;

		ASTNode prec_tree=null;
		ASTNode scale_tree=null;
		ASTNode length_tree=null;
		ASTNode KW_TINYINT976_tree=null;
		ASTNode KW_SMALLINT977_tree=null;
		ASTNode KW_INT978_tree=null;
		ASTNode KW_BIGINT979_tree=null;
		ASTNode KW_BOOLEAN980_tree=null;
		ASTNode KW_FLOAT981_tree=null;
		ASTNode KW_DOUBLE982_tree=null;
		ASTNode KW_PRECISION983_tree=null;
		ASTNode KW_DATE984_tree=null;
		ASTNode KW_DATETIME985_tree=null;
		ASTNode KW_TIMESTAMP986_tree=null;
		ASTNode KW_TIMESTAMPLOCALTZ987_tree=null;
		ASTNode KW_TIMESTAMP988_tree=null;
		ASTNode KW_WITH989_tree=null;
		ASTNode KW_LOCAL990_tree=null;
		ASTNode KW_TIME991_tree=null;
		ASTNode KW_ZONE992_tree=null;
		ASTNode KW_STRING993_tree=null;
		ASTNode KW_BINARY994_tree=null;
		ASTNode KW_DECIMAL995_tree=null;
		ASTNode LPAREN996_tree=null;
		ASTNode COMMA997_tree=null;
		ASTNode RPAREN998_tree=null;
		ASTNode KW_VARCHAR999_tree=null;
		ASTNode LPAREN1000_tree=null;
		ASTNode RPAREN1001_tree=null;
		ASTNode KW_CHAR1002_tree=null;
		ASTNode LPAREN1003_tree=null;
		ASTNode RPAREN1004_tree=null;
		RewriteRuleTokenStream stream_KW_DATETIME=new RewriteRuleTokenStream(adaptor,"token KW_DATETIME");
		RewriteRuleTokenStream stream_KW_TIMESTAMP=new RewriteRuleTokenStream(adaptor,"token KW_TIMESTAMP");
		RewriteRuleTokenStream stream_KW_BOOLEAN=new RewriteRuleTokenStream(adaptor,"token KW_BOOLEAN");
		RewriteRuleTokenStream stream_KW_DOUBLE=new RewriteRuleTokenStream(adaptor,"token KW_DOUBLE");
		RewriteRuleTokenStream stream_KW_TIME=new RewriteRuleTokenStream(adaptor,"token KW_TIME");
		RewriteRuleTokenStream stream_KW_CHAR=new RewriteRuleTokenStream(adaptor,"token KW_CHAR");
		RewriteRuleTokenStream stream_KW_INT=new RewriteRuleTokenStream(adaptor,"token KW_INT");
		RewriteRuleTokenStream stream_KW_DECIMAL=new RewriteRuleTokenStream(adaptor,"token KW_DECIMAL");
		RewriteRuleTokenStream stream_KW_ZONE=new RewriteRuleTokenStream(adaptor,"token KW_ZONE");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_TINYINT=new RewriteRuleTokenStream(adaptor,"token KW_TINYINT");
		RewriteRuleTokenStream stream_KW_PRECISION=new RewriteRuleTokenStream(adaptor,"token KW_PRECISION");
		RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_SMALLINT=new RewriteRuleTokenStream(adaptor,"token KW_SMALLINT");
		RewriteRuleTokenStream stream_KW_DATE=new RewriteRuleTokenStream(adaptor,"token KW_DATE");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_BIGINT=new RewriteRuleTokenStream(adaptor,"token KW_BIGINT");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_STRING=new RewriteRuleTokenStream(adaptor,"token KW_STRING");
		RewriteRuleTokenStream stream_KW_VARCHAR=new RewriteRuleTokenStream(adaptor,"token KW_VARCHAR");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_FLOAT=new RewriteRuleTokenStream(adaptor,"token KW_FLOAT");
		RewriteRuleTokenStream stream_KW_TIMESTAMPLOCALTZ=new RewriteRuleTokenStream(adaptor,"token KW_TIMESTAMPLOCALTZ");
		RewriteRuleTokenStream stream_KW_BINARY=new RewriteRuleTokenStream(adaptor,"token KW_BINARY");

		 pushMsg("primitive type specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2636:5: ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE ( KW_PRECISION )? -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_TIMESTAMPLOCALTZ -> TOK_TIMESTAMPLOCALTZ | KW_TIMESTAMP KW_WITH KW_LOCAL KW_TIME KW_ZONE -> TOK_TIMESTAMPLOCALTZ | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) )
			int alt306=17;
			switch ( input.LA(1) ) {
			case KW_TINYINT:
				{
				alt306=1;
				}
				break;
			case KW_SMALLINT:
				{
				alt306=2;
				}
				break;
			case KW_INT:
				{
				alt306=3;
				}
				break;
			case KW_BIGINT:
				{
				alt306=4;
				}
				break;
			case KW_BOOLEAN:
				{
				alt306=5;
				}
				break;
			case KW_FLOAT:
				{
				alt306=6;
				}
				break;
			case KW_DOUBLE:
				{
				alt306=7;
				}
				break;
			case KW_DATE:
				{
				alt306=8;
				}
				break;
			case KW_DATETIME:
				{
				alt306=9;
				}
				break;
			case KW_TIMESTAMP:
				{
				int LA306_10 = input.LA(2);
				if ( (LA306_10==KW_WITH) ) {
					alt306=12;
				}
				else if ( (LA306_10==EOF||LA306_10==COMMA||LA306_10==GREATERTHAN||LA306_10==KW_AFTER||LA306_10==KW_CASCADE||(LA306_10 >= KW_CHECK && LA306_10 <= KW_CLUSTER)||LA306_10==KW_COMMENT||LA306_10==KW_CONSTRAINT||LA306_10==KW_DEFAULT||LA306_10==KW_DISTRIBUTE||LA306_10==KW_EXCEPT||LA306_10==KW_FIRST||LA306_10==KW_FORMAT||LA306_10==KW_FROM||LA306_10==KW_GROUP||LA306_10==KW_HAVING||LA306_10==KW_INSERT||LA306_10==KW_INTERSECT||LA306_10==KW_LATERAL||LA306_10==KW_LIMIT||LA306_10==KW_MAP||LA306_10==KW_MINUS||LA306_10==KW_NOT||LA306_10==KW_ORDER||LA306_10==KW_PRIMARY||LA306_10==KW_RECORDREADER||(LA306_10 >= KW_REDUCE && LA306_10 <= KW_REFERENCES)||LA306_10==KW_RESTRICT||LA306_10==KW_ROW||LA306_10==KW_SELECT||LA306_10==KW_SORT||LA306_10==KW_UNION||LA306_10==KW_UNIQUE||LA306_10==KW_WHERE||LA306_10==KW_WINDOW||LA306_10==RPAREN) ) {
					alt306=10;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 306, 10, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_TIMESTAMPLOCALTZ:
				{
				alt306=11;
				}
				break;
			case KW_STRING:
				{
				alt306=13;
				}
				break;
			case KW_BINARY:
				{
				alt306=14;
				}
				break;
			case KW_DECIMAL:
				{
				alt306=15;
				}
				break;
			case KW_VARCHAR:
				{
				alt306=16;
				}
				break;
			case KW_CHAR:
				{
				alt306=17;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 306, 0, input);
				throw nvae;
			}
			switch (alt306) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2636:7: KW_TINYINT
					{
					KW_TINYINT976=(Token)match(input,KW_TINYINT,FOLLOW_KW_TINYINT_in_primitiveType16665); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TINYINT.add(KW_TINYINT976);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2636:24: -> TOK_TINYINT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TINYINT, "TOK_TINYINT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2637:7: KW_SMALLINT
					{
					KW_SMALLINT977=(Token)match(input,KW_SMALLINT,FOLLOW_KW_SMALLINT_in_primitiveType16686); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SMALLINT.add(KW_SMALLINT977);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2637:24: -> TOK_SMALLINT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_SMALLINT, "TOK_SMALLINT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2638:7: KW_INT
					{
					KW_INT978=(Token)match(input,KW_INT,FOLLOW_KW_INT_in_primitiveType16706); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INT.add(KW_INT978);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2638:24: -> TOK_INT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_INT, "TOK_INT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2639:7: KW_BIGINT
					{
					KW_BIGINT979=(Token)match(input,KW_BIGINT,FOLLOW_KW_BIGINT_in_primitiveType16731); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BIGINT.add(KW_BIGINT979);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2639:24: -> TOK_BIGINT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BIGINT, "TOK_BIGINT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2640:7: KW_BOOLEAN
					{
					KW_BOOLEAN980=(Token)match(input,KW_BOOLEAN,FOLLOW_KW_BOOLEAN_in_primitiveType16753); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BOOLEAN.add(KW_BOOLEAN980);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2640:24: -> TOK_BOOLEAN
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BOOLEAN, "TOK_BOOLEAN"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:7: KW_FLOAT
					{
					KW_FLOAT981=(Token)match(input,KW_FLOAT,FOLLOW_KW_FLOAT_in_primitiveType16774); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FLOAT.add(KW_FLOAT981);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2641:24: -> TOK_FLOAT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_FLOAT, "TOK_FLOAT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2642:7: KW_DOUBLE ( KW_PRECISION )?
					{
					KW_DOUBLE982=(Token)match(input,KW_DOUBLE,FOLLOW_KW_DOUBLE_in_primitiveType16797); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DOUBLE.add(KW_DOUBLE982);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2642:17: ( KW_PRECISION )?
					int alt303=2;
					int LA303_0 = input.LA(1);
					if ( (LA303_0==KW_PRECISION) ) {
						alt303=1;
					}
					switch (alt303) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2642:17: KW_PRECISION
							{
							KW_PRECISION983=(Token)match(input,KW_PRECISION,FOLLOW_KW_PRECISION_in_primitiveType16799); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PRECISION.add(KW_PRECISION983);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2642:37: -> TOK_DOUBLE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DOUBLE, "TOK_DOUBLE"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2643:7: KW_DATE
					{
					KW_DATE984=(Token)match(input,KW_DATE,FOLLOW_KW_DATE_in_primitiveType16821); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATE.add(KW_DATE984);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2643:24: -> TOK_DATE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DATE, "TOK_DATE"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2644:7: KW_DATETIME
					{
					KW_DATETIME985=(Token)match(input,KW_DATETIME,FOLLOW_KW_DATETIME_in_primitiveType16845); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATETIME.add(KW_DATETIME985);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2644:24: -> TOK_DATETIME
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DATETIME, "TOK_DATETIME"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2645:7: KW_TIMESTAMP
					{
					KW_TIMESTAMP986=(Token)match(input,KW_TIMESTAMP,FOLLOW_KW_TIMESTAMP_in_primitiveType16865); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIMESTAMP.add(KW_TIMESTAMP986);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2645:24: -> TOK_TIMESTAMP
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TIMESTAMP, "TOK_TIMESTAMP"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2646:7: KW_TIMESTAMPLOCALTZ
					{
					KW_TIMESTAMPLOCALTZ987=(Token)match(input,KW_TIMESTAMPLOCALTZ,FOLLOW_KW_TIMESTAMPLOCALTZ_in_primitiveType16884); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIMESTAMPLOCALTZ.add(KW_TIMESTAMPLOCALTZ987);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2646:29: -> TOK_TIMESTAMPLOCALTZ
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TIMESTAMPLOCALTZ, "TOK_TIMESTAMPLOCALTZ"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2648:7: KW_TIMESTAMP KW_WITH KW_LOCAL KW_TIME KW_ZONE
					{
					KW_TIMESTAMP988=(Token)match(input,KW_TIMESTAMP,FOLLOW_KW_TIMESTAMP_in_primitiveType16906); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIMESTAMP.add(KW_TIMESTAMP988);

					KW_WITH989=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_primitiveType16908); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH989);

					KW_LOCAL990=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_primitiveType16910); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCAL.add(KW_LOCAL990);

					KW_TIME991=(Token)match(input,KW_TIME,FOLLOW_KW_TIME_in_primitiveType16912); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIME.add(KW_TIME991);

					KW_ZONE992=(Token)match(input,KW_ZONE,FOLLOW_KW_ZONE_in_primitiveType16914); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ZONE.add(KW_ZONE992);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2648:53: -> TOK_TIMESTAMPLOCALTZ
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TIMESTAMPLOCALTZ, "TOK_TIMESTAMPLOCALTZ"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2653:7: KW_STRING
					{
					KW_STRING993=(Token)match(input,KW_STRING,FOLLOW_KW_STRING_in_primitiveType16946); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STRING.add(KW_STRING993);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2653:24: -> TOK_STRING
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_STRING, "TOK_STRING"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2654:7: KW_BINARY
					{
					KW_BINARY994=(Token)match(input,KW_BINARY,FOLLOW_KW_BINARY_in_primitiveType16968); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BINARY.add(KW_BINARY994);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2654:24: -> TOK_BINARY
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BINARY, "TOK_BINARY"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 15 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2655:7: KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
					{
					KW_DECIMAL995=(Token)match(input,KW_DECIMAL,FOLLOW_KW_DECIMAL_in_primitiveType16990); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DECIMAL.add(KW_DECIMAL995);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2655:18: ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
					int alt305=2;
					int LA305_0 = input.LA(1);
					if ( (LA305_0==LPAREN) ) {
						alt305=1;
					}
					switch (alt305) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2655:19: LPAREN prec= Number ( COMMA scale= Number )? RPAREN
							{
							LPAREN996=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType16993); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN996);

							prec=(Token)match(input,Number,FOLLOW_Number_in_primitiveType16997); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(prec);

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2655:38: ( COMMA scale= Number )?
							int alt304=2;
							int LA304_0 = input.LA(1);
							if ( (LA304_0==COMMA) ) {
								alt304=1;
							}
							switch (alt304) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:2655:39: COMMA scale= Number
									{
									COMMA997=(Token)match(input,COMMA,FOLLOW_COMMA_in_primitiveType17000); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_COMMA.add(COMMA997);

									scale=(Token)match(input,Number,FOLLOW_Number_in_primitiveType17004); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_Number.add(scale);

									}
									break;

							}

							RPAREN998=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType17008); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN998);

							}
							break;

					}

					// AST REWRITE
					// elements: scale, prec
					// token labels: prec, scale
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_prec=new RewriteRuleTokenStream(adaptor,"token prec",prec);
					RewriteRuleTokenStream stream_scale=new RewriteRuleTokenStream(adaptor,"token scale",scale);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2655:69: -> ^( TOK_DECIMAL ( $prec)? ( $scale)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2655:72: ^( TOK_DECIMAL ( $prec)? ( $scale)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DECIMAL, "TOK_DECIMAL"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2655:87: ( $prec)?
						if ( stream_prec.hasNext() ) {
							adaptor.addChild(root_1, stream_prec.nextNode());
						}
						stream_prec.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2655:94: ( $scale)?
						if ( stream_scale.hasNext() ) {
							adaptor.addChild(root_1, stream_scale.nextNode());
						}
						stream_scale.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 16 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2656:7: KW_VARCHAR LPAREN length= Number RPAREN
					{
					KW_VARCHAR999=(Token)match(input,KW_VARCHAR,FOLLOW_KW_VARCHAR_in_primitiveType17032); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VARCHAR.add(KW_VARCHAR999);

					LPAREN1000=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType17034); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN1000);

					length=(Token)match(input,Number,FOLLOW_Number_in_primitiveType17038); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(length);

					RPAREN1001=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType17040); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN1001);

					// AST REWRITE
					// elements: length
					// token labels: length
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_length=new RewriteRuleTokenStream(adaptor,"token length",length);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2656:51: -> ^( TOK_VARCHAR $length)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2656:57: ^( TOK_VARCHAR $length)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VARCHAR, "TOK_VARCHAR"), root_1);
						adaptor.addChild(root_1, stream_length.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 17 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2657:7: KW_CHAR LPAREN length= Number RPAREN
					{
					KW_CHAR1002=(Token)match(input,KW_CHAR,FOLLOW_KW_CHAR_in_primitiveType17065); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CHAR.add(KW_CHAR1002);

					LPAREN1003=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType17067); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN1003);

					length=(Token)match(input,Number,FOLLOW_Number_in_primitiveType17071); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(length);

					RPAREN1004=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType17073); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN1004);

					// AST REWRITE
					// elements: length
					// token labels: length
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_length=new RewriteRuleTokenStream(adaptor,"token length",length);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2657:48: -> ^( TOK_CHAR $length)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2657:54: ^( TOK_CHAR $length)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CHAR, "TOK_CHAR"), root_1);
						adaptor.addChild(root_1, stream_length.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "primitiveType"


	public static class listType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "listType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2660:1: listType : KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) ;
	public final HiveParser.listType_return listType() throws RecognitionException {
		HiveParser.listType_return retval = new HiveParser.listType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ARRAY1005=null;
		Token LESSTHAN1006=null;
		Token GREATERTHAN1008=null;
		ParserRuleReturnScope type1007 =null;

		ASTNode KW_ARRAY1005_tree=null;
		ASTNode LESSTHAN1006_tree=null;
		ASTNode GREATERTHAN1008_tree=null;
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_KW_ARRAY=new RewriteRuleTokenStream(adaptor,"token KW_ARRAY");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_type=new RewriteRuleSubtreeStream(adaptor,"rule type");

		 pushMsg("list type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:5: ( KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:7: KW_ARRAY LESSTHAN type GREATERTHAN
			{
			KW_ARRAY1005=(Token)match(input,KW_ARRAY,FOLLOW_KW_ARRAY_in_listType17117); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ARRAY.add(KW_ARRAY1005);

			LESSTHAN1006=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_listType17119); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN1006);

			pushFollow(FOLLOW_type_in_listType17121);
			type1007=type();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_type.add(type1007.getTree());
			GREATERTHAN1008=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_listType17123); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN1008);

			// AST REWRITE
			// elements: type
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2663:44: -> ^( TOK_LIST type )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:47: ^( TOK_LIST type )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIST, "TOK_LIST"), root_1);
				adaptor.addChild(root_1, stream_type.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "listType"


	public static class structType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "structType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2666:1: structType : KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) ;
	public final HiveParser.structType_return structType() throws RecognitionException {
		HiveParser.structType_return retval = new HiveParser.structType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_STRUCT1009=null;
		Token LESSTHAN1010=null;
		Token GREATERTHAN1012=null;
		ParserRuleReturnScope columnNameColonTypeList1011 =null;

		ASTNode KW_STRUCT1009_tree=null;
		ASTNode LESSTHAN1010_tree=null;
		ASTNode GREATERTHAN1012_tree=null;
		RewriteRuleTokenStream stream_KW_STRUCT=new RewriteRuleTokenStream(adaptor,"token KW_STRUCT");
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_columnNameColonTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameColonTypeList");

		 pushMsg("struct type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2669:5: ( KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2669:7: KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN
			{
			KW_STRUCT1009=(Token)match(input,KW_STRUCT,FOLLOW_KW_STRUCT_in_structType17160); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STRUCT.add(KW_STRUCT1009);

			LESSTHAN1010=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_structType17162); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN1010);

			pushFollow(FOLLOW_columnNameColonTypeList_in_structType17164);
			columnNameColonTypeList1011=columnNameColonTypeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameColonTypeList.add(columnNameColonTypeList1011.getTree());
			GREATERTHAN1012=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_structType17166); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN1012);

			// AST REWRITE
			// elements: columnNameColonTypeList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2669:62: -> ^( TOK_STRUCT columnNameColonTypeList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2669:65: ^( TOK_STRUCT columnNameColonTypeList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_STRUCT, "TOK_STRUCT"), root_1);
				adaptor.addChild(root_1, stream_columnNameColonTypeList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "structType"


	public static class mapType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "mapType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2672:1: mapType : KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) ;
	public final HiveParser.mapType_return mapType() throws RecognitionException {
		HiveParser.mapType_return retval = new HiveParser.mapType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_MAP1013=null;
		Token LESSTHAN1014=null;
		Token COMMA1015=null;
		Token GREATERTHAN1016=null;
		ParserRuleReturnScope left =null;
		ParserRuleReturnScope right =null;

		ASTNode KW_MAP1013_tree=null;
		ASTNode LESSTHAN1014_tree=null;
		ASTNode COMMA1015_tree=null;
		ASTNode GREATERTHAN1016_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_MAP=new RewriteRuleTokenStream(adaptor,"token KW_MAP");
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_type=new RewriteRuleSubtreeStream(adaptor,"rule type");
		RewriteRuleSubtreeStream stream_primitiveType=new RewriteRuleSubtreeStream(adaptor,"rule primitiveType");

		 pushMsg("map type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2675:5: ( KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2675:7: KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN
			{
			KW_MAP1013=(Token)match(input,KW_MAP,FOLLOW_KW_MAP_in_mapType17201); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MAP.add(KW_MAP1013);

			LESSTHAN1014=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_mapType17203); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN1014);

			pushFollow(FOLLOW_primitiveType_in_mapType17207);
			left=primitiveType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_primitiveType.add(left.getTree());
			COMMA1015=(Token)match(input,COMMA,FOLLOW_COMMA_in_mapType17209); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_COMMA.add(COMMA1015);

			pushFollow(FOLLOW_type_in_mapType17213);
			right=type();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_type.add(right.getTree());
			GREATERTHAN1016=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_mapType17215); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN1016);

			// AST REWRITE
			// elements: right, left
			// token labels: 
			// rule labels: left, right, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_left=new RewriteRuleSubtreeStream(adaptor,"rule left",left!=null?left.getTree():null);
			RewriteRuleSubtreeStream stream_right=new RewriteRuleSubtreeStream(adaptor,"rule right",right!=null?right.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2676:5: -> ^( TOK_MAP $left $right)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2676:8: ^( TOK_MAP $left $right)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MAP, "TOK_MAP"), root_1);
				adaptor.addChild(root_1, stream_left.nextTree());
				adaptor.addChild(root_1, stream_right.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "mapType"


	public static class unionType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "unionType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2679:1: unionType : KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) ;
	public final HiveParser.unionType_return unionType() throws RecognitionException {
		HiveParser.unionType_return retval = new HiveParser.unionType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNIONTYPE1017=null;
		Token LESSTHAN1018=null;
		Token GREATERTHAN1020=null;
		ParserRuleReturnScope colTypeList1019 =null;

		ASTNode KW_UNIONTYPE1017_tree=null;
		ASTNode LESSTHAN1018_tree=null;
		ASTNode GREATERTHAN1020_tree=null;
		RewriteRuleTokenStream stream_KW_UNIONTYPE=new RewriteRuleTokenStream(adaptor,"token KW_UNIONTYPE");
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_colTypeList=new RewriteRuleSubtreeStream(adaptor,"rule colTypeList");

		 pushMsg("uniontype type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2682:5: ( KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2682:7: KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN
			{
			KW_UNIONTYPE1017=(Token)match(input,KW_UNIONTYPE,FOLLOW_KW_UNIONTYPE_in_unionType17258); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNIONTYPE.add(KW_UNIONTYPE1017);

			LESSTHAN1018=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_unionType17260); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN1018);

			pushFollow(FOLLOW_colTypeList_in_unionType17262);
			colTypeList1019=colTypeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colTypeList.add(colTypeList1019.getTree());
			GREATERTHAN1020=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_unionType17264); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN1020);

			// AST REWRITE
			// elements: colTypeList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2682:53: -> ^( TOK_UNIONTYPE colTypeList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2682:56: ^( TOK_UNIONTYPE colTypeList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONTYPE, "TOK_UNIONTYPE"), root_1);
				adaptor.addChild(root_1, stream_colTypeList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "unionType"


	public static class setOperator_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setOperator"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2685:1: setOperator : ( KW_UNION KW_ALL -> ^( TOK_UNIONALL ) | KW_UNION ( KW_DISTINCT )? -> ^( TOK_UNIONDISTINCT ) | KW_INTERSECT KW_ALL -> ^( TOK_INTERSECTALL ) | KW_INTERSECT ( KW_DISTINCT )? -> ^( TOK_INTERSECTDISTINCT ) | KW_EXCEPT KW_ALL -> ^( TOK_EXCEPTALL ) | KW_EXCEPT ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) | KW_MINUS KW_ALL -> ^( TOK_EXCEPTALL ) | KW_MINUS ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) );
	public final HiveParser.setOperator_return setOperator() throws RecognitionException {
		HiveParser.setOperator_return retval = new HiveParser.setOperator_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNION1021=null;
		Token KW_ALL1022=null;
		Token KW_UNION1023=null;
		Token KW_DISTINCT1024=null;
		Token KW_INTERSECT1025=null;
		Token KW_ALL1026=null;
		Token KW_INTERSECT1027=null;
		Token KW_DISTINCT1028=null;
		Token KW_EXCEPT1029=null;
		Token KW_ALL1030=null;
		Token KW_EXCEPT1031=null;
		Token KW_DISTINCT1032=null;
		Token KW_MINUS1033=null;
		Token KW_ALL1034=null;
		Token KW_MINUS1035=null;
		Token KW_DISTINCT1036=null;

		ASTNode KW_UNION1021_tree=null;
		ASTNode KW_ALL1022_tree=null;
		ASTNode KW_UNION1023_tree=null;
		ASTNode KW_DISTINCT1024_tree=null;
		ASTNode KW_INTERSECT1025_tree=null;
		ASTNode KW_ALL1026_tree=null;
		ASTNode KW_INTERSECT1027_tree=null;
		ASTNode KW_DISTINCT1028_tree=null;
		ASTNode KW_EXCEPT1029_tree=null;
		ASTNode KW_ALL1030_tree=null;
		ASTNode KW_EXCEPT1031_tree=null;
		ASTNode KW_DISTINCT1032_tree=null;
		ASTNode KW_MINUS1033_tree=null;
		ASTNode KW_ALL1034_tree=null;
		ASTNode KW_MINUS1035_tree=null;
		ASTNode KW_DISTINCT1036_tree=null;
		RewriteRuleTokenStream stream_KW_INTERSECT=new RewriteRuleTokenStream(adaptor,"token KW_INTERSECT");
		RewriteRuleTokenStream stream_KW_EXCEPT=new RewriteRuleTokenStream(adaptor,"token KW_EXCEPT");
		RewriteRuleTokenStream stream_KW_UNION=new RewriteRuleTokenStream(adaptor,"token KW_UNION");
		RewriteRuleTokenStream stream_KW_DISTINCT=new RewriteRuleTokenStream(adaptor,"token KW_DISTINCT");
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
		RewriteRuleTokenStream stream_KW_MINUS=new RewriteRuleTokenStream(adaptor,"token KW_MINUS");

		 pushMsg("set operator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:5: ( KW_UNION KW_ALL -> ^( TOK_UNIONALL ) | KW_UNION ( KW_DISTINCT )? -> ^( TOK_UNIONDISTINCT ) | KW_INTERSECT KW_ALL -> ^( TOK_INTERSECTALL ) | KW_INTERSECT ( KW_DISTINCT )? -> ^( TOK_INTERSECTDISTINCT ) | KW_EXCEPT KW_ALL -> ^( TOK_EXCEPTALL ) | KW_EXCEPT ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) | KW_MINUS KW_ALL -> ^( TOK_EXCEPTALL ) | KW_MINUS ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) )
			int alt311=8;
			switch ( input.LA(1) ) {
			case KW_UNION:
				{
				int LA311_1 = input.LA(2);
				if ( (LA311_1==KW_ALL) ) {
					alt311=1;
				}
				else if ( (LA311_1==EOF||LA311_1==KW_DISTINCT||LA311_1==KW_FROM||LA311_1==KW_MAP||LA311_1==KW_REDUCE||LA311_1==KW_SELECT||LA311_1==LPAREN) ) {
					alt311=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 311, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_INTERSECT:
				{
				int LA311_2 = input.LA(2);
				if ( (LA311_2==KW_ALL) ) {
					alt311=3;
				}
				else if ( (LA311_2==EOF||LA311_2==KW_DISTINCT||LA311_2==KW_FROM||LA311_2==KW_MAP||LA311_2==KW_REDUCE||LA311_2==KW_SELECT||LA311_2==LPAREN) ) {
					alt311=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 311, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_EXCEPT:
				{
				int LA311_3 = input.LA(2);
				if ( (LA311_3==KW_ALL) ) {
					alt311=5;
				}
				else if ( (LA311_3==EOF||LA311_3==KW_DISTINCT||LA311_3==KW_FROM||LA311_3==KW_MAP||LA311_3==KW_REDUCE||LA311_3==KW_SELECT||LA311_3==LPAREN) ) {
					alt311=6;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 311, 3, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_MINUS:
				{
				int LA311_4 = input.LA(2);
				if ( (LA311_4==KW_ALL) ) {
					alt311=7;
				}
				else if ( (LA311_4==EOF||LA311_4==KW_DISTINCT||LA311_4==KW_FROM||LA311_4==KW_MAP||LA311_4==KW_REDUCE||LA311_4==KW_SELECT||LA311_4==LPAREN) ) {
					alt311=8;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 311, 4, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 311, 0, input);
				throw nvae;
			}
			switch (alt311) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:7: KW_UNION KW_ALL
					{
					KW_UNION1021=(Token)match(input,KW_UNION,FOLLOW_KW_UNION_in_setOperator17299); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNION.add(KW_UNION1021);

					KW_ALL1022=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator17301); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL1022);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2688:23: -> ^( TOK_UNIONALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:26: ^( TOK_UNIONALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2689:7: KW_UNION ( KW_DISTINCT )?
					{
					KW_UNION1023=(Token)match(input,KW_UNION,FOLLOW_KW_UNION_in_setOperator17315); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNION.add(KW_UNION1023);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2689:16: ( KW_DISTINCT )?
					int alt307=2;
					int LA307_0 = input.LA(1);
					if ( (LA307_0==KW_DISTINCT) ) {
						alt307=1;
					}
					switch (alt307) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2689:16: KW_DISTINCT
							{
							KW_DISTINCT1024=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator17317); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT1024);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2689:29: -> ^( TOK_UNIONDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2689:32: ^( TOK_UNIONDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONDISTINCT, "TOK_UNIONDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2690:7: KW_INTERSECT KW_ALL
					{
					KW_INTERSECT1025=(Token)match(input,KW_INTERSECT,FOLLOW_KW_INTERSECT_in_setOperator17332); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INTERSECT.add(KW_INTERSECT1025);

					KW_ALL1026=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator17334); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL1026);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2690:27: -> ^( TOK_INTERSECTALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2690:30: ^( TOK_INTERSECTALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INTERSECTALL, "TOK_INTERSECTALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2691:7: KW_INTERSECT ( KW_DISTINCT )?
					{
					KW_INTERSECT1027=(Token)match(input,KW_INTERSECT,FOLLOW_KW_INTERSECT_in_setOperator17348); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INTERSECT.add(KW_INTERSECT1027);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2691:20: ( KW_DISTINCT )?
					int alt308=2;
					int LA308_0 = input.LA(1);
					if ( (LA308_0==KW_DISTINCT) ) {
						alt308=1;
					}
					switch (alt308) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2691:20: KW_DISTINCT
							{
							KW_DISTINCT1028=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator17350); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT1028);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2691:33: -> ^( TOK_INTERSECTDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2691:36: ^( TOK_INTERSECTDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INTERSECTDISTINCT, "TOK_INTERSECTDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2692:7: KW_EXCEPT KW_ALL
					{
					KW_EXCEPT1029=(Token)match(input,KW_EXCEPT,FOLLOW_KW_EXCEPT_in_setOperator17365); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXCEPT.add(KW_EXCEPT1029);

					KW_ALL1030=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator17367); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL1030);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2692:24: -> ^( TOK_EXCEPTALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2692:27: ^( TOK_EXCEPTALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTALL, "TOK_EXCEPTALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2693:7: KW_EXCEPT ( KW_DISTINCT )?
					{
					KW_EXCEPT1031=(Token)match(input,KW_EXCEPT,FOLLOW_KW_EXCEPT_in_setOperator17381); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXCEPT.add(KW_EXCEPT1031);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2693:17: ( KW_DISTINCT )?
					int alt309=2;
					int LA309_0 = input.LA(1);
					if ( (LA309_0==KW_DISTINCT) ) {
						alt309=1;
					}
					switch (alt309) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2693:17: KW_DISTINCT
							{
							KW_DISTINCT1032=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator17383); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT1032);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2693:30: -> ^( TOK_EXCEPTDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2693:33: ^( TOK_EXCEPTDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTDISTINCT, "TOK_EXCEPTDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2694:7: KW_MINUS KW_ALL
					{
					KW_MINUS1033=(Token)match(input,KW_MINUS,FOLLOW_KW_MINUS_in_setOperator17398); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MINUS.add(KW_MINUS1033);

					KW_ALL1034=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator17400); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL1034);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2694:23: -> ^( TOK_EXCEPTALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2694:26: ^( TOK_EXCEPTALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTALL, "TOK_EXCEPTALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2695:7: KW_MINUS ( KW_DISTINCT )?
					{
					KW_MINUS1035=(Token)match(input,KW_MINUS,FOLLOW_KW_MINUS_in_setOperator17414); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MINUS.add(KW_MINUS1035);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2695:16: ( KW_DISTINCT )?
					int alt310=2;
					int LA310_0 = input.LA(1);
					if ( (LA310_0==KW_DISTINCT) ) {
						alt310=1;
					}
					switch (alt310) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2695:16: KW_DISTINCT
							{
							KW_DISTINCT1036=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator17416); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT1036);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2695:29: -> ^( TOK_EXCEPTDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2695:32: ^( TOK_EXCEPTDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTDISTINCT, "TOK_EXCEPTDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setOperator"


	public static class queryStatementExpression_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "queryStatementExpression"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2698:1: queryStatementExpression : (w= withClause )? queryStatementExpressionBody -> queryStatementExpressionBody ;
	public final HiveParser.queryStatementExpression_return queryStatementExpression() throws RecognitionException {
		HiveParser.queryStatementExpression_return retval = new HiveParser.queryStatementExpression_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope w =null;
		ParserRuleReturnScope queryStatementExpressionBody1037 =null;

		RewriteRuleSubtreeStream stream_withClause=new RewriteRuleSubtreeStream(adaptor,"rule withClause");
		RewriteRuleSubtreeStream stream_queryStatementExpressionBody=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpressionBody");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2699:5: ( (w= withClause )? queryStatementExpressionBody -> queryStatementExpressionBody )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2704:5: (w= withClause )? queryStatementExpressionBody
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2704:5: (w= withClause )?
			int alt312=2;
			int LA312_0 = input.LA(1);
			if ( (LA312_0==KW_WITH) ) {
				alt312=1;
			}
			switch (alt312) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2704:6: w= withClause
					{
					pushFollow(FOLLOW_withClause_in_queryStatementExpression17453);
					w=withClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withClause.add(w.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_queryStatementExpressionBody_in_queryStatementExpression17461);
			queryStatementExpressionBody1037=queryStatementExpressionBody();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_queryStatementExpressionBody.add(queryStatementExpressionBody1037.getTree());
			if ( state.backtracking==0 ) {
			      if ((w!=null?((ASTNode)w.getTree()):null) != null) {
			      (queryStatementExpressionBody1037!=null?((ASTNode)queryStatementExpressionBody1037.getTree()):null).insertChild(0, (w!=null?((ASTNode)w.getTree()):null));
			      }
			    }
			// AST REWRITE
			// elements: queryStatementExpressionBody
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2710:5: -> queryStatementExpressionBody
			{
				adaptor.addChild(root_0, stream_queryStatementExpressionBody.nextTree());
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "queryStatementExpression"


	public static class queryStatementExpressionBody_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "queryStatementExpressionBody"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2713:1: queryStatementExpressionBody : ( fromStatement | regularBody );
	public final HiveParser.queryStatementExpressionBody_return queryStatementExpressionBody() throws RecognitionException {
		HiveParser.queryStatementExpressionBody_return retval = new HiveParser.queryStatementExpressionBody_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope fromStatement1038 =null;
		ParserRuleReturnScope regularBody1039 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2714:5: ( fromStatement | regularBody )
			int alt313=2;
			int LA313_0 = input.LA(1);
			if ( (LA313_0==KW_FROM) ) {
				alt313=1;
			}
			else if ( (LA313_0==KW_INSERT||LA313_0==KW_MAP||LA313_0==KW_REDUCE||LA313_0==KW_SELECT||LA313_0==LPAREN) ) {
				alt313=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 313, 0, input);
				throw nvae;
			}

			switch (alt313) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2715:5: fromStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_fromStatement_in_queryStatementExpressionBody17493);
					fromStatement1038=fromStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, fromStatement1038.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2716:7: regularBody
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_regularBody_in_queryStatementExpressionBody17501);
					regularBody1039=regularBody();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, regularBody1039.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "queryStatementExpressionBody"


	public static class withClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "withClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2719:1: withClause : KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) ;
	public final HiveParser.withClause_return withClause() throws RecognitionException {
		HiveParser.withClause_return retval = new HiveParser.withClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WITH1040=null;
		Token COMMA1042=null;
		ParserRuleReturnScope cteStatement1041 =null;
		ParserRuleReturnScope cteStatement1043 =null;

		ASTNode KW_WITH1040_tree=null;
		ASTNode COMMA1042_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleSubtreeStream stream_cteStatement=new RewriteRuleSubtreeStream(adaptor,"rule cteStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2720:3: ( KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2721:3: KW_WITH cteStatement ( COMMA cteStatement )*
			{
			KW_WITH1040=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withClause17518); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH1040);

			pushFollow(FOLLOW_cteStatement_in_withClause17520);
			cteStatement1041=cteStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_cteStatement.add(cteStatement1041.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2721:24: ( COMMA cteStatement )*
			loop314:
			while (true) {
				int alt314=2;
				int LA314_0 = input.LA(1);
				if ( (LA314_0==COMMA) ) {
					alt314=1;
				}

				switch (alt314) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2721:25: COMMA cteStatement
					{
					COMMA1042=(Token)match(input,COMMA,FOLLOW_COMMA_in_withClause17523); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA1042);

					pushFollow(FOLLOW_cteStatement_in_withClause17525);
					cteStatement1043=cteStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_cteStatement.add(cteStatement1043.getTree());
					}
					break;

				default :
					break loop314;
				}
			}

			// AST REWRITE
			// elements: cteStatement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2721:46: -> ^( TOK_CTE ( cteStatement )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2721:49: ^( TOK_CTE ( cteStatement )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CTE, "TOK_CTE"), root_1);
				if ( !(stream_cteStatement.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_cteStatement.hasNext() ) {
					adaptor.addChild(root_1, stream_cteStatement.nextTree());
				}
				stream_cteStatement.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "withClause"


	public static class cteStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "cteStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2724:1: cteStatement : identifier KW_AS LPAREN queryStatementExpression RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ) ;
	public final HiveParser.cteStatement_return cteStatement() throws RecognitionException {
		HiveParser.cteStatement_return retval = new HiveParser.cteStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_AS1045=null;
		Token LPAREN1046=null;
		Token RPAREN1048=null;
		ParserRuleReturnScope identifier1044 =null;
		ParserRuleReturnScope queryStatementExpression1047 =null;

		ASTNode KW_AS1045_tree=null;
		ASTNode LPAREN1046_tree=null;
		ASTNode RPAREN1048_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_queryStatementExpression=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpression");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2725:4: ( identifier KW_AS LPAREN queryStatementExpression RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2726:4: identifier KW_AS LPAREN queryStatementExpression RPAREN
			{
			pushFollow(FOLLOW_identifier_in_cteStatement17551);
			identifier1044=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier1044.getTree());
			KW_AS1045=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_cteStatement17553); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS1045);

			LPAREN1046=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_cteStatement17555); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN1046);

			pushFollow(FOLLOW_queryStatementExpression_in_cteStatement17557);
			queryStatementExpression1047=queryStatementExpression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_queryStatementExpression.add(queryStatementExpression1047.getTree());
			RPAREN1048=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_cteStatement17559); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN1048);

			// AST REWRITE
			// elements: queryStatementExpression, identifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2727:4: -> ^( TOK_SUBQUERY queryStatementExpression identifier )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2727:7: ^( TOK_SUBQUERY queryStatementExpression identifier )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_1);
				adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());
				adaptor.addChild(root_1, stream_identifier.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "cteStatement"


	public static class fromStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "fromStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2730:1: fromStatement : ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->;
	public final HiveParser.fromStatement_return fromStatement() throws RecognitionException {
		HiveParser.fromStatement_return retval = new HiveParser.fromStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope u =null;
		ParserRuleReturnScope r =null;
		ParserRuleReturnScope singleFromStatement1049 =null;

		RewriteRuleSubtreeStream stream_setOperator=new RewriteRuleSubtreeStream(adaptor,"rule setOperator");
		RewriteRuleSubtreeStream stream_singleFromStatement=new RewriteRuleSubtreeStream(adaptor,"rule singleFromStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2731:3: ( ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2731:3: ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )*
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2731:3: ( singleFromStatement -> singleFromStatement )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2731:4: singleFromStatement
			{
			pushFollow(FOLLOW_singleFromStatement_in_fromStatement17582);
			singleFromStatement1049=singleFromStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_singleFromStatement.add(singleFromStatement1049.getTree());
			// AST REWRITE
			// elements: singleFromStatement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2731:25: -> singleFromStatement
			{
				adaptor.addChild(root_0, stream_singleFromStatement.nextTree());
			}


			retval.tree = root_0;
			}

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2732:2: (u= setOperator r= singleFromStatement -> ^( $u $r) )*
			loop315:
			while (true) {
				int alt315=2;
				int LA315_0 = input.LA(1);
				if ( (LA315_0==KW_EXCEPT||LA315_0==KW_INTERSECT||LA315_0==KW_MINUS||LA315_0==KW_UNION) ) {
					alt315=1;
				}

				switch (alt315) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2732:3: u= setOperator r= singleFromStatement
					{
					pushFollow(FOLLOW_setOperator_in_fromStatement17594);
					u=setOperator();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setOperator.add(u.getTree());
					pushFollow(FOLLOW_singleFromStatement_in_fromStatement17598);
					r=singleFromStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_singleFromStatement.add(r.getTree());
					// AST REWRITE
					// elements: u, r
					// token labels: 
					// rule labels: r, u, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_r=new RewriteRuleSubtreeStream(adaptor,"rule r",r!=null?r.getTree():null);
					RewriteRuleSubtreeStream stream_u=new RewriteRuleSubtreeStream(adaptor,"rule u",u!=null?u.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2733:4: -> ^( $u $r)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2733:7: ^( $u $r)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);
						adaptor.addChild(root_1, retval.tree);
						adaptor.addChild(root_1, stream_r.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

				default :
					break loop315;
				}
			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2735:3: -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
			if (u != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2735:19: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2736:9: ^( TOK_FROM ^( TOK_SUBQUERY ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2737:11: ^( TOK_SUBQUERY )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
				adaptor.addChild(root_3, retval.tree);
				adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2742:9: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2743:12: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2743:30: ^( TOK_DIR TOK_TMP_FILE )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2744:12: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2744:25: ^( TOK_SELEXPR TOK_SETCOLREF )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2747:5: ->
			{
				adaptor.addChild(root_0, retval.tree);
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "fromStatement"


	public static class singleFromStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "singleFromStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2751:1: singleFromStatement : fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) ;
	public final HiveParser.singleFromStatement_return singleFromStatement() throws RecognitionException {
		HiveParser.singleFromStatement_return retval = new HiveParser.singleFromStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		List<Object> list_b=null;
		ParserRuleReturnScope fromClause1050 =null;
		RuleReturnScope b = null;
		RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
		RewriteRuleSubtreeStream stream_body=new RewriteRuleSubtreeStream(adaptor,"rule body");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2752:5: ( fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2753:5: fromClause (b+= body )+
			{
			pushFollow(FOLLOW_fromClause_in_singleFromStatement17805);
			fromClause1050=fromClause();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_fromClause.add(fromClause1050.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2754:5: (b+= body )+
			int cnt316=0;
			loop316:
			while (true) {
				int alt316=2;
				int LA316_0 = input.LA(1);
				if ( (LA316_0==KW_INSERT||LA316_0==KW_MAP||LA316_0==KW_REDUCE||LA316_0==KW_SELECT) ) {
					alt316=1;
				}

				switch (alt316) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2754:7: b+= body
					{
					pushFollow(FOLLOW_body_in_singleFromStatement17815);
					b=body();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_body.add(b.getTree());
					if (list_b==null) list_b=new ArrayList<Object>();
					list_b.add(b.getTree());
					}
					break;

				default :
					if ( cnt316 >= 1 ) break loop316;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(316, input);
					throw eee;
				}
				cnt316++;
			}

			// AST REWRITE
			// elements: body, fromClause
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2754:18: -> ^( TOK_QUERY fromClause ( body )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2754:21: ^( TOK_QUERY fromClause ( body )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				adaptor.addChild(root_1, stream_fromClause.nextTree());
				if ( !(stream_body.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_body.hasNext() ) {
					adaptor.addChild(root_1, stream_body.nextTree());
				}
				stream_body.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "singleFromStatement"


	public static class regularBody_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "regularBody"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2763:1: regularBody : (i= insertClause (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) ) ) | selectStatement );
	public final HiveParser.regularBody_return regularBody() throws RecognitionException {
		HiveParser.regularBody_return retval = new HiveParser.regularBody_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope i =null;
		ParserRuleReturnScope s =null;
		ParserRuleReturnScope valuesClause1051 =null;
		ParserRuleReturnScope selectStatement1052 =null;

		RewriteRuleSubtreeStream stream_insertClause=new RewriteRuleSubtreeStream(adaptor,"rule insertClause");
		RewriteRuleSubtreeStream stream_valuesClause=new RewriteRuleSubtreeStream(adaptor,"rule valuesClause");
		RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2764:4: (i= insertClause (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) ) ) | selectStatement )
			int alt318=2;
			int LA318_0 = input.LA(1);
			if ( (LA318_0==KW_INSERT) ) {
				alt318=1;
			}
			else if ( (LA318_0==KW_MAP||LA318_0==KW_REDUCE||LA318_0==KW_SELECT||LA318_0==LPAREN) ) {
				alt318=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 318, 0, input);
				throw nvae;
			}

			switch (alt318) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2765:4: i= insertClause (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) ) )
					{
					pushFollow(FOLLOW_insertClause_in_regularBody17852);
					i=insertClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_insertClause.add(i.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2766:4: (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) ) )
					int alt317=2;
					int LA317_0 = input.LA(1);
					if ( (LA317_0==KW_MAP||LA317_0==KW_REDUCE||LA317_0==KW_SELECT||LA317_0==LPAREN) ) {
						alt317=1;
					}
					else if ( (LA317_0==KW_VALUES) ) {
						alt317=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 317, 0, input);
						throw nvae;
					}

					switch (alt317) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2767:4: s= selectStatement
							{
							pushFollow(FOLLOW_selectStatement_in_regularBody17864);
							s=selectStatement();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_selectStatement.add(s.getTree());
							if ( state.backtracking==0 ) {(s!=null?((ASTNode)s.getTree()):null).getFirstChildWithType(TOK_INSERT).replaceChildren(0, 0, (i!=null?((ASTNode)i.getTree()):null));}
							// AST REWRITE
							// elements: 
							// token labels: 
							// rule labels: retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 2768:82: ->
							{
								adaptor.addChild(root_0, (s!=null?((ASTNode)s.getTree()):null));
							}


							retval.tree = root_0;
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2770:6: valuesClause
							{
							pushFollow(FOLLOW_valuesClause_in_regularBody17889);
							valuesClause1051=valuesClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_valuesClause.add(valuesClause1051.getTree());
							// AST REWRITE
							// elements: valuesClause
							// token labels: 
							// rule labels: retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 2771:7: -> ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:2771:10: ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:2772:13: ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) )
								{
								ASTNode root_2 = (ASTNode)adaptor.nil();
								root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
								adaptor.addChild(root_2, (i!=null?((ASTNode)i.getTree()):null));
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:2772:36: ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) )
								{
								ASTNode root_3 = (ASTNode)adaptor.nil();
								root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:2772:49: ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) )
								{
								ASTNode root_4 = (ASTNode)adaptor.nil();
								root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:2772:63: ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause )
								{
								ASTNode root_5 = (ASTNode)adaptor.nil();
								root_5 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FUNCTION, "TOK_FUNCTION"), root_5);
								adaptor.addChild(root_5, (ASTNode)adaptor.create(Identifier, "inline"));
								adaptor.addChild(root_5, stream_valuesClause.nextTree());
								adaptor.addChild(root_4, root_5);
								}

								adaptor.addChild(root_3, root_4);
								}

								adaptor.addChild(root_2, root_3);
								}

								adaptor.addChild(root_1, root_2);
								}

								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2776:4: selectStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_selectStatement_in_regularBody17962);
					selectStatement1052=selectStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatement1052.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "regularBody"


	public static class atomSelectStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "atomSelectStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2779:1: atomSelectStatement : (s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )? -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) ) | LPAREN ! selectStatement RPAREN !);
	public final HiveParser.atomSelectStatement_return atomSelectStatement() throws RecognitionException {
		HiveParser.atomSelectStatement_return retval = new HiveParser.atomSelectStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN1053=null;
		Token RPAREN1055=null;
		ParserRuleReturnScope s =null;
		ParserRuleReturnScope f =null;
		ParserRuleReturnScope w =null;
		ParserRuleReturnScope g =null;
		ParserRuleReturnScope h =null;
		ParserRuleReturnScope win =null;
		ParserRuleReturnScope selectStatement1054 =null;

		ASTNode LPAREN1053_tree=null;
		ASTNode RPAREN1055_tree=null;
		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
		RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
		RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
		RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
		RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2780:4: (s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )? -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) ) | LPAREN ! selectStatement RPAREN !)
			int alt324=2;
			int LA324_0 = input.LA(1);
			if ( (LA324_0==KW_MAP||LA324_0==KW_REDUCE||LA324_0==KW_SELECT) ) {
				alt324=1;
			}
			else if ( (LA324_0==LPAREN) ) {
				alt324=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 324, 0, input);
				throw nvae;
			}

			switch (alt324) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2781:4: s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )?
					{
					pushFollow(FOLLOW_selectClause_in_atomSelectStatement17982);
					s=selectClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_selectClause.add(s.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2782:5: (f= fromClause )?
					int alt319=2;
					int LA319_0 = input.LA(1);
					if ( (LA319_0==KW_FROM) ) {
						alt319=1;
					}
					switch (alt319) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2782:5: f= fromClause
							{
							pushFollow(FOLLOW_fromClause_in_atomSelectStatement17989);
							f=fromClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_fromClause.add(f.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2783:5: (w= whereClause )?
					int alt320=2;
					int LA320_0 = input.LA(1);
					if ( (LA320_0==KW_WHERE) ) {
						alt320=1;
					}
					switch (alt320) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2783:5: w= whereClause
							{
							pushFollow(FOLLOW_whereClause_in_atomSelectStatement17997);
							w=whereClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_whereClause.add(w.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2784:5: (g= groupByClause )?
					int alt321=2;
					int LA321_0 = input.LA(1);
					if ( (LA321_0==KW_GROUP) ) {
						alt321=1;
					}
					switch (alt321) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2784:5: g= groupByClause
							{
							pushFollow(FOLLOW_groupByClause_in_atomSelectStatement18005);
							g=groupByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_groupByClause.add(g.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2785:5: (h= havingClause )?
					int alt322=2;
					int LA322_0 = input.LA(1);
					if ( (LA322_0==KW_HAVING) ) {
						alt322=1;
					}
					switch (alt322) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2785:5: h= havingClause
							{
							pushFollow(FOLLOW_havingClause_in_atomSelectStatement18013);
							h=havingClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_havingClause.add(h.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2786:7: (win= window_clause )?
					int alt323=2;
					int LA323_0 = input.LA(1);
					if ( (LA323_0==KW_WINDOW) ) {
						alt323=1;
					}
					switch (alt323) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2786:7: win= window_clause
							{
							pushFollow(FOLLOW_window_clause_in_atomSelectStatement18021);
							win=window_clause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_window_clause.add(win.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: f, w, h, win, s, g
					// token labels: 
					// rule labels: s, f, w, g, h, win, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_s=new RewriteRuleSubtreeStream(adaptor,"rule s",s!=null?s.getTree():null);
					RewriteRuleSubtreeStream stream_f=new RewriteRuleSubtreeStream(adaptor,"rule f",f!=null?f.getTree():null);
					RewriteRuleSubtreeStream stream_w=new RewriteRuleSubtreeStream(adaptor,"rule w",w!=null?w.getTree():null);
					RewriteRuleSubtreeStream stream_g=new RewriteRuleSubtreeStream(adaptor,"rule g",g!=null?g.getTree():null);
					RewriteRuleSubtreeStream stream_h=new RewriteRuleSubtreeStream(adaptor,"rule h",h!=null?h.getTree():null);
					RewriteRuleSubtreeStream stream_win=new RewriteRuleSubtreeStream(adaptor,"rule win",win!=null?win.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2787:4: -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2787:7: ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2787:20: ( $f)?
						if ( stream_f.hasNext() ) {
							adaptor.addChild(root_1, stream_f.nextTree());
						}
						stream_f.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2787:23: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2787:36: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2787:54: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_2, stream_s.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2788:26: ( $w)?
						if ( stream_w.hasNext() ) {
							adaptor.addChild(root_2, stream_w.nextTree());
						}
						stream_w.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2788:30: ( $g)?
						if ( stream_g.hasNext() ) {
							adaptor.addChild(root_2, stream_g.nextTree());
						}
						stream_g.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2788:34: ( $h)?
						if ( stream_h.hasNext() ) {
							adaptor.addChild(root_2, stream_h.nextTree());
						}
						stream_h.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2788:38: ( $win)?
						if ( stream_win.hasNext() ) {
							adaptor.addChild(root_2, stream_win.nextTree());
						}
						stream_win.reset();

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2790:4: LPAREN ! selectStatement RPAREN !
					{
					root_0 = (ASTNode)adaptor.nil();


					LPAREN1053=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_atomSelectStatement18099); if (state.failed) return retval;
					pushFollow(FOLLOW_selectStatement_in_atomSelectStatement18102);
					selectStatement1054=selectStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatement1054.getTree());

					RPAREN1055=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_atomSelectStatement18104); if (state.failed) return retval;
					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "atomSelectStatement"


	public static class selectStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "selectStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2793:1: selectStatement : a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )? -> {set == null}? -> {o==null && c==null && d==null && sort==null && l==null}? -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) ) ;
	public final HiveParser.selectStatement_return selectStatement() throws RecognitionException {
		HiveParser.selectStatement_return retval = new HiveParser.selectStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope a =null;
		ParserRuleReturnScope set =null;
		ParserRuleReturnScope o =null;
		ParserRuleReturnScope c =null;
		ParserRuleReturnScope d =null;
		ParserRuleReturnScope sort =null;
		ParserRuleReturnScope l =null;

		RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
		RewriteRuleSubtreeStream stream_setOpSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule setOpSelectStatement");
		RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
		RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
		RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
		RewriteRuleSubtreeStream stream_atomSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule atomSelectStatement");
		RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2794:4: (a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )? -> {set == null}? -> {o==null && c==null && d==null && sort==null && l==null}? -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2795:4: a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )?
			{
			pushFollow(FOLLOW_atomSelectStatement_in_selectStatement18125);
			a=atomSelectStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_atomSelectStatement.add(a.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2796:7: (set= setOpSelectStatement[$atomSelectStatement.tree] )?
			int alt325=2;
			int LA325_0 = input.LA(1);
			if ( (LA325_0==KW_EXCEPT||LA325_0==KW_INTERSECT||LA325_0==KW_MINUS||LA325_0==KW_UNION) ) {
				alt325=1;
			}
			switch (alt325) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2796:7: set= setOpSelectStatement[$atomSelectStatement.tree]
					{
					pushFollow(FOLLOW_setOpSelectStatement_in_selectStatement18132);
					set=setOpSelectStatement((a!=null?((ASTNode)a.getTree()):null));
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setOpSelectStatement.add(set.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2797:5: (o= orderByClause )?
			int alt326=2;
			int LA326_0 = input.LA(1);
			if ( (LA326_0==KW_ORDER) ) {
				alt326=1;
			}
			switch (alt326) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2797:5: o= orderByClause
					{
					pushFollow(FOLLOW_orderByClause_in_selectStatement18141);
					o=orderByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orderByClause.add(o.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2798:5: (c= clusterByClause )?
			int alt327=2;
			int LA327_0 = input.LA(1);
			if ( (LA327_0==KW_CLUSTER) ) {
				alt327=1;
			}
			switch (alt327) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2798:5: c= clusterByClause
					{
					pushFollow(FOLLOW_clusterByClause_in_selectStatement18149);
					c=clusterByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_clusterByClause.add(c.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2799:5: (d= distributeByClause )?
			int alt328=2;
			int LA328_0 = input.LA(1);
			if ( (LA328_0==KW_DISTRIBUTE) ) {
				alt328=1;
			}
			switch (alt328) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2799:5: d= distributeByClause
					{
					pushFollow(FOLLOW_distributeByClause_in_selectStatement18157);
					d=distributeByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_distributeByClause.add(d.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2800:8: (sort= sortByClause )?
			int alt329=2;
			int LA329_0 = input.LA(1);
			if ( (LA329_0==KW_SORT) ) {
				alt329=1;
			}
			switch (alt329) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2800:8: sort= sortByClause
					{
					pushFollow(FOLLOW_sortByClause_in_selectStatement18165);
					sort=sortByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_sortByClause.add(sort.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2801:5: (l= limitClause )?
			int alt330=2;
			int LA330_0 = input.LA(1);
			if ( (LA330_0==KW_LIMIT) ) {
				alt330=1;
			}
			switch (alt330) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2801:5: l= limitClause
					{
					pushFollow(FOLLOW_limitClause_in_selectStatement18173);
					l=limitClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_limitClause.add(l.getTree());
					}
					break;

			}

			if ( state.backtracking==0 ) {
			   if(set == null){
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((o!=null?((ASTNode)o.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((c!=null?((ASTNode)c.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((d!=null?((ASTNode)d.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((sort!=null?((ASTNode)sort.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((l!=null?((ASTNode)l.getTree()):null));
			   }
			   }
			// AST REWRITE
			// elements: l, o, sort, d, c
			// token labels: 
			// rule labels: c, d, sort, l, retval, o
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_c=new RewriteRuleSubtreeStream(adaptor,"rule c",c!=null?c.getTree():null);
			RewriteRuleSubtreeStream stream_d=new RewriteRuleSubtreeStream(adaptor,"rule d",d!=null?d.getTree():null);
			RewriteRuleSubtreeStream stream_sort=new RewriteRuleSubtreeStream(adaptor,"rule sort",sort!=null?sort.getTree():null);
			RewriteRuleSubtreeStream stream_l=new RewriteRuleSubtreeStream(adaptor,"rule l",l!=null?l.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_o=new RewriteRuleSubtreeStream(adaptor,"rule o",o!=null?o.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2811:4: -> {set == null}?
			if (set == null) {
				adaptor.addChild(root_0, (a!=null?((ASTNode)a.getTree()):null));
			}

			else // 2813:4: -> {o==null && c==null && d==null && sort==null && l==null}?
			if (o==null && c==null && d==null && sort==null && l==null) {
				adaptor.addChild(root_0, (set!=null?((ASTNode)set.getTree()):null));
			}

			else // 2815:4: -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2815:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2816:11: ^( TOK_FROM ^( TOK_SUBQUERY ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2817:13: ^( TOK_SUBQUERY )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
				adaptor.addChild(root_3, (set!=null?((ASTNode)set.getTree()):null));
				adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2822:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2823:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2823:32: ^( TOK_DIR TOK_TMP_FILE )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2824:14: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2824:27: ^( TOK_SELEXPR TOK_SETCOLREF )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2825:15: ( $o)?
				if ( stream_o.hasNext() ) {
					adaptor.addChild(root_2, stream_o.nextTree());
				}
				stream_o.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2825:19: ( $c)?
				if ( stream_c.hasNext() ) {
					adaptor.addChild(root_2, stream_c.nextTree());
				}
				stream_c.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2825:23: ( $d)?
				if ( stream_d.hasNext() ) {
					adaptor.addChild(root_2, stream_d.nextTree());
				}
				stream_d.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2825:27: ( $sort)?
				if ( stream_sort.hasNext() ) {
					adaptor.addChild(root_2, stream_sort.nextTree());
				}
				stream_sort.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2825:34: ( $l)?
				if ( stream_l.hasNext() ) {
					adaptor.addChild(root_2, stream_l.nextTree());
				}
				stream_l.reset();

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "selectStatement"


	public static class setOpSelectStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setOpSelectStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2830:1: setOpSelectStatement[CommonTree t] : (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+ -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->;
	public final HiveParser.setOpSelectStatement_return setOpSelectStatement(CommonTree t) throws RecognitionException {
		HiveParser.setOpSelectStatement_return retval = new HiveParser.setOpSelectStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope u =null;
		ParserRuleReturnScope b =null;

		RewriteRuleSubtreeStream stream_setOperator=new RewriteRuleSubtreeStream(adaptor,"rule setOperator");
		RewriteRuleSubtreeStream stream_atomSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule atomSelectStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2831:4: ( (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+ -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2832:4: (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2832:4: (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+
			int cnt331=0;
			loop331:
			while (true) {
				int alt331=2;
				int LA331_0 = input.LA(1);
				if ( (LA331_0==KW_EXCEPT||LA331_0==KW_INTERSECT||LA331_0==KW_MINUS||LA331_0==KW_UNION) ) {
					alt331=1;
				}

				switch (alt331) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2832:5: u= setOperator b= atomSelectStatement
					{
					pushFollow(FOLLOW_setOperator_in_setOpSelectStatement18438);
					u=setOperator();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setOperator.add(u.getTree());
					pushFollow(FOLLOW_atomSelectStatement_in_setOpSelectStatement18442);
					b=atomSelectStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_atomSelectStatement.add(b.getTree());
					// AST REWRITE
					// elements: u, b, b, b, u, b
					// token labels: 
					// rule labels: b, u, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_b=new RewriteRuleSubtreeStream(adaptor,"rule b",b!=null?b.getTree():null);
					RewriteRuleSubtreeStream stream_u=new RewriteRuleSubtreeStream(adaptor,"rule u",u!=null?u.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2833:4: -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
					if (retval.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2834:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2835:11: ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2836:13: ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2837:15: ^( TOK_UNIONALL $b)
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL"), root_4);
						adaptor.addChild(root_4, retval.tree);
						adaptor.addChild(root_4, stream_b.nextTree());
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2841:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2842:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2842:32: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2843:14: ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECTDI, "TOK_SELECTDI"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2843:29: ^( TOK_SELEXPR TOK_SETCOLREF )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_0, root_1);
						}

					}

					else // 2846:4: -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b)
					if (retval.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2847:7: ^( $u $b)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);
						adaptor.addChild(root_1, retval.tree);
						adaptor.addChild(root_1, stream_b.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}

					else // 2848:4: -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
					if (retval.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2849:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2850:11: ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2851:13: ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2852:15: ^( TOK_UNIONALL $b)
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL"), root_4);
						adaptor.addChild(root_4, t);
						adaptor.addChild(root_4, stream_b.nextTree());
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2856:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2857:13: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2857:31: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2858:13: ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECTDI, "TOK_SELECTDI"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2858:28: ^( TOK_SELEXPR TOK_SETCOLREF )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_0, root_1);
						}

					}

					else // 2861:4: -> ^( $u $b)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2861:7: ^( $u $b)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);
						adaptor.addChild(root_1, t);
						adaptor.addChild(root_1, stream_b.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

				default :
					if ( cnt331 >= 1 ) break loop331;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(331, input);
					throw eee;
				}
				cnt331++;
			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2863:4: -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
			if (retval.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2868:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2869:11: ^( TOK_FROM ^( TOK_SUBQUERY ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2870:13: ^( TOK_SUBQUERY )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
				adaptor.addChild(root_3, retval.tree);
				adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2875:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2876:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2876:32: ^( TOK_DIR TOK_TMP_FILE )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2877:14: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2877:27: ^( TOK_SELEXPR TOK_SETCOLREF )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2880:4: ->
			{
				adaptor.addChild(root_0, retval.tree);
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setOpSelectStatement"


	public static class selectStatementWithCTE_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "selectStatementWithCTE"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2883:1: selectStatementWithCTE : (w= withClause )? selectStatement -> selectStatement ;
	public final HiveParser.selectStatementWithCTE_return selectStatementWithCTE() throws RecognitionException {
		HiveParser.selectStatementWithCTE_return retval = new HiveParser.selectStatementWithCTE_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope w =null;
		ParserRuleReturnScope selectStatement1056 =null;

		RewriteRuleSubtreeStream stream_withClause=new RewriteRuleSubtreeStream(adaptor,"rule withClause");
		RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2884:5: ( (w= withClause )? selectStatement -> selectStatement )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2885:5: (w= withClause )? selectStatement
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2885:5: (w= withClause )?
			int alt332=2;
			int LA332_0 = input.LA(1);
			if ( (LA332_0==KW_WITH) ) {
				alt332=1;
			}
			switch (alt332) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2885:6: w= withClause
					{
					pushFollow(FOLLOW_withClause_in_selectStatementWithCTE19077);
					w=withClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withClause.add(w.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_selectStatement_in_selectStatementWithCTE19085);
			selectStatement1056=selectStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_selectStatement.add(selectStatement1056.getTree());
			if ( state.backtracking==0 ) {
			      if ((w!=null?((ASTNode)w.getTree()):null) != null) {
			      (selectStatement1056!=null?((ASTNode)selectStatement1056.getTree()):null).insertChild(0, (w!=null?((ASTNode)w.getTree()):null));
			      }
			    }
			// AST REWRITE
			// elements: selectStatement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2891:5: -> selectStatement
			{
				adaptor.addChild(root_0, stream_selectStatement.nextTree());
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "selectStatementWithCTE"


	public static class body_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "body"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2894:1: body : ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) );
	public final HiveParser.body_return body() throws RecognitionException {
		HiveParser.body_return retval = new HiveParser.body_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope insertClause1057 =null;
		ParserRuleReturnScope selectClause1058 =null;
		ParserRuleReturnScope lateralView1059 =null;
		ParserRuleReturnScope whereClause1060 =null;
		ParserRuleReturnScope groupByClause1061 =null;
		ParserRuleReturnScope havingClause1062 =null;
		ParserRuleReturnScope window_clause1063 =null;
		ParserRuleReturnScope orderByClause1064 =null;
		ParserRuleReturnScope clusterByClause1065 =null;
		ParserRuleReturnScope distributeByClause1066 =null;
		ParserRuleReturnScope sortByClause1067 =null;
		ParserRuleReturnScope limitClause1068 =null;
		ParserRuleReturnScope selectClause1069 =null;
		ParserRuleReturnScope lateralView1070 =null;
		ParserRuleReturnScope whereClause1071 =null;
		ParserRuleReturnScope groupByClause1072 =null;
		ParserRuleReturnScope havingClause1073 =null;
		ParserRuleReturnScope window_clause1074 =null;
		ParserRuleReturnScope orderByClause1075 =null;
		ParserRuleReturnScope clusterByClause1076 =null;
		ParserRuleReturnScope distributeByClause1077 =null;
		ParserRuleReturnScope sortByClause1078 =null;
		ParserRuleReturnScope limitClause1079 =null;

		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
		RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
		RewriteRuleSubtreeStream stream_lateralView=new RewriteRuleSubtreeStream(adaptor,"rule lateralView");
		RewriteRuleSubtreeStream stream_insertClause=new RewriteRuleSubtreeStream(adaptor,"rule insertClause");
		RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
		RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
		RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
		RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
		RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
		RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");
		RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2895:4: ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
			int alt353=2;
			int LA353_0 = input.LA(1);
			if ( (LA353_0==KW_INSERT) ) {
				alt353=1;
			}
			else if ( (LA353_0==KW_MAP||LA353_0==KW_REDUCE||LA353_0==KW_SELECT) ) {
				alt353=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 353, 0, input);
				throw nvae;
			}

			switch (alt353) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2896:4: insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )?
					{
					pushFollow(FOLLOW_insertClause_in_body19115);
					insertClause1057=insertClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_insertClause.add(insertClause1057.getTree());
					pushFollow(FOLLOW_selectClause_in_body19120);
					selectClause1058=selectClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_selectClause.add(selectClause1058.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2898:4: ( lateralView )?
					int alt333=2;
					int LA333_0 = input.LA(1);
					if ( (LA333_0==COMMA||LA333_0==KW_LATERAL) ) {
						alt333=1;
					}
					switch (alt333) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2898:4: lateralView
							{
							pushFollow(FOLLOW_lateralView_in_body19125);
							lateralView1059=lateralView();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_lateralView.add(lateralView1059.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2899:4: ( whereClause )?
					int alt334=2;
					int LA334_0 = input.LA(1);
					if ( (LA334_0==KW_WHERE) ) {
						alt334=1;
					}
					switch (alt334) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2899:4: whereClause
							{
							pushFollow(FOLLOW_whereClause_in_body19131);
							whereClause1060=whereClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_whereClause.add(whereClause1060.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2900:4: ( groupByClause )?
					int alt335=2;
					int LA335_0 = input.LA(1);
					if ( (LA335_0==KW_GROUP) ) {
						alt335=1;
					}
					switch (alt335) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2900:4: groupByClause
							{
							pushFollow(FOLLOW_groupByClause_in_body19137);
							groupByClause1061=groupByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_groupByClause.add(groupByClause1061.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2901:4: ( havingClause )?
					int alt336=2;
					int LA336_0 = input.LA(1);
					if ( (LA336_0==KW_HAVING) ) {
						alt336=1;
					}
					switch (alt336) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2901:4: havingClause
							{
							pushFollow(FOLLOW_havingClause_in_body19143);
							havingClause1062=havingClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_havingClause.add(havingClause1062.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2902:4: ( window_clause )?
					int alt337=2;
					int LA337_0 = input.LA(1);
					if ( (LA337_0==KW_WINDOW) ) {
						alt337=1;
					}
					switch (alt337) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2902:4: window_clause
							{
							pushFollow(FOLLOW_window_clause_in_body19149);
							window_clause1063=window_clause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_window_clause.add(window_clause1063.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2903:4: ( orderByClause )?
					int alt338=2;
					int LA338_0 = input.LA(1);
					if ( (LA338_0==KW_ORDER) ) {
						alt338=1;
					}
					switch (alt338) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2903:4: orderByClause
							{
							pushFollow(FOLLOW_orderByClause_in_body19155);
							orderByClause1064=orderByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause1064.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2904:4: ( clusterByClause )?
					int alt339=2;
					int LA339_0 = input.LA(1);
					if ( (LA339_0==KW_CLUSTER) ) {
						alt339=1;
					}
					switch (alt339) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2904:4: clusterByClause
							{
							pushFollow(FOLLOW_clusterByClause_in_body19161);
							clusterByClause1065=clusterByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_clusterByClause.add(clusterByClause1065.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:4: ( distributeByClause )?
					int alt340=2;
					int LA340_0 = input.LA(1);
					if ( (LA340_0==KW_DISTRIBUTE) ) {
						alt340=1;
					}
					switch (alt340) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:4: distributeByClause
							{
							pushFollow(FOLLOW_distributeByClause_in_body19167);
							distributeByClause1066=distributeByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_distributeByClause.add(distributeByClause1066.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2906:4: ( sortByClause )?
					int alt341=2;
					int LA341_0 = input.LA(1);
					if ( (LA341_0==KW_SORT) ) {
						alt341=1;
					}
					switch (alt341) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2906:4: sortByClause
							{
							pushFollow(FOLLOW_sortByClause_in_body19173);
							sortByClause1067=sortByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_sortByClause.add(sortByClause1067.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2907:4: ( limitClause )?
					int alt342=2;
					int LA342_0 = input.LA(1);
					if ( (LA342_0==KW_LIMIT) ) {
						alt342=1;
					}
					switch (alt342) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2907:4: limitClause
							{
							pushFollow(FOLLOW_limitClause_in_body19179);
							limitClause1068=limitClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_limitClause.add(limitClause1068.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: clusterByClause, lateralView, whereClause, groupByClause, havingClause, selectClause, distributeByClause, insertClause, sortByClause, window_clause, orderByClause, limitClause
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2907:17: -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2907:20: ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_1);
						adaptor.addChild(root_1, stream_insertClause.nextTree());
						adaptor.addChild(root_1, stream_selectClause.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2908:35: ( lateralView )?
						if ( stream_lateralView.hasNext() ) {
							adaptor.addChild(root_1, stream_lateralView.nextTree());
						}
						stream_lateralView.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2908:48: ( whereClause )?
						if ( stream_whereClause.hasNext() ) {
							adaptor.addChild(root_1, stream_whereClause.nextTree());
						}
						stream_whereClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2908:61: ( groupByClause )?
						if ( stream_groupByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_groupByClause.nextTree());
						}
						stream_groupByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2908:76: ( havingClause )?
						if ( stream_havingClause.hasNext() ) {
							adaptor.addChild(root_1, stream_havingClause.nextTree());
						}
						stream_havingClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2908:90: ( orderByClause )?
						if ( stream_orderByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_orderByClause.nextTree());
						}
						stream_orderByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2908:105: ( clusterByClause )?
						if ( stream_clusterByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_clusterByClause.nextTree());
						}
						stream_clusterByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2909:22: ( distributeByClause )?
						if ( stream_distributeByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_distributeByClause.nextTree());
						}
						stream_distributeByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2909:42: ( sortByClause )?
						if ( stream_sortByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_sortByClause.nextTree());
						}
						stream_sortByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2909:56: ( window_clause )?
						if ( stream_window_clause.hasNext() ) {
							adaptor.addChild(root_1, stream_window_clause.nextTree());
						}
						stream_window_clause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2909:71: ( limitClause )?
						if ( stream_limitClause.hasNext() ) {
							adaptor.addChild(root_1, stream_limitClause.nextTree());
						}
						stream_limitClause.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2911:4: selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )?
					{
					pushFollow(FOLLOW_selectClause_in_body19272);
					selectClause1069=selectClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_selectClause.add(selectClause1069.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2912:4: ( lateralView )?
					int alt343=2;
					int LA343_0 = input.LA(1);
					if ( (LA343_0==COMMA||LA343_0==KW_LATERAL) ) {
						alt343=1;
					}
					switch (alt343) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2912:4: lateralView
							{
							pushFollow(FOLLOW_lateralView_in_body19277);
							lateralView1070=lateralView();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_lateralView.add(lateralView1070.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2913:4: ( whereClause )?
					int alt344=2;
					int LA344_0 = input.LA(1);
					if ( (LA344_0==KW_WHERE) ) {
						alt344=1;
					}
					switch (alt344) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2913:4: whereClause
							{
							pushFollow(FOLLOW_whereClause_in_body19283);
							whereClause1071=whereClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_whereClause.add(whereClause1071.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2914:4: ( groupByClause )?
					int alt345=2;
					int LA345_0 = input.LA(1);
					if ( (LA345_0==KW_GROUP) ) {
						alt345=1;
					}
					switch (alt345) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2914:4: groupByClause
							{
							pushFollow(FOLLOW_groupByClause_in_body19289);
							groupByClause1072=groupByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_groupByClause.add(groupByClause1072.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2915:4: ( havingClause )?
					int alt346=2;
					int LA346_0 = input.LA(1);
					if ( (LA346_0==KW_HAVING) ) {
						alt346=1;
					}
					switch (alt346) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2915:4: havingClause
							{
							pushFollow(FOLLOW_havingClause_in_body19295);
							havingClause1073=havingClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_havingClause.add(havingClause1073.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2916:4: ( window_clause )?
					int alt347=2;
					int LA347_0 = input.LA(1);
					if ( (LA347_0==KW_WINDOW) ) {
						alt347=1;
					}
					switch (alt347) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2916:4: window_clause
							{
							pushFollow(FOLLOW_window_clause_in_body19301);
							window_clause1074=window_clause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_window_clause.add(window_clause1074.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2917:4: ( orderByClause )?
					int alt348=2;
					int LA348_0 = input.LA(1);
					if ( (LA348_0==KW_ORDER) ) {
						alt348=1;
					}
					switch (alt348) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2917:4: orderByClause
							{
							pushFollow(FOLLOW_orderByClause_in_body19307);
							orderByClause1075=orderByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause1075.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2918:4: ( clusterByClause )?
					int alt349=2;
					int LA349_0 = input.LA(1);
					if ( (LA349_0==KW_CLUSTER) ) {
						alt349=1;
					}
					switch (alt349) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2918:4: clusterByClause
							{
							pushFollow(FOLLOW_clusterByClause_in_body19313);
							clusterByClause1076=clusterByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_clusterByClause.add(clusterByClause1076.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2919:4: ( distributeByClause )?
					int alt350=2;
					int LA350_0 = input.LA(1);
					if ( (LA350_0==KW_DISTRIBUTE) ) {
						alt350=1;
					}
					switch (alt350) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2919:4: distributeByClause
							{
							pushFollow(FOLLOW_distributeByClause_in_body19319);
							distributeByClause1077=distributeByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_distributeByClause.add(distributeByClause1077.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2920:4: ( sortByClause )?
					int alt351=2;
					int LA351_0 = input.LA(1);
					if ( (LA351_0==KW_SORT) ) {
						alt351=1;
					}
					switch (alt351) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2920:4: sortByClause
							{
							pushFollow(FOLLOW_sortByClause_in_body19325);
							sortByClause1078=sortByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_sortByClause.add(sortByClause1078.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2921:4: ( limitClause )?
					int alt352=2;
					int LA352_0 = input.LA(1);
					if ( (LA352_0==KW_LIMIT) ) {
						alt352=1;
					}
					switch (alt352) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2921:4: limitClause
							{
							pushFollow(FOLLOW_limitClause_in_body19331);
							limitClause1079=limitClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_limitClause.add(limitClause1079.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: distributeByClause, lateralView, whereClause, havingClause, selectClause, groupByClause, orderByClause, limitClause, sortByClause, clusterByClause, window_clause
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2921:17: -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2921:20: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2921:33: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2921:51: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_3);
						adaptor.addChild(root_3, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_1, stream_selectClause.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:35: ( lateralView )?
						if ( stream_lateralView.hasNext() ) {
							adaptor.addChild(root_1, stream_lateralView.nextTree());
						}
						stream_lateralView.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:48: ( whereClause )?
						if ( stream_whereClause.hasNext() ) {
							adaptor.addChild(root_1, stream_whereClause.nextTree());
						}
						stream_whereClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:61: ( groupByClause )?
						if ( stream_groupByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_groupByClause.nextTree());
						}
						stream_groupByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:76: ( havingClause )?
						if ( stream_havingClause.hasNext() ) {
							adaptor.addChild(root_1, stream_havingClause.nextTree());
						}
						stream_havingClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:90: ( orderByClause )?
						if ( stream_orderByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_orderByClause.nextTree());
						}
						stream_orderByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:105: ( clusterByClause )?
						if ( stream_clusterByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_clusterByClause.nextTree());
						}
						stream_clusterByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2923:22: ( distributeByClause )?
						if ( stream_distributeByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_distributeByClause.nextTree());
						}
						stream_distributeByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2923:42: ( sortByClause )?
						if ( stream_sortByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_sortByClause.nextTree());
						}
						stream_sortByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2923:56: ( window_clause )?
						if ( stream_window_clause.hasNext() ) {
							adaptor.addChild(root_1, stream_window_clause.nextTree());
						}
						stream_window_clause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2923:71: ( limitClause )?
						if ( stream_limitClause.hasNext() ) {
							adaptor.addChild(root_1, stream_limitClause.nextTree());
						}
						stream_limitClause.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "body"


	public static class insertClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "insertClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2926:1: insertClause : ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )? -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? ) );
	public final HiveParser.insertClause_return insertClause() throws RecognitionException {
		HiveParser.insertClause_return retval = new HiveParser.insertClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_INSERT1080=null;
		Token KW_OVERWRITE1081=null;
		Token KW_INSERT1084=null;
		Token KW_INTO1085=null;
		Token KW_TABLE1086=null;
		Token LPAREN1088=null;
		Token RPAREN1089=null;
		ParserRuleReturnScope targetCols =null;
		ParserRuleReturnScope destination1082 =null;
		ParserRuleReturnScope ifNotExists1083 =null;
		ParserRuleReturnScope tableOrPartition1087 =null;

		ASTNode KW_INSERT1080_tree=null;
		ASTNode KW_OVERWRITE1081_tree=null;
		ASTNode KW_INSERT1084_tree=null;
		ASTNode KW_INTO1085_tree=null;
		ASTNode KW_TABLE1086_tree=null;
		ASTNode LPAREN1088_tree=null;
		ASTNode RPAREN1089_tree=null;
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
		RewriteRuleSubtreeStream stream_destination=new RewriteRuleSubtreeStream(adaptor,"rule destination");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("insert clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2929:4: ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )? -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? ) )
			int alt357=2;
			int LA357_0 = input.LA(1);
			if ( (LA357_0==KW_INSERT) ) {
				int LA357_1 = input.LA(2);
				if ( (LA357_1==KW_OVERWRITE) ) {
					alt357=1;
				}
				else if ( (LA357_1==KW_INTO) ) {
					alt357=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 357, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 357, 0, input);
				throw nvae;
			}

			switch (alt357) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2930:6: KW_INSERT KW_OVERWRITE destination ( ifNotExists )?
					{
					KW_INSERT1080=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_insertClause19452); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT1080);

					KW_OVERWRITE1081=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_insertClause19454); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(KW_OVERWRITE1081);

					pushFollow(FOLLOW_destination_in_insertClause19456);
					destination1082=destination();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_destination.add(destination1082.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2930:41: ( ifNotExists )?
					int alt354=2;
					int LA354_0 = input.LA(1);
					if ( (LA354_0==KW_IF) ) {
						alt354=1;
					}
					switch (alt354) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2930:41: ifNotExists
							{
							pushFollow(FOLLOW_ifNotExists_in_insertClause19458);
							ifNotExists1083=ifNotExists();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists1083.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: ifNotExists, destination
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2930:54: -> ^( TOK_DESTINATION destination ( ifNotExists )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2930:57: ^( TOK_DESTINATION destination ( ifNotExists )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_1);
						adaptor.addChild(root_1, stream_destination.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2930:87: ( ifNotExists )?
						if ( stream_ifNotExists.hasNext() ) {
							adaptor.addChild(root_1, stream_ifNotExists.nextTree());
						}
						stream_ifNotExists.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2931:6: KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )?
					{
					KW_INSERT1084=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_insertClause19477); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT1084);

					KW_INTO1085=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_insertClause19479); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO1085);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2931:24: ( KW_TABLE )?
					int alt355=2;
					int LA355_0 = input.LA(1);
					if ( (LA355_0==KW_TABLE) ) {
						alt355=1;
					}
					switch (alt355) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2931:24: KW_TABLE
							{
							KW_TABLE1086=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_insertClause19481); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE1086);

							}
							break;

					}

					pushFollow(FOLLOW_tableOrPartition_in_insertClause19484);
					tableOrPartition1087=tableOrPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableOrPartition.add(tableOrPartition1087.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2931:51: ( LPAREN targetCols= columnNameList RPAREN )?
					int alt356=2;
					int LA356_0 = input.LA(1);
					if ( (LA356_0==LPAREN) ) {
						int LA356_1 = input.LA(2);
						if ( (LA356_1==Identifier||(LA356_1 >= KW_ABORT && LA356_1 <= KW_AFTER)||LA356_1==KW_ALLOC_FRACTION||LA356_1==KW_ANALYZE||LA356_1==KW_ARCHIVE||LA356_1==KW_ASC||(LA356_1 >= KW_AUTOCOMMIT && LA356_1 <= KW_BEFORE)||(LA356_1 >= KW_BUCKET && LA356_1 <= KW_BUCKETS)||(LA356_1 >= KW_CACHE && LA356_1 <= KW_CASCADE)||(LA356_1 >= KW_CBO && LA356_1 <= KW_CHANGE)||(LA356_1 >= KW_CHECK && LA356_1 <= KW_COLLECTION)||(LA356_1 >= KW_COLUMNS && LA356_1 <= KW_COMMENT)||(LA356_1 >= KW_COMPACT && LA356_1 <= KW_CONCATENATE)||(LA356_1 >= KW_CONTINUE && LA356_1 <= KW_COST)||LA356_1==KW_DATA||LA356_1==KW_DATABASES||(LA356_1 >= KW_DATETIME && LA356_1 <= KW_DEBUG)||(LA356_1 >= KW_DEFAULT && LA356_1 <= KW_DEFINED)||(LA356_1 >= KW_DELIMITED && LA356_1 <= KW_DESC)||(LA356_1 >= KW_DETAIL && LA356_1 <= KW_DISABLE)||(LA356_1 >= KW_DISTRIBUTE && LA356_1 <= KW_DO)||LA356_1==KW_DOW||(LA356_1 >= KW_DUMP && LA356_1 <= KW_ELEM_TYPE)||LA356_1==KW_ENABLE||(LA356_1 >= KW_ENFORCED && LA356_1 <= KW_ESCAPED)||LA356_1==KW_EXCLUSIVE||(LA356_1 >= KW_EXPLAIN && LA356_1 <= KW_EXPRESSION)||(LA356_1 >= KW_FIELDS && LA356_1 <= KW_FIRST)||(LA356_1 >= KW_FORMAT && LA356_1 <= KW_FORMATTED)||LA356_1==KW_FUNCTIONS||(LA356_1 >= KW_HOUR && LA356_1 <= KW_IDXPROPERTIES)||(LA356_1 >= KW_INDEX && LA356_1 <= KW_INDEXES)||(LA356_1 >= KW_INPATH && LA356_1 <= KW_INPUTFORMAT)||(LA356_1 >= KW_ISOLATION && LA356_1 <= KW_JAR)||(LA356_1 >= KW_JOINCOST && LA356_1 <= KW_LAST)||LA356_1==KW_LEVEL||(LA356_1 >= KW_LIMIT && LA356_1 <= KW_LOAD)||(LA356_1 >= KW_LOCATION && LA356_1 <= KW_LONG)||LA356_1==KW_MANAGEMENT||(LA356_1 >= KW_MAPJOIN && LA356_1 <= KW_MATERIALIZED)||LA356_1==KW_METADATA||(LA356_1 >= KW_MINUTE && LA356_1 <= KW_MONTH)||(LA356_1 >= KW_MOVE && LA356_1 <= KW_MSCK)||(LA356_1 >= KW_NORELY && LA356_1 <= KW_NOSCAN)||LA356_1==KW_NOVALIDATE||LA356_1==KW_NULLS||LA356_1==KW_OFFSET||(LA356_1 >= KW_OPERATOR && LA356_1 <= KW_OPTION)||(LA356_1 >= KW_OUTPUTDRIVER && LA356_1 <= KW_OUTPUTFORMAT)||(LA356_1 >= KW_OVERWRITE && LA356_1 <= KW_OWNER)||(LA356_1 >= KW_PARTITIONED && LA356_1 <= KW_PATH)||(LA356_1 >= KW_PLAN && LA356_1 <= KW_POOL)||LA356_1==KW_PRINCIPALS||(LA356_1 >= KW_PURGE && LA356_1 <= KW_QUERY_PARALLELISM)||LA356_1==KW_READ||(LA356_1 >= KW_REBUILD && LA356_1 <= KW_RECORDWRITER)||(LA356_1 >= KW_RELOAD && LA356_1 <= KW_RESTRICT)||LA356_1==KW_REWRITE||(LA356_1 >= KW_ROLE && LA356_1 <= KW_ROLES)||(LA356_1 >= KW_SCHEDULING_POLICY && LA356_1 <= KW_SECOND)||(LA356_1 >= KW_SEMI && LA356_1 <= KW_SERVER)||(LA356_1 >= KW_SETS && LA356_1 <= KW_SKEWED)||(LA356_1 >= KW_SNAPSHOT && LA356_1 <= KW_SSL)||(LA356_1 >= KW_STATISTICS && LA356_1 <= KW_SUMMARY)||LA356_1==KW_TABLES||(LA356_1 >= KW_TBLPROPERTIES && LA356_1 <= KW_TERMINATED)||LA356_1==KW_TINYINT||(LA356_1 >= KW_TOUCH && LA356_1 <= KW_TRANSACTIONS)||LA356_1==KW_UNARCHIVE||LA356_1==KW_UNDO||LA356_1==KW_UNIONTYPE||(LA356_1 >= KW_UNLOCK && LA356_1 <= KW_UNSIGNED)||(LA356_1 >= KW_URI && LA356_1 <= KW_USE)||(LA356_1 >= KW_UTC && LA356_1 <= KW_VALIDATE)||LA356_1==KW_VALUE_TYPE||(LA356_1 >= KW_VECTORIZATION && LA356_1 <= KW_WEEK)||LA356_1==KW_WHILE||(LA356_1 >= KW_WORK && LA356_1 <= KW_ZONE)||LA356_1==KW_BATCH||LA356_1==KW_DAYOFWEEK||LA356_1==KW_HOLD_DDLTIME||LA356_1==KW_IGNORE||LA356_1==KW_NO_DROP||LA356_1==KW_OFFLINE||LA356_1==KW_PROTECTION||LA356_1==KW_READONLY||LA356_1==KW_TIMESTAMPTZ) ) {
							alt356=1;
						}
					}
					switch (alt356) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2931:52: LPAREN targetCols= columnNameList RPAREN
							{
							LPAREN1088=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_insertClause19487); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN1088);

							pushFollow(FOLLOW_columnNameList_in_insertClause19491);
							targetCols=columnNameList();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_columnNameList.add(targetCols.getTree());
							RPAREN1089=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_insertClause19493); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN1089);

							}
							break;

					}

					// AST REWRITE
					// elements: targetCols, tableOrPartition
					// token labels: 
					// rule labels: targetCols, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_targetCols=new RewriteRuleSubtreeStream(adaptor,"rule targetCols",targetCols!=null?targetCols.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2932:8: -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2932:11: ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT_INTO, "TOK_INSERT_INTO"), root_1);
						adaptor.addChild(root_1, stream_tableOrPartition.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2932:47: ( $targetCols)?
						if ( stream_targetCols.hasNext() ) {
							adaptor.addChild(root_1, stream_targetCols.nextTree());
						}
						stream_targetCols.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "insertClause"


	public static class destination_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "destination"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2935:1: destination : ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition );
	public final HiveParser.destination_return destination() throws RecognitionException {
		HiveParser.destination_return retval = new HiveParser.destination_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token local=null;
		Token KW_DIRECTORY1090=null;
		Token StringLiteral1091=null;
		Token KW_TABLE1094=null;
		ParserRuleReturnScope tableRowFormat1092 =null;
		ParserRuleReturnScope tableFileFormat1093 =null;
		ParserRuleReturnScope tableOrPartition1095 =null;

		ASTNode local_tree=null;
		ASTNode KW_DIRECTORY1090_tree=null;
		ASTNode StringLiteral1091_tree=null;
		ASTNode KW_TABLE1094_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_DIRECTORY=new RewriteRuleTokenStream(adaptor,"token KW_DIRECTORY");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
		RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
		RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");

		 pushMsg("destination specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2938:4: ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition )
			int alt361=2;
			int LA361_0 = input.LA(1);
			if ( (LA361_0==KW_DIRECTORY||LA361_0==KW_LOCAL) ) {
				alt361=1;
			}
			else if ( (LA361_0==KW_TABLE) ) {
				alt361=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 361, 0, input);
				throw nvae;
			}

			switch (alt361) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2939:6: (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2939:6: (local= KW_LOCAL )?
					int alt358=2;
					int LA358_0 = input.LA(1);
					if ( (LA358_0==KW_LOCAL) ) {
						alt358=1;
					}
					switch (alt358) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2939:7: local= KW_LOCAL
							{
							local=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_destination19549); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LOCAL.add(local);

							}
							break;

					}

					KW_DIRECTORY1090=(Token)match(input,KW_DIRECTORY,FOLLOW_KW_DIRECTORY_in_destination19553); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DIRECTORY.add(KW_DIRECTORY1090);

					StringLiteral1091=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_destination19555); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral1091);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2939:53: ( tableRowFormat )?
					int alt359=2;
					int LA359_0 = input.LA(1);
					if ( (LA359_0==KW_ROW) ) {
						alt359=1;
					}
					switch (alt359) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2939:53: tableRowFormat
							{
							pushFollow(FOLLOW_tableRowFormat_in_destination19557);
							tableRowFormat1092=tableRowFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat1092.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2939:69: ( tableFileFormat )?
					int alt360=2;
					int LA360_0 = input.LA(1);
					if ( (LA360_0==KW_STORED) ) {
						alt360=1;
					}
					switch (alt360) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2939:69: tableFileFormat
							{
							pushFollow(FOLLOW_tableFileFormat_in_destination19560);
							tableFileFormat1093=tableFileFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat1093.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: local, tableFileFormat, StringLiteral, tableRowFormat
					// token labels: local
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_local=new RewriteRuleTokenStream(adaptor,"token local",local);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2940:8: -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2940:11: ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2940:36: ( $local)?
						if ( stream_local.hasNext() ) {
							adaptor.addChild(root_1, stream_local.nextNode());
						}
						stream_local.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2940:43: ( tableRowFormat )?
						if ( stream_tableRowFormat.hasNext() ) {
							adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
						}
						stream_tableRowFormat.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2940:59: ( tableFileFormat )?
						if ( stream_tableFileFormat.hasNext() ) {
							adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
						}
						stream_tableFileFormat.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2941:6: KW_TABLE tableOrPartition
					{
					KW_TABLE1094=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_destination19593); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE1094);

					pushFollow(FOLLOW_tableOrPartition_in_destination19595);
					tableOrPartition1095=tableOrPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableOrPartition.add(tableOrPartition1095.getTree());
					// AST REWRITE
					// elements: tableOrPartition
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2941:32: -> tableOrPartition
					{
						adaptor.addChild(root_0, stream_tableOrPartition.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "destination"


	public static class limitClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "limitClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2944:1: limitClause : ( KW_LIMIT ( (offset= Number COMMA )? num= Number ) -> ^( TOK_LIMIT ( $offset)? $num) | KW_LIMIT num= Number KW_OFFSET offset= Number -> ^( TOK_LIMIT ( $offset)? $num) );
	public final HiveParser.limitClause_return limitClause() throws RecognitionException {
		HiveParser.limitClause_return retval = new HiveParser.limitClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token offset=null;
		Token num=null;
		Token KW_LIMIT1096=null;
		Token COMMA1097=null;
		Token KW_LIMIT1098=null;
		Token KW_OFFSET1099=null;

		ASTNode offset_tree=null;
		ASTNode num_tree=null;
		ASTNode KW_LIMIT1096_tree=null;
		ASTNode COMMA1097_tree=null;
		ASTNode KW_LIMIT1098_tree=null;
		ASTNode KW_OFFSET1099_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_LIMIT=new RewriteRuleTokenStream(adaptor,"token KW_LIMIT");
		RewriteRuleTokenStream stream_KW_OFFSET=new RewriteRuleTokenStream(adaptor,"token KW_OFFSET");

		 pushMsg("limit clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2947:4: ( KW_LIMIT ( (offset= Number COMMA )? num= Number ) -> ^( TOK_LIMIT ( $offset)? $num) | KW_LIMIT num= Number KW_OFFSET offset= Number -> ^( TOK_LIMIT ( $offset)? $num) )
			int alt363=2;
			int LA363_0 = input.LA(1);
			if ( (LA363_0==KW_LIMIT) ) {
				int LA363_1 = input.LA(2);
				if ( (LA363_1==Number) ) {
					int LA363_2 = input.LA(3);
					if ( (LA363_2==KW_OFFSET) ) {
						alt363=2;
					}
					else if ( (LA363_2==EOF||LA363_2==COMMA||LA363_2==KW_EXCEPT||LA363_2==KW_INSERT||LA363_2==KW_INTERSECT||LA363_2==KW_MAP||LA363_2==KW_MINUS||LA363_2==KW_REDUCE||LA363_2==KW_SELECT||LA363_2==KW_UNION||LA363_2==RPAREN) ) {
						alt363=1;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 363, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 363, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 363, 0, input);
				throw nvae;
			}

			switch (alt363) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:4: KW_LIMIT ( (offset= Number COMMA )? num= Number )
					{
					KW_LIMIT1096=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_limitClause19627); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT1096);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:13: ( (offset= Number COMMA )? num= Number )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:14: (offset= Number COMMA )? num= Number
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:14: (offset= Number COMMA )?
					int alt362=2;
					int LA362_0 = input.LA(1);
					if ( (LA362_0==Number) ) {
						int LA362_1 = input.LA(2);
						if ( (LA362_1==COMMA) ) {
							alt362=1;
						}
					}
					switch (alt362) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:15: offset= Number COMMA
							{
							offset=(Token)match(input,Number,FOLLOW_Number_in_limitClause19633); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(offset);

							COMMA1097=(Token)match(input,COMMA,FOLLOW_COMMA_in_limitClause19635); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA1097);

							}
							break;

					}

					num=(Token)match(input,Number,FOLLOW_Number_in_limitClause19641); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(num);

					}

					// AST REWRITE
					// elements: num, offset
					// token labels: offset, num
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_offset=new RewriteRuleTokenStream(adaptor,"token offset",offset);
					RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2948:49: -> ^( TOK_LIMIT ( $offset)? $num)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:52: ^( TOK_LIMIT ( $offset)? $num)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:64: ( $offset)?
						if ( stream_offset.hasNext() ) {
							adaptor.addChild(root_1, stream_offset.nextNode());
						}
						stream_offset.reset();

						adaptor.addChild(root_1, stream_num.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2949:6: KW_LIMIT num= Number KW_OFFSET offset= Number
					{
					KW_LIMIT1098=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_limitClause19664); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT1098);

					num=(Token)match(input,Number,FOLLOW_Number_in_limitClause19668); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(num);

					KW_OFFSET1099=(Token)match(input,KW_OFFSET,FOLLOW_KW_OFFSET_in_limitClause19670); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OFFSET.add(KW_OFFSET1099);

					offset=(Token)match(input,Number,FOLLOW_Number_in_limitClause19674); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(offset);

					// AST REWRITE
					// elements: num, offset
					// token labels: offset, num
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_offset=new RewriteRuleTokenStream(adaptor,"token offset",offset);
					RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2949:50: -> ^( TOK_LIMIT ( $offset)? $num)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2949:53: ^( TOK_LIMIT ( $offset)? $num)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2949:65: ( $offset)?
						if ( stream_offset.hasNext() ) {
							adaptor.addChild(root_1, stream_offset.nextNode());
						}
						stream_offset.reset();

						adaptor.addChild(root_1, stream_num.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "limitClause"


	public static class deleteStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "deleteStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2953:1: deleteStatement : KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) ;
	public final HiveParser.deleteStatement_return deleteStatement() throws RecognitionException {
		HiveParser.deleteStatement_return retval = new HiveParser.deleteStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DELETE1100=null;
		Token KW_FROM1101=null;
		ParserRuleReturnScope tableName1102 =null;
		ParserRuleReturnScope whereClause1103 =null;

		ASTNode KW_DELETE1100_tree=null;
		ASTNode KW_FROM1101_tree=null;
		RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("delete statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2956:4: ( KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2957:4: KW_DELETE KW_FROM tableName ( whereClause )?
			{
			KW_DELETE1100=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_deleteStatement19718); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE1100);

			KW_FROM1101=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_deleteStatement19720); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM1101);

			pushFollow(FOLLOW_tableName_in_deleteStatement19722);
			tableName1102=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName1102.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2957:32: ( whereClause )?
			int alt364=2;
			int LA364_0 = input.LA(1);
			if ( (LA364_0==KW_WHERE) ) {
				alt364=1;
			}
			switch (alt364) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2957:33: whereClause
					{
					pushFollow(FOLLOW_whereClause_in_deleteStatement19725);
					whereClause1103=whereClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_whereClause.add(whereClause1103.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: whereClause, tableName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2957:47: -> ^( TOK_DELETE_FROM tableName ( whereClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2957:50: ^( TOK_DELETE_FROM tableName ( whereClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DELETE_FROM, "TOK_DELETE_FROM"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2957:78: ( whereClause )?
				if ( stream_whereClause.hasNext() ) {
					adaptor.addChild(root_1, stream_whereClause.nextTree());
				}
				stream_whereClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "deleteStatement"


	public static class columnAssignmentClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnAssignmentClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2961:1: columnAssignmentClause : tableOrColumn EQUAL ^ precedencePlusExpression ;
	public final HiveParser.columnAssignmentClause_return columnAssignmentClause() throws RecognitionException {
		HiveParser.columnAssignmentClause_return retval = new HiveParser.columnAssignmentClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token EQUAL1105=null;
		ParserRuleReturnScope tableOrColumn1104 =null;
		ParserRuleReturnScope precedencePlusExpression1106 =null;

		ASTNode EQUAL1105_tree=null;

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2962:4: ( tableOrColumn EQUAL ^ precedencePlusExpression )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2963:4: tableOrColumn EQUAL ^ precedencePlusExpression
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_tableOrColumn_in_columnAssignmentClause19758);
			tableOrColumn1104=tableOrColumn();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, tableOrColumn1104.getTree());

			EQUAL1105=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_columnAssignmentClause19760); if (state.failed) return retval;
			if ( state.backtracking==0 ) {
			EQUAL1105_tree = (ASTNode)adaptor.create(EQUAL1105);
			root_0 = (ASTNode)adaptor.becomeRoot(EQUAL1105_tree, root_0);
			}

			pushFollow(FOLLOW_precedencePlusExpression_in_columnAssignmentClause19763);
			precedencePlusExpression1106=precedencePlusExpression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, precedencePlusExpression1106.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnAssignmentClause"


	public static class setColumnsClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setColumnsClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2967:1: setColumnsClause : KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) ;
	public final HiveParser.setColumnsClause_return setColumnsClause() throws RecognitionException {
		HiveParser.setColumnsClause_return retval = new HiveParser.setColumnsClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET1107=null;
		Token COMMA1109=null;
		ParserRuleReturnScope columnAssignmentClause1108 =null;
		ParserRuleReturnScope columnAssignmentClause1110 =null;

		ASTNode KW_SET1107_tree=null;
		ASTNode COMMA1109_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_columnAssignmentClause=new RewriteRuleSubtreeStream(adaptor,"rule columnAssignmentClause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2968:4: ( KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2969:4: KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )*
			{
			KW_SET1107=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setColumnsClause19783); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET1107);

			pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause19785);
			columnAssignmentClause1108=columnAssignmentClause();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnAssignmentClause.add(columnAssignmentClause1108.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2969:34: ( COMMA columnAssignmentClause )*
			loop365:
			while (true) {
				int alt365=2;
				int LA365_0 = input.LA(1);
				if ( (LA365_0==COMMA) ) {
					alt365=1;
				}

				switch (alt365) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2969:35: COMMA columnAssignmentClause
					{
					COMMA1109=(Token)match(input,COMMA,FOLLOW_COMMA_in_setColumnsClause19788); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA1109);

					pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause19790);
					columnAssignmentClause1110=columnAssignmentClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnAssignmentClause.add(columnAssignmentClause1110.getTree());
					}
					break;

				default :
					break loop365;
				}
			}

			// AST REWRITE
			// elements: columnAssignmentClause
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2969:66: -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2969:69: ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_COLUMNS_CLAUSE, "TOK_SET_COLUMNS_CLAUSE"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2969:94: ( columnAssignmentClause )*
				while ( stream_columnAssignmentClause.hasNext() ) {
					adaptor.addChild(root_1, stream_columnAssignmentClause.nextTree());
				}
				stream_columnAssignmentClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setColumnsClause"


	public static class updateStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "updateStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2976:1: updateStatement : KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) ;
	public final HiveParser.updateStatement_return updateStatement() throws RecognitionException {
		HiveParser.updateStatement_return retval = new HiveParser.updateStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UPDATE1111=null;
		ParserRuleReturnScope tableName1112 =null;
		ParserRuleReturnScope setColumnsClause1113 =null;
		ParserRuleReturnScope whereClause1114 =null;

		ASTNode KW_UPDATE1111_tree=null;
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleSubtreeStream stream_setColumnsClause=new RewriteRuleSubtreeStream(adaptor,"rule setColumnsClause");
		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("update statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2979:4: ( KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2980:4: KW_UPDATE tableName setColumnsClause ( whereClause )?
			{
			KW_UPDATE1111=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_updateStatement19832); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE1111);

			pushFollow(FOLLOW_tableName_in_updateStatement19834);
			tableName1112=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName1112.getTree());
			pushFollow(FOLLOW_setColumnsClause_in_updateStatement19836);
			setColumnsClause1113=setColumnsClause();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_setColumnsClause.add(setColumnsClause1113.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2980:41: ( whereClause )?
			int alt366=2;
			int LA366_0 = input.LA(1);
			if ( (LA366_0==KW_WHERE) ) {
				alt366=1;
			}
			switch (alt366) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2980:41: whereClause
					{
					pushFollow(FOLLOW_whereClause_in_updateStatement19838);
					whereClause1114=whereClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_whereClause.add(whereClause1114.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: setColumnsClause, tableName, whereClause
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2980:54: -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2980:57: ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UPDATE_TABLE, "TOK_UPDATE_TABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				adaptor.addChild(root_1, stream_setColumnsClause.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2980:103: ( whereClause )?
				if ( stream_whereClause.hasNext() ) {
					adaptor.addChild(root_1, stream_whereClause.nextTree());
				}
				stream_whereClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "updateStatement"


	public static class sqlTransactionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "sqlTransactionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2987:1: sqlTransactionStatement : ( startTransactionStatement | commitStatement | rollbackStatement | setAutoCommitStatement );
	public final HiveParser.sqlTransactionStatement_return sqlTransactionStatement() throws RecognitionException {
		HiveParser.sqlTransactionStatement_return retval = new HiveParser.sqlTransactionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope startTransactionStatement1115 =null;
		ParserRuleReturnScope commitStatement1116 =null;
		ParserRuleReturnScope rollbackStatement1117 =null;
		ParserRuleReturnScope setAutoCommitStatement1118 =null;


		 pushMsg("transaction statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2990:3: ( startTransactionStatement | commitStatement | rollbackStatement | setAutoCommitStatement )
			int alt367=4;
			switch ( input.LA(1) ) {
			case KW_START:
				{
				alt367=1;
				}
				break;
			case KW_COMMIT:
				{
				alt367=2;
				}
				break;
			case KW_ROLLBACK:
				{
				alt367=3;
				}
				break;
			case KW_SET:
				{
				alt367=4;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 367, 0, input);
				throw nvae;
			}
			switch (alt367) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2991:3: startTransactionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_startTransactionStatement_in_sqlTransactionStatement19880);
					startTransactionStatement1115=startTransactionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, startTransactionStatement1115.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2992:4: commitStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_commitStatement_in_sqlTransactionStatement19885);
					commitStatement1116=commitStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, commitStatement1116.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2993:4: rollbackStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_rollbackStatement_in_sqlTransactionStatement19890);
					rollbackStatement1117=rollbackStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, rollbackStatement1117.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2994:4: setAutoCommitStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_setAutoCommitStatement_in_sqlTransactionStatement19895);
					setAutoCommitStatement1118=setAutoCommitStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, setAutoCommitStatement1118.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "sqlTransactionStatement"


	public static class startTransactionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "startTransactionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2997:1: startTransactionStatement : KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )? -> ^( TOK_START_TRANSACTION ( transactionMode )* ) ;
	public final HiveParser.startTransactionStatement_return startTransactionStatement() throws RecognitionException {
		HiveParser.startTransactionStatement_return retval = new HiveParser.startTransactionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_START1119=null;
		Token KW_TRANSACTION1120=null;
		Token COMMA1122=null;
		ParserRuleReturnScope transactionMode1121 =null;
		ParserRuleReturnScope transactionMode1123 =null;

		ASTNode KW_START1119_tree=null;
		ASTNode KW_TRANSACTION1120_tree=null;
		ASTNode COMMA1122_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_START=new RewriteRuleTokenStream(adaptor,"token KW_START");
		RewriteRuleTokenStream stream_KW_TRANSACTION=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTION");
		RewriteRuleSubtreeStream stream_transactionMode=new RewriteRuleSubtreeStream(adaptor,"rule transactionMode");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2998:3: ( KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )? -> ^( TOK_START_TRANSACTION ( transactionMode )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2999:3: KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )?
			{
			KW_START1119=(Token)match(input,KW_START,FOLLOW_KW_START_in_startTransactionStatement19909); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_START.add(KW_START1119);

			KW_TRANSACTION1120=(Token)match(input,KW_TRANSACTION,FOLLOW_KW_TRANSACTION_in_startTransactionStatement19911); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TRANSACTION.add(KW_TRANSACTION1120);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2999:27: ( transactionMode ( COMMA transactionMode )* )?
			int alt369=2;
			int LA369_0 = input.LA(1);
			if ( (LA369_0==KW_ISOLATION||LA369_0==KW_READ) ) {
				alt369=1;
			}
			switch (alt369) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2999:29: transactionMode ( COMMA transactionMode )*
					{
					pushFollow(FOLLOW_transactionMode_in_startTransactionStatement19915);
					transactionMode1121=transactionMode();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_transactionMode.add(transactionMode1121.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2999:46: ( COMMA transactionMode )*
					loop368:
					while (true) {
						int alt368=2;
						int LA368_0 = input.LA(1);
						if ( (LA368_0==COMMA) ) {
							alt368=1;
						}

						switch (alt368) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2999:48: COMMA transactionMode
							{
							COMMA1122=(Token)match(input,COMMA,FOLLOW_COMMA_in_startTransactionStatement19920); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA1122);

							pushFollow(FOLLOW_transactionMode_in_startTransactionStatement19922);
							transactionMode1123=transactionMode();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_transactionMode.add(transactionMode1123.getTree());
							}
							break;

						default :
							break loop368;
						}
					}

					}
					break;

			}

			// AST REWRITE
			// elements: transactionMode
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2999:77: -> ^( TOK_START_TRANSACTION ( transactionMode )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2999:80: ^( TOK_START_TRANSACTION ( transactionMode )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_START_TRANSACTION, "TOK_START_TRANSACTION"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2999:104: ( transactionMode )*
				while ( stream_transactionMode.hasNext() ) {
					adaptor.addChild(root_1, stream_transactionMode.nextTree());
				}
				stream_transactionMode.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "startTransactionStatement"


	public static class transactionMode_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "transactionMode"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3002:1: transactionMode : ( isolationLevel | transactionAccessMode -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode ) );
	public final HiveParser.transactionMode_return transactionMode() throws RecognitionException {
		HiveParser.transactionMode_return retval = new HiveParser.transactionMode_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope isolationLevel1124 =null;
		ParserRuleReturnScope transactionAccessMode1125 =null;

		RewriteRuleSubtreeStream stream_transactionAccessMode=new RewriteRuleSubtreeStream(adaptor,"rule transactionAccessMode");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3003:3: ( isolationLevel | transactionAccessMode -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode ) )
			int alt370=2;
			int LA370_0 = input.LA(1);
			if ( (LA370_0==KW_ISOLATION) ) {
				alt370=1;
			}
			else if ( (LA370_0==KW_READ) ) {
				alt370=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 370, 0, input);
				throw nvae;
			}

			switch (alt370) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3004:3: isolationLevel
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_isolationLevel_in_transactionMode19953);
					isolationLevel1124=isolationLevel();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, isolationLevel1124.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3005:5: transactionAccessMode
					{
					pushFollow(FOLLOW_transactionAccessMode_in_transactionMode19959);
					transactionAccessMode1125=transactionAccessMode();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_transactionAccessMode.add(transactionAccessMode1125.getTree());
					// AST REWRITE
					// elements: transactionAccessMode
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3005:27: -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3005:30: ^( TOK_TXN_ACCESS_MODE transactionAccessMode )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TXN_ACCESS_MODE, "TOK_TXN_ACCESS_MODE"), root_1);
						adaptor.addChild(root_1, stream_transactionAccessMode.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "transactionMode"


	public static class transactionAccessMode_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "transactionAccessMode"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3008:1: transactionAccessMode : ( KW_READ KW_ONLY -> TOK_TXN_READ_ONLY | KW_READ KW_WRITE -> TOK_TXN_READ_WRITE );
	public final HiveParser.transactionAccessMode_return transactionAccessMode() throws RecognitionException {
		HiveParser.transactionAccessMode_return retval = new HiveParser.transactionAccessMode_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_READ1126=null;
		Token KW_ONLY1127=null;
		Token KW_READ1128=null;
		Token KW_WRITE1129=null;

		ASTNode KW_READ1126_tree=null;
		ASTNode KW_ONLY1127_tree=null;
		ASTNode KW_READ1128_tree=null;
		ASTNode KW_WRITE1129_tree=null;
		RewriteRuleTokenStream stream_KW_READ=new RewriteRuleTokenStream(adaptor,"token KW_READ");
		RewriteRuleTokenStream stream_KW_ONLY=new RewriteRuleTokenStream(adaptor,"token KW_ONLY");
		RewriteRuleTokenStream stream_KW_WRITE=new RewriteRuleTokenStream(adaptor,"token KW_WRITE");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3009:3: ( KW_READ KW_ONLY -> TOK_TXN_READ_ONLY | KW_READ KW_WRITE -> TOK_TXN_READ_WRITE )
			int alt371=2;
			int LA371_0 = input.LA(1);
			if ( (LA371_0==KW_READ) ) {
				int LA371_1 = input.LA(2);
				if ( (LA371_1==KW_ONLY) ) {
					alt371=1;
				}
				else if ( (LA371_1==KW_WRITE) ) {
					alt371=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 371, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 371, 0, input);
				throw nvae;
			}

			switch (alt371) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3010:3: KW_READ KW_ONLY
					{
					KW_READ1126=(Token)match(input,KW_READ,FOLLOW_KW_READ_in_transactionAccessMode19982); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_READ.add(KW_READ1126);

					KW_ONLY1127=(Token)match(input,KW_ONLY,FOLLOW_KW_ONLY_in_transactionAccessMode19984); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ONLY.add(KW_ONLY1127);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3010:19: -> TOK_TXN_READ_ONLY
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TXN_READ_ONLY, "TOK_TXN_READ_ONLY"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3011:5: KW_READ KW_WRITE
					{
					KW_READ1128=(Token)match(input,KW_READ,FOLLOW_KW_READ_in_transactionAccessMode19994); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_READ.add(KW_READ1128);

					KW_WRITE1129=(Token)match(input,KW_WRITE,FOLLOW_KW_WRITE_in_transactionAccessMode19996); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WRITE.add(KW_WRITE1129);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3011:22: -> TOK_TXN_READ_WRITE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TXN_READ_WRITE, "TOK_TXN_READ_WRITE"));
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "transactionAccessMode"


	public static class isolationLevel_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "isolationLevel"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3014:1: isolationLevel : KW_ISOLATION KW_LEVEL levelOfIsolation -> ^( TOK_ISOLATION_LEVEL levelOfIsolation ) ;
	public final HiveParser.isolationLevel_return isolationLevel() throws RecognitionException {
		HiveParser.isolationLevel_return retval = new HiveParser.isolationLevel_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ISOLATION1130=null;
		Token KW_LEVEL1131=null;
		ParserRuleReturnScope levelOfIsolation1132 =null;

		ASTNode KW_ISOLATION1130_tree=null;
		ASTNode KW_LEVEL1131_tree=null;
		RewriteRuleTokenStream stream_KW_LEVEL=new RewriteRuleTokenStream(adaptor,"token KW_LEVEL");
		RewriteRuleTokenStream stream_KW_ISOLATION=new RewriteRuleTokenStream(adaptor,"token KW_ISOLATION");
		RewriteRuleSubtreeStream stream_levelOfIsolation=new RewriteRuleSubtreeStream(adaptor,"rule levelOfIsolation");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3015:3: ( KW_ISOLATION KW_LEVEL levelOfIsolation -> ^( TOK_ISOLATION_LEVEL levelOfIsolation ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3016:3: KW_ISOLATION KW_LEVEL levelOfIsolation
			{
			KW_ISOLATION1130=(Token)match(input,KW_ISOLATION,FOLLOW_KW_ISOLATION_in_isolationLevel20015); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ISOLATION.add(KW_ISOLATION1130);

			KW_LEVEL1131=(Token)match(input,KW_LEVEL,FOLLOW_KW_LEVEL_in_isolationLevel20017); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LEVEL.add(KW_LEVEL1131);

			pushFollow(FOLLOW_levelOfIsolation_in_isolationLevel20019);
			levelOfIsolation1132=levelOfIsolation();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_levelOfIsolation.add(levelOfIsolation1132.getTree());
			// AST REWRITE
			// elements: levelOfIsolation
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3016:42: -> ^( TOK_ISOLATION_LEVEL levelOfIsolation )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3016:45: ^( TOK_ISOLATION_LEVEL levelOfIsolation )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ISOLATION_LEVEL, "TOK_ISOLATION_LEVEL"), root_1);
				adaptor.addChild(root_1, stream_levelOfIsolation.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "isolationLevel"


	public static class levelOfIsolation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "levelOfIsolation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3020:1: levelOfIsolation : KW_SNAPSHOT -> TOK_ISOLATION_SNAPSHOT ;
	public final HiveParser.levelOfIsolation_return levelOfIsolation() throws RecognitionException {
		HiveParser.levelOfIsolation_return retval = new HiveParser.levelOfIsolation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SNAPSHOT1133=null;

		ASTNode KW_SNAPSHOT1133_tree=null;
		RewriteRuleTokenStream stream_KW_SNAPSHOT=new RewriteRuleTokenStream(adaptor,"token KW_SNAPSHOT");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3021:3: ( KW_SNAPSHOT -> TOK_ISOLATION_SNAPSHOT )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3022:3: KW_SNAPSHOT
			{
			KW_SNAPSHOT1133=(Token)match(input,KW_SNAPSHOT,FOLLOW_KW_SNAPSHOT_in_levelOfIsolation20044); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SNAPSHOT.add(KW_SNAPSHOT1133);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3022:15: -> TOK_ISOLATION_SNAPSHOT
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_ISOLATION_SNAPSHOT, "TOK_ISOLATION_SNAPSHOT"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "levelOfIsolation"


	public static class commitStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "commitStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3025:1: commitStatement : KW_COMMIT ( KW_WORK )? -> TOK_COMMIT ;
	public final HiveParser.commitStatement_return commitStatement() throws RecognitionException {
		HiveParser.commitStatement_return retval = new HiveParser.commitStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_COMMIT1134=null;
		Token KW_WORK1135=null;

		ASTNode KW_COMMIT1134_tree=null;
		ASTNode KW_WORK1135_tree=null;
		RewriteRuleTokenStream stream_KW_WORK=new RewriteRuleTokenStream(adaptor,"token KW_WORK");
		RewriteRuleTokenStream stream_KW_COMMIT=new RewriteRuleTokenStream(adaptor,"token KW_COMMIT");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3026:3: ( KW_COMMIT ( KW_WORK )? -> TOK_COMMIT )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3027:3: KW_COMMIT ( KW_WORK )?
			{
			KW_COMMIT1134=(Token)match(input,KW_COMMIT,FOLLOW_KW_COMMIT_in_commitStatement20063); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMMIT.add(KW_COMMIT1134);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3027:13: ( KW_WORK )?
			int alt372=2;
			int LA372_0 = input.LA(1);
			if ( (LA372_0==KW_WORK) ) {
				alt372=1;
			}
			switch (alt372) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3027:15: KW_WORK
					{
					KW_WORK1135=(Token)match(input,KW_WORK,FOLLOW_KW_WORK_in_commitStatement20067); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WORK.add(KW_WORK1135);

					}
					break;

			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3027:26: -> TOK_COMMIT
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_COMMIT, "TOK_COMMIT"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "commitStatement"


	public static class rollbackStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rollbackStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3030:1: rollbackStatement : KW_ROLLBACK ( KW_WORK )? -> TOK_ROLLBACK ;
	public final HiveParser.rollbackStatement_return rollbackStatement() throws RecognitionException {
		HiveParser.rollbackStatement_return retval = new HiveParser.rollbackStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ROLLBACK1136=null;
		Token KW_WORK1137=null;

		ASTNode KW_ROLLBACK1136_tree=null;
		ASTNode KW_WORK1137_tree=null;
		RewriteRuleTokenStream stream_KW_ROLLBACK=new RewriteRuleTokenStream(adaptor,"token KW_ROLLBACK");
		RewriteRuleTokenStream stream_KW_WORK=new RewriteRuleTokenStream(adaptor,"token KW_WORK");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3031:3: ( KW_ROLLBACK ( KW_WORK )? -> TOK_ROLLBACK )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3032:3: KW_ROLLBACK ( KW_WORK )?
			{
			KW_ROLLBACK1136=(Token)match(input,KW_ROLLBACK,FOLLOW_KW_ROLLBACK_in_rollbackStatement20089); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLLBACK.add(KW_ROLLBACK1136);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3032:15: ( KW_WORK )?
			int alt373=2;
			int LA373_0 = input.LA(1);
			if ( (LA373_0==KW_WORK) ) {
				alt373=1;
			}
			switch (alt373) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3032:17: KW_WORK
					{
					KW_WORK1137=(Token)match(input,KW_WORK,FOLLOW_KW_WORK_in_rollbackStatement20093); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WORK.add(KW_WORK1137);

					}
					break;

			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3032:28: -> TOK_ROLLBACK
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_ROLLBACK, "TOK_ROLLBACK"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rollbackStatement"


	public static class setAutoCommitStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setAutoCommitStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3034:1: setAutoCommitStatement : KW_SET KW_AUTOCOMMIT booleanValueTok -> ^( TOK_SET_AUTOCOMMIT booleanValueTok ) ;
	public final HiveParser.setAutoCommitStatement_return setAutoCommitStatement() throws RecognitionException {
		HiveParser.setAutoCommitStatement_return retval = new HiveParser.setAutoCommitStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET1138=null;
		Token KW_AUTOCOMMIT1139=null;
		ParserRuleReturnScope booleanValueTok1140 =null;

		ASTNode KW_SET1138_tree=null;
		ASTNode KW_AUTOCOMMIT1139_tree=null;
		RewriteRuleTokenStream stream_KW_AUTOCOMMIT=new RewriteRuleTokenStream(adaptor,"token KW_AUTOCOMMIT");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_booleanValueTok=new RewriteRuleSubtreeStream(adaptor,"rule booleanValueTok");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3035:3: ( KW_SET KW_AUTOCOMMIT booleanValueTok -> ^( TOK_SET_AUTOCOMMIT booleanValueTok ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3036:3: KW_SET KW_AUTOCOMMIT booleanValueTok
			{
			KW_SET1138=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setAutoCommitStatement20114); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET1138);

			KW_AUTOCOMMIT1139=(Token)match(input,KW_AUTOCOMMIT,FOLLOW_KW_AUTOCOMMIT_in_setAutoCommitStatement20116); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AUTOCOMMIT.add(KW_AUTOCOMMIT1139);

			pushFollow(FOLLOW_booleanValueTok_in_setAutoCommitStatement20118);
			booleanValueTok1140=booleanValueTok();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_booleanValueTok.add(booleanValueTok1140.getTree());
			// AST REWRITE
			// elements: booleanValueTok
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3036:40: -> ^( TOK_SET_AUTOCOMMIT booleanValueTok )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3036:43: ^( TOK_SET_AUTOCOMMIT booleanValueTok )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_AUTOCOMMIT, "TOK_SET_AUTOCOMMIT"), root_1);
				adaptor.addChild(root_1, stream_booleanValueTok.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setAutoCommitStatement"


	public static class abortTransactionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "abortTransactionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3042:1: abortTransactionStatement : KW_ABORT KW_TRANSACTIONS ( Number )+ -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ ) ;
	public final HiveParser.abortTransactionStatement_return abortTransactionStatement() throws RecognitionException {
		HiveParser.abortTransactionStatement_return retval = new HiveParser.abortTransactionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ABORT1141=null;
		Token KW_TRANSACTIONS1142=null;
		Token Number1143=null;

		ASTNode KW_ABORT1141_tree=null;
		ASTNode KW_TRANSACTIONS1142_tree=null;
		ASTNode Number1143_tree=null;
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_TRANSACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTIONS");
		RewriteRuleTokenStream stream_KW_ABORT=new RewriteRuleTokenStream(adaptor,"token KW_ABORT");

		 pushMsg("abort transactions statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3045:3: ( KW_ABORT KW_TRANSACTIONS ( Number )+ -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3046:3: KW_ABORT KW_TRANSACTIONS ( Number )+
			{
			KW_ABORT1141=(Token)match(input,KW_ABORT,FOLLOW_KW_ABORT_in_abortTransactionStatement20153); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ABORT.add(KW_ABORT1141);

			KW_TRANSACTIONS1142=(Token)match(input,KW_TRANSACTIONS,FOLLOW_KW_TRANSACTIONS_in_abortTransactionStatement20155); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TRANSACTIONS.add(KW_TRANSACTIONS1142);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3046:28: ( Number )+
			int cnt374=0;
			loop374:
			while (true) {
				int alt374=2;
				int LA374_0 = input.LA(1);
				if ( (LA374_0==Number) ) {
					alt374=1;
				}

				switch (alt374) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3046:30: Number
					{
					Number1143=(Token)match(input,Number,FOLLOW_Number_in_abortTransactionStatement20159); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(Number1143);

					}
					break;

				default :
					if ( cnt374 >= 1 ) break loop374;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(374, input);
					throw eee;
				}
				cnt374++;
			}

			// AST REWRITE
			// elements: Number
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3046:40: -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3046:43: ^( TOK_ABORT_TRANSACTIONS ( Number )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ABORT_TRANSACTIONS, "TOK_ABORT_TRANSACTIONS"), root_1);
				if ( !(stream_Number.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_Number.hasNext() ) {
					adaptor.addChild(root_1, stream_Number.nextNode());
				}
				stream_Number.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "abortTransactionStatement"


	public static class mergeStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "mergeStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3053:1: mergeStatement : KW_MERGE ( QUERY_HINT )? KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses ) ;
	public final HiveParser.mergeStatement_return mergeStatement() throws RecognitionException {
		HiveParser.mergeStatement_return retval = new HiveParser.mergeStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_MERGE1144=null;
		Token QUERY_HINT1145=null;
		Token KW_INTO1146=null;
		Token KW_AS1148=null;
		Token KW_USING1150=null;
		Token KW_ON1152=null;
		ParserRuleReturnScope tableName1147 =null;
		ParserRuleReturnScope identifier1149 =null;
		ParserRuleReturnScope joinSourcePart1151 =null;
		ParserRuleReturnScope expression1153 =null;
		ParserRuleReturnScope whenClauses1154 =null;

		ASTNode KW_MERGE1144_tree=null;
		ASTNode QUERY_HINT1145_tree=null;
		ASTNode KW_INTO1146_tree=null;
		ASTNode KW_AS1148_tree=null;
		ASTNode KW_USING1150_tree=null;
		ASTNode KW_ON1152_tree=null;
		RewriteRuleTokenStream stream_KW_MERGE=new RewriteRuleTokenStream(adaptor,"token KW_MERGE");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_USING=new RewriteRuleTokenStream(adaptor,"token KW_USING");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_QUERY_HINT=new RewriteRuleTokenStream(adaptor,"token QUERY_HINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_whenClauses=new RewriteRuleSubtreeStream(adaptor,"rule whenClauses");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
		RewriteRuleSubtreeStream stream_joinSourcePart=new RewriteRuleSubtreeStream(adaptor,"rule joinSourcePart");

		 pushMsg("MERGE statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3056:4: ( KW_MERGE ( QUERY_HINT )? KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3057:4: KW_MERGE ( QUERY_HINT )? KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses
			{
			KW_MERGE1144=(Token)match(input,KW_MERGE,FOLLOW_KW_MERGE_in_mergeStatement20205); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MERGE.add(KW_MERGE1144);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3057:13: ( QUERY_HINT )?
			int alt375=2;
			int LA375_0 = input.LA(1);
			if ( (LA375_0==QUERY_HINT) ) {
				alt375=1;
			}
			switch (alt375) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3057:13: QUERY_HINT
					{
					QUERY_HINT1145=(Token)match(input,QUERY_HINT,FOLLOW_QUERY_HINT_in_mergeStatement20207); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_QUERY_HINT.add(QUERY_HINT1145);

					}
					break;

			}

			KW_INTO1146=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_mergeStatement20210); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO1146);

			pushFollow(FOLLOW_tableName_in_mergeStatement20212);
			tableName1147=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName1147.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3057:43: ( ( KW_AS )? identifier )?
			int alt377=2;
			int LA377_0 = input.LA(1);
			if ( (LA377_0==Identifier||(LA377_0 >= KW_ABORT && LA377_0 <= KW_AFTER)||LA377_0==KW_ALLOC_FRACTION||LA377_0==KW_ANALYZE||LA377_0==KW_ARCHIVE||(LA377_0 >= KW_AS && LA377_0 <= KW_ASC)||(LA377_0 >= KW_AUTOCOMMIT && LA377_0 <= KW_BEFORE)||(LA377_0 >= KW_BUCKET && LA377_0 <= KW_BUCKETS)||(LA377_0 >= KW_CACHE && LA377_0 <= KW_CASCADE)||(LA377_0 >= KW_CBO && LA377_0 <= KW_CHANGE)||(LA377_0 >= KW_CHECK && LA377_0 <= KW_COLLECTION)||(LA377_0 >= KW_COLUMNS && LA377_0 <= KW_COMMENT)||(LA377_0 >= KW_COMPACT && LA377_0 <= KW_CONCATENATE)||(LA377_0 >= KW_CONTINUE && LA377_0 <= KW_COST)||LA377_0==KW_DATA||LA377_0==KW_DATABASES||(LA377_0 >= KW_DATETIME && LA377_0 <= KW_DEBUG)||(LA377_0 >= KW_DEFAULT && LA377_0 <= KW_DEFINED)||(LA377_0 >= KW_DELIMITED && LA377_0 <= KW_DESC)||(LA377_0 >= KW_DETAIL && LA377_0 <= KW_DISABLE)||(LA377_0 >= KW_DISTRIBUTE && LA377_0 <= KW_DO)||LA377_0==KW_DOW||(LA377_0 >= KW_DUMP && LA377_0 <= KW_ELEM_TYPE)||LA377_0==KW_ENABLE||(LA377_0 >= KW_ENFORCED && LA377_0 <= KW_ESCAPED)||LA377_0==KW_EXCLUSIVE||(LA377_0 >= KW_EXPLAIN && LA377_0 <= KW_EXPRESSION)||(LA377_0 >= KW_FIELDS && LA377_0 <= KW_FIRST)||(LA377_0 >= KW_FORMAT && LA377_0 <= KW_FORMATTED)||LA377_0==KW_FUNCTIONS||(LA377_0 >= KW_HOUR && LA377_0 <= KW_IDXPROPERTIES)||(LA377_0 >= KW_INDEX && LA377_0 <= KW_INDEXES)||(LA377_0 >= KW_INPATH && LA377_0 <= KW_INPUTFORMAT)||(LA377_0 >= KW_ISOLATION && LA377_0 <= KW_JAR)||(LA377_0 >= KW_JOINCOST && LA377_0 <= KW_LAST)||LA377_0==KW_LEVEL||(LA377_0 >= KW_LIMIT && LA377_0 <= KW_LOAD)||(LA377_0 >= KW_LOCATION && LA377_0 <= KW_LONG)||LA377_0==KW_MANAGEMENT||(LA377_0 >= KW_MAPJOIN && LA377_0 <= KW_MATERIALIZED)||LA377_0==KW_METADATA||(LA377_0 >= KW_MINUTE && LA377_0 <= KW_MONTH)||(LA377_0 >= KW_MOVE && LA377_0 <= KW_MSCK)||(LA377_0 >= KW_NORELY && LA377_0 <= KW_NOSCAN)||LA377_0==KW_NOVALIDATE||LA377_0==KW_NULLS||LA377_0==KW_OFFSET||(LA377_0 >= KW_OPERATOR && LA377_0 <= KW_OPTION)||(LA377_0 >= KW_OUTPUTDRIVER && LA377_0 <= KW_OUTPUTFORMAT)||(LA377_0 >= KW_OVERWRITE && LA377_0 <= KW_OWNER)||(LA377_0 >= KW_PARTITIONED && LA377_0 <= KW_PATH)||(LA377_0 >= KW_PLAN && LA377_0 <= KW_POOL)||LA377_0==KW_PRINCIPALS||(LA377_0 >= KW_PURGE && LA377_0 <= KW_QUERY_PARALLELISM)||LA377_0==KW_READ||(LA377_0 >= KW_REBUILD && LA377_0 <= KW_RECORDWRITER)||(LA377_0 >= KW_RELOAD && LA377_0 <= KW_RESTRICT)||LA377_0==KW_REWRITE||(LA377_0 >= KW_ROLE && LA377_0 <= KW_ROLES)||(LA377_0 >= KW_SCHEDULING_POLICY && LA377_0 <= KW_SECOND)||(LA377_0 >= KW_SEMI && LA377_0 <= KW_SERVER)||(LA377_0 >= KW_SETS && LA377_0 <= KW_SKEWED)||(LA377_0 >= KW_SNAPSHOT && LA377_0 <= KW_SSL)||(LA377_0 >= KW_STATISTICS && LA377_0 <= KW_SUMMARY)||LA377_0==KW_TABLES||(LA377_0 >= KW_TBLPROPERTIES && LA377_0 <= KW_TERMINATED)||LA377_0==KW_TINYINT||(LA377_0 >= KW_TOUCH && LA377_0 <= KW_TRANSACTIONS)||LA377_0==KW_UNARCHIVE||LA377_0==KW_UNDO||LA377_0==KW_UNIONTYPE||(LA377_0 >= KW_UNLOCK && LA377_0 <= KW_UNSIGNED)||(LA377_0 >= KW_URI && LA377_0 <= KW_USE)||(LA377_0 >= KW_UTC && LA377_0 <= KW_VALIDATE)||LA377_0==KW_VALUE_TYPE||(LA377_0 >= KW_VECTORIZATION && LA377_0 <= KW_WEEK)||LA377_0==KW_WHILE||(LA377_0 >= KW_WORK && LA377_0 <= KW_ZONE)||LA377_0==KW_BATCH||LA377_0==KW_DAYOFWEEK||LA377_0==KW_HOLD_DDLTIME||LA377_0==KW_IGNORE||LA377_0==KW_NO_DROP||LA377_0==KW_OFFLINE||LA377_0==KW_PROTECTION||LA377_0==KW_READONLY||LA377_0==KW_TIMESTAMPTZ) ) {
				alt377=1;
			}
			switch (alt377) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3057:44: ( KW_AS )? identifier
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3057:44: ( KW_AS )?
					int alt376=2;
					int LA376_0 = input.LA(1);
					if ( (LA376_0==KW_AS) ) {
						alt376=1;
					}
					switch (alt376) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3057:44: KW_AS
							{
							KW_AS1148=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_mergeStatement20215); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS1148);

							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_mergeStatement20218);
					identifier1149=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier1149.getTree());
					}
					break;

			}

			KW_USING1150=(Token)match(input,KW_USING,FOLLOW_KW_USING_in_mergeStatement20222); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_USING.add(KW_USING1150);

			pushFollow(FOLLOW_joinSourcePart_in_mergeStatement20224);
			joinSourcePart1151=joinSourcePart();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_joinSourcePart.add(joinSourcePart1151.getTree());
			KW_ON1152=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_mergeStatement20226); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON1152);

			pushFollow(FOLLOW_expression_in_mergeStatement20228);
			expression1153=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression1153.getTree());
			pushFollow(FOLLOW_whenClauses_in_mergeStatement20230);
			whenClauses1154=whenClauses();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_whenClauses.add(whenClauses1154.getTree());
			// AST REWRITE
			// elements: joinSourcePart, tableName, identifier, whenClauses, QUERY_HINT, expression
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3058:6: -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3058:9: ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MERGE, "TOK_MERGE"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3058:21: ^( TOK_TABREF tableName ( identifier )? )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABREF, "TOK_TABREF"), root_2);
				adaptor.addChild(root_2, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3058:44: ( identifier )?
				if ( stream_identifier.hasNext() ) {
					adaptor.addChild(root_2, stream_identifier.nextTree());
				}
				stream_identifier.reset();

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_joinSourcePart.nextTree());
				adaptor.addChild(root_1, stream_expression.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3058:83: ( QUERY_HINT )?
				if ( stream_QUERY_HINT.hasNext() ) {
					adaptor.addChild(root_1, stream_QUERY_HINT.nextNode());
				}
				stream_QUERY_HINT.reset();

				adaptor.addChild(root_1, stream_whenClauses.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "mergeStatement"


	public static class whenClauses_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenClauses"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3066:1: whenClauses : ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )? ;
	public final HiveParser.whenClauses_return whenClauses() throws RecognitionException {
		HiveParser.whenClauses_return retval = new HiveParser.whenClauses_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope whenMatchedAndClause1155 =null;
		ParserRuleReturnScope whenMatchedThenClause1156 =null;
		ParserRuleReturnScope whenNotMatchedClause1157 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3067:4: ( ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3068:4: ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )?
			{
			root_0 = (ASTNode)adaptor.nil();


			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3068:4: ( whenMatchedAndClause | whenMatchedThenClause )*
			loop378:
			while (true) {
				int alt378=3;
				int LA378_0 = input.LA(1);
				if ( (LA378_0==KW_WHEN) ) {
					int LA378_1 = input.LA(2);
					if ( (LA378_1==KW_MATCHED) ) {
						int LA378_4 = input.LA(3);
						if ( (LA378_4==KW_AND) ) {
							alt378=1;
						}
						else if ( (LA378_4==KW_THEN) ) {
							alt378=2;
						}

					}

				}

				switch (alt378) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3068:5: whenMatchedAndClause
					{
					pushFollow(FOLLOW_whenMatchedAndClause_in_whenClauses20279);
					whenMatchedAndClause1155=whenMatchedAndClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, whenMatchedAndClause1155.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3068:26: whenMatchedThenClause
					{
					pushFollow(FOLLOW_whenMatchedThenClause_in_whenClauses20281);
					whenMatchedThenClause1156=whenMatchedThenClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, whenMatchedThenClause1156.getTree());

					}
					break;

				default :
					break loop378;
				}
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3068:50: ( whenNotMatchedClause )?
			int alt379=2;
			int LA379_0 = input.LA(1);
			if ( (LA379_0==KW_WHEN) ) {
				alt379=1;
			}
			switch (alt379) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3068:50: whenNotMatchedClause
					{
					pushFollow(FOLLOW_whenNotMatchedClause_in_whenClauses20285);
					whenNotMatchedClause1157=whenNotMatchedClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, whenNotMatchedClause1157.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenClauses"


	public static class whenNotMatchedClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenNotMatchedClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3070:1: whenNotMatchedClause : KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT (targetCols= columnParenthesesList )? KW_VALUES valueRowConstructor -> ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? ) ;
	public final HiveParser.whenNotMatchedClause_return whenNotMatchedClause() throws RecognitionException {
		HiveParser.whenNotMatchedClause_return retval = new HiveParser.whenNotMatchedClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHEN1158=null;
		Token KW_NOT1159=null;
		Token KW_MATCHED1160=null;
		Token KW_AND1161=null;
		Token KW_THEN1163=null;
		Token KW_INSERT1164=null;
		Token KW_VALUES1165=null;
		ParserRuleReturnScope targetCols =null;
		ParserRuleReturnScope expression1162 =null;
		ParserRuleReturnScope valueRowConstructor1166 =null;

		ASTNode KW_WHEN1158_tree=null;
		ASTNode KW_NOT1159_tree=null;
		ASTNode KW_MATCHED1160_tree=null;
		ASTNode KW_AND1161_tree=null;
		ASTNode KW_THEN1163_tree=null;
		ASTNode KW_INSERT1164_tree=null;
		ASTNode KW_VALUES1165_tree=null;
		RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_AND=new RewriteRuleTokenStream(adaptor,"token KW_AND");
		RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
		RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
		RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
		RewriteRuleTokenStream stream_KW_VALUES=new RewriteRuleTokenStream(adaptor,"token KW_VALUES");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_valueRowConstructor=new RewriteRuleSubtreeStream(adaptor,"rule valueRowConstructor");

		 pushMsg("WHEN NOT MATCHED clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3073:4: ( KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT (targetCols= columnParenthesesList )? KW_VALUES valueRowConstructor -> ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3074:3: KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT (targetCols= columnParenthesesList )? KW_VALUES valueRowConstructor
			{
			KW_WHEN1158=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenNotMatchedClause20312); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1158);

			KW_NOT1159=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_whenNotMatchedClause20314); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT1159);

			KW_MATCHED1160=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenNotMatchedClause20316); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1160);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3074:29: ( KW_AND expression )?
			int alt380=2;
			int LA380_0 = input.LA(1);
			if ( (LA380_0==KW_AND) ) {
				alt380=1;
			}
			switch (alt380) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3074:30: KW_AND expression
					{
					KW_AND1161=(Token)match(input,KW_AND,FOLLOW_KW_AND_in_whenNotMatchedClause20319); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AND.add(KW_AND1161);

					pushFollow(FOLLOW_expression_in_whenNotMatchedClause20321);
					expression1162=expression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_expression.add(expression1162.getTree());
					}
					break;

			}

			KW_THEN1163=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenNotMatchedClause20325); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1163);

			KW_INSERT1164=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_whenNotMatchedClause20327); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT1164);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3074:68: (targetCols= columnParenthesesList )?
			int alt381=2;
			int LA381_0 = input.LA(1);
			if ( (LA381_0==LPAREN) ) {
				alt381=1;
			}
			switch (alt381) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3074:69: targetCols= columnParenthesesList
					{
					pushFollow(FOLLOW_columnParenthesesList_in_whenNotMatchedClause20332);
					targetCols=columnParenthesesList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnParenthesesList.add(targetCols.getTree());
					}
					break;

			}

			KW_VALUES1165=(Token)match(input,KW_VALUES,FOLLOW_KW_VALUES_in_whenNotMatchedClause20336); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VALUES.add(KW_VALUES1165);

			pushFollow(FOLLOW_valueRowConstructor_in_whenNotMatchedClause20338);
			valueRowConstructor1166=valueRowConstructor();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_valueRowConstructor.add(valueRowConstructor1166.getTree());
			// AST REWRITE
			// elements: expression, targetCols, valueRowConstructor
			// token labels: 
			// rule labels: targetCols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_targetCols=new RewriteRuleSubtreeStream(adaptor,"rule targetCols",targetCols!=null?targetCols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3074:134: -> ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3075:5: ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NOT_MATCHED, "TOK_NOT_MATCHED"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3075:23: ^( TOK_INSERT ( $targetCols)? valueRowConstructor )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3075:37: ( $targetCols)?
				if ( stream_targetCols.hasNext() ) {
					adaptor.addChild(root_2, stream_targetCols.nextTree());
				}
				stream_targetCols.reset();

				adaptor.addChild(root_2, stream_valueRowConstructor.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3075:70: ( expression )?
				if ( stream_expression.hasNext() ) {
					adaptor.addChild(root_1, stream_expression.nextTree());
				}
				stream_expression.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenNotMatchedClause"


	public static class whenMatchedAndClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenMatchedAndClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3077:1: whenMatchedAndClause : KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete expression ) ;
	public final HiveParser.whenMatchedAndClause_return whenMatchedAndClause() throws RecognitionException {
		HiveParser.whenMatchedAndClause_return retval = new HiveParser.whenMatchedAndClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHEN1167=null;
		Token KW_MATCHED1168=null;
		Token KW_AND1169=null;
		Token KW_THEN1171=null;
		ParserRuleReturnScope expression1170 =null;
		ParserRuleReturnScope updateOrDelete1172 =null;

		ASTNode KW_WHEN1167_tree=null;
		ASTNode KW_MATCHED1168_tree=null;
		ASTNode KW_AND1169_tree=null;
		ASTNode KW_THEN1171_tree=null;
		RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
		RewriteRuleTokenStream stream_KW_AND=new RewriteRuleTokenStream(adaptor,"token KW_AND");
		RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
		RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_updateOrDelete=new RewriteRuleSubtreeStream(adaptor,"rule updateOrDelete");

		 pushMsg("WHEN MATCHED AND clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3080:3: ( KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete expression ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3081:3: KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete
			{
			KW_WHEN1167=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenMatchedAndClause20385); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1167);

			KW_MATCHED1168=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenMatchedAndClause20387); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1168);

			KW_AND1169=(Token)match(input,KW_AND,FOLLOW_KW_AND_in_whenMatchedAndClause20389); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AND.add(KW_AND1169);

			pushFollow(FOLLOW_expression_in_whenMatchedAndClause20391);
			expression1170=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression1170.getTree());
			KW_THEN1171=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenMatchedAndClause20393); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1171);

			pushFollow(FOLLOW_updateOrDelete_in_whenMatchedAndClause20395);
			updateOrDelete1172=updateOrDelete();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_updateOrDelete.add(updateOrDelete1172.getTree());
			// AST REWRITE
			// elements: updateOrDelete, expression
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3081:63: -> ^( TOK_MATCHED updateOrDelete expression )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3082:5: ^( TOK_MATCHED updateOrDelete expression )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MATCHED, "TOK_MATCHED"), root_1);
				adaptor.addChild(root_1, stream_updateOrDelete.nextTree());
				adaptor.addChild(root_1, stream_expression.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenMatchedAndClause"


	public static class whenMatchedThenClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenMatchedThenClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3084:1: whenMatchedThenClause : KW_WHEN KW_MATCHED KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete ) ;
	public final HiveParser.whenMatchedThenClause_return whenMatchedThenClause() throws RecognitionException {
		HiveParser.whenMatchedThenClause_return retval = new HiveParser.whenMatchedThenClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHEN1173=null;
		Token KW_MATCHED1174=null;
		Token KW_THEN1175=null;
		ParserRuleReturnScope updateOrDelete1176 =null;

		ASTNode KW_WHEN1173_tree=null;
		ASTNode KW_MATCHED1174_tree=null;
		ASTNode KW_THEN1175_tree=null;
		RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
		RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
		RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
		RewriteRuleSubtreeStream stream_updateOrDelete=new RewriteRuleSubtreeStream(adaptor,"rule updateOrDelete");

		 pushMsg("WHEN MATCHED THEN clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3087:3: ( KW_WHEN KW_MATCHED KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3088:3: KW_WHEN KW_MATCHED KW_THEN updateOrDelete
			{
			KW_WHEN1173=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenMatchedThenClause20433); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1173);

			KW_MATCHED1174=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenMatchedThenClause20435); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1174);

			KW_THEN1175=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenMatchedThenClause20437); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1175);

			pushFollow(FOLLOW_updateOrDelete_in_whenMatchedThenClause20439);
			updateOrDelete1176=updateOrDelete();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_updateOrDelete.add(updateOrDelete1176.getTree());
			// AST REWRITE
			// elements: updateOrDelete
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3088:45: -> ^( TOK_MATCHED updateOrDelete )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3089:6: ^( TOK_MATCHED updateOrDelete )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MATCHED, "TOK_MATCHED"), root_1);
				adaptor.addChild(root_1, stream_updateOrDelete.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenMatchedThenClause"


	public static class updateOrDelete_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "updateOrDelete"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3091:1: updateOrDelete : ( KW_UPDATE setColumnsClause -> ^( TOK_UPDATE setColumnsClause ) | KW_DELETE -> TOK_DELETE );
	public final HiveParser.updateOrDelete_return updateOrDelete() throws RecognitionException {
		HiveParser.updateOrDelete_return retval = new HiveParser.updateOrDelete_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UPDATE1177=null;
		Token KW_DELETE1179=null;
		ParserRuleReturnScope setColumnsClause1178 =null;

		ASTNode KW_UPDATE1177_tree=null;
		ASTNode KW_DELETE1179_tree=null;
		RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleSubtreeStream stream_setColumnsClause=new RewriteRuleSubtreeStream(adaptor,"rule setColumnsClause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3092:4: ( KW_UPDATE setColumnsClause -> ^( TOK_UPDATE setColumnsClause ) | KW_DELETE -> TOK_DELETE )
			int alt382=2;
			int LA382_0 = input.LA(1);
			if ( (LA382_0==KW_UPDATE) ) {
				alt382=1;
			}
			else if ( (LA382_0==KW_DELETE) ) {
				alt382=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 382, 0, input);
				throw nvae;
			}

			switch (alt382) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3093:4: KW_UPDATE setColumnsClause
					{
					KW_UPDATE1177=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_updateOrDelete20468); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE1177);

					pushFollow(FOLLOW_setColumnsClause_in_updateOrDelete20470);
					setColumnsClause1178=setColumnsClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setColumnsClause.add(setColumnsClause1178.getTree());
					// AST REWRITE
					// elements: setColumnsClause
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3093:31: -> ^( TOK_UPDATE setColumnsClause )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3093:34: ^( TOK_UPDATE setColumnsClause )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UPDATE, "TOK_UPDATE"), root_1);
						adaptor.addChild(root_1, stream_setColumnsClause.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3095:4: KW_DELETE
					{
					KW_DELETE1179=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_updateOrDelete20488); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE1179);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3095:14: -> TOK_DELETE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DELETE, "TOK_DELETE"));
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "updateOrDelete"


	public static class killQueryStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "killQueryStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3101:1: killQueryStatement : KW_KILL KW_QUERY ( StringLiteral )+ -> ^( TOK_KILL_QUERY ( StringLiteral )+ ) ;
	public final HiveParser.killQueryStatement_return killQueryStatement() throws RecognitionException {
		HiveParser.killQueryStatement_return retval = new HiveParser.killQueryStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_KILL1180=null;
		Token KW_QUERY1181=null;
		Token StringLiteral1182=null;

		ASTNode KW_KILL1180_tree=null;
		ASTNode KW_QUERY1181_tree=null;
		ASTNode StringLiteral1182_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_KILL=new RewriteRuleTokenStream(adaptor,"token KW_KILL");
		RewriteRuleTokenStream stream_KW_QUERY=new RewriteRuleTokenStream(adaptor,"token KW_QUERY");

		 pushMsg("kill query statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3104:3: ( KW_KILL KW_QUERY ( StringLiteral )+ -> ^( TOK_KILL_QUERY ( StringLiteral )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3105:3: KW_KILL KW_QUERY ( StringLiteral )+
			{
			KW_KILL1180=(Token)match(input,KW_KILL,FOLLOW_KW_KILL_in_killQueryStatement20520); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KILL.add(KW_KILL1180);

			KW_QUERY1181=(Token)match(input,KW_QUERY,FOLLOW_KW_QUERY_in_killQueryStatement20522); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_QUERY.add(KW_QUERY1181);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3105:20: ( StringLiteral )+
			int cnt383=0;
			loop383:
			while (true) {
				int alt383=2;
				int LA383_0 = input.LA(1);
				if ( (LA383_0==StringLiteral) ) {
					alt383=1;
				}

				switch (alt383) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3105:22: StringLiteral
					{
					StringLiteral1182=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_killQueryStatement20526); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral1182);

					}
					break;

				default :
					if ( cnt383 >= 1 ) break loop383;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(383, input);
					throw eee;
				}
				cnt383++;
			}

			// AST REWRITE
			// elements: StringLiteral
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3105:39: -> ^( TOK_KILL_QUERY ( StringLiteral )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3105:42: ^( TOK_KILL_QUERY ( StringLiteral )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_KILL_QUERY, "TOK_KILL_QUERY"), root_1);
				if ( !(stream_StringLiteral.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_StringLiteral.hasNext() ) {
					adaptor.addChild(root_1, stream_StringLiteral.nextNode());
				}
				stream_StringLiteral.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "killQueryStatement"

	// $ANTLR start synpred1_HiveParser
	public final void synpred1_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:982:7: ( grantPrivileges )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:982:8: grantPrivileges
		{
		pushFollow(FOLLOW_grantPrivileges_in_synpred1_HiveParser2941);
		grantPrivileges();
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred1_HiveParser

	// $ANTLR start synpred2_HiveParser
	public final void synpred2_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:983:7: ( revokePrivileges )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:983:8: revokePrivileges
		{
		pushFollow(FOLLOW_revokePrivileges_in_synpred2_HiveParser2955);
		revokePrivileges();
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred2_HiveParser

	// $ANTLR start synpred3_HiveParser
	public final void synpred3_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1171:7: ( alterStatementSuffixRename[true] )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1171:8: alterStatementSuffixRename[true]
		{
		pushFollow(FOLLOW_alterStatementSuffixRename_in_synpred3_HiveParser4487);
		alterStatementSuffixRename(true);
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred3_HiveParser

	// $ANTLR start synpred4_HiveParser
	public final void synpred4_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1558:4: ( KW_ELEM_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1558:5: KW_ELEM_TYPE
		{
		match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_synpred4_HiveParser7331); if (state.failed) return;

		}

	}
	// $ANTLR end synpred4_HiveParser

	// $ANTLR start synpred5_HiveParser
	public final void synpred5_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1560:4: ( KW_KEY_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1560:5: KW_KEY_TYPE
		{
		match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_synpred5_HiveParser7348); if (state.failed) return;

		}

	}
	// $ANTLR end synpred5_HiveParser

	// $ANTLR start synpred6_HiveParser
	public final void synpred6_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1562:4: ( KW_VALUE_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1562:5: KW_VALUE_TYPE
		{
		match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_synpred6_HiveParser7365); if (state.failed) return;

		}

	}
	// $ANTLR end synpred6_HiveParser

	// $ANTLR start synpred7_HiveParser
	public final void synpred7_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:5: ( KW_DATABASE | KW_SCHEMA )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred7_HiveParser

	// $ANTLR start synpred8_HiveParser
	public final void synpred8_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:5: ( KW_FUNCTION )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:6: KW_FUNCTION
		{
		match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_synpred8_HiveParser7573); if (state.failed) return;

		}

	}
	// $ANTLR end synpred8_HiveParser

	// $ANTLR start synpred9_HiveParser
	public final void synpred9_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1590:5: ( KW_FORMATTED | KW_EXTENDED )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_EXTENDED||input.LA(1)==KW_FORMATTED ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred9_HiveParser

	// $ANTLR start synpred10_HiveParser
	public final void synpred10_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:7: ( KW_COMPUTE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:8: KW_COMPUTE
		{
		match(input,KW_COMPUTE,FOLLOW_KW_COMPUTE_in_synpred10_HiveParser7726); if (state.failed) return;

		}

	}
	// $ANTLR end synpred10_HiveParser

	// $ANTLR start synpred11_HiveParser
	public final void synpred11_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1605:7: ( KW_CACHE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1605:8: KW_CACHE
		{
		match(input,KW_CACHE,FOLLOW_KW_CACHE_in_synpred11_HiveParser7854); if (state.failed) return;

		}

	}
	// $ANTLR end synpred11_HiveParser

	// $ANTLR start synpred12_HiveParser
	public final void synpred12_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:9: ( KW_DATABASE | KW_SCHEMA )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred12_HiveParser

	// $ANTLR start synpred13_HiveParser
	public final void synpred13_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:7: ( KW_DATABASE | KW_SCHEMA )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred13_HiveParser

	// $ANTLR start synpred14_HiveParser
	public final void synpred14_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1756:5: ( KW_ALL )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1756:6: KW_ALL
		{
		match(input,KW_ALL,FOLLOW_KW_ALL_in_synpred14_HiveParser9448); if (state.failed) return;

		}

	}
	// $ANTLR end synpred14_HiveParser

	// $ANTLR start synpred15_HiveParser
	public final void synpred15_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1758:5: ( KW_NONE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1758:6: KW_NONE
		{
		match(input,KW_NONE,FOLLOW_KW_NONE_in_synpred15_HiveParser9479); if (state.failed) return;

		}

	}
	// $ANTLR end synpred15_HiveParser

	// $ANTLR start synpred16_HiveParser
	public final void synpred16_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1782:7: ( KW_ALL )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1782:8: KW_ALL
		{
		match(input,KW_ALL,FOLLOW_KW_ALL_in_synpred16_HiveParser9653); if (state.failed) return;

		}

	}
	// $ANTLR end synpred16_HiveParser

	// $ANTLR start synpred17_HiveParser
	public final void synpred17_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:117: ( storedAsDirs )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:118: storedAsDirs
		{
		pushFollow(FOLLOW_storedAsDirs_in_synpred17_HiveParser12291);
		storedAsDirs();
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred17_HiveParser

	// $ANTLR start synpred18_HiveParser
	public final void synpred18_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:7: ( KW_STORED KW_AS KW_INPUTFORMAT )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:8: KW_STORED KW_AS KW_INPUTFORMAT
		{
		match(input,KW_STORED,FOLLOW_KW_STORED_in_synpred18_HiveParser13272); if (state.failed) return;

		match(input,KW_AS,FOLLOW_KW_AS_in_synpred18_HiveParser13274); if (state.failed) return;

		match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_synpred18_HiveParser13276); if (state.failed) return;

		}

	}
	// $ANTLR end synpred18_HiveParser

	// $ANTLR start synpred19_HiveParser
	public final void synpred19_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:25: ( KW_ELEM_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:26: KW_ELEM_TYPE
		{
		match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_synpred19_HiveParser13714); if (state.failed) return;

		}

	}
	// $ANTLR end synpred19_HiveParser

	// $ANTLR start synpred20_HiveParser
	public final void synpred20_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:58: ( KW_KEY_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:59: KW_KEY_TYPE
		{
		match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_synpred20_HiveParser13724); if (state.failed) return;

		}

	}
	// $ANTLR end synpred20_HiveParser

	// $ANTLR start synpred21_HiveParser
	public final void synpred21_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:89: ( KW_VALUE_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:90: KW_VALUE_TYPE
		{
		match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_synpred21_HiveParser13734); if (state.failed) return;

		}

	}
	// $ANTLR end synpred21_HiveParser

	// Delegated rules
	public HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier() throws RecognitionException { return gIdentifiersParser.functionIdentifier(); }

	public HiveParser_FromClauseParser.splitSample_return splitSample() throws RecognitionException { return gFromClauseParser.splitSample(); }

	public HiveParser_SelectClauseParser.window_value_expression_return window_value_expression() throws RecognitionException { return gSelectClauseParser.window_value_expression(); }

	public HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression_return precedenceUnaryPrefixExpression() throws RecognitionException { return gIdentifiersParser.precedenceUnaryPrefixExpression(); }

	public HiveParser_IdentifiersParser.precedenceUnaryOperator_return precedenceUnaryOperator() throws RecognitionException { return gIdentifiersParser.precedenceUnaryOperator(); }

	public HiveParser_IdentifiersParser.groupby_expression_return groupby_expression() throws RecognitionException { return gIdentifiersParser.groupby_expression(); }

	public HiveParser_FromClauseParser.partitioningSpec_return partitioningSpec() throws RecognitionException { return gFromClauseParser.partitioningSpec(); }

	public HiveParser_FromClauseParser.valuesTableConstructor_return valuesTableConstructor() throws RecognitionException { return gFromClauseParser.valuesTableConstructor(); }

	public HiveParser_ResourcePlanParser.triggerOrExpression_return triggerOrExpression() throws RecognitionException { return gResourcePlanParser.triggerOrExpression(); }

	public HiveParser_IdentifiersParser.expressionPart_return expressionPart(CommonTree t, boolean isStruct) throws RecognitionException { return gIdentifiersParser.expressionPart(t, isStruct); }

	public HiveParser_IdentifiersParser.groupByClause_return groupByClause() throws RecognitionException { return gIdentifiersParser.groupByClause(); }

	public HiveParser_FromClauseParser.joinSource_return joinSource() throws RecognitionException { return gFromClauseParser.joinSource(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpression_return precedenceSimilarExpression() throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpression(); }

	public HiveParser_ResourcePlanParser.poolAssign_return poolAssign() throws RecognitionException { return gResourcePlanParser.poolAssign(); }

	public HiveParser_FromClauseParser.valueRowConstructor_return valueRowConstructor() throws RecognitionException { return gFromClauseParser.valueRowConstructor(); }

	public HiveParser_IdentifiersParser.constant_return constant() throws RecognitionException { return gIdentifiersParser.constant(); }

	public HiveParser_IdentifiersParser.descFuncNames_return descFuncNames() throws RecognitionException { return gIdentifiersParser.descFuncNames(); }

	public HiveParser_FromClauseParser.tableSample_return tableSample() throws RecognitionException { return gFromClauseParser.tableSample(); }

	public HiveParser_IdentifiersParser.whenExpression_return whenExpression() throws RecognitionException { return gIdentifiersParser.whenExpression(); }

	public HiveParser_FromClauseParser.uniqueJoinToken_return uniqueJoinToken() throws RecognitionException { return gFromClauseParser.uniqueJoinToken(); }

	public HiveParser_IdentifiersParser.expressions_return expressions() throws RecognitionException { return gIdentifiersParser.expressions(); }

	public HiveParser_IdentifiersParser.expression_return expression() throws RecognitionException { return gIdentifiersParser.expression(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionIn_return precedenceSimilarExpressionIn(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionIn(t); }

	public HiveParser_FromClauseParser.lateralView_return lateralView() throws RecognitionException { return gFromClauseParser.lateralView(); }

	public HiveParser_ResourcePlanParser.triggerExpressionStandalone_return triggerExpressionStandalone() throws RecognitionException { return gResourcePlanParser.triggerExpressionStandalone(); }

	public HiveParser_FromClauseParser.tableBucketSample_return tableBucketSample() throws RecognitionException { return gFromClauseParser.tableBucketSample(); }

	public HiveParser_IdentifiersParser.precedenceOrExpression_return precedenceOrExpression() throws RecognitionException { return gIdentifiersParser.precedenceOrExpression(); }

	public HiveParser_IdentifiersParser.precedenceOrOperator_return precedenceOrOperator() throws RecognitionException { return gIdentifiersParser.precedenceOrOperator(); }

	public HiveParser_IdentifiersParser.function_return function() throws RecognitionException { return gIdentifiersParser.function(); }

	public HiveParser_IdentifiersParser.precedenceNotOperator_return precedenceNotOperator() throws RecognitionException { return gIdentifiersParser.precedenceNotOperator(); }

	public HiveParser_IdentifiersParser.columnRefOrderNotInParenthesis_return columnRefOrderNotInParenthesis() throws RecognitionException { return gIdentifiersParser.columnRefOrderNotInParenthesis(); }

	public HiveParser_FromClauseParser.fromClause_return fromClause() throws RecognitionException { return gFromClauseParser.fromClause(); }

	public HiveParser_IdentifiersParser.precedenceUnarySuffixExpression_return precedenceUnarySuffixExpression() throws RecognitionException { return gIdentifiersParser.precedenceUnarySuffixExpression(); }

	public HiveParser_ResourcePlanParser.poolAssignList_return poolAssignList() throws RecognitionException { return gResourcePlanParser.poolAssignList(); }

	public HiveParser_IdentifiersParser.groupingSetExpression_return groupingSetExpression() throws RecognitionException { return gIdentifiersParser.groupingSetExpression(); }

	public HiveParser_IdentifiersParser.intervalExpression_return intervalExpression() throws RecognitionException { return gIdentifiersParser.intervalExpression(); }

	public HiveParser_IdentifiersParser.rollupOldSyntax_return rollupOldSyntax() throws RecognitionException { return gIdentifiersParser.rollupOldSyntax(); }

	public HiveParser_IdentifiersParser.precedenceNotExpression_return precedenceNotExpression() throws RecognitionException { return gIdentifiersParser.precedenceNotExpression(); }

	public HiveParser_SelectClauseParser.window_range_expression_return window_range_expression() throws RecognitionException { return gSelectClauseParser.window_range_expression(); }

	public HiveParser_IdentifiersParser.columnRefOrderInParenthesis_return columnRefOrderInParenthesis() throws RecognitionException { return gIdentifiersParser.columnRefOrderInParenthesis(); }

	public HiveParser_IdentifiersParser.isCondition_return isCondition() throws RecognitionException { return gIdentifiersParser.isCondition(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseXorOperator_return precedenceBitwiseXorOperator() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseXorOperator(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseOrExpression_return precedenceBitwiseOrExpression() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseOrExpression(); }

	public HiveParser_ResourcePlanParser.dropResourcePlanStatement_return dropResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.dropResourcePlanStatement(); }

	public HiveParser_IdentifiersParser.precedenceConcatenateOperator_return precedenceConcatenateOperator() throws RecognitionException { return gIdentifiersParser.precedenceConcatenateOperator(); }

	public HiveParser_ResourcePlanParser.activate_return activate() throws RecognitionException { return gResourcePlanParser.activate(); }

	public HiveParser_IdentifiersParser.precedenceAndExpression_return precedenceAndExpression() throws RecognitionException { return gIdentifiersParser.precedenceAndExpression(); }

	public HiveParser_ResourcePlanParser.replaceResourcePlanStatement_return replaceResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.replaceResourcePlanStatement(); }

	public HiveParser_FromClauseParser.partitionTableFunctionSource_return partitionTableFunctionSource() throws RecognitionException { return gFromClauseParser.partitionTableFunctionSource(); }

	public HiveParser_ResourcePlanParser.triggerAndExpression_return triggerAndExpression() throws RecognitionException { return gResourcePlanParser.triggerAndExpression(); }

	public HiveParser_IdentifiersParser.groupByEmpty_return groupByEmpty() throws RecognitionException { return gIdentifiersParser.groupByEmpty(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionPart_return precedenceSimilarExpressionPart(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionPart(t); }

	public HiveParser_ResourcePlanParser.rpUnassign_return rpUnassign() throws RecognitionException { return gResourcePlanParser.rpUnassign(); }

	public HiveParser_SelectClauseParser.selectItem_return selectItem() throws RecognitionException { return gSelectClauseParser.selectItem(); }

	public HiveParser_IdentifiersParser.orderByClause_return orderByClause() throws RecognitionException { return gIdentifiersParser.orderByClause(); }

	public HiveParser_ResourcePlanParser.createResourcePlanStatement_return createResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.createResourcePlanStatement(); }

	public HiveParser_IdentifiersParser.timestampLiteral_return timestampLiteral() throws RecognitionException { return gIdentifiersParser.timestampLiteral(); }

	public HiveParser_ResourcePlanParser.poolPath_return poolPath() throws RecognitionException { return gResourcePlanParser.poolPath(); }

	public HiveParser_IdentifiersParser.caseExpression_return caseExpression() throws RecognitionException { return gIdentifiersParser.caseExpression(); }

	public HiveParser_IdentifiersParser.timestampLocalTZLiteral_return timestampLocalTZLiteral() throws RecognitionException { return gIdentifiersParser.timestampLocalTZLiteral(); }

	public HiveParser_ResourcePlanParser.createMappingStatement_return createMappingStatement() throws RecognitionException { return gResourcePlanParser.createMappingStatement(); }

	public HiveParser_ResourcePlanParser.createPoolStatement_return createPoolStatement() throws RecognitionException { return gResourcePlanParser.createPoolStatement(); }

	public HiveParser_ResourcePlanParser.triggerAtomExpression_return triggerAtomExpression() throws RecognitionException { return gResourcePlanParser.triggerAtomExpression(); }

	public HiveParser_SelectClauseParser.window_defn_return window_defn() throws RecognitionException { return gSelectClauseParser.window_defn(); }

	public HiveParser_SelectClauseParser.selectClause_return selectClause() throws RecognitionException { return gSelectClauseParser.selectClause(); }

	public HiveParser_ResourcePlanParser.dropTriggerStatement_return dropTriggerStatement() throws RecognitionException { return gResourcePlanParser.dropTriggerStatement(); }

	public HiveParser_ResourcePlanParser.createTriggerStatement_return createTriggerStatement() throws RecognitionException { return gResourcePlanParser.createTriggerStatement(); }

	public HiveParser_IdentifiersParser.havingClause_return havingClause() throws RecognitionException { return gIdentifiersParser.havingClause(); }

	public HiveParser_IdentifiersParser.rollupStandard_return rollupStandard() throws RecognitionException { return gIdentifiersParser.rollupStandard(); }

	public HiveParser_IdentifiersParser.partitionByClause_return partitionByClause() throws RecognitionException { return gIdentifiersParser.partitionByClause(); }

	public HiveParser_SelectClauseParser.window_clause_return window_clause() throws RecognitionException { return gSelectClauseParser.window_clause(); }

	public HiveParser_IdentifiersParser.booleanValueTok_return booleanValueTok() throws RecognitionException { return gIdentifiersParser.booleanValueTok(); }

	public HiveParser_IdentifiersParser.nonReserved_return nonReserved() throws RecognitionException { return gIdentifiersParser.nonReserved(); }

	public HiveParser_ResourcePlanParser.triggerActionExpression_return triggerActionExpression() throws RecognitionException { return gResourcePlanParser.triggerActionExpression(); }

	public HiveParser_IdentifiersParser.charSetStringLiteral_return charSetStringLiteral() throws RecognitionException { return gIdentifiersParser.charSetStringLiteral(); }

	public HiveParser_IdentifiersParser.precedenceEqualExpression_return precedenceEqualExpression() throws RecognitionException { return gIdentifiersParser.precedenceEqualExpression(); }

	public HiveParser_ResourcePlanParser.rpUnassignList_return rpUnassignList() throws RecognitionException { return gResourcePlanParser.rpUnassignList(); }

	public HiveParser_IdentifiersParser.precedencePlusOperator_return precedencePlusOperator() throws RecognitionException { return gIdentifiersParser.precedencePlusOperator(); }

	public HiveParser_FromClauseParser.searchCondition_return searchCondition() throws RecognitionException { return gFromClauseParser.searchCondition(); }

	public HiveParser_ResourcePlanParser.rpAssign_return rpAssign() throws RecognitionException { return gResourcePlanParser.rpAssign(); }

	public HiveParser_ResourcePlanParser.dropPoolStatement_return dropPoolStatement() throws RecognitionException { return gResourcePlanParser.dropPoolStatement(); }

	public HiveParser_FromClauseParser.partitionedTableFunction_return partitionedTableFunction() throws RecognitionException { return gFromClauseParser.partitionedTableFunction(); }

	public HiveParser_ResourcePlanParser.alterTriggerStatement_return alterTriggerStatement() throws RecognitionException { return gResourcePlanParser.alterTriggerStatement(); }

	public HiveParser_SelectClauseParser.selectList_return selectList() throws RecognitionException { return gSelectClauseParser.selectList(); }

	public HiveParser_IdentifiersParser.sysFuncNames_return sysFuncNames() throws RecognitionException { return gIdentifiersParser.sysFuncNames(); }

	public HiveParser_ResourcePlanParser.globalWmStatement_return globalWmStatement() throws RecognitionException { return gResourcePlanParser.globalWmStatement(); }

	public HiveParser_ResourcePlanParser.disable_return disable() throws RecognitionException { return gResourcePlanParser.disable(); }

	public HiveParser_IdentifiersParser.stringLiteralSequence_return stringLiteralSequence() throws RecognitionException { return gIdentifiersParser.stringLiteralSequence(); }

	public HiveParser_IdentifiersParser.functionName_return functionName() throws RecognitionException { return gIdentifiersParser.functionName(); }

	public HiveParser_IdentifiersParser.clusterByClause_return clusterByClause() throws RecognitionException { return gIdentifiersParser.clusterByClause(); }

	public HiveParser_IdentifiersParser.precedenceRegexpOperator_return precedenceRegexpOperator() throws RecognitionException { return gIdentifiersParser.precedenceRegexpOperator(); }

	public HiveParser_FromClauseParser.uniqueJoinExpr_return uniqueJoinExpr() throws RecognitionException { return gFromClauseParser.uniqueJoinExpr(); }

	public HiveParser_IdentifiersParser.dropPartitionOperator_return dropPartitionOperator() throws RecognitionException { return gIdentifiersParser.dropPartitionOperator(); }

	public HiveParser_IdentifiersParser.partitionSpec_return partitionSpec() throws RecognitionException { return gIdentifiersParser.partitionSpec(); }

	public HiveParser_IdentifiersParser.intervalLiteral_return intervalLiteral() throws RecognitionException { return gIdentifiersParser.intervalLiteral(); }

	public HiveParser_IdentifiersParser.dateLiteral_return dateLiteral() throws RecognitionException { return gIdentifiersParser.dateLiteral(); }

	public HiveParser_IdentifiersParser.identifier_return identifier() throws RecognitionException { return gIdentifiersParser.identifier(); }

	public HiveParser_FromClauseParser.tableSource_return tableSource() throws RecognitionException { return gFromClauseParser.tableSource(); }

	public HiveParser_IdentifiersParser.precedencePlusExpression_return precedencePlusExpression() throws RecognitionException { return gIdentifiersParser.precedencePlusExpression(); }

	public HiveParser_FromClauseParser.whereClause_return whereClause() throws RecognitionException { return gFromClauseParser.whereClause(); }

	public HiveParser_IdentifiersParser.sortByClause_return sortByClause() throws RecognitionException { return gIdentifiersParser.sortByClause(); }

	public HiveParser_IdentifiersParser.precedenceFieldExpression_return precedenceFieldExpression() throws RecognitionException { return gIdentifiersParser.precedenceFieldExpression(); }

	public HiveParser_SelectClauseParser.trfmClause_return trfmClause() throws RecognitionException { return gSelectClauseParser.trfmClause(); }

	public HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec() throws RecognitionException { return gIdentifiersParser.dropPartitionSpec(); }

	public HiveParser_IdentifiersParser.havingCondition_return havingCondition() throws RecognitionException { return gIdentifiersParser.havingCondition(); }

	public HiveParser_IdentifiersParser.partitionVal_return partitionVal() throws RecognitionException { return gIdentifiersParser.partitionVal(); }

	public HiveParser_FromClauseParser.atomjoinSource_return atomjoinSource() throws RecognitionException { return gFromClauseParser.atomjoinSource(); }

	public HiveParser_FromClauseParser.valuesClause_return valuesClause() throws RecognitionException { return gFromClauseParser.valuesClause(); }

	public HiveParser_IdentifiersParser.groupingExpressionSingle_return groupingExpressionSingle() throws RecognitionException { return gIdentifiersParser.groupingExpressionSingle(); }

	public HiveParser_IdentifiersParser.precedenceStarExpression_return precedenceStarExpression() throws RecognitionException { return gIdentifiersParser.precedenceStarExpression(); }

	public HiveParser_ResourcePlanParser.alterResourcePlanStatement_return alterResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.alterResourcePlanStatement(); }

	public HiveParser_ResourcePlanParser.triggerActionExpressionStandalone_return triggerActionExpressionStandalone() throws RecognitionException { return gResourcePlanParser.triggerActionExpressionStandalone(); }

	public HiveParser_IdentifiersParser.floorExpression_return floorExpression() throws RecognitionException { return gIdentifiersParser.floorExpression(); }

	public HiveParser_IdentifiersParser.booleanValue_return booleanValue() throws RecognitionException { return gIdentifiersParser.booleanValue(); }

	public HiveParser_IdentifiersParser.precedenceAmpersandOperator_return precedenceAmpersandOperator() throws RecognitionException { return gIdentifiersParser.precedenceAmpersandOperator(); }

	public HiveParser_ResourcePlanParser.withReplace_return withReplace() throws RecognitionException { return gResourcePlanParser.withReplace(); }

	public HiveParser_ResourcePlanParser.resourcePlanDdlStatements_return resourcePlanDdlStatements() throws RecognitionException { return gResourcePlanParser.resourcePlanDdlStatements(); }

	public HiveParser_FromClauseParser.joinToken_return joinToken() throws RecognitionException { return gFromClauseParser.joinToken(); }

	public HiveParser_IdentifiersParser.atomExpression_return atomExpression() throws RecognitionException { return gIdentifiersParser.atomExpression(); }

	public HiveParser_FromClauseParser.fromSource_return fromSource() throws RecognitionException { return gFromClauseParser.fromSource(); }

	public HiveParser_FromClauseParser.tableAlias_return tableAlias() throws RecognitionException { return gFromClauseParser.tableAlias(); }

	public HiveParser_ResourcePlanParser.comparisionOperator_return comparisionOperator() throws RecognitionException { return gResourcePlanParser.comparisionOperator(); }

	public HiveParser_ResourcePlanParser.alterPoolStatement_return alterPoolStatement() throws RecognitionException { return gResourcePlanParser.alterPoolStatement(); }

	public HiveParser_FromClauseParser.joinSourcePart_return joinSourcePart() throws RecognitionException { return gFromClauseParser.joinSourcePart(); }

	public HiveParser_SelectClauseParser.window_specification_return window_specification() throws RecognitionException { return gSelectClauseParser.window_specification(); }

	public HiveParser_IdentifiersParser.precedenceEqualOperator_return precedenceEqualOperator() throws RecognitionException { return gIdentifiersParser.precedenceEqualOperator(); }

	public HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier() throws RecognitionException { return gIdentifiersParser.principalIdentifier(); }

	public HiveParser_IdentifiersParser.distributeByClause_return distributeByClause() throws RecognitionException { return gIdentifiersParser.distributeByClause(); }

	public HiveParser_IdentifiersParser.precedenceStarOperator_return precedenceStarOperator() throws RecognitionException { return gIdentifiersParser.precedenceStarOperator(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionPartNot_return precedenceSimilarExpressionPartNot(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionPartNot(t); }

	public HiveParser_IdentifiersParser.timeQualifiers_return timeQualifiers() throws RecognitionException { return gIdentifiersParser.timeQualifiers(); }

	public HiveParser_FromClauseParser.uniqueJoinSource_return uniqueJoinSource() throws RecognitionException { return gFromClauseParser.uniqueJoinSource(); }

	public HiveParser_FromClauseParser.viewName_return viewName() throws RecognitionException { return gFromClauseParser.viewName(); }

	public HiveParser_SelectClauseParser.window_frame_start_boundary_return window_frame_start_boundary() throws RecognitionException { return gSelectClauseParser.window_frame_start_boundary(); }

	public HiveParser_IdentifiersParser.floorDateQualifiers_return floorDateQualifiers() throws RecognitionException { return gIdentifiersParser.floorDateQualifiers(); }

	public HiveParser_ResourcePlanParser.triggerExpression_return triggerExpression() throws RecognitionException { return gResourcePlanParser.triggerExpression(); }

	public HiveParser_IdentifiersParser.precedenceDistinctOperator_return precedenceDistinctOperator() throws RecognitionException { return gIdentifiersParser.precedenceDistinctOperator(); }

	public HiveParser_ResourcePlanParser.dropMappingStatement_return dropMappingStatement() throws RecognitionException { return gResourcePlanParser.dropMappingStatement(); }

	public HiveParser_IdentifiersParser.subQueryExpression_return subQueryExpression() throws RecognitionException { return gIdentifiersParser.subQueryExpression(); }

	public HiveParser_FromClauseParser.subQuerySource_return subQuerySource() throws RecognitionException { return gFromClauseParser.subQuerySource(); }

	public HiveParser_SelectClauseParser.selectExpression_return selectExpression() throws RecognitionException { return gSelectClauseParser.selectExpression(); }

	public HiveParser_IdentifiersParser.precedenceConcatenateExpression_return precedenceConcatenateExpression() throws RecognitionException { return gIdentifiersParser.precedenceConcatenateExpression(); }

	public HiveParser_ResourcePlanParser.unmanaged_return unmanaged() throws RecognitionException { return gResourcePlanParser.unmanaged(); }

	public HiveParser_IdentifiersParser.expressionsInParenthesis_return expressionsInParenthesis(boolean isStruct, boolean forceStruct) throws RecognitionException { return gIdentifiersParser.expressionsInParenthesis(isStruct, forceStruct); }

	public HiveParser_IdentifiersParser.intervalQualifiers_return intervalQualifiers() throws RecognitionException { return gIdentifiersParser.intervalQualifiers(); }

	public HiveParser_ResourcePlanParser.rpAssignList_return rpAssignList() throws RecognitionException { return gResourcePlanParser.rpAssignList(); }

	public HiveParser_IdentifiersParser.extractExpression_return extractExpression() throws RecognitionException { return gIdentifiersParser.extractExpression(); }

	public HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition() throws RecognitionException { return gIdentifiersParser.tableOrPartition(); }

	public HiveParser_IdentifiersParser.expressionsNotInParenthesis_return expressionsNotInParenthesis(boolean isStruct, boolean forceStruct) throws RecognitionException { return gIdentifiersParser.expressionsNotInParenthesis(isStruct, forceStruct); }

	public HiveParser_IdentifiersParser.precedenceAmpersandExpression_return precedenceAmpersandExpression() throws RecognitionException { return gIdentifiersParser.precedenceAmpersandExpression(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseXorExpression_return precedenceBitwiseXorExpression() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseXorExpression(); }

	public HiveParser_FromClauseParser.tableOrColumn_return tableOrColumn() throws RecognitionException { return gFromClauseParser.tableOrColumn(); }

	public HiveParser_ResourcePlanParser.alterMappingStatement_return alterMappingStatement() throws RecognitionException { return gResourcePlanParser.alterMappingStatement(); }

	public HiveParser_ResourcePlanParser.triggerLiteral_return triggerLiteral() throws RecognitionException { return gResourcePlanParser.triggerLiteral(); }

	public HiveParser_SelectClauseParser.window_frame_boundary_return window_frame_boundary() throws RecognitionException { return gSelectClauseParser.window_frame_boundary(); }

	public HiveParser_FromClauseParser.tableName_return tableName() throws RecognitionException { return gFromClauseParser.tableName(); }

	public HiveParser_FromClauseParser.expressionList_return expressionList() throws RecognitionException { return gFromClauseParser.expressionList(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionMain_return precedenceSimilarExpressionMain() throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionMain(); }

	public HiveParser_ResourcePlanParser.enable_return enable() throws RecognitionException { return gResourcePlanParser.enable(); }

	public HiveParser_IdentifiersParser.dropPartitionVal_return dropPartitionVal() throws RecognitionException { return gIdentifiersParser.dropPartitionVal(); }

	public HiveParser_IdentifiersParser.groupingSetExpressionMultiple_return groupingSetExpressionMultiple() throws RecognitionException { return gIdentifiersParser.groupingSetExpressionMultiple(); }

	public HiveParser_IdentifiersParser.sql11ReservedKeywordsUsedAsFunctionName_return sql11ReservedKeywordsUsedAsFunctionName() throws RecognitionException { return gIdentifiersParser.sql11ReservedKeywordsUsedAsFunctionName(); }

	public HiveParser_IdentifiersParser.precedenceSimilarOperator_return precedenceSimilarOperator() throws RecognitionException { return gIdentifiersParser.precedenceSimilarOperator(); }

	public HiveParser_FromClauseParser.aliasList_return aliasList() throws RecognitionException { return gFromClauseParser.aliasList(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionAtom_return precedenceSimilarExpressionAtom(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionAtom(t); }

	public HiveParser_SelectClauseParser.selectExpressionList_return selectExpressionList() throws RecognitionException { return gSelectClauseParser.selectExpressionList(); }

	public HiveParser_FromClauseParser.tableAllColumns_return tableAllColumns() throws RecognitionException { return gFromClauseParser.tableAllColumns(); }

	public HiveParser_IdentifiersParser.intervalValue_return intervalValue() throws RecognitionException { return gIdentifiersParser.intervalValue(); }

	public HiveParser_IdentifiersParser.precedenceAndOperator_return precedenceAndOperator() throws RecognitionException { return gIdentifiersParser.precedenceAndOperator(); }

	public HiveParser_SelectClauseParser.selectTrfmClause_return selectTrfmClause() throws RecognitionException { return gSelectClauseParser.selectTrfmClause(); }

	public HiveParser_FromClauseParser.virtualTableSource_return virtualTableSource() throws RecognitionException { return gFromClauseParser.virtualTableSource(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseOrOperator_return precedenceBitwiseOrOperator() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseOrOperator(); }

	public HiveParser_FromClauseParser.uniqueJoinTableSource_return uniqueJoinTableSource() throws RecognitionException { return gFromClauseParser.uniqueJoinTableSource(); }

	public HiveParser_SelectClauseParser.window_frame_return window_frame() throws RecognitionException { return gSelectClauseParser.window_frame(); }

	public HiveParser_IdentifiersParser.castExpression_return castExpression() throws RecognitionException { return gIdentifiersParser.castExpression(); }

	public final boolean synpred18_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred18_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred21_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred21_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred7_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred7_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred11_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred11_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred15_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred15_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred13_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred13_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred10_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred10_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred8_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred8_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred4_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred4_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred2_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred2_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred6_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred6_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred19_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred19_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred14_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred14_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred17_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred17_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred20_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred20_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred12_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred12_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred3_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred3_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred9_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred9_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred16_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred16_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred5_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred5_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred1_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred1_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}


	protected DFA2 dfa2 = new DFA2(this);
	protected DFA29 dfa29 = new DFA29(this);
	protected DFA237 dfa237 = new DFA237(this);
	static final String DFA2_eotS =
		"\142\uffff";
	static final String DFA2_eofS =
		"\142\uffff";
	static final String DFA2_minS =
		"\1\32\25\uffff\1\32\113\uffff";
	static final String DFA2_maxS =
		"\1\u0170\25\uffff\1\u0170\113\uffff";
	static final String DFA2_acceptS =
		"\1\uffff\1\2\45\uffff\1\1\72\uffff";
	static final String DFA2_specialS =
		"\142\uffff}>";
	static final String[] DFA2_transitionS = {
			"\1\1\7\uffff\1\1\1\26\7\uffff\1\47\16\uffff\1\47\12\uffff\1\1\10\uffff"+
			"\1\1\15\uffff\1\47\4\uffff\1\1\1\uffff\1\47\2\1\3\uffff\1\1\6\uffff\1"+
			"\1\3\uffff\1\1\10\uffff\1\1\1\uffff\1\47\17\uffff\1\47\1\1\3\uffff\1"+
			"\1\6\uffff\1\1\7\uffff\1\1\15\uffff\1\1\10\uffff\1\1\2\uffff\1\1\2\47"+
			"\3\uffff\1\1\4\uffff\1\1\6\uffff\1\1\57\uffff\1\1\2\uffff\1\1\2\uffff"+
			"\1\47\1\uffff\2\1\3\uffff\1\1\5\uffff\1\1\7\uffff\1\1\4\uffff\1\1\2\uffff"+
			"\1\1\7\uffff\1\1\33\uffff\1\1\7\uffff\1\1\3\uffff\1\1\1\uffff\1\1\10"+
			"\uffff\1\47\10\uffff\1\1\11\uffff\1\1",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\47\7\uffff\2\47\7\uffff\1\47\16\uffff\1\47\12\uffff\1\47\10\uffff"+
			"\1\47\15\uffff\1\47\4\uffff\1\47\1\uffff\3\47\3\uffff\1\47\6\uffff\1"+
			"\47\3\uffff\1\47\10\uffff\1\47\1\uffff\1\47\17\uffff\2\47\3\uffff\1\47"+
			"\6\uffff\1\47\7\uffff\1\47\15\uffff\1\47\10\uffff\1\47\2\uffff\3\47\3"+
			"\uffff\1\47\4\uffff\1\47\6\uffff\1\47\57\uffff\1\47\2\uffff\1\47\2\uffff"+
			"\1\47\1\uffff\2\47\3\uffff\1\47\5\uffff\1\47\7\uffff\1\47\4\uffff\1\47"+
			"\2\uffff\1\47\7\uffff\1\47\10\uffff\1\1\22\uffff\1\47\7\uffff\1\47\3"+
			"\uffff\1\47\1\uffff\1\47\10\uffff\1\47\10\uffff\1\47\11\uffff\1\47",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			""
	};

	static final short[] DFA2_eot = DFA.unpackEncodedString(DFA2_eotS);
	static final short[] DFA2_eof = DFA.unpackEncodedString(DFA2_eofS);
	static final char[] DFA2_min = DFA.unpackEncodedStringToUnsignedChars(DFA2_minS);
	static final char[] DFA2_max = DFA.unpackEncodedStringToUnsignedChars(DFA2_maxS);
	static final short[] DFA2_accept = DFA.unpackEncodedString(DFA2_acceptS);
	static final short[] DFA2_special = DFA.unpackEncodedString(DFA2_specialS);
	static final short[][] DFA2_transition;

	static {
		int numStates = DFA2_transitionS.length;
		DFA2_transition = new short[numStates][];
		for (int i=0; i<numStates; i++) {
			DFA2_transition[i] = DFA.unpackEncodedString(DFA2_transitionS[i]);
		}
	}

	protected class DFA2 extends DFA {

		public DFA2(BaseRecognizer recognizer) {
			this.recognizer = recognizer;
			this.decisionNumber = 2;
			this.eot = DFA2_eot;
			this.eof = DFA2_eof;
			this.min = DFA2_min;
			this.max = DFA2_max;
			this.accept = DFA2_accept;
			this.special = DFA2_special;
			this.transition = DFA2_transition;
		}
		@Override
		public String getDescription() {
			return "()* loopback of 798:6: ( explainOption )*";
		}
	}

	static final String DFA29_eotS =
		"\u008f\uffff";
	static final String DFA29_eofS =
		"\u008f\uffff";
	static final String DFA29_minS =
		"\1\32\1\46\1\uffff\1\46\1\uffff\1\46\2\uffff\1\103\3\uffff\2\126\2\30"+
		"\7\uffff\1\u0080\22\uffff\1\u0092\66\uffff\1\11\1\uffff\1\11\13\uffff"+
		"\1\11\1\uffff\1\11\16\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1"+
		"\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0";
	static final String DFA29_maxS =
		"\1\u0154\1\u015e\1\uffff\1\u015e\1\uffff\1\u015e\2\uffff\1\u015f\3\uffff"+
		"\2\u0133\2\u0295\7\uffff\1\u0141\22\uffff\1\u00c1\66\uffff\1\u0170\1\uffff"+
		"\1\u0170\13\uffff\1\u0170\1\uffff\1\u0170\16\uffff\1\0\1\uffff\1\0\1\uffff"+
		"\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0";
	static final String DFA29_acceptS =
		"\2\uffff\1\2\1\uffff\1\6\1\uffff\1\10\2\uffff\1\12\1\22\1\24\4\uffff\1"+
		"\43\1\45\1\46\1\47\2\uffff\1\14\1\uffff\1\31\3\uffff\1\1\1\uffff\1\4\2"+
		"\uffff\1\13\1\uffff\1\17\3\uffff\1\5\1\15\1\16\1\uffff\1\32\3\uffff\1"+
		"\3\1\uffff\1\21\3\uffff\1\7\12\uffff\1\11\14\uffff\1\35\1\36\1\37\1\40"+
		"\1\44\4\uffff\1\25\1\27\1\uffff\1\26\1\30\1\uffff\5\33\1\uffff\1\33\1"+
		"\uffff\2\33\1\41\2\uffff\6\34\1\uffff\1\34\1\uffff\2\34\1\42\3\uffff\1"+
		"\20\4\uffff\1\23\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1"+
		"\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff";
	static final String DFA29_specialS =
		"\16\uffff\1\0\1\1\121\uffff\1\2\1\uffff\1\3\13\uffff\1\4\1\uffff\1\5\16"+
		"\uffff\1\6\1\uffff\1\7\1\uffff\1\10\1\uffff\1\11\1\uffff\1\12\1\uffff"+
		"\1\13\1\uffff\1\14\1\uffff\1\15}>";
	static final String[] DFA29_transitionS = {
			"\1\21\7\uffff\1\5\1\13\52\uffff\1\1\25\uffff\2\6\3\uffff\1\23\6\uffff"+
			"\1\3\3\uffff\1\23\37\uffff\1\16\34\uffff\1\22\13\uffff\1\14\21\uffff"+
			"\1\11\62\uffff\1\12\5\uffff\1\23\3\uffff\1\17\22\uffff\1\20\2\uffff\1"+
			"\10\43\uffff\1\4\7\uffff\1\15\5\uffff\1\2",
			"\1\23\57\uffff\1\34\51\uffff\1\36\21\uffff\1\43\2\uffff\1\23\61\uffff"+
			"\1\26\25\uffff\1\41\20\uffff\1\23\33\uffff\1\23\5\uffff\1\30\6\uffff"+
			"\1\34\33\uffff\1\36\3\uffff\1\27\11\uffff\1\36\2\uffff\1\23\20\uffff"+
			"\1\23\10\uffff\1\41",
			"",
			"\1\23\57\uffff\1\57\73\uffff\1\61\2\uffff\1\23\61\uffff\1\51\46\uffff"+
			"\1\23\33\uffff\1\23\5\uffff\1\53\6\uffff\1\57\33\uffff\1\47\3\uffff\1"+
			"\52\14\uffff\1\23\20\uffff\1\23\10\uffff\1\50",
			"",
			"\1\23\57\uffff\1\65\76\uffff\1\23\61\uffff\1\65\46\uffff\1\23\33\uffff"+
			"\1\23\14\uffff\1\65\33\uffff\1\65\20\uffff\1\23\20\uffff\1\23\10\uffff"+
			"\1\65",
			"",
			"",
			"\1\100\3\uffff\1\100\2\uffff\1\100\3\uffff\1\100\2\uffff\1\121\5\uffff"+
			"\1\100\47\uffff\1\100\23\uffff\1\100\1\115\51\uffff\1\100\10\uffff\1"+
			"\100\40\uffff\1\100\12\uffff\1\117\26\uffff\1\100\5\uffff\1\116\1\120"+
			"\6\uffff\1\100\32\uffff\2\100\1\uffff\1\100\13\uffff\1\100\34\uffff\1"+
			"\100",
			"",
			"",
			"",
			"\1\127\u00c0\uffff\1\127\33\uffff\1\126",
			"\1\132\u00c0\uffff\1\132\33\uffff\1\131",
			"\1\146\1\uffff\6\146\1\134\1\146\1\135\1\146\3\uffff\1\146\2\uffff\1"+
			"\146\1\uffff\2\146\5\uffff\2\146\1\uffff\2\146\2\uffff\2\146\1\uffff"+
			"\5\146\1\uffff\2\146\1\uffff\4\146\2\uffff\2\146\1\137\6\uffff\1\146"+
			"\1\uffff\1\146\1\uffff\4\146\1\uffff\3\146\1\145\3\146\1\uffff\4\146"+
			"\1\uffff\3\146\1\uffff\1\146\1\140\2\146\1\uffff\1\146\1\uffff\2\146"+
			"\2\uffff\1\146\1\uffff\3\146\5\uffff\4\146\6\uffff\2\146\3\uffff\1\146"+
			"\4\uffff\2\146\3\uffff\2\146\1\uffff\3\146\1\144\5\uffff\3\146\1\uffff"+
			"\6\146\3\uffff\1\146\1\uffff\3\146\1\uffff\1\146\1\141\3\146\1\uffff"+
			"\1\146\1\uffff\4\146\1\uffff\1\146\1\uffff\2\146\1\uffff\2\146\1\uffff"+
			"\2\146\1\uffff\1\146\1\uffff\1\146\1\uffff\1\146\2\uffff\2\146\4\uffff"+
			"\2\146\1\uffff\2\146\1\uffff\3\146\1\uffff\4\146\4\uffff\1\146\1\uffff"+
			"\4\146\1\uffff\1\146\1\uffff\3\146\3\uffff\12\146\1\uffff\1\146\2\uffff"+
			"\2\146\4\uffff\4\146\1\142\4\146\1\uffff\3\146\1\143\1\146\1\uffff\4"+
			"\146\1\uffff\7\146\2\uffff\1\146\1\uffff\3\146\4\uffff\1\146\1\uffff"+
			"\4\146\4\uffff\1\146\1\uffff\1\146\1\uffff\1\146\2\uffff\4\146\1\136"+
			"\2\146\2\uffff\3\146\1\uffff\1\146\1\uffff\5\146\2\uffff\1\146\2\uffff"+
			"\5\146\74\uffff\1\146\46\uffff\1\146\60\uffff\1\146\3\uffff\1\146\57"+
			"\uffff\1\146\3\uffff\1\146\31\uffff\1\146\6\uffff\1\146\73\uffff\1\146",
			"\1\164\1\uffff\6\164\1\152\1\164\1\153\1\164\3\uffff\1\164\2\uffff\1"+
			"\164\1\uffff\2\164\5\uffff\2\164\1\uffff\2\164\2\uffff\2\164\1\uffff"+
			"\5\164\1\uffff\2\164\1\uffff\4\164\2\uffff\2\164\1\155\6\uffff\1\164"+
			"\1\uffff\1\164\1\uffff\4\164\1\uffff\3\164\1\163\3\164\1\uffff\4\164"+
			"\1\uffff\3\164\1\uffff\1\164\1\156\2\164\1\uffff\1\164\1\uffff\2\164"+
			"\2\uffff\1\164\1\uffff\3\164\5\uffff\4\164\6\uffff\2\164\3\uffff\1\164"+
			"\1\151\3\uffff\2\164\3\uffff\2\164\1\uffff\3\164\1\162\5\uffff\3\164"+
			"\1\uffff\6\164\3\uffff\1\164\1\uffff\3\164\1\uffff\1\164\1\157\3\164"+
			"\1\uffff\1\164\1\uffff\4\164\1\uffff\1\164\1\uffff\2\164\1\uffff\2\164"+
			"\1\uffff\2\164\1\uffff\1\164\1\uffff\1\164\1\uffff\1\164\2\uffff\2\164"+
			"\4\uffff\2\164\1\uffff\2\164\1\uffff\3\164\1\uffff\4\164\4\uffff\1\164"+
			"\1\uffff\4\164\1\uffff\1\164\1\uffff\3\164\3\uffff\12\164\1\uffff\1\164"+
			"\2\uffff\2\164\4\uffff\4\164\1\160\4\164\1\uffff\3\164\1\161\1\164\1"+
			"\uffff\4\164\1\uffff\7\164\2\uffff\1\164\1\uffff\3\164\4\uffff\1\164"+
			"\1\uffff\4\164\4\uffff\1\164\1\uffff\1\164\1\uffff\1\164\2\uffff\4\164"+
			"\1\154\2\164\2\uffff\3\164\1\uffff\1\164\1\uffff\5\164\2\uffff\1\164"+
			"\2\uffff\5\164\74\uffff\1\164\46\uffff\1\164\60\uffff\1\164\3\uffff\1"+
			"\164\57\uffff\1\164\3\uffff\1\164\31\uffff\1\164\6\uffff\1\164\73\uffff"+
			"\1\164",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\36\21\uffff\1\43\56\uffff\1\170\161\uffff\1\36\15\uffff\1\36",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\61\56\uffff\1\175",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\u0080\u00cf\uffff\1\u0081\144\uffff\1\u0082\61\uffff\1\177",
			"",
			"\1\u0084\u00cf\uffff\1\u0085\144\uffff\1\u0086\61\uffff\1\u0083",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\u0088\u0086\uffff\1\u008a\110\uffff\1\u0089\u0096\uffff\1\u0087",
			"",
			"\1\u008c\u0086\uffff\1\u008e\110\uffff\1\u008d\u0096\uffff\1\u008b",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff"
	};

	static final short[] DFA29_eot = DFA.unpackEncodedString(DFA29_eotS);
	static final short[] DFA29_eof = DFA.unpackEncodedString(DFA29_eofS);
	static final char[] DFA29_min = DFA.unpackEncodedStringToUnsignedChars(DFA29_minS);
	static final char[] DFA29_max = DFA.unpackEncodedStringToUnsignedChars(DFA29_maxS);
	static final short[] DFA29_accept = DFA.unpackEncodedString(DFA29_acceptS);
	static final short[] DFA29_special = DFA.unpackEncodedString(DFA29_specialS);
	static final short[][] DFA29_transition;

	static {
		int numStates = DFA29_transitionS.length;
		DFA29_transition = new short[numStates][];
		for (int i=0; i<numStates; i++) {
			DFA29_transition[i] = DFA.unpackEncodedString(DFA29_transitionS[i]);
		}
	}

	protected class DFA29 extends DFA {

		public DFA29(BaseRecognizer recognizer) {
			this.recognizer = recognizer;
			this.decisionNumber = 29;
			this.eot = DFA29_eot;
			this.eof = DFA29_eof;
			this.min = DFA29_min;
			this.max = DFA29_max;
			this.accept = DFA29_accept;
			this.special = DFA29_special;
			this.transition = DFA29_transition;
		}
		@Override
		public String getDescription() {
			return "953:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement | dropViewStatement | dropMaterializedViewStatement | createFunctionStatement | createMacroStatement | dropFunctionStatement | reloadFunctionsStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements );";
		}
		@Override
		public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
			TokenStream input = (TokenStream)_input;
			int _s = s;
			switch ( s ) {
					case 0 : 
						int LA29_14 = input.LA(1);
						 
						int index29_14 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_14==KW_ALL) && (synpred1_HiveParser())) {s = 92;}
						else if ( (LA29_14==KW_ALTER) && (synpred1_HiveParser())) {s = 93;}
						else if ( (LA29_14==KW_UPDATE) && (synpred1_HiveParser())) {s = 94;}
						else if ( (LA29_14==KW_CREATE) && (synpred1_HiveParser())) {s = 95;}
						else if ( (LA29_14==KW_DROP) && (synpred1_HiveParser())) {s = 96;}
						else if ( (LA29_14==KW_LOCK) ) {s = 97;}
						else if ( (LA29_14==KW_SELECT) && (synpred1_HiveParser())) {s = 98;}
						else if ( (LA29_14==KW_SHOW_DATABASE) ) {s = 99;}
						else if ( (LA29_14==KW_INSERT) && (synpred1_HiveParser())) {s = 100;}
						else if ( (LA29_14==KW_DELETE) && (synpred1_HiveParser())) {s = 101;}
						else if ( (LA29_14==Identifier||(LA29_14 >= KW_ABORT && LA29_14 <= KW_AFTER)||LA29_14==KW_ALLOC_FRACTION||LA29_14==KW_ANALYZE||LA29_14==KW_ARCHIVE||LA29_14==KW_ASC||(LA29_14 >= KW_AUTOCOMMIT && LA29_14 <= KW_BEFORE)||(LA29_14 >= KW_BUCKET && LA29_14 <= KW_BUCKETS)||(LA29_14 >= KW_CACHE && LA29_14 <= KW_CASCADE)||(LA29_14 >= KW_CBO && LA29_14 <= KW_CHANGE)||(LA29_14 >= KW_CHECK && LA29_14 <= KW_COLLECTION)||(LA29_14 >= KW_COLUMNS && LA29_14 <= KW_COMMENT)||(LA29_14 >= KW_COMPACT && LA29_14 <= KW_CONCATENATE)||(LA29_14 >= KW_CONTINUE && LA29_14 <= KW_COST)||LA29_14==KW_DATA||LA29_14==KW_DATABASES||(LA29_14 >= KW_DATETIME && LA29_14 <= KW_DEBUG)||(LA29_14 >= KW_DEFAULT && LA29_14 <= KW_DEFINED)||(LA29_14 >= KW_DELIMITED && LA29_14 <= KW_DESC)||(LA29_14 >= KW_DETAIL && LA29_14 <= KW_DISABLE)||(LA29_14 >= KW_DISTRIBUTE && LA29_14 <= KW_DO)||LA29_14==KW_DOW||(LA29_14 >= KW_DUMP && LA29_14 <= KW_ELEM_TYPE)||LA29_14==KW_ENABLE||(LA29_14 >= KW_ENFORCED && LA29_14 <= KW_ESCAPED)||LA29_14==KW_EXCLUSIVE||(LA29_14 >= KW_EXPLAIN && LA29_14 <= KW_EXPRESSION)||(LA29_14 >= KW_FIELDS && LA29_14 <= KW_FIRST)||(LA29_14 >= KW_FORMAT && LA29_14 <= KW_FORMATTED)||LA29_14==KW_FUNCTIONS||(LA29_14 >= KW_HOUR && LA29_14 <= KW_IDXPROPERTIES)||(LA29_14 >= KW_INDEX && LA29_14 <= KW_INDEXES)||(LA29_14 >= KW_INPATH && LA29_14 <= KW_INPUTFORMAT)||(LA29_14 >= KW_ISOLATION && LA29_14 <= KW_JAR)||(LA29_14 >= KW_JOINCOST && LA29_14 <= KW_LAST)||LA29_14==KW_LEVEL||(LA29_14 >= KW_LIMIT && LA29_14 <= KW_LOAD)||LA29_14==KW_LOCATION||(LA29_14 >= KW_LOCKS && LA29_14 <= KW_LONG)||LA29_14==KW_MANAGEMENT||(LA29_14 >= KW_MAPJOIN && LA29_14 <= KW_MATERIALIZED)||LA29_14==KW_METADATA||(LA29_14 >= KW_MINUTE && LA29_14 <= KW_MONTH)||(LA29_14 >= KW_MOVE && LA29_14 <= KW_MSCK)||(LA29_14 >= KW_NORELY && LA29_14 <= KW_NOSCAN)||LA29_14==KW_NOVALIDATE||LA29_14==KW_NULLS||LA29_14==KW_OFFSET||(LA29_14 >= KW_OPERATOR && LA29_14 <= KW_OPTION)||(LA29_14 >= KW_OUTPUTDRIVER && LA29_14 <= KW_OUTPUTFORMAT)||(LA29_14 >= KW_OVERWRITE && LA29_14 <= KW_OWNER)||(LA29_14 >= KW_PARTITIONED && LA29_14 <= KW_PATH)||(LA29_14 >= KW_PLAN && LA29_14 <= KW_POOL)||LA29_14==KW_PRINCIPALS||(LA29_14 >= KW_PURGE && LA29_14 <= KW_QUERY_PARALLELISM)||LA29_14==KW_READ||(LA29_14 >= KW_REBUILD && LA29_14 <= KW_RECORDWRITER)||(LA29_14 >= KW_RELOAD && LA29_14 <= KW_RESTRICT)||LA29_14==KW_REWRITE||(LA29_14 >= KW_ROLE && LA29_14 <= KW_ROLES)||(LA29_14 >= KW_SCHEDULING_POLICY && LA29_14 <= KW_SECOND)||(LA29_14 >= KW_SEMI && LA29_14 <= KW_SERVER)||(LA29_14 >= KW_SETS && LA29_14 <= KW_SHOW)||LA29_14==KW_SKEWED||(LA29_14 >= KW_SNAPSHOT && LA29_14 <= KW_SSL)||(LA29_14 >= KW_STATISTICS && LA29_14 <= KW_SUMMARY)||LA29_14==KW_TABLES||(LA29_14 >= KW_TBLPROPERTIES && LA29_14 <= KW_TERMINATED)||LA29_14==KW_TINYINT||(LA29_14 >= KW_TOUCH && LA29_14 <= KW_TRANSACTIONS)||LA29_14==KW_UNARCHIVE||LA29_14==KW_UNDO||LA29_14==KW_UNIONTYPE||(LA29_14 >= KW_UNLOCK && LA29_14 <= KW_UNSIGNED)||(LA29_14 >= KW_URI && LA29_14 <= KW_USE)||(LA29_14 >= KW_UTC && LA29_14 <= KW_VALIDATE)||LA29_14==KW_VALUE_TYPE||(LA29_14 >= KW_VECTORIZATION && LA29_14 <= KW_WEEK)||LA29_14==KW_WHILE||(LA29_14 >= KW_WORK && LA29_14 <= KW_ZONE)||LA29_14==KW_BATCH||LA29_14==KW_DAYOFWEEK||LA29_14==KW_HOLD_DDLTIME||LA29_14==KW_IGNORE||LA29_14==KW_NO_DROP||LA29_14==KW_OFFLINE||LA29_14==KW_PROTECTION||LA29_14==KW_READONLY||LA29_14==KW_TIMESTAMPTZ) ) {s = 102;}
						 
						input.seek(index29_14);
						if ( s>=0 ) return s;
						break;

					case 1 : 
						int LA29_15 = input.LA(1);
						 
						int index29_15 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_15==KW_GRANT) && (synpred2_HiveParser())) {s = 105;}
						else if ( (LA29_15==KW_ALL) && (synpred2_HiveParser())) {s = 106;}
						else if ( (LA29_15==KW_ALTER) && (synpred2_HiveParser())) {s = 107;}
						else if ( (LA29_15==KW_UPDATE) && (synpred2_HiveParser())) {s = 108;}
						else if ( (LA29_15==KW_CREATE) && (synpred2_HiveParser())) {s = 109;}
						else if ( (LA29_15==KW_DROP) && (synpred2_HiveParser())) {s = 110;}
						else if ( (LA29_15==KW_LOCK) ) {s = 111;}
						else if ( (LA29_15==KW_SELECT) && (synpred2_HiveParser())) {s = 112;}
						else if ( (LA29_15==KW_SHOW_DATABASE) ) {s = 113;}
						else if ( (LA29_15==KW_INSERT) && (synpred2_HiveParser())) {s = 114;}
						else if ( (LA29_15==KW_DELETE) && (synpred2_HiveParser())) {s = 115;}
						else if ( (LA29_15==Identifier||(LA29_15 >= KW_ABORT && LA29_15 <= KW_AFTER)||LA29_15==KW_ALLOC_FRACTION||LA29_15==KW_ANALYZE||LA29_15==KW_ARCHIVE||LA29_15==KW_ASC||(LA29_15 >= KW_AUTOCOMMIT && LA29_15 <= KW_BEFORE)||(LA29_15 >= KW_BUCKET && LA29_15 <= KW_BUCKETS)||(LA29_15 >= KW_CACHE && LA29_15 <= KW_CASCADE)||(LA29_15 >= KW_CBO && LA29_15 <= KW_CHANGE)||(LA29_15 >= KW_CHECK && LA29_15 <= KW_COLLECTION)||(LA29_15 >= KW_COLUMNS && LA29_15 <= KW_COMMENT)||(LA29_15 >= KW_COMPACT && LA29_15 <= KW_CONCATENATE)||(LA29_15 >= KW_CONTINUE && LA29_15 <= KW_COST)||LA29_15==KW_DATA||LA29_15==KW_DATABASES||(LA29_15 >= KW_DATETIME && LA29_15 <= KW_DEBUG)||(LA29_15 >= KW_DEFAULT && LA29_15 <= KW_DEFINED)||(LA29_15 >= KW_DELIMITED && LA29_15 <= KW_DESC)||(LA29_15 >= KW_DETAIL && LA29_15 <= KW_DISABLE)||(LA29_15 >= KW_DISTRIBUTE && LA29_15 <= KW_DO)||LA29_15==KW_DOW||(LA29_15 >= KW_DUMP && LA29_15 <= KW_ELEM_TYPE)||LA29_15==KW_ENABLE||(LA29_15 >= KW_ENFORCED && LA29_15 <= KW_ESCAPED)||LA29_15==KW_EXCLUSIVE||(LA29_15 >= KW_EXPLAIN && LA29_15 <= KW_EXPRESSION)||(LA29_15 >= KW_FIELDS && LA29_15 <= KW_FIRST)||(LA29_15 >= KW_FORMAT && LA29_15 <= KW_FORMATTED)||LA29_15==KW_FUNCTIONS||(LA29_15 >= KW_HOUR && LA29_15 <= KW_IDXPROPERTIES)||(LA29_15 >= KW_INDEX && LA29_15 <= KW_INDEXES)||(LA29_15 >= KW_INPATH && LA29_15 <= KW_INPUTFORMAT)||(LA29_15 >= KW_ISOLATION && LA29_15 <= KW_JAR)||(LA29_15 >= KW_JOINCOST && LA29_15 <= KW_LAST)||LA29_15==KW_LEVEL||(LA29_15 >= KW_LIMIT && LA29_15 <= KW_LOAD)||LA29_15==KW_LOCATION||(LA29_15 >= KW_LOCKS && LA29_15 <= KW_LONG)||LA29_15==KW_MANAGEMENT||(LA29_15 >= KW_MAPJOIN && LA29_15 <= KW_MATERIALIZED)||LA29_15==KW_METADATA||(LA29_15 >= KW_MINUTE && LA29_15 <= KW_MONTH)||(LA29_15 >= KW_MOVE && LA29_15 <= KW_MSCK)||(LA29_15 >= KW_NORELY && LA29_15 <= KW_NOSCAN)||LA29_15==KW_NOVALIDATE||LA29_15==KW_NULLS||LA29_15==KW_OFFSET||(LA29_15 >= KW_OPERATOR && LA29_15 <= KW_OPTION)||(LA29_15 >= KW_OUTPUTDRIVER && LA29_15 <= KW_OUTPUTFORMAT)||(LA29_15 >= KW_OVERWRITE && LA29_15 <= KW_OWNER)||(LA29_15 >= KW_PARTITIONED && LA29_15 <= KW_PATH)||(LA29_15 >= KW_PLAN && LA29_15 <= KW_POOL)||LA29_15==KW_PRINCIPALS||(LA29_15 >= KW_PURGE && LA29_15 <= KW_QUERY_PARALLELISM)||LA29_15==KW_READ||(LA29_15 >= KW_REBUILD && LA29_15 <= KW_RECORDWRITER)||(LA29_15 >= KW_RELOAD && LA29_15 <= KW_RESTRICT)||LA29_15==KW_REWRITE||(LA29_15 >= KW_ROLE && LA29_15 <= KW_ROLES)||(LA29_15 >= KW_SCHEDULING_POLICY && LA29_15 <= KW_SECOND)||(LA29_15 >= KW_SEMI && LA29_15 <= KW_SERVER)||(LA29_15 >= KW_SETS && LA29_15 <= KW_SHOW)||LA29_15==KW_SKEWED||(LA29_15 >= KW_SNAPSHOT && LA29_15 <= KW_SSL)||(LA29_15 >= KW_STATISTICS && LA29_15 <= KW_SUMMARY)||LA29_15==KW_TABLES||(LA29_15 >= KW_TBLPROPERTIES && LA29_15 <= KW_TERMINATED)||LA29_15==KW_TINYINT||(LA29_15 >= KW_TOUCH && LA29_15 <= KW_TRANSACTIONS)||LA29_15==KW_UNARCHIVE||LA29_15==KW_UNDO||LA29_15==KW_UNIONTYPE||(LA29_15 >= KW_UNLOCK && LA29_15 <= KW_UNSIGNED)||(LA29_15 >= KW_URI && LA29_15 <= KW_USE)||(LA29_15 >= KW_UTC && LA29_15 <= KW_VALIDATE)||LA29_15==KW_VALUE_TYPE||(LA29_15 >= KW_VECTORIZATION && LA29_15 <= KW_WEEK)||LA29_15==KW_WHILE||(LA29_15 >= KW_WORK && LA29_15 <= KW_ZONE)||LA29_15==KW_BATCH||LA29_15==KW_DAYOFWEEK||LA29_15==KW_HOLD_DDLTIME||LA29_15==KW_IGNORE||LA29_15==KW_NO_DROP||LA29_15==KW_OFFLINE||LA29_15==KW_PROTECTION||LA29_15==KW_READONLY||LA29_15==KW_TIMESTAMPTZ) ) {s = 116;}
						 
						input.seek(index29_15);
						if ( s>=0 ) return s;
						break;

					case 2 : 
						int LA29_97 = input.LA(1);
						 
						int index29_97 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_97==LPAREN) && (synpred1_HiveParser())) {s = 127;}
						else if ( (LA29_97==COMMA) ) {s = 128;}
						else if ( (LA29_97==KW_ON) && (synpred1_HiveParser())) {s = 129;}
						else if ( (LA29_97==KW_TO) ) {s = 130;}
						 
						input.seek(index29_97);
						if ( s>=0 ) return s;
						break;

					case 3 : 
						int LA29_99 = input.LA(1);
						 
						int index29_99 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_99==LPAREN) && (synpred1_HiveParser())) {s = 131;}
						else if ( (LA29_99==COMMA) ) {s = 132;}
						else if ( (LA29_99==KW_ON) && (synpred1_HiveParser())) {s = 133;}
						else if ( (LA29_99==KW_TO) ) {s = 134;}
						 
						input.seek(index29_99);
						if ( s>=0 ) return s;
						break;

					case 4 : 
						int LA29_111 = input.LA(1);
						 
						int index29_111 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_111==LPAREN) && (synpred2_HiveParser())) {s = 135;}
						else if ( (LA29_111==COMMA) ) {s = 136;}
						else if ( (LA29_111==KW_ON) && (synpred2_HiveParser())) {s = 137;}
						else if ( (LA29_111==KW_FROM) ) {s = 138;}
						 
						input.seek(index29_111);
						if ( s>=0 ) return s;
						break;

					case 5 : 
						int LA29_113 = input.LA(1);
						 
						int index29_113 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_113==LPAREN) && (synpred2_HiveParser())) {s = 139;}
						else if ( (LA29_113==COMMA) ) {s = 140;}
						else if ( (LA29_113==KW_ON) && (synpred2_HiveParser())) {s = 141;}
						else if ( (LA29_113==KW_FROM) ) {s = 142;}
						 
						input.seek(index29_113);
						if ( s>=0 ) return s;
						break;

					case 6 : 
						int LA29_128 = input.LA(1);
						 
						int index29_128 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 133;}
						else if ( (true) ) {s = 102;}
						 
						input.seek(index29_128);
						if ( s>=0 ) return s;
						break;

					case 7 : 
						int LA29_130 = input.LA(1);
						 
						int index29_130 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 133;}
						else if ( (true) ) {s = 102;}
						 
						input.seek(index29_130);
						if ( s>=0 ) return s;
						break;

					case 8 : 
						int LA29_132 = input.LA(1);
						 
						int index29_132 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 133;}
						else if ( (true) ) {s = 102;}
						 
						input.seek(index29_132);
						if ( s>=0 ) return s;
						break;

					case 9 : 
						int LA29_134 = input.LA(1);
						 
						int index29_134 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 133;}
						else if ( (true) ) {s = 102;}
						 
						input.seek(index29_134);
						if ( s>=0 ) return s;
						break;

					case 10 : 
						int LA29_136 = input.LA(1);
						 
						int index29_136 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 141;}
						else if ( (true) ) {s = 116;}
						 
						input.seek(index29_136);
						if ( s>=0 ) return s;
						break;

					case 11 : 
						int LA29_138 = input.LA(1);
						 
						int index29_138 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 141;}
						else if ( (true) ) {s = 116;}
						 
						input.seek(index29_138);
						if ( s>=0 ) return s;
						break;

					case 12 : 
						int LA29_140 = input.LA(1);
						 
						int index29_140 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 141;}
						else if ( (true) ) {s = 116;}
						 
						input.seek(index29_140);
						if ( s>=0 ) return s;
						break;

					case 13 : 
						int LA29_142 = input.LA(1);
						 
						int index29_142 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 141;}
						else if ( (true) ) {s = 116;}
						 
						input.seek(index29_142);
						if ( s>=0 ) return s;
						break;
			}
			if (state.backtracking>0) {state.failed=true; return -1;}
			NoViableAltException nvae =
				new NoViableAltException(getDescription(), 29, _s, input);
			error(nvae);
			throw nvae;
		}
	}

	static final String DFA237_eotS =
		"\134\uffff";
	static final String DFA237_eofS =
		"\1\2\133\uffff";
	static final String DFA237_minS =
		"\1\11\1\14\41\uffff\1\4\70\uffff";
	static final String DFA237_maxS =
		"\1\u017d\1\u0295\41\uffff\1\u0181\70\uffff";
	static final String DFA237_acceptS =
		"\2\uffff\1\2\73\uffff\1\1\35\uffff";
	static final String DFA237_specialS =
		"\134\uffff}>";
	static final String[] DFA237_transitionS = {
			"\1\2\37\uffff\1\2\24\uffff\1\2\54\uffff\1\2\14\uffff\1\2\27\uffff\1\2"+
			"\4\uffff\1\2\1\uffff\1\2\2\uffff\1\2\10\uffff\1\2\1\uffff\1\2\15\uffff"+
			"\1\2\4\uffff\2\2\2\uffff\1\2\6\uffff\1\1\6\uffff\1\2\12\uffff\1\2\10"+
			"\uffff\1\2\36\uffff\3\2\32\uffff\1\2\14\uffff\1\2\5\uffff\1\2\10\uffff"+
			"\1\2\23\uffff\1\2\13\uffff\1\2\3\uffff\1\2\10\uffff\1\2\1\uffff\1\2\12"+
			"\uffff\1\2\14\uffff\1\2",
			"\1\2\13\uffff\10\2\1\uffff\1\2\1\uffff\1\2\3\uffff\2\2\1\uffff\1\2\1"+
			"\uffff\2\2\1\uffff\3\2\1\uffff\2\2\1\uffff\6\2\1\uffff\5\2\1\uffff\2"+
			"\2\1\uffff\4\2\2\uffff\2\2\4\uffff\2\2\1\uffff\1\2\1\uffff\6\2\1\uffff"+
			"\3\2\1\uffff\3\2\1\uffff\4\2\1\uffff\5\2\1\uffff\2\2\1\uffff\1\2\1\uffff"+
			"\2\2\2\uffff\5\2\2\uffff\2\2\1\uffff\6\2\4\uffff\2\2\3\uffff\1\2\2\uffff"+
			"\1\2\1\uffff\3\2\2\uffff\2\2\1\uffff\3\2\1\uffff\1\2\1\uffff\1\2\2\uffff"+
			"\3\2\1\uffff\2\2\1\43\3\2\3\uffff\1\2\1\uffff\3\2\1\uffff\5\2\1\uffff"+
			"\6\2\1\uffff\1\2\1\uffff\2\2\1\uffff\2\2\1\uffff\6\2\1\uffff\1\2\2\uffff"+
			"\2\2\4\uffff\2\2\1\uffff\2\2\1\uffff\3\2\1\uffff\4\2\4\uffff\1\2\1\uffff"+
			"\4\2\1\uffff\1\2\1\uffff\3\2\3\uffff\12\2\1\uffff\1\2\2\uffff\2\2\4\uffff"+
			"\4\2\1\uffff\4\2\1\uffff\12\2\1\uffff\7\2\2\uffff\1\2\1\uffff\3\2\2\uffff"+
			"\3\2\1\uffff\4\2\2\uffff\1\2\1\uffff\1\2\1\uffff\1\2\1\uffff\1\2\2\uffff"+
			"\4\2\1\uffff\2\2\2\uffff\3\2\1\uffff\1\2\1\uffff\5\2\2\uffff\1\2\2\uffff"+
			"\5\2\4\uffff\1\2\2\uffff\1\2\2\uffff\3\2\10\uffff\3\2\44\uffff\1\2\46"+
			"\uffff\1\2\60\uffff\1\2\3\uffff\1\2\57\uffff\1\2\3\uffff\1\2\31\uffff"+
			"\1\2\6\uffff\1\2\73\uffff\1\2",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\3\2\2\uffff\2\2\2\uffff\2\2\1\uffff\1\2\1\uffff\2\2\1\uffff\2\2\15"+
			"\uffff\1\2\11\uffff\1\2\155\uffff\1\2\13\uffff\1\2\16\uffff\1\2\33\uffff"+
			"\1\2\11\uffff\1\2\40\uffff\1\2\2\uffff\1\2\15\uffff\1\2\4\uffff\1\2\43"+
			"\uffff\1\76\35\uffff\1\2\26\uffff\2\2\1\uffff\2\2\1\uffff\3\2\2\uffff"+
			"\1\2\10\uffff\1\2",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			""
	};

	static final short[] DFA237_eot = DFA.unpackEncodedString(DFA237_eotS);
	static final short[] DFA237_eof = DFA.unpackEncodedString(DFA237_eofS);
	static final char[] DFA237_min = DFA.unpackEncodedStringToUnsignedChars(DFA237_minS);
	static final char[] DFA237_max = DFA.unpackEncodedStringToUnsignedChars(DFA237_maxS);
	static final short[] DFA237_accept = DFA.unpackEncodedString(DFA237_acceptS);
	static final short[] DFA237_special = DFA.unpackEncodedString(DFA237_specialS);
	static final short[][] DFA237_transition;

	static {
		int numStates = DFA237_transitionS.length;
		DFA237_transition = new short[numStates][];
		for (int i=0; i<numStates; i++) {
			DFA237_transition[i] = DFA.unpackEncodedString(DFA237_transitionS[i]);
		}
	}

	protected class DFA237 extends DFA {

		public DFA237(BaseRecognizer recognizer) {
			this.recognizer = recognizer;
			this.decisionNumber = 237;
			this.eot = DFA237_eot;
			this.eof = DFA237_eof;
			this.min = DFA237_min;
			this.max = DFA237_max;
			this.accept = DFA237_accept;
			this.special = DFA237_special;
			this.transition = DFA237_transition;
		}
		@Override
		public String getDescription() {
			return "2138:103: ( tableRowFormatMapKeysIdentifier )?";
		}
	}

	public static final BitSet FOLLOW_explainStatement_in_statement1298 = new BitSet(new long[]{0x0000000000000000L});
	public static final BitSet FOLLOW_EOF_in_statement1300 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_execStatement_in_statement1305 = new BitSet(new long[]{0x0000000000000000L});
	public static final BitSet FOLLOW_EOF_in_statement1307 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXPLAIN_in_explainStatement1328 = new BitSet(new long[]{0x0400080C04000000L,0xA011023A10004020L,0xE402000808118000L,0x8000000000008108L,0x00000404840431A4L,0x0001004020144040L});
	public static final BitSet FOLLOW_explainOption_in_explainStatement1337 = new BitSet(new long[]{0x0400080C04000000L,0xA011023A10004020L,0xE402000808118000L,0x8000000000008108L,0x00000404840411A4L,0x0001004020144040L});
	public static final BitSet FOLLOW_execStatement_in_explainStatement1340 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REWRITE_in_explainStatement1371 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000800010000L,0x8000000000000008L,0x0000000004000000L,0x0001004000000000L});
	public static final BitSet FOLLOW_queryStatementExpression_in_explainStatement1373 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_explainOption1413 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FORMATTED_in_explainOption1421 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DEPENDENCY_in_explainOption1429 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CBO_in_explainOption1437 = new BitSet(new long[]{0x0000000000000002L,0x0000000000002000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_LOGICAL_in_explainOption1454 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_AUTHORIZATION_in_explainOption1462 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ANALYZE_in_explainOption1470 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REOPTIMIZATION_in_explainOption1478 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCKS_in_explainOption1486 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_VECTORIZATION_in_explainOption1495 = new BitSet(new long[]{0x0000000000000002L,0x4000004000000000L,0x0000000000000000L,0x000000000C000000L,0x0002000000000000L});
	public static final BitSet FOLLOW_vectorizationOnly_in_explainOption1497 = new BitSet(new long[]{0x0000000000000002L,0x4000004000000000L,0x0000000000000000L,0x0000000008000000L,0x0002000000000000L});
	public static final BitSet FOLLOW_vectorizatonDetail_in_explainOption1500 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DEBUG_in_explainOption1510 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ONLY_in_vectorizationOnly1537 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SUMMARY_in_vectorizatonDetail1574 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_OPERATOR_in_vectorizatonDetail1592 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXPRESSION_in_vectorizatonDetail1610 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DETAIL_in_vectorizatonDetail1628 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_queryStatementExpression_in_execStatement1665 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_loadStatement_in_execStatement1673 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_exportStatement_in_execStatement1681 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_importStatement_in_execStatement1689 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_replDumpStatement_in_execStatement1697 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_replLoadStatement_in_execStatement1705 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_replStatusStatement_in_execStatement1713 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_ddlStatement_in_execStatement1721 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_deleteStatement_in_execStatement1729 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_updateStatement_in_execStatement1737 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_sqlTransactionStatement_in_execStatement1745 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_mergeStatement_in_execStatement1753 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOAD_in_loadStatement1780 = new BitSet(new long[]{0x0000000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_DATA_in_loadStatement1782 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0800000100000000L});
	public static final BitSet FOLLOW_KW_LOCAL_in_loadStatement1787 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000100000000L});
	public static final BitSet FOLLOW_KW_INPATH_in_loadStatement1791 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_loadStatement1796 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000000000L,0x0000001000000000L});
	public static final BitSet FOLLOW_KW_OVERWRITE_in_loadStatement1802 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_INTO_in_loadStatement1806 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_loadStatement1808 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableOrPartition_in_loadStatement1813 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_inputFileFormat_in_loadStatement1816 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FOR_in_replicationClause1871 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000000000000200L});
	public static final BitSet FOLLOW_KW_METADATA_in_replicationClause1876 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_KW_REPLICATION_in_replicationClause1880 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_replicationClause1882 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_replicationClause1887 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_replicationClause1890 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXPORT_in_exportStatement1934 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_exportStatement1942 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableOrPartition_in_exportStatement1947 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_KW_TO_in_exportStatement1956 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_exportStatement1961 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_replicationClause_in_exportStatement1970 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_IMPORT_in_importStatement2020 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010001L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_EXTERNAL_in_importStatement2035 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_importStatement2039 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableOrPartition_in_importStatement2044 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_FROM_in_importStatement2058 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_importStatement2063 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x1000000000000000L});
	public static final BitSet FOLLOW_tableLocation_in_importStatement2075 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REPL_in_replDumpStatement2129 = new BitSet(new long[]{0x0000000000000000L,0x0002000000000000L});
	public static final BitSet FOLLOW_KW_DUMP_in_replDumpStatement2131 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_replDbPolicy_in_replDumpStatement2144 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L,0x0000000000000000L,0x0000000000000100L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_REPLACE_in_replDumpStatement2156 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_replDbPolicy_in_replDumpStatement2160 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_FROM_in_replDumpStatement2173 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_replDumpStatement2178 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0100000000000000L,0x0000000000000000L,0x4000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_TO_in_replDumpStatement2192 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_replDumpStatement2197 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0100000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_LIMIT_in_replDumpStatement2213 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_replDumpStatement2218 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_replDumpStatement2243 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_replConfigs_in_replDumpStatement2247 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_replDbPolicy2334 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_DOT_in_replDbPolicy2338 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_replTableLevelPolicy_in_replDbPolicy2342 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REPL_in_replLoadStatement2382 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_LOAD_in_replLoadStatement2384 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076309C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_replLoadStatement2397 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_FROM_in_replLoadStatement2409 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_replLoadStatement2414 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_replLoadStatement2426 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_replConfigs_in_replLoadStatement2430 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_replConfigs2494 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_replConfigsList_in_replConfigs2496 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_replConfigs2498 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_keyValueProperty_in_replConfigsList2539 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_replConfigsList2542 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_keyValueProperty_in_replConfigsList2544 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_StringLiteral_in_replTableLevelPolicy2592 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_DOT_in_replTableLevelPolicy2596 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_replTableLevelPolicy2600 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REPL_in_replStatusStatement2651 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_STATUS_in_replStatusStatement2653 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_replStatusStatement2666 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_replStatusStatement2678 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_replConfigs_in_replStatusStatement2682 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createDatabaseStatement_in_ddlStatement2732 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_switchDatabaseStatement_in_ddlStatement2740 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropDatabaseStatement_in_ddlStatement2748 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createTableStatement_in_ddlStatement2756 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropTableStatement_in_ddlStatement2764 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_truncateTableStatement_in_ddlStatement2772 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatement_in_ddlStatement2780 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_descStatement_in_ddlStatement2788 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showStatement_in_ddlStatement2796 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_metastoreCheck_in_ddlStatement2804 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createViewStatement_in_ddlStatement2812 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createMaterializedViewStatement_in_ddlStatement2820 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropViewStatement_in_ddlStatement2828 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropMaterializedViewStatement_in_ddlStatement2836 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createFunctionStatement_in_ddlStatement2844 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createMacroStatement_in_ddlStatement2852 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropFunctionStatement_in_ddlStatement2860 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_reloadFunctionsStatement_in_ddlStatement2868 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropMacroStatement_in_ddlStatement2876 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_analyzeStatement_in_ddlStatement2884 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_lockStatement_in_ddlStatement2892 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_unlockStatement_in_ddlStatement2900 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_lockDatabase_in_ddlStatement2908 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_unlockDatabase_in_ddlStatement2916 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createRoleStatement_in_ddlStatement2924 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropRoleStatement_in_ddlStatement2932 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_grantPrivileges_in_ddlStatement2946 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_revokePrivileges_in_ddlStatement2960 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showGrants_in_ddlStatement2968 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showRoleGrants_in_ddlStatement2976 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showRolePrincipals_in_ddlStatement2984 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showRoles_in_ddlStatement2992 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_grantRole_in_ddlStatement3000 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_revokeRole_in_ddlStatement3008 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_setRole_in_ddlStatement3016 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showCurrentRole_in_ddlStatement3024 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_abortTransactionStatement_in_ddlStatement3032 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_killQueryStatement_in_ddlStatement3040 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_resourcePlanDdlStatements_in_ddlStatement3048 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_IF_in_ifExists3075 = new BitSet(new long[]{0x0000000000000000L,0x0800000000000000L});
	public static final BitSet FOLLOW_KW_EXISTS_in_ifExists3077 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RESTRICT_in_restrictOrCascade3114 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CASCADE_in_restrictOrCascade3132 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_IF_in_ifNotExists3169 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_KW_NOT_in_ifNotExists3171 = new BitSet(new long[]{0x0000000000000000L,0x0800000000000000L});
	public static final BitSet FOLLOW_KW_EXISTS_in_ifNotExists3173 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FORCE_in_force3210 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ENABLE_in_rewriteEnabled3247 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
	public static final BitSet FOLLOW_KW_REWRITE_in_rewriteEnabled3249 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DISABLE_in_rewriteDisabled3286 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
	public static final BitSet FOLLOW_KW_REWRITE_in_rewriteDisabled3288 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STORED_in_storedAsDirs3325 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_storedAsDirs3327 = new BitSet(new long[]{0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_DIRECTORIES_in_storedAsDirs3329 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_OR_in_orReplace3366 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000100L});
	public static final BitSet FOLLOW_KW_REPLACE_in_orReplace3368 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createDatabaseStatement3405 = new BitSet(new long[]{0x0000000000000000L,0x0000000000400000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_createDatabaseStatement3408 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_createDatabaseStatement3410 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_ifNotExists_in_createDatabaseStatement3421 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_createDatabaseStatement3434 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000010L,0x1000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_databaseComment_in_createDatabaseStatement3444 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_dbLocation_in_createDatabaseStatement3455 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_createDatabaseStatement3467 = new BitSet(new long[]{0x0000000000000000L,0x0000000008000000L});
	public static final BitSet FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement3469 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_dbProperties_in_createDatabaseStatement3473 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCATION_in_dbLocation3534 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_dbLocation3538 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_dbProperties3580 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_dbPropertiesList_in_dbProperties3582 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_dbProperties3584 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList3625 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_dbPropertiesList3628 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList3630 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_KW_USE_in_switchDatabaseStatement3669 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_switchDatabaseStatement3671 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropDatabaseStatement3710 = new BitSet(new long[]{0x0000000000000000L,0x0000000000400000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_dropDatabaseStatement3713 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_dropDatabaseStatement3715 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_ifExists_in_dropDatabaseStatement3718 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_dropDatabaseStatement3721 = new BitSet(new long[]{0x0080000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_restrictOrCascade_in_dropDatabaseStatement3723 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COMMENT_in_databaseComment3769 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_databaseComment3773 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createTableStatement3813 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000001L,0x0000000000000000L,0x0088000000000000L,0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TEMPORARY_in_createTableStatement3818 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000001L,0x0000000000000000L,0x0008000000000000L,0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TRANSACTIONAL_in_createTableStatement3825 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000001L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_EXTERNAL_in_createTableStatement3832 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_createTableStatement3836 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_ifNotExists_in_createTableStatement3838 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_createTableStatement3843 = new BitSet(new long[]{0x8000020000000002L,0x0000000000000010L,0x1080000000000000L,0x0000008000000000L,0x0040201000100000L,0x0001000000000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_createTableStatement3856 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_createTableStatement3860 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040200000100000L});
	public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement3871 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040200000000000L});
	public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement3883 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_tableLocation_in_createTableStatement3895 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement3907 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_createTableStatement3920 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA03BDBL,0xF747EE076308E0F0L,0x75EC7BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BDA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameTypeOrConstraintList_in_createTableStatement3922 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_createTableStatement3924 = new BitSet(new long[]{0x8000020000000002L,0x0000000000000010L,0x1000000000000000L,0x0000008000000000L,0x0040201000100000L});
	public static final BitSet FOLLOW_tableComment_in_createTableStatement3937 = new BitSet(new long[]{0x8000020000000002L,0x0000000000000000L,0x1000000000000000L,0x0000008000000000L,0x0040201000100000L});
	public static final BitSet FOLLOW_createTablePartitionSpec_in_createTableStatement3949 = new BitSet(new long[]{0x8000020000000002L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040201000100000L});
	public static final BitSet FOLLOW_tableBuckets_in_createTableStatement3961 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040201000100000L});
	public static final BitSet FOLLOW_tableSkewed_in_createTableStatement3973 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040200000100000L});
	public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement3985 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040200000000000L});
	public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement3997 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_tableLocation_in_createTableStatement4009 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement4021 = new BitSet(new long[]{0x0000020000000002L});
	public static final BitSet FOLLOW_KW_AS_in_createTableStatement4034 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000008L,0x0000000004000000L,0x0001004000000000L});
	public static final BitSet FOLLOW_selectStatementWithCTE_in_createTableStatement4036 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TRUNCATE_in_truncateTableStatement4247 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_truncateTableStatement4249 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tablePartitionPrefix_in_truncateTableStatement4251 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000008L,0x0000000000001000L});
	public static final BitSet FOLLOW_KW_COLUMNS_in_truncateTableStatement4254 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_truncateTableStatement4256 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_truncateTableStatement4258 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_truncateTableStatement4260 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_force_in_truncateTableStatement4264 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropTableStatement4305 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_dropTableStatement4307 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_ifExists_in_dropTableStatement4309 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_dropTableStatement4312 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000800L,0x0020000000000000L});
	public static final BitSet FOLLOW_KW_PURGE_in_dropTableStatement4314 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_replicationClause_in_dropTableStatement4317 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4366 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_alterStatement4368 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_alterStatement4370 = new BitSet(new long[]{0x8800008020000000L,0x0201000000000240L,0x0000008000000000L,0x0000004000080000L,0x8000001080000110L,0x0000000000050080L});
	public static final BitSet FOLLOW_alterTableStatementSuffix_in_alterStatement4372 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4390 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_alterStatement4392 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_alterStatement4394 = new BitSet(new long[]{0x0000020020000000L,0x0001000000000000L,0x0000000000000000L,0x8000000000000008L,0x0000000084000010L,0x0001004000010000L});
	public static final BitSet FOLLOW_KW_AS_in_alterStatement4396 = new BitSet(new long[]{0x0000000020000000L,0x0001000000000000L,0x0000000000000000L,0x8000000000000008L,0x0000000084000010L,0x0001004000010000L});
	public static final BitSet FOLLOW_alterViewStatementSuffix_in_alterStatement4399 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4417 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
	public static final BitSet FOLLOW_KW_MATERIALIZED_in_alterStatement4419 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_alterStatement4421 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_alterStatement4423 = new BitSet(new long[]{0x0000000000000000L,0x0010020000000000L,0x0000000000000000L,0x1000000000000000L});
	public static final BitSet FOLLOW_alterMaterializedViewStatementSuffix_in_alterStatement4425 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4447 = new BitSet(new long[]{0x0000000000000000L,0x0000000000400000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_alterStatement4450 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_alterStatement4452 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_alterDatabaseStatementSuffix_in_alterStatement4455 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix4493 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix4502 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix4511 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix4520 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix4528 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix4536 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix4544 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix4552 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix4560 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementPartitionKeyType_in_alterTableStatementSuffix4568 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixDropConstraint_in_alterTableStatementSuffix4576 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixAddConstraint_in_alterTableStatementSuffix4584 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_partitionSpec_in_alterTableStatementSuffix4592 = new BitSet(new long[]{0x8800000020000000L,0x0000000000000240L,0x0000008000000000L,0x0000000000080000L,0x0000000080000110L,0x0000000000040000L});
	public static final BitSet FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix4595 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixSetOwner_in_alterTableStatementSuffix4610 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix4635 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix4641 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix4647 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix4653 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix4659 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix4665 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix4671 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix4677 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixCompact_in_alterTblPartitionStatementSuffix4683 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTblPartitionStatementSuffix4689 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixUpdateStats_in_alterTblPartitionStatementSuffix4695 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixRenameCol_in_alterTblPartitionStatementSuffix4701 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixAddCol_in_alterTblPartitionStatementSuffix4707 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixUpdateColumns_in_alterTblPartitionStatementSuffix4713 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_PARTITION_in_alterStatementPartitionKeyType4735 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementPartitionKeyType4737 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_alterStatementPartitionKeyType4739 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameType_in_alterStatementPartitionKeyType4741 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_alterStatementPartitionKeyType4743 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix4776 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix4784 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix4793 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix4802 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_selectStatementWithCTE_in_alterViewStatementSuffix4811 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterMaterializedViewSuffixRewrite_in_alterMaterializedViewStatementSuffix4838 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterMaterializedViewSuffixRebuild_in_alterMaterializedViewStatementSuffix4846 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix4873 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterDatabaseSuffixSetOwner_in_alterDatabaseStatementSuffix4881 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterDatabaseSuffixSetLocation_in_alterDatabaseStatementSuffix4889 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixProperties4918 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixProperties4920 = new BitSet(new long[]{0x0000000000000000L,0x0000000008000000L});
	public static final BitSet FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties4922 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_dbProperties_in_alterDatabaseSuffixProperties4924 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixSetOwner4968 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixSetOwner4970 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_KW_OWNER_in_alterDatabaseSuffixSetOwner4972 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L,0x0000000000000000L,0x0000000000010000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalName_in_alterDatabaseSuffixSetOwner4974 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixSetLocation5018 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixSetLocation5020 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x1000000000000000L});
	public static final BitSet FOLLOW_KW_LOCATION_in_alterDatabaseSuffixSetLocation5022 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_alterDatabaseSuffixSetLocation5026 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRename5070 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRename5072 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_alterStatementSuffixRename5074 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddCol5141 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000008L});
	public static final BitSet FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol5147 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000008L});
	public static final BitSet FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol5150 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_alterStatementSuffixAddCol5152 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol5154 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_alterStatementSuffixAddCol5156 = new BitSet(new long[]{0x0080000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixAddCol5158 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddConstraint5234 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_alterForeignKeyWithName_in_alterStatementSuffixAddConstraint5239 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterConstraintWithName_in_alterStatementSuffixAddConstraint5243 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateColumns5308 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000008L});
	public static final BitSet FOLLOW_KW_COLUMNS_in_alterStatementSuffixUpdateColumns5310 = new BitSet(new long[]{0x0080000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixUpdateColumns5312 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_alterStatementSuffixDropConstraint5352 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterStatementSuffixDropConstraint5354 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementSuffixDropConstraint5358 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol5395 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DFL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol5397 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol5402 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol5406 = new BitSet(new long[]{0x1003810000000000L,0x0000400023000000L,0x0000001000000100L,0x0000000000000008L,0x3801802000000000L,0x0000000010000800L});
	public static final BitSet FOLLOW_colType_in_alterStatementSuffixRenameCol5408 = new BitSet(new long[]{0x2080000080000002L,0x0000000040000810L,0x0000000000000080L,0x0004000000080000L,0x0000000000000801L,0x0000000000001000L});
	public static final BitSet FOLLOW_alterColumnConstraint_in_alterStatementSuffixRenameCol5410 = new BitSet(new long[]{0x0080000080000002L,0x0000000000000010L,0x0000000000000080L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol5415 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol5419 = new BitSet(new long[]{0x0080000080000002L,0x0000000000000000L,0x0000000000000080L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol5423 = new BitSet(new long[]{0x0080000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixRenameCol5426 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStatsCol5484 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000080000000000L});
	public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStatsCol5486 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_KW_FOR_in_alterStatementSuffixUpdateStatsCol5488 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DFL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixUpdateStatsCol5490 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementSuffixUpdateStatsCol5495 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixUpdateStatsCol5497 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixUpdateStatsCol5499 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixUpdateStatsCol5502 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixUpdateStatsCol5506 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStats5553 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000080000000000L});
	public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStats5555 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixUpdateStats5557 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixUpdateStats5559 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FIRST_in_alterStatementChangeColPosition5589 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_AFTER_in_alterStatementChangeColPosition5591 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementChangeColPosition5595 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions5648 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions5650 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions5653 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement5716 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x1000000000000000L});
	public static final BitSet FOLLOW_partitionLocation_in_alterStatementSuffixAddPartitionsElement5718 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch5746 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixTouch5749 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive5793 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixArchive5796 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive5840 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive5843 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_LOCATION_in_partitionLocation5893 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_partitionLocation5897 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions5934 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixDropPartitions5936 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5939 = new BitSet(new long[]{0x0000000000000202L,0x0000000000000000L,0x0000000000000800L,0x0020000000000000L});
	public static final BitSet FOLLOW_COMMA_in_alterStatementSuffixDropPartitions5942 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5944 = new BitSet(new long[]{0x0000000000000202L,0x0000000000000000L,0x0000000000000800L,0x0020000000000000L});
	public static final BitSet FOLLOW_KW_PURGE_in_alterStatementSuffixDropPartitions5948 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_replicationClause_in_alterStatementSuffixDropPartitions5951 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixProperties6033 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties6035 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties6037 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNSET_in_alterStatementSuffixProperties6057 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties6059 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixProperties6061 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties6064 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterViewSuffixProperties6106 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties6108 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties6110 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNSET_in_alterViewSuffixProperties6130 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties6132 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_ifExists_in_alterViewSuffixProperties6134 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties6137 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rewriteEnabled_in_alterMaterializedViewSuffixRewrite6182 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rewriteDisabled_in_alterMaterializedViewSuffixRewrite6188 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REBUILD_in_alterMaterializedViewSuffixRebuild6229 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties6262 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties6264 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties6268 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties6271 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
	public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties6273 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties6275 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties6301 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
	public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties6303 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties6305 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableName_in_tablePartitionPrefix6342 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_tablePartitionPrefix6344 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixFileFormat6379 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
	public static final BitSet FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat6381 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_fileFormat_in_alterStatementSuffixFileFormat6383 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6414 = new BitSet(new long[]{0x8000000000000000L});
	public static final BitSet FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby6416 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6430 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby6432 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby6446 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation6477 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
	public static final BitSet FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation6479 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x1000000000000000L});
	public static final BitSet FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation6481 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation6483 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_skewedLocations6526 = new BitSet(new long[]{0x0000000002001000L,0x00000000010C0000L,0x0000000000000004L,0x0000000000200000L,0x1800000000000000L,0x00C1000000000020L,0x0000000000000004L});
	public static final BitSet FOLLOW_skewedLocationsList_in_skewedLocations6528 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_skewedLocations6530 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList6571 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_skewedLocationsList6574 = new BitSet(new long[]{0x0000000002001000L,0x00000000010C0000L,0x0000000000000004L,0x0000000000200000L,0x1800000000000000L,0x00C1000000000020L,0x0000000000000004L});
	public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList6576 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_skewedValueLocationElement_in_skewedLocationMap6622 = new BitSet(new long[]{0x0000000000040000L});
	public static final BitSet FOLLOW_EQUAL_in_skewedLocationMap6624 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_skewedLocationMap6628 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixLocation6665 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x1000000000000000L});
	public static final BitSet FOLLOW_KW_LOCATION_in_alterStatementSuffixLocation6667 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixLocation6671 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby6705 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby6720 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
	public static final BitSet FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby6722 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby6735 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby6737 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition6768 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition6770 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition6772 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition6774 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_alterStatementSuffixExchangePartition6778 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart6820 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRenamePart6822 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart6824 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixStatsPart6862 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000080000000000L});
	public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixStatsPart6864 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_KW_FOR_in_alterStatementSuffixStatsPart6866 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DFL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixStatsPart6868 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementSuffixStatsPart6873 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixStatsPart6875 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixStatsPart6877 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixStatsPart6880 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixStatsPart6884 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles6931 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum6968 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_alterStatementSuffixBucketNum6972 = new BitSet(new long[]{0x0010000000000000L});
	public static final BitSet FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum6974 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_AND_in_blocking7002 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000100000000L});
	public static final BitSet FOLLOW_KW_WAIT_in_blocking7004 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COMPACT_in_alterStatementSuffixCompact7035 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixCompact7039 = new BitSet(new long[]{0x0000001000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_blocking_in_alterStatementSuffixCompact7041 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixCompact7045 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
	public static final BitSet FOLLOW_KW_OVERWRITE_in_alterStatementSuffixCompact7047 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixCompact7049 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixCompact7051 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSetOwner7099 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_KW_OWNER_in_alterStatementSuffixSetOwner7101 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L,0x0000000000000000L,0x0000000000010000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalName_in_alterStatementSuffixSetOwner7103 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INPUTFORMAT_in_fileFormat7142 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_fileFormat7146 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_fileFormat7148 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_fileFormat7152 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_SERDE_in_fileFormat7154 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_fileFormat7158 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000200000000L});
	public static final BitSet FOLLOW_KW_INPUTDRIVER_in_fileFormat7161 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_fileFormat7165 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000200000000L});
	public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_fileFormat7167 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_fileFormat7171 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_fileFormat7212 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INPUTFORMAT_in_inputFileFormat7248 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_inputFileFormat7252 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_SERDE_in_inputFileFormat7254 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_inputFileFormat7258 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_tabTypeExpr7302 = new BitSet(new long[]{0xECD8348AFD010002L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_DOT_in_tabTypeExpr7305 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_tabTypeExpr7308 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_tabTypeExpr7316 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_DOT_in_tabTypeExpr7319 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr7336 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_KW_KEY_TYPE_in_tabTypeExpr7353 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr7370 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_identifier_in_tabTypeExpr7378 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_tabTypeExpr_in_partTypeExpr7418 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_partTypeExpr7420 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableName_in_tabPartColTypeExpr7460 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BF61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_partitionSpec_in_tabPartColTypeExpr7462 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_extColumnName_in_tabPartColTypeExpr7465 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement7512 = new BitSet(new long[]{0xECD8348AFD000000L,0xF4D6BBDDDEE033DBL,0xF747EE07630CC0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_DESC_in_descStatement7514 = new BitSet(new long[]{0xECD8348AFD000000L,0xF4D6BBDDDEE033DBL,0xF747EE07630CC0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_descStatement7536 = new BitSet(new long[]{0xECD8348AFD000000L,0xF4D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_descStatement7538 = new BitSet(new long[]{0xECD8348AFD000000L,0xF4D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement7541 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_descStatement7547 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FUNCTION_in_descStatement7578 = new BitSet(new long[]{0xEDDBF59AFD6C6070L,0xF4D6FBDDDEA033DBL,0xF7C7EE177708C3F0L,0x75E87BB6395EDAFDL,0xA1D3FBFF7BC3AFFEL,0x01386F97EB9BCA87L,0x000001000000000EL,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement7580 = new BitSet(new long[]{0xEDDBF59AFD6C6070L,0x74D6FBDDDEA033DBL,0xF7C7EE177708C3F0L,0x75E87BB6395EDAFDL,0xA1D3FBFF7BC3AFFEL,0x01386F97EB9BCA87L,0x000001000000000EL,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_descFuncNames_in_descStatement7586 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FORMATTED_in_descStatement7623 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement7627 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tabPartColTypeExpr_in_descStatement7632 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tabPartColTypeExpr_in_descStatement7659 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ANALYZE_in_analyzeStatement7701 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_analyzeStatement7703 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableOrPartition_in_analyzeStatement7708 = new BitSet(new long[]{0x0040000000000000L,0x0000000000000100L});
	public static final BitSet FOLLOW_KW_COMPUTE_in_analyzeStatement7731 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000080000000000L});
	public static final BitSet FOLLOW_KW_STATISTICS_in_analyzeStatement7733 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000800L,0x0000000000040000L});
	public static final BitSet FOLLOW_KW_NOSCAN_in_analyzeStatement7739 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FOR_in_analyzeStatement7799 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000008L});
	public static final BitSet FOLLOW_KW_COLUMNS_in_analyzeStatement7801 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_analyzeStatement7806 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CACHE_in_analyzeStatement7859 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_KW_METADATA_in_analyzeStatement7861 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement7905 = new BitSet(new long[]{0x0000000000000000L,0x0000000000800000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
	public static final BitSet FOLLOW_KW_DATABASES_in_showStatement7908 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_SCHEMAS_in_showStatement7910 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement7914 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement7916 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement7935 = new BitSet(new long[]{0x0000000000000000L,0x8000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement7940 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
	public static final BitSet FOLLOW_KW_TABLES_in_showStatement7944 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF7C7EE077309C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F9BEB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement7948 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement7950 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_showStatement7955 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF7C7EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F9BEB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_showTablesFilterExpr_in_showStatement7962 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement7998 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_VIEWS_in_showStatement8000 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF7C7EE077309C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8004 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8006 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8011 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF7C7EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8016 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8018 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8020 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8048 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
	public static final BitSet FOLLOW_KW_MATERIALIZED_in_showStatement8050 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_VIEWS_in_showStatement8052 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF7C7EE077309C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8056 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8058 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8063 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF7C7EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8068 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8070 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8072 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8100 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000008L});
	public static final BitSet FOLLOW_KW_COLUMNS_in_showStatement8102 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000010010000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8105 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8107 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_showStatement8110 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF7C7EE077309C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8114 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8116 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8121 = new BitSet(new long[]{0xECD8348AFD000002L,0x74D6BBDDDEA033DBL,0xF7C7EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8126 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8128 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8130 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8163 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_KW_FUNCTIONS_in_showStatement8165 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8168 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_showFunctionIdentifier_in_showStatement8170 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8193 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_KW_PARTITIONS_in_showStatement8195 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_showStatement8199 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_showStatement8201 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8223 = new BitSet(new long[]{0x0000000000000000L,0x0000000000004000L});
	public static final BitSet FOLLOW_KW_CREATE_in_showStatement8225 = new BitSet(new long[]{0x0000000000000000L,0x0000000000400000L,0x0000000000000000L,0x0000000000000000L,0x0008000000800000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_showStatement8246 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_showStatement8248 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8253 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TABLE_in_showStatement8282 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_showStatement8286 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8311 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_showStatement8313 = new BitSet(new long[]{0x0000000000000000L,0x8000000000000000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement8315 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0080000010010000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8319 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8321 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8326 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8330 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8332 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_showStatement8334 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8362 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_showStatement8364 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_showStatement8366 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_showStatement8369 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_showStatement8373 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_showStatement8375 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8397 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_KW_LOCKS_in_showStatement8399 = new BitSet(new long[]{0xECD8348AFD000002L,0xF4D6BBDDDEE033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_showStatement8425 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_showStatement8427 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8433 = new BitSet(new long[]{0x0000000000000002L,0x8000000000000000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement8439 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_partTypeExpr_in_showStatement8473 = new BitSet(new long[]{0x0000000000000002L,0x8000000000000000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement8480 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8512 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000080L});
	public static final BitSet FOLLOW_KW_COMPACTIONS_in_showStatement8514 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8528 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_KW_TRANSACTIONS_in_showStatement8530 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8544 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000400L});
	public static final BitSet FOLLOW_KW_CONF_in_showStatement8546 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_showStatement8548 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8564 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
	public static final BitSet FOLLOW_KW_RESOURCE_in_showStatement8566 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000180000000000L});
	public static final BitSet FOLLOW_KW_PLAN_in_showStatement8585 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8589 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_PLANS_in_showStatement8612 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WHERE_in_showTablesFilterExpr8654 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_showTablesFilterExpr8656 = new BitSet(new long[]{0x0000000000040000L});
	public static final BitSet FOLLOW_EQUAL_in_showTablesFilterExpr8658 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_showTablesFilterExpr8660 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LIKE_in_showTablesFilterExpr8682 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showTablesFilterExpr8684 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showTablesFilterExpr8686 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCK_in_lockStatement8721 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_lockStatement8723 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_lockStatement8725 = new BitSet(new long[]{0x0000000000000000L,0x0400000000000000L,0x0000000000000000L,0x0000004000000000L,0x0000000200000000L});
	public static final BitSet FOLLOW_partitionSpec_in_lockStatement8727 = new BitSet(new long[]{0x0000000000000000L,0x0400000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000200000000L});
	public static final BitSet FOLLOW_lockMode_in_lockStatement8730 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCK_in_lockDatabase8770 = new BitSet(new long[]{0x0000000000000000L,0x0000000000400000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_lockDatabase8773 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_lockDatabase8775 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_lockDatabase8781 = new BitSet(new long[]{0x0000000000000000L,0x0400000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000200000000L});
	public static final BitSet FOLLOW_lockMode_in_lockDatabase8784 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNLOCK_in_unlockStatement8853 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_unlockStatement8855 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_unlockStatement8857 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_unlockStatement8859 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNLOCK_in_unlockDatabase8899 = new BitSet(new long[]{0x0000000000000000L,0x0000000000400000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_unlockDatabase8902 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_unlockDatabase8904 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_unlockDatabase8910 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createRoleStatement8947 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_ROLE_in_createRoleStatement8949 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_createRoleStatement8953 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropRoleStatement8993 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_ROLE_in_dropRoleStatement8995 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_dropRoleStatement8999 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_GRANT_in_grantPrivileges9039 = new BitSet(new long[]{0x0000000500000000L,0x0001000200004000L,0x2000000800000000L,0x0000000000000000L,0x0000000804000000L,0x0000000000040000L});
	public static final BitSet FOLLOW_privilegeList_in_grantPrivileges9043 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_privilegeObject_in_grantPrivileges9051 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_KW_TO_in_grantPrivileges9060 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L,0x0000000000000000L,0x0000000000010000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalSpecification_in_grantPrivileges9062 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_withGrantOption_in_grantPrivileges9070 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REVOKE_in_revokePrivileges9119 = new BitSet(new long[]{0x0000000500000000L,0x0001000200004000L,0x2000000800100000L,0x0000000000000000L,0x0000000804000000L,0x0000000000040000L});
	public static final BitSet FOLLOW_grantOptionFor_in_revokePrivileges9121 = new BitSet(new long[]{0x0000000500000000L,0x0001000200004000L,0x2000000800000000L,0x0000000000000000L,0x0000000804000000L,0x0000000000040000L});
	public static final BitSet FOLLOW_privilegeList_in_revokePrivileges9124 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L,0x0000000002000000L});
	public static final BitSet FOLLOW_privilegeObject_in_revokePrivileges9126 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_FROM_in_revokePrivileges9129 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L,0x0000000000000000L,0x0000000000010000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalSpecification_in_revokePrivileges9131 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_GRANT_in_grantRole9178 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_ROLE_in_grantRole9180 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_grantRole9183 = new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_COMMA_in_grantRole9186 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_grantRole9188 = new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_KW_TO_in_grantRole9192 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L,0x0000000000000000L,0x0000000000010000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalSpecification_in_grantRole9194 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_withAdminOption_in_grantRole9196 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REVOKE_in_revokeRole9242 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_adminOptionFor_in_revokeRole9244 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_ROLE_in_revokeRole9247 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_revokeRole9250 = new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_COMMA_in_revokeRole9253 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_revokeRole9255 = new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_FROM_in_revokeRole9259 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L,0x0000000000000000L,0x0000000000010000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalSpecification_in_revokeRole9261 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showRoleGrants9306 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_ROLE_in_showRoleGrants9308 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
	public static final BitSet FOLLOW_KW_GRANT_in_showRoleGrants9310 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L,0x0000000000000000L,0x0000000000010000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalName_in_showRoleGrants9312 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showRoles9352 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_KW_ROLES_in_showRoles9354 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showCurrentRole9391 = new BitSet(new long[]{0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_KW_CURRENT_in_showCurrentRole9393 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_KW_ROLES_in_showCurrentRole9395 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_setRole9432 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_ROLE_in_setRole9434 = new BitSet(new long[]{0xECD8348BFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61957DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_ALL_in_setRole9456 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NONE_in_setRole9487 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_setRole9509 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showGrants9550 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
	public static final BitSet FOLLOW_KW_GRANT_in_showGrants9552 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000200000L,0x0000000002000000L,0x0000000000010000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalName_in_showGrants9554 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_ON_in_showGrants9558 = new BitSet(new long[]{0xECD8348BFD000000L,0x74D6BBDDDEE033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1DBFBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_privilegeIncludeColObject_in_showGrants9560 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showRolePrincipals9605 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_PRINCIPALS_in_showRolePrincipals9607 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_showRolePrincipals9611 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALL_in_privilegeIncludeColObject9658 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_privObjectCols_in_privilegeIncludeColObject9672 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ON_in_privilegeObject9707 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEE033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1DBFBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_privObject_in_privilegeObject9709 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DATABASE_in_privObject9736 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_privObject9738 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_privObject9741 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TABLE_in_privObject9757 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_privObject9760 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_privObject9762 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_URI_in_privObject9782 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_privObject9787 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SERVER_in_privObject9806 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_privObject9808 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DATABASE_in_privObjectCols9834 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_privObjectCols9836 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_privObjectCols9839 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TABLE_in_privObjectCols9855 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_privObjectCols9858 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_privObjectCols9861 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_privObjectCols9865 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_privObjectCols9867 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_privObjectCols9871 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_URI_in_privObjectCols9895 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_privObjectCols9900 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SERVER_in_privObjectCols9919 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_privObjectCols9921 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_privlegeDef_in_privilegeList9956 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_privilegeList9959 = new BitSet(new long[]{0x0000000500000000L,0x0001000200004000L,0x2000000800000000L,0x0000000000000000L,0x0000000804000000L,0x0000000000040000L});
	public static final BitSet FOLLOW_privlegeDef_in_privilegeList9961 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_privilegeType_in_privlegeDef10003 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_privlegeDef10006 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_privlegeDef10010 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_privlegeDef10012 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALL_in_privilegeType10057 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_privilegeType10071 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_privilegeType10085 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_privilegeType10099 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_privilegeType10113 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCK_in_privilegeType10127 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SELECT_in_privilegeType10141 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_DATABASE_in_privilegeType10155 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INSERT_in_privilegeType10169 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DELETE_in_privilegeType10183 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_principalName_in_principalSpecification10216 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_principalSpecification10219 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L,0x0000000000000000L,0x0000000000010000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalName_in_principalSpecification10221 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_KW_USER_in_principalName10259 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x08000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalIdentifier_in_principalName10261 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_GROUP_in_principalName10277 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x08000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_principalIdentifier_in_principalName10279 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ROLE_in_principalName10295 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_principalName10297 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WITH_in_withGrantOption10332 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
	public static final BitSet FOLLOW_KW_GRANT_in_withGrantOption10334 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_OPTION_in_withGrantOption10336 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_GRANT_in_grantOptionFor10373 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_OPTION_in_grantOptionFor10375 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_KW_FOR_in_grantOptionFor10377 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ADMIN_in_adminOptionFor10410 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_OPTION_in_adminOptionFor10412 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_KW_FOR_in_adminOptionFor10414 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WITH_in_withAdminOption10447 = new BitSet(new long[]{0x0000000040000000L});
	public static final BitSet FOLLOW_KW_ADMIN_in_withAdminOption10449 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_OPTION_in_withAdminOption10451 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MSCK_in_metastoreCheck10488 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L,0x0008000000000040L});
	public static final BitSet FOLLOW_KW_REPAIR_in_metastoreCheck10493 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_metastoreCheck10504 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_metastoreCheck10506 = new BitSet(new long[]{0x0000000020000002L,0x0001000000000000L,0x0000000000000000L,0x0000000000000000L,0x0004000000000000L});
	public static final BitSet FOLLOW_KW_ADD_in_metastoreCheck10520 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_KW_DROP_in_metastoreCheck10526 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_KW_SYNC_in_metastoreCheck10532 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_KW_PARTITIONS_in_metastoreCheck10538 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_partitionSpec_in_metastoreCheck10554 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_resource_in_resourceList10619 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_resourceList10622 = new BitSet(new long[]{0x0000008000000000L,0x0000000000000000L,0x0000080000000020L});
	public static final BitSet FOLLOW_resource_in_resourceList10624 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_resourceType_in_resource10662 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_resource10666 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_JAR_in_resourceType10703 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FILE_in_resourceType10717 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ARCHIVE_in_resourceType10731 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createFunctionStatement10762 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000040000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_TEMPORARY_in_createFunctionStatement10767 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
	public static final BitSet FOLLOW_KW_FUNCTION_in_createFunctionStatement10771 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_functionIdentifier_in_createFunctionStatement10773 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_createFunctionStatement10775 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_createFunctionStatement10777 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
	public static final BitSet FOLLOW_KW_USING_in_createFunctionStatement10786 = new BitSet(new long[]{0x0000008000000000L,0x0000000000000000L,0x0000080000000020L});
	public static final BitSet FOLLOW_resourceList_in_createFunctionStatement10790 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropFunctionStatement10876 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000040000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_TEMPORARY_in_dropFunctionStatement10881 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
	public static final BitSet FOLLOW_KW_FUNCTION_in_dropFunctionStatement10885 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_ifExists_in_dropFunctionStatement10887 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_functionIdentifier_in_dropFunctionStatement10890 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RELOAD_in_reloadFunctionsStatement10968 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x00000000000C0000L});
	public static final BitSet FOLLOW_KW_FUNCTIONS_in_reloadFunctionsStatement10971 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FUNCTION_in_reloadFunctionsStatement10973 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createMacroStatement11002 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_TEMPORARY_in_createMacroStatement11004 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MACRO_in_createMacroStatement11006 = new BitSet(new long[]{0x0000000001000000L});
	public static final BitSet FOLLOW_Identifier_in_createMacroStatement11008 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_createMacroStatement11016 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x20000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameTypeList_in_createMacroStatement11018 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_createMacroStatement11021 = new BitSet(new long[]{0xEFDBB58AFF001000L,0x7CD6FBDDDFAC33DBL,0xF747EE576748C3F6L,0x75E87BB6197EDAFDL,0xB9D3FBFF7BC32FFCL,0x01C90F93EB9BCAA7L,0x000001000000000CL,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_expression_in_createMacroStatement11023 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropMacroStatement11067 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_TEMPORARY_in_dropMacroStatement11069 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MACRO_in_dropMacroStatement11071 = new BitSet(new long[]{0x0000000001000000L,0x0000000000000000L,0x0000000004000000L});
	public static final BitSet FOLLOW_ifExists_in_dropMacroStatement11073 = new BitSet(new long[]{0x0000000001000000L});
	public static final BitSet FOLLOW_Identifier_in_dropMacroStatement11076 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createViewStatement11118 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_orReplace_in_createViewStatement11121 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_createViewStatement11125 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_ifNotExists_in_createViewStatement11128 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_createViewStatement11134 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000010L,0x0000000000000000L,0x0000008000000000L,0x0040000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_createViewStatement11145 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameCommentList_in_createViewStatement11147 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_createViewStatement11149 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000010L,0x0000000000000000L,0x0000008000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_tableComment_in_createViewStatement11153 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_viewPartition_in_createViewStatement11156 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createViewStatement11167 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_createViewStatement11178 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000008L,0x0000000004000000L,0x0001004000000000L});
	public static final BitSet FOLLOW_selectStatementWithCTE_in_createViewStatement11188 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_PARTITIONED_in_viewPartition11311 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_ON_in_viewPartition11313 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_viewPartition11315 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_viewPartition11317 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_viewPartition11319 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_viewClusterSpec_in_viewOrganization11358 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_viewComplexSpec_in_viewOrganization11366 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CLUSTERED_in_viewClusterSpec11393 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_ON_in_viewClusterSpec11395 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_viewClusterSpec11397 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_viewClusterSpec11399 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_viewClusterSpec11401 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_viewDistSpec_in_viewComplexSpec11440 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_viewSortSpec_in_viewComplexSpec11442 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DISTRIBUTED_in_viewDistSpec11469 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_ON_in_viewDistSpec11471 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_viewDistSpec11473 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_viewDistSpec11477 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_viewDistSpec11479 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SORTED_in_viewSortSpec11519 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_ON_in_viewSortSpec11521 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_viewSortSpec11523 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_viewSortSpec11527 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_viewSortSpec11529 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropViewStatement11569 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_dropViewStatement11571 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_ifExists_in_dropViewStatement11573 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_viewName_in_dropViewStatement11576 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createMaterializedViewStatement11614 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
	public static final BitSet FOLLOW_KW_MATERIALIZED_in_createMaterializedViewStatement11616 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_createMaterializedViewStatement11618 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_ifNotExists_in_createMaterializedViewStatement11621 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_createMaterializedViewStatement11627 = new BitSet(new long[]{0x8000020000000000L,0x0000120000000010L,0x1000000000000000L,0x0000008000000000L,0x0040200000100000L});
	public static final BitSet FOLLOW_rewriteDisabled_in_createMaterializedViewStatement11637 = new BitSet(new long[]{0x8000020000000000L,0x0000100000000010L,0x1000000000000000L,0x0000008000000000L,0x0040200000100000L});
	public static final BitSet FOLLOW_tableComment_in_createMaterializedViewStatement11640 = new BitSet(new long[]{0x8000020000000000L,0x0000100000000000L,0x1000000000000000L,0x0000008000000000L,0x0040200000100000L});
	public static final BitSet FOLLOW_viewPartition_in_createMaterializedViewStatement11643 = new BitSet(new long[]{0x8000020000000000L,0x0000100000000000L,0x1000000000000000L,0x0000000000000000L,0x0040200000100000L});
	public static final BitSet FOLLOW_viewOrganization_in_createMaterializedViewStatement11646 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040200000100000L});
	public static final BitSet FOLLOW_tableRowFormat_in_createMaterializedViewStatement11657 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040200000000000L});
	public static final BitSet FOLLOW_tableFileFormat_in_createMaterializedViewStatement11660 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x1000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_tableLocation_in_createMaterializedViewStatement11663 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createMaterializedViewStatement11674 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_createMaterializedViewStatement11677 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000008L,0x0000000004000000L,0x0001004000000000L});
	public static final BitSet FOLLOW_selectStatementWithCTE_in_createMaterializedViewStatement11679 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropMaterializedViewStatement11847 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
	public static final BitSet FOLLOW_KW_MATERIALIZED_in_dropMaterializedViewStatement11849 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_dropMaterializedViewStatement11851 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076708C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_ifExists_in_dropMaterializedViewStatement11853 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_viewName_in_dropMaterializedViewStatement11856 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_functionIdentifier_in_showFunctionIdentifier11894 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_StringLiteral_in_showFunctionIdentifier11902 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_showStmtIdentifier11929 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_StringLiteral_in_showStmtIdentifier11937 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COMMENT_in_tableComment11970 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableComment11974 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_PARTITIONED_in_createTablePartitionSpec12011 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_createTablePartitionSpec12013 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_createTablePartitionSpec12015 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_createTablePartitionColumnTypeSpec_in_createTablePartitionSpec12022 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_createTablePartitionColumnSpec_in_createTablePartitionSpec12030 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_createTablePartitionSpec12033 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec12080 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_createTablePartitionColumnTypeSpec12083 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec12085 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_columnName_in_createTablePartitionColumnSpec12127 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_createTablePartitionColumnSpec12130 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnName_in_createTablePartitionColumnSpec12132 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_KW_CLUSTERED_in_tableBuckets12180 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableBuckets12182 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_tableBuckets12184 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_tableBuckets12188 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_tableBuckets12190 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_KW_SORTED_in_tableBuckets12193 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableBuckets12195 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_tableBuckets12197 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameOrderList_in_tableBuckets12201 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_tableBuckets12203 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_INTO_in_tableBuckets12207 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_tableBuckets12211 = new BitSet(new long[]{0x0010000000000000L});
	public static final BitSet FOLLOW_KW_BUCKETS_in_tableBuckets12213 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SKEWED_in_tableSkewed12265 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableSkewed12267 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_tableSkewed12269 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_tableSkewed12273 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_tableSkewed12275 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_ON_in_tableSkewed12277 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_tableSkewed12279 = new BitSet(new long[]{0x0000000002001000L,0x00000000010C0000L,0x0000000000000004L,0x0000000000200000L,0x1800000000000000L,0x00C1000000000020L,0x0000000000000004L});
	public static final BitSet FOLLOW_skewedValueElement_in_tableSkewed12284 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_tableSkewed12287 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_storedAsDirs_in_tableSkewed12296 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rowFormatSerde_in_rowFormat12344 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rowFormatDelimited_in_rowFormat12360 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RECORDREADER_in_recordReader12409 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_recordReader12411 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RECORDWRITER_in_recordWriter12460 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_recordWriter12462 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ROW_in_rowFormatSerde12511 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
	public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatSerde12513 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_SERDE_in_rowFormatSerde12515 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_rowFormatSerde12519 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_rowFormatSerde12522 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
	public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde12524 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_rowFormatSerde12528 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ROW_in_rowFormatDelimited12580 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
	public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatDelimited12582 = new BitSet(new long[]{0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_KW_DELIMITED_in_rowFormatDelimited12584 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000002L,0x0200000000000010L,0x0000000000200008L});
	public static final BitSet FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited12586 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000002L,0x0200000000000000L,0x0000000000200008L});
	public static final BitSet FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited12589 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0200000000000000L,0x0000000000200008L});
	public static final BitSet FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited12592 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0200000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited12595 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableRowNullFormat_in_rowFormatDelimited12598 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rowFormatDelimited_in_tableRowFormat12657 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rowFormatSerde_in_tableRowFormat12677 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed12724 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_tablePropertiesPrefixed12727 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_tableProperties12760 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_tablePropertiesList_in_tableProperties12762 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_tableProperties12764 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList12805 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_tablePropertiesList12808 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList12810 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList12835 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_tablePropertiesList12838 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList12840 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty12886 = new BitSet(new long[]{0x0000000000040000L});
	public static final BitSet FOLLOW_EQUAL_in_keyValueProperty12888 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty12892 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_StringLiteral_in_keyProperty12939 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier12983 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L});
	public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier12985 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier12987 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier12991 = new BitSet(new long[]{0x0000000000000002L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier12994 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier12996 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier13000 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier13052 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000040000000000L});
	public static final BitSet FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier13054 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L});
	public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier13056 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier13058 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier13062 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier13108 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000800000000000L});
	public static final BitSet FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier13110 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L});
	public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier13112 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier13114 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier13118 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier13164 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L});
	public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier13166 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier13168 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier13172 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NULL_in_tableRowNullFormat13218 = new BitSet(new long[]{0x0000000000000000L,0x0000000100000000L});
	public static final BitSet FOLLOW_KW_DEFINED_in_tableRowNullFormat13220 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_tableRowNullFormat13222 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowNullFormat13226 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat13281 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_tableFileFormat13283 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_KW_INPUTFORMAT_in_tableFileFormat13285 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat13289 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat13291 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat13295 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000200000000L});
	public static final BitSet FOLLOW_KW_INPUTDRIVER_in_tableFileFormat13298 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat13302 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000200000000L});
	public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat13304 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat13308 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat13346 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableFileFormat13348 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat13352 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_tableFileFormat13364 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
	public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat13366 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_tableFileFormat13370 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat13401 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_tableFileFormat13403 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_tableFileFormat13407 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCATION_in_tableLocation13455 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_tableLocation13459 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList13495 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameTypeList13498 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList13500 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList13538 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameTypeOrConstraintList13541 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA03BDBL,0xF747EE076308E0F0L,0x75EC7BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BDA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList13543 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList13581 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameColonTypeList13584 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList13586 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_columnName_in_columnNameList13624 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameList13627 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnName_in_columnNameList13629 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_identifier_in_columnName13673 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_extColumnName13706 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_DOT_in_extColumnName13709 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_ELEM_TYPE_in_extColumnName13719 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_KW_KEY_TYPE_in_extColumnName13729 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_KW_VALUE_TYPE_in_extColumnName13739 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_identifier_in_extColumnName13743 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList13773 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameOrderList13776 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList13778 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_LPAREN_in_columnParenthesesList13816 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_columnParenthesesList13819 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_columnParenthesesList13821 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_enableSpecification_in_enableValidateSpecification13849 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_validateSpecification_in_enableValidateSpecification13851 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_enforcedSpecification_in_enableValidateSpecification13860 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ENABLE_in_enableSpecification13887 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DISABLE_in_enableSpecification13901 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_VALIDATE_in_validateSpecification13934 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOVALIDATE_in_validateSpecification13948 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ENFORCED_in_enforcedSpecification13981 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_enforcedSpecification13995 = new BitSet(new long[]{0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_KW_ENFORCED_in_enforcedSpecification13997 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RELY_in_relySpecification14031 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NORELY_in_relySpecification14046 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_createConstraint14080 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_createConstraint14084 = new BitSet(new long[]{0x2000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0004000000000000L,0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_tableLevelConstraint_in_createConstraint14088 = new BitSet(new long[]{0x0000000000000002L,0x0050020000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_constraintOptsCreate_in_createConstraint14090 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterConstraintWithName14165 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_alterConstraintWithName14169 = new BitSet(new long[]{0x2000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0004000000000000L,0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_tableLevelConstraint_in_alterConstraintWithName14171 = new BitSet(new long[]{0x0000000000000002L,0x0050020000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_constraintOptsAlter_in_alterConstraintWithName14173 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_pkUkConstraint_in_tableLevelConstraint14210 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_checkConstraint_in_tableLevelConstraint14218 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableConstraintType_in_pkUkConstraint14245 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_pkUkConstraint14249 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CHECK_in_checkConstraint14289 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_checkConstraint14291 = new BitSet(new long[]{0xEFDBB58AFF001000L,0x7CD6FBDDDFAC33DBL,0xF747EE576748C3F6L,0x75E87BB6197EDAFDL,0xB9D3FBFF7BC32FFCL,0x01C90F93EB9BCAA7L,0x000001000000000CL,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_expression_in_checkConstraint14293 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_checkConstraint14295 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_createForeignKey14335 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_createForeignKey14339 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
	public static final BitSet FOLLOW_KW_FOREIGN_in_createForeignKey14343 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_KW_KEY_in_createForeignKey14345 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_createForeignKey14349 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_REFERENCES_in_createForeignKey14352 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_createForeignKey14356 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_createForeignKey14360 = new BitSet(new long[]{0x0000000000000002L,0x0050020000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_constraintOptsCreate_in_createForeignKey14362 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterForeignKeyWithName14455 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_alterForeignKeyWithName14459 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
	public static final BitSet FOLLOW_KW_FOREIGN_in_alterForeignKeyWithName14461 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_KW_KEY_in_alterForeignKeyWithName14463 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_alterForeignKeyWithName14467 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_REFERENCES_in_alterForeignKeyWithName14470 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_alterForeignKeyWithName14474 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_alterForeignKeyWithName14478 = new BitSet(new long[]{0x0000000000000002L,0x0050020000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_constraintOptsAlter_in_alterForeignKeyWithName14480 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValues_in_skewedValueElement14544 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValuePairList_in_skewedValueElement14553 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList14580 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_skewedColumnValuePairList14583 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList14585 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_LPAREN_in_skewedColumnValuePair14630 = new BitSet(new long[]{0x0000000002001000L,0x00000000010C0000L,0x0000000000000004L,0x0000000000200000L,0x1800000000000000L,0x00C0000000000020L,0x0000000000000004L});
	public static final BitSet FOLLOW_skewedColumnValues_in_skewedColumnValuePair14634 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_skewedColumnValuePair14636 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues14679 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_skewedColumnValues14682 = new BitSet(new long[]{0x0000000002001000L,0x00000000010C0000L,0x0000000000000004L,0x0000000000200000L,0x1800000000000000L,0x00C0000000000020L,0x0000000000000004L});
	public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues14684 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_constant_in_skewedColumnValue14728 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValue_in_skewedValueLocationElement14762 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement14771 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NULLS_in_nullOrdering14825 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
	public static final BitSet FOLLOW_KW_FIRST_in_nullOrdering14827 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NULLS_in_nullOrdering14841 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000000000L});
	public static final BitSet FOLLOW_KW_LAST_in_nullOrdering14843 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_columnNameOrder14876 = new BitSet(new long[]{0x0000040000000002L,0x0000001000000000L,0x0000000000000000L,0x0000000000400000L});
	public static final BitSet FOLLOW_orderSpecification_in_columnNameOrder14880 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
	public static final BitSet FOLLOW_nullOrdering_in_columnNameOrder14885 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList15082 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameCommentList15085 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList15087 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_identifier_in_columnNameComment15127 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_COMMENT_in_columnNameComment15130 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_columnNameComment15134 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ASC_in_orderSpecificationRewrite15182 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DESC_in_orderSpecificationRewrite15196 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_expression_in_columnRefOrder15229 = new BitSet(new long[]{0x0000040000000002L,0x0000001000000000L,0x0000000000000000L,0x0000000000400000L});
	public static final BitSet FOLLOW_orderSpecificationRewrite_in_columnRefOrder15233 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
	public static final BitSet FOLLOW_nullOrdering_in_columnRefOrder15238 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_columnNameType15469 = new BitSet(new long[]{0x1003810000000000L,0x0000400023000000L,0x0000001000000100L,0x0000000000000008L,0x3801802000000000L,0x0000000010000800L});
	public static final BitSet FOLLOW_colType_in_columnNameType15471 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_COMMENT_in_columnNameType15474 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_columnNameType15478 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableConstraint_in_columnNameTypeOrConstraint15574 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_columnNameTypeConstraint_in_columnNameTypeOrConstraint15586 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createForeignKey_in_tableConstraint15617 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createConstraint_in_tableConstraint15629 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_columnNameTypeConstraint15660 = new BitSet(new long[]{0x1003810000000000L,0x0000400023000000L,0x0000001000000100L,0x0000000000000008L,0x3801802000000000L,0x0000000010000800L});
	public static final BitSet FOLLOW_colType_in_columnNameTypeConstraint15662 = new BitSet(new long[]{0x2000000000000002L,0x0000000040000810L,0x0000000000000000L,0x0004000000080000L,0x0000000000000001L,0x0000000000001000L});
	public static final BitSet FOLLOW_columnConstraint_in_columnNameTypeConstraint15664 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_COMMENT_in_columnNameTypeConstraint15669 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_columnNameTypeConstraint15673 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_foreignKeyConstraint_in_columnConstraint15737 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_colConstraint_in_columnConstraint15750 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_foreignKeyConstraint15781 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_foreignKeyConstraint15785 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_REFERENCES_in_foreignKeyConstraint15789 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_foreignKeyConstraint15793 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_foreignKeyConstraint15795 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnName_in_foreignKeyConstraint15799 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_foreignKeyConstraint15801 = new BitSet(new long[]{0x0000000000000002L,0x0050020000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_constraintOptsCreate_in_foreignKeyConstraint15803 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_colConstraint15911 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_colConstraint15915 = new BitSet(new long[]{0x2000000000000000L,0x0000000040000000L,0x0000000000000000L,0x0004000000080000L,0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_columnConstraintType_in_colConstraint15919 = new BitSet(new long[]{0x0000000000000002L,0x0050020000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_constraintOptsCreate_in_colConstraint15921 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterForeignKeyConstraint_in_alterColumnConstraint15999 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterColConstraint_in_alterColumnConstraint16012 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterForeignKeyConstraint16043 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_alterForeignKeyConstraint16047 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_REFERENCES_in_alterForeignKeyConstraint16051 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_alterForeignKeyConstraint16055 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_alterForeignKeyConstraint16057 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnName_in_alterForeignKeyConstraint16061 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_alterForeignKeyConstraint16063 = new BitSet(new long[]{0x0000000000000002L,0x0050020000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_constraintOptsAlter_in_alterForeignKeyConstraint16065 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterColConstraint16173 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_alterColConstraint16177 = new BitSet(new long[]{0x2000000000000000L,0x0000000040000000L,0x0000000000000000L,0x0004000000080000L,0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_columnConstraintType_in_alterColConstraint16181 = new BitSet(new long[]{0x0000000000000002L,0x0050020000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_constraintOptsAlter_in_alterColConstraint16183 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_columnConstraintType16248 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_NULL_in_columnConstraintType16250 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DEFAULT_in_columnConstraintType16271 = new BitSet(new long[]{0xEEDBB58AFF001000L,0x74D6FBDDDFAC33DBL,0xF747EE176748C1F4L,0x75E87BB61976DAFDL,0xB9D3FBFF7BC32FFCL,0x00C00F93EB9BCAA7L,0x0000010000000004L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_defaultVal_in_columnConstraintType16273 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_checkConstraint_in_columnConstraintType16291 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableConstraintType_in_columnConstraintType16299 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_constant_in_defaultVal16316 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_function_in_defaultVal16324 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_castExpression_in_defaultVal16332 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_PRIMARY_in_tableConstraintType16349 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_KW_KEY_in_tableConstraintType16351 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNIQUE_in_tableConstraintType16369 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_enableValidateSpecification_in_constraintOptsCreate16404 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L,0x0000000000000008L});
	public static final BitSet FOLLOW_relySpecification_in_constraintOptsCreate16406 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_enableValidateSpecification_in_constraintOptsAlter16424 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L,0x0000000000000008L});
	public static final BitSet FOLLOW_relySpecification_in_constraintOptsAlter16426 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_columnNameColonType16456 = new BitSet(new long[]{0x0000000000000100L});
	public static final BitSet FOLLOW_COLON_in_columnNameColonType16458 = new BitSet(new long[]{0x1003810000000000L,0x0000400023000000L,0x0000001000000100L,0x0000000000000008L,0x3801802000000000L,0x0000000010000800L});
	public static final BitSet FOLLOW_colType_in_columnNameColonType16460 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_COMMENT_in_columnNameColonType16463 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_columnNameColonType16467 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_type_in_colType16551 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_colType_in_colTypeList16578 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_colTypeList16581 = new BitSet(new long[]{0x1003810000000000L,0x0000400023000000L,0x0000001000000100L,0x0000000000000008L,0x3801802000000000L,0x0000000010000800L});
	public static final BitSet FOLLOW_colType_in_colTypeList16583 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_primitiveType_in_type16611 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_listType_in_type16619 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_structType_in_type16627 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_mapType_in_type16635 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_unionType_in_type16643 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TINYINT_in_primitiveType16665 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SMALLINT_in_primitiveType16686 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INT_in_primitiveType16706 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_BIGINT_in_primitiveType16731 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_BOOLEAN_in_primitiveType16753 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FLOAT_in_primitiveType16774 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DOUBLE_in_primitiveType16797 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_KW_PRECISION_in_primitiveType16799 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DATE_in_primitiveType16821 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DATETIME_in_primitiveType16845 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TIMESTAMP_in_primitiveType16865 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TIMESTAMPLOCALTZ_in_primitiveType16884 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TIMESTAMP_in_primitiveType16906 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_primitiveType16908 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
	public static final BitSet FOLLOW_KW_LOCAL_in_primitiveType16910 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TIME_in_primitiveType16912 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000080000000000L});
	public static final BitSet FOLLOW_KW_ZONE_in_primitiveType16914 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STRING_in_primitiveType16946 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_BINARY_in_primitiveType16968 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DECIMAL_in_primitiveType16990 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_primitiveType16993 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_primitiveType16997 = new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_COMMA_in_primitiveType17000 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_primitiveType17004 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_primitiveType17008 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_VARCHAR_in_primitiveType17032 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_primitiveType17034 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_primitiveType17038 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_primitiveType17040 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CHAR_in_primitiveType17065 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_primitiveType17067 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_primitiveType17071 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_primitiveType17073 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ARRAY_in_listType17117 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_LESSTHAN_in_listType17119 = new BitSet(new long[]{0x1003810000000000L,0x0000400023000000L,0x0000001000000100L,0x0000000000000008L,0x3801802000000000L,0x0000000010000800L});
	public static final BitSet FOLLOW_type_in_listType17121 = new BitSet(new long[]{0x0000000000200000L});
	public static final BitSet FOLLOW_GREATERTHAN_in_listType17123 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STRUCT_in_structType17160 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_LESSTHAN_in_structType17162 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameColonTypeList_in_structType17164 = new BitSet(new long[]{0x0000000000200000L});
	public static final BitSet FOLLOW_GREATERTHAN_in_structType17166 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MAP_in_mapType17201 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_LESSTHAN_in_mapType17203 = new BitSet(new long[]{0x1003800000000000L,0x0000400023000000L,0x0000001000000100L,0x0000000000000000L,0x3800802000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_primitiveType_in_mapType17207 = new BitSet(new long[]{0x0000000000000200L});
	public static final BitSet FOLLOW_COMMA_in_mapType17209 = new BitSet(new long[]{0x1003810000000000L,0x0000400023000000L,0x0000001000000100L,0x0000000000000008L,0x3801802000000000L,0x0000000010000800L});
	public static final BitSet FOLLOW_type_in_mapType17213 = new BitSet(new long[]{0x0000000000200000L});
	public static final BitSet FOLLOW_GREATERTHAN_in_mapType17215 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNIONTYPE_in_unionType17258 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_LESSTHAN_in_unionType17260 = new BitSet(new long[]{0x1003810000000000L,0x0000400023000000L,0x0000001000000100L,0x0000000000000008L,0x3801802000000000L,0x0000000010000800L});
	public static final BitSet FOLLOW_colTypeList_in_unionType17262 = new BitSet(new long[]{0x0000000000200000L});
	public static final BitSet FOLLOW_GREATERTHAN_in_unionType17264 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNION_in_setOperator17299 = new BitSet(new long[]{0x0000000100000000L});
	public static final BitSet FOLLOW_KW_ALL_in_setOperator17301 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNION_in_setOperator17315 = new BitSet(new long[]{0x0000000000000002L,0x0000040000000000L});
	public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator17317 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INTERSECT_in_setOperator17332 = new BitSet(new long[]{0x0000000100000000L});
	public static final BitSet FOLLOW_KW_ALL_in_setOperator17334 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INTERSECT_in_setOperator17348 = new BitSet(new long[]{0x0000000000000002L,0x0000040000000000L});
	public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator17350 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXCEPT_in_setOperator17365 = new BitSet(new long[]{0x0000000100000000L});
	public static final BitSet FOLLOW_KW_ALL_in_setOperator17367 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXCEPT_in_setOperator17381 = new BitSet(new long[]{0x0000000000000002L,0x0000040000000000L});
	public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator17383 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MINUS_in_setOperator17398 = new BitSet(new long[]{0x0000000100000000L});
	public static final BitSet FOLLOW_KW_ALL_in_setOperator17400 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MINUS_in_setOperator17414 = new BitSet(new long[]{0x0000000000000002L,0x0000040000000000L});
	public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator17416 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_withClause_in_queryStatementExpression17453 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000800010000L,0x8000000000000008L,0x0000000004000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_queryStatementExpressionBody_in_queryStatementExpression17461 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_fromStatement_in_queryStatementExpressionBody17493 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_regularBody_in_queryStatementExpressionBody17501 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WITH_in_withClause17518 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_cteStatement_in_withClause17520 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_withClause17523 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_cteStatement_in_withClause17525 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_identifier_in_cteStatement17551 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_cteStatement17553 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_cteStatement17555 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000800010000L,0x8000000000000008L,0x0000000004000000L,0x0001004000000000L});
	public static final BitSet FOLLOW_queryStatementExpression_in_cteStatement17557 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_cteStatement17559 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_singleFromStatement_in_fromStatement17582 = new BitSet(new long[]{0x0000000000000002L,0x0100000000000000L,0x0000002000000000L,0x0000000000000400L,0x0000000000000000L,0x0000000000000400L});
	public static final BitSet FOLLOW_setOperator_in_fromStatement17594 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_singleFromStatement_in_fromStatement17598 = new BitSet(new long[]{0x0000000000000002L,0x0100000000000000L,0x0000002000000000L,0x0000000000000400L,0x0000000000000000L,0x0000000000000400L});
	public static final BitSet FOLLOW_fromClause_in_singleFromStatement17805 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000800000000L,0x8000000000000008L,0x0000000004000000L});
	public static final BitSet FOLLOW_body_in_singleFromStatement17815 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000800000000L,0x8000000000000008L,0x0000000004000000L});
	public static final BitSet FOLLOW_insertClause_in_regularBody17852 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000008L,0x0000000004000000L,0x0001000004000000L});
	public static final BitSet FOLLOW_selectStatement_in_regularBody17864 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_valuesClause_in_regularBody17889 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_selectStatement_in_regularBody17962 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_selectClause_in_atomSelectStatement17982 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000A10000L,0x0000000000000000L,0x0000000000000000L,0x0000002800000000L});
	public static final BitSet FOLLOW_fromClause_in_atomSelectStatement17989 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000A00000L,0x0000000000000000L,0x0000000000000000L,0x0000002800000000L});
	public static final BitSet FOLLOW_whereClause_in_atomSelectStatement17997 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000A00000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_groupByClause_in_atomSelectStatement18005 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000800000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_havingClause_in_atomSelectStatement18013 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_window_clause_in_atomSelectStatement18021 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_atomSelectStatement18099 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000008L,0x0000000004000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_selectStatement_in_atomSelectStatement18102 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_atomSelectStatement18104 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_atomSelectStatement_in_selectStatement18125 = new BitSet(new long[]{0x4000000000000002L,0x0100080000000000L,0x0100002000000000L,0x0000000040000400L,0x0000008000000000L,0x0000000000000400L});
	public static final BitSet FOLLOW_setOpSelectStatement_in_selectStatement18132 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000040000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_orderByClause_in_selectStatement18141 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_clusterByClause_in_selectStatement18149 = new BitSet(new long[]{0x0000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_distributeByClause_in_selectStatement18157 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0100000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_sortByClause_in_selectStatement18165 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0100000000000000L});
	public static final BitSet FOLLOW_limitClause_in_selectStatement18173 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_setOperator_in_setOpSelectStatement18438 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000008L,0x0000000004000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_atomSelectStatement_in_setOpSelectStatement18442 = new BitSet(new long[]{0x0000000000000002L,0x0100000000000000L,0x0000002000000000L,0x0000000000000400L,0x0000000000000000L,0x0000000000000400L});
	public static final BitSet FOLLOW_withClause_in_selectStatementWithCTE19077 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000008L,0x0000000004000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_selectStatement_in_selectStatementWithCTE19085 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_insertClause_in_body19115 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000008L,0x0000000004000000L});
	public static final BitSet FOLLOW_selectClause_in_body19120 = new BitSet(new long[]{0x4000000000000202L,0x0000080000000000L,0x0108000000A00000L,0x0000000040000000L,0x0000008000000000L,0x0000002800000000L});
	public static final BitSet FOLLOW_lateralView_in_body19125 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000A00000L,0x0000000040000000L,0x0000008000000000L,0x0000002800000000L});
	public static final BitSet FOLLOW_whereClause_in_body19131 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000A00000L,0x0000000040000000L,0x0000008000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_groupByClause_in_body19137 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000800000L,0x0000000040000000L,0x0000008000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_havingClause_in_body19143 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000040000000L,0x0000008000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_window_clause_in_body19149 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000040000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_orderByClause_in_body19155 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_clusterByClause_in_body19161 = new BitSet(new long[]{0x0000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_distributeByClause_in_body19167 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0100000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_sortByClause_in_body19173 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0100000000000000L});
	public static final BitSet FOLLOW_limitClause_in_body19179 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_selectClause_in_body19272 = new BitSet(new long[]{0x4000000000000202L,0x0000080000000000L,0x0108000000A00000L,0x0000000040000000L,0x0000008000000000L,0x0000002800000000L});
	public static final BitSet FOLLOW_lateralView_in_body19277 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000A00000L,0x0000000040000000L,0x0000008000000000L,0x0000002800000000L});
	public static final BitSet FOLLOW_whereClause_in_body19283 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000A00000L,0x0000000040000000L,0x0000008000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_groupByClause_in_body19289 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000800000L,0x0000000040000000L,0x0000008000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_havingClause_in_body19295 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000040000000L,0x0000008000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_window_clause_in_body19301 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000040000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_orderByClause_in_body19307 = new BitSet(new long[]{0x4000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_clusterByClause_in_body19313 = new BitSet(new long[]{0x0000000000000002L,0x0000080000000000L,0x0100000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_distributeByClause_in_body19319 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0100000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_sortByClause_in_body19325 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0100000000000000L});
	public static final BitSet FOLLOW_limitClause_in_body19331 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INSERT_in_insertClause19452 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
	public static final BitSet FOLLOW_KW_OVERWRITE_in_insertClause19454 = new BitSet(new long[]{0x0000000000000000L,0x0000010000000000L,0x0800000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_destination_in_insertClause19456 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000004000000L});
	public static final BitSet FOLLOW_ifNotExists_in_insertClause19458 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INSERT_in_insertClause19477 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_INTO_in_insertClause19479 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1DBFBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_TABLE_in_insertClause19481 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableOrPartition_in_insertClause19484 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_insertClause19487 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnNameList_in_insertClause19491 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_RPAREN_in_insertClause19493 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCAL_in_destination19549 = new BitSet(new long[]{0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_KW_DIRECTORY_in_destination19553 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_destination19555 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000100000L});
	public static final BitSet FOLLOW_tableRowFormat_in_destination19557 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_tableFileFormat_in_destination19560 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TABLE_in_destination19593 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableOrPartition_in_destination19595 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LIMIT_in_limitClause19627 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_limitClause19633 = new BitSet(new long[]{0x0000000000000200L});
	public static final BitSet FOLLOW_COMMA_in_limitClause19635 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_limitClause19641 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LIMIT_in_limitClause19664 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_limitClause19668 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
	public static final BitSet FOLLOW_KW_OFFSET_in_limitClause19670 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_limitClause19674 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DELETE_in_deleteStatement19718 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_FROM_in_deleteStatement19720 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_deleteStatement19722 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
	public static final BitSet FOLLOW_whereClause_in_deleteStatement19725 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableOrColumn_in_columnAssignmentClause19758 = new BitSet(new long[]{0x0000000000040000L});
	public static final BitSet FOLLOW_EQUAL_in_columnAssignmentClause19760 = new BitSet(new long[]{0xEFDBB58AFF001000L,0x74D6FBDDDFAC33DBL,0xF747EE576748C3F6L,0x75E87BB61976DAFDL,0xB9D3FBFF7BC32FFCL,0x01C90F93EB9BCAA7L,0x000001000000000CL,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_precedencePlusExpression_in_columnAssignmentClause19763 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_setColumnsClause19783 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause19785 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_setColumnsClause19788 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause19790 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_KW_UPDATE_in_updateStatement19832 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_updateStatement19834 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_setColumnsClause_in_updateStatement19836 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
	public static final BitSet FOLLOW_whereClause_in_updateStatement19838 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_startTransactionStatement_in_sqlTransactionStatement19880 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_commitStatement_in_sqlTransactionStatement19885 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rollbackStatement_in_sqlTransactionStatement19890 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_setAutoCommitStatement_in_sqlTransactionStatement19895 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_START_in_startTransactionStatement19909 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_TRANSACTION_in_startTransactionStatement19911 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000020000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_transactionMode_in_startTransactionStatement19915 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_startTransactionStatement19920 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000020000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_transactionMode_in_startTransactionStatement19922 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_isolationLevel_in_transactionMode19953 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_transactionAccessMode_in_transactionMode19959 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_READ_in_transactionAccessMode19982 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
	public static final BitSet FOLLOW_KW_ONLY_in_transactionAccessMode19984 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_READ_in_transactionAccessMode19994 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
	public static final BitSet FOLLOW_KW_WRITE_in_transactionAccessMode19996 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ISOLATION_in_isolationLevel20015 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_KW_LEVEL_in_isolationLevel20017 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_levelOfIsolation_in_isolationLevel20019 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SNAPSHOT_in_levelOfIsolation20044 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COMMIT_in_commitStatement20063 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_WORK_in_commitStatement20067 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ROLLBACK_in_rollbackStatement20089 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_WORK_in_rollbackStatement20093 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_setAutoCommitStatement20114 = new BitSet(new long[]{0x0000100000000000L});
	public static final BitSet FOLLOW_KW_AUTOCOMMIT_in_setAutoCommitStatement20116 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
	public static final BitSet FOLLOW_booleanValueTok_in_setAutoCommitStatement20118 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ABORT_in_abortTransactionStatement20153 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_KW_TRANSACTIONS_in_abortTransactionStatement20155 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_Number_in_abortTransactionStatement20159 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_KW_MERGE_in_mergeStatement20205 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000000000L,0x0000000000000000L,0x0000000000000000L,0x0200000000000000L});
	public static final BitSet FOLLOW_QUERY_HINT_in_mergeStatement20207 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_INTO_in_mergeStatement20210 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_tableName_in_mergeStatement20212 = new BitSet(new long[]{0xECD8368AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EBDBCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_AS_in_mergeStatement20215 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1D3FBDF7BC32FFCL,0x00000F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_identifier_in_mergeStatement20218 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
	public static final BitSet FOLLOW_KW_USING_in_mergeStatement20222 = new BitSet(new long[]{0xECD8348AFD000000L,0x74D6BBDDDEA033DBL,0xF747EE076308C0F0L,0x75E87BB61956DAF5L,0xA1DBFBDF7BC32FFCL,0x00010F93EB9BCA87L,0x0000010000000000L,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_joinSourcePart_in_mergeStatement20224 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_ON_in_mergeStatement20226 = new BitSet(new long[]{0xEFDBB58AFF001000L,0x7CD6FBDDDFAC33DBL,0xF747EE576748C3F6L,0x75E87BB6197EDAFDL,0xB9D3FBFF7BC32FFCL,0x01C90F93EB9BCAA7L,0x000001000000000CL,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_expression_in_mergeStatement20228 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_whenClauses_in_mergeStatement20230 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_whenMatchedAndClause_in_whenClauses20279 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_whenMatchedThenClause_in_whenClauses20281 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_whenNotMatchedClause_in_whenClauses20285 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WHEN_in_whenNotMatchedClause20312 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_KW_NOT_in_whenNotMatchedClause20314 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
	public static final BitSet FOLLOW_KW_MATCHED_in_whenNotMatchedClause20316 = new BitSet(new long[]{0x0000001000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0200000000000000L});
	public static final BitSet FOLLOW_KW_AND_in_whenNotMatchedClause20319 = new BitSet(new long[]{0xEFDBB58AFF001000L,0x7CD6FBDDDFAC33DBL,0xF747EE576748C3F6L,0x75E87BB6197EDAFDL,0xB9D3FBFF7BC32FFCL,0x01C90F93EB9BCAA7L,0x000001000000000CL,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_expression_in_whenNotMatchedClause20321 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0200000000000000L});
	public static final BitSet FOLLOW_KW_THEN_in_whenNotMatchedClause20325 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_INSERT_in_whenNotMatchedClause20327 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000004000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_whenNotMatchedClause20332 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
	public static final BitSet FOLLOW_KW_VALUES_in_whenNotMatchedClause20336 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_valueRowConstructor_in_whenNotMatchedClause20338 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WHEN_in_whenMatchedAndClause20385 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
	public static final BitSet FOLLOW_KW_MATCHED_in_whenMatchedAndClause20387 = new BitSet(new long[]{0x0000001000000000L});
	public static final BitSet FOLLOW_KW_AND_in_whenMatchedAndClause20389 = new BitSet(new long[]{0xEFDBB58AFF001000L,0x7CD6FBDDDFAC33DBL,0xF747EE576748C3F6L,0x75E87BB6197EDAFDL,0xB9D3FBFF7BC32FFCL,0x01C90F93EB9BCAA7L,0x000001000000000CL,0x0000000000008000L,0x0110000000000011L,0x0000000002040000L,0x0000000000200000L});
	public static final BitSet FOLLOW_expression_in_whenMatchedAndClause20391 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0200000000000000L});
	public static final BitSet FOLLOW_KW_THEN_in_whenMatchedAndClause20393 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
	public static final BitSet FOLLOW_updateOrDelete_in_whenMatchedAndClause20395 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WHEN_in_whenMatchedThenClause20433 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
	public static final BitSet FOLLOW_KW_MATCHED_in_whenMatchedThenClause20435 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0200000000000000L});
	public static final BitSet FOLLOW_KW_THEN_in_whenMatchedThenClause20437 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
	public static final BitSet FOLLOW_updateOrDelete_in_whenMatchedThenClause20439 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_updateOrDelete20468 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_setColumnsClause_in_updateOrDelete20470 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DELETE_in_updateOrDelete20488 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_KILL_in_killQueryStatement20520 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_QUERY_in_killQueryStatement20522 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_StringLiteral_in_killQueryStatement20526 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_grantPrivileges_in_synpred1_HiveParser2941 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_revokePrivileges_in_synpred2_HiveParser2955 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixRename_in_synpred3_HiveParser4487 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ELEM_TYPE_in_synpred4_HiveParser7331 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_KEY_TYPE_in_synpred5_HiveParser7348 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_VALUE_TYPE_in_synpred6_HiveParser7365 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FUNCTION_in_synpred8_HiveParser7573 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COMPUTE_in_synpred10_HiveParser7726 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CACHE_in_synpred11_HiveParser7854 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALL_in_synpred14_HiveParser9448 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NONE_in_synpred15_HiveParser9479 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALL_in_synpred16_HiveParser9653 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_storedAsDirs_in_synpred17_HiveParser12291 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STORED_in_synpred18_HiveParser13272 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_synpred18_HiveParser13274 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_KW_INPUTFORMAT_in_synpred18_HiveParser13276 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ELEM_TYPE_in_synpred19_HiveParser13714 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_KEY_TYPE_in_synpred20_HiveParser13724 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_VALUE_TYPE_in_synpred21_HiveParser13734 = new BitSet(new long[]{0x0000000000000002L});
}
